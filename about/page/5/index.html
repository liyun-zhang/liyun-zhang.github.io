<!DOCTYPE html>
<html lang="zh-Hans">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222" media="(prefers-color-scheme: light)">
<meta name="theme-color" content="#222" media="(prefers-color-scheme: dark)"><meta name="generator" content="Hexo 6.3.0">

  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">



<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css" integrity="sha256-HtsXJanqjKTc8vVQjO4YMhiqFoXkfBsjBWcX91T1jr8=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/animate.css/3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">

<script class="next-config" data-name="main" type="application/json">{"hostname":"liyun-zhang.github.io","root":"/","images":"/images","scheme":"Mist","darkmode":true,"version":"8.17.0","exturl":false,"sidebar":{"position":"right","display":"hide","padding":18,"offset":12},"copycode":{"enable":false,"style":null},"bookmark":{"enable":false,"color":"#222","save":"auto"},"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"stickytabs":false,"motion":{"enable":true,"async":false,"transition":{"menu_item":"fadeInDown","post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"prism":false,"i18n":{"placeholder":"Searching...","empty":"We didn't find any results for the search: ${query}","hits_time":"${hits} results found in ${time} ms","hits":"${hits} results found"},"path":"/search.xml","localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false}}</script><script src="/js/config.js"></script>

    <meta property="og:type" content="website">
<meta property="og:title" content="LiyunZhang">
<meta property="og:url" content="http://liyun-zhang.github.io/about/page/5/index.html">
<meta property="og:site_name" content="LiyunZhang">
<meta property="og:locale">
<meta property="article:author" content="LiyunZhang">
<meta name="twitter:card" content="summary">


<link rel="canonical" href="http://liyun-zhang.github.io/about/page/5/">



<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":true,"isPost":false,"lang":"zh-Hans","comments":"","permalink":"","path":"about/page/5/index.html","title":""}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>LiyunZhang</title>
  








  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
</head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <div class="column">
      <header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar" role="button">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <h1 class="site-title">LiyunZhang</h1>
      <i class="logo-line"></i>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger" aria-label="Search" role="button">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i>Home</a></li><li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>Tags</a></li><li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>Categories</a></li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>Search
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup"><div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off" maxlength="80"
           placeholder="Searching..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close" role="button">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div class="search-result-container no-result">
  <div class="search-result-icon">
    <i class="fa fa-spinner fa-pulse fa-5x"></i>
  </div>
</div>
    </div>
  </div>

</header>
        
  
  <aside class="sidebar">

    <div class="sidebar-inner sidebar-overview-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">LiyunZhang</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/archives/">
          <span class="site-state-item-count">62</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
          <a href="/categories/">
        <span class="site-state-item-count">10</span>
        <span class="site-state-item-name">categories</span></a>
      </div>
      <div class="site-state-item site-state-tags">
          <a href="/tags/">
        <span class="site-state-item-count">29</span>
        <span class="site-state-item-name">tags</span></a>
      </div>
  </nav>
</div>

        </div>
      </div>
    </div>

    
  </aside>


    </div>

    <div class="main-inner index posts-expand">

    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://liyun-zhang.github.io/2023/06/24/Courses/15445/03-Buffer-Pool-Manage/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="LiyunZhang">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="LiyunZhang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | LiyunZhang">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2023/06/24/Courses/15445/03-Buffer-Pool-Manage/" class="post-title-link" itemprop="url">03 Buffer Pool Manage</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2023-06-24 17:12:13" itemprop="dateCreated datePublished" datetime="2023-06-24T17:12:13+08:00">2023-06-24</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">Edited on</span>
      <time title="Modified: 2024-03-16 13:58:29" itemprop="dateModified" datetime="2024-03-16T13:58:29+08:00">2024-03-16</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">In</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Open-Courses/" itemprop="url" rel="index"><span itemprop="name">Open Courses</span></a>
        </span>
          , 
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Open-Courses/CMU-15-445-645-Database-System/" itemprop="url" rel="index"><span itemprop="name">CMU 15-445/645 Database System</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p><ul class="markdownIt-TOC">
<li><a href="#buffer-pool-manage">Buffer pool manage</a>
<ul>
<li><a href="#what-does-the-databse-storage-need-to-control">What does the databse storage need to control?</a></li>
<li><a href="#how-is-the-buffer-pool-organized">How is the buffer pool organized?</a></li>
<li><a href="#clarification-what-are-the-locks-and-latches-referenced-in-the-database">Clarification: What are the locks and latches referenced in the database?</a></li>
<li><a href="#how-can-we-optimize-performance-with-multiple-buffer-pools">How can we optimize performance with multiple buffer pools?</a></li>
<li><a href="#how-can-we-optimize-performance-with-pre-fetching">How can we optimize performance with pre-fetching?</a></li>
<li><a href="#how-can-we-optimize-performance-with-scan-sharing">How can we optimize performance with scan sharing?</a></li>
<li><a href="#how-can-we-optimize-performance-with-buffer-pool-bypass">How can we optimize performance with buffer pool bypass?</a></li>
<li><a href="#should-we-use-the-os-page-cache">Should we use the OS page cache?</a></li>
</ul>
</li>
<li><a href="#buffer-replacement-policies">Buffer replacement policies</a>
<ul>
<li><a href="#what-is-the-lru-least-recently-used-policy-and-clock-policy">What is the LRU (Least-Recently Used) policy and clock policy?</a></li>
<li><a href="#what-is-the-problem-with-lru-and-the-clock-and-how-can-it-be-alleviated">What is the problem with LRU and the clock, and how can it be alleviated?</a></li>
<li><a href="#how-do-we-deal-with-evicted-pages">How do we deal with evicted pages?</a></li>
</ul>
</li>
</ul>
</p>
<h1 id="buffer-pool-manage"><a class="markdownIt-Anchor" href="#buffer-pool-manage"></a> Buffer pool manage</h1>
<h2 id="what-does-the-databse-storage-need-to-control"><a class="markdownIt-Anchor" href="#what-does-the-databse-storage-need-to-control"></a> What does the databse storage need to control?</h2>
<ol>
<li>Spatial Control: Where to write pages on disk.
<ul>
<li>The goal is to keep pages that are used together often as physically close together as possible on disk.</li>
</ul>
</li>
<li>Temporal Control: When to read pages into memory and write them to disk.
<ul>
<li>The goal is to minimize the number of stalls from having to read data from a disk.</li>
</ul>
</li>
</ol>
<h2 id="how-is-the-buffer-pool-organized"><a class="markdownIt-Anchor" href="#how-is-the-buffer-pool-organized"></a> How is the buffer pool organized?</h2>
<ol>
<li>The memory region is organized as an array of fixed-size pages. An array entry is called a <strong>frame</strong>.
<ul>
<li>Pages are on disk, while frames are on memory.</li>
</ul>
</li>
<li>When the DBMS requests a page, an exact copy is placed into one of these frames.</li>
<li>The buffer pool manager needs to maintain a <strong>page table</strong> to track pages currently in memory.
<ul>
<li>The page table maps from page IDs to a copy of the page in buffer pool frames.
<ul>
<li>This in-memory data structure does not need to be stored on disk.</li>
</ul>
</li>
<li>The page directory maps from page IDs to page locations in the database files.
<ul>
<li>All changes must be recorded on disk to allow the DBMS to find on restart.</li>
</ul>
</li>
</ul>
</li>
<li>Some additional meta-data per page also need to be maintained:
<ul>
<li><strong>Dirty flag</strong>: Mark whether a page has been modified to show whether can safely evict this page.</li>
<li><strong>Pin/reference counter</strong>: Some queries use it to prevent the buffer pool manager from evicting this page. They unpinned this page after no longer using it.</li>
<li><strong>Latches</strong>: This can be used to pre-occupy an entry in the page table and release the latch after copying that page and updating the entry.</li>
<li>These meta-data can either be stored in a page or page table.</li>
</ul>
</li>
</ol>
<h2 id="clarification-what-are-the-locks-and-latches-referenced-in-the-database"><a class="markdownIt-Anchor" href="#clarification-what-are-the-locks-and-latches-referenced-in-the-database"></a> Clarification: What are the locks and latches referenced in the database?</h2>
<ol>
<li>Locks:
<ul>
<li>It protects the database’s logical contents from other transactions.</li>
<li>It is held for transaction duration. Need to be able to rollback changes.</li>
<li>Locks can be taken on a tuple or table but not on a page.</li>
</ul>
</li>
<li>Latches:
<ul>
<li>It protects the critical sections of the DBMS’s internal data structure from other threads.</li>
<li>It is held for operation duration. Do not need to be able to rollback changes.</li>
<li>This is similar to the mutex provided by OS.</li>
</ul>
</li>
</ol>
<h2 id="how-can-we-optimize-performance-with-multiple-buffer-pools"><a class="markdownIt-Anchor" href="#how-can-we-optimize-performance-with-multiple-buffer-pools"></a> How can we optimize performance with multiple buffer pools?</h2>
<ol>
<li>Advantages:
<ul>
<li>The different pools can have different eviction policies to improve locality.</li>
<li>Each time accessing the meta-data of each buffer pool needs to take a latch. Multiple buffer pools can reduce latch contention.</li>
</ul>
</li>
<li>The manager can use a per-database buffer pool, per-page type buffer pool, or per-index type buffer pool.</li>
<li>Managers decide which pool to store pages in two approaches:
<ul>
<li>The first is to embed an object identifier in record IDs and then maintain a mapping from objects to specific buffer pools.
<ul>
<li>This can be used to specify certain pages must be stored in a specific pool.</li>
</ul>
</li>
<li>The other is to hash the page ID to select which buffer pool to access.</li>
</ul>
</li>
</ol>
<h2 id="how-can-we-optimize-performance-with-pre-fetching"><a class="markdownIt-Anchor" href="#how-can-we-optimize-performance-with-pre-fetching"></a> How can we optimize performance with pre-fetching?</h2>
<ol>
<li>Pre-fetching can be easily used in two situations: sequential scans and index scans.</li>
<li>In sequential scans, when the manager fetches the first few consecutive pages, it can be inferred that the following consecutive pages will be used soon and pre-fetched into memory.</li>
<li>The query may not access consecutive pages in index scans, but DBMS sees the B+ tree structure and thus knows where the following indices are.</li>
</ol>
<h2 id="how-can-we-optimize-performance-with-scan-sharing"><a class="markdownIt-Anchor" href="#how-can-we-optimize-performance-with-scan-sharing"></a> How can we optimize performance with scan sharing?</h2>
<ol>
<li>It allows multiple queries to attach to a single cursor that scans a table.
<ul>
<li>The queries do not have to be the same.</li>
<li>They can also share intermediate results.</li>
</ul>
</li>
<li>If a query wants to scan a table and another query is already doing this, the DBMS will attach the second query’s cursor to the existing cursor.</li>
<li>After the earlier query is finished, the later query will return to read the pages the earlier one already read before the later one begins.</li>
<li>If the later query has a <code>LIMIT</code> clause without WHERE or ORDER BY clause, given that the relation is unordered, it may not need to read extra data if those scan-sharing data are enough to satisfy the <code>LIMIT</code> clause.</li>
</ol>
<h2 id="how-can-we-optimize-performance-with-buffer-pool-bypass"><a class="markdownIt-Anchor" href="#how-can-we-optimize-performance-with-buffer-pool-bypass"></a> How can we optimize performance with buffer pool bypass?</h2>
<ol>
<li>Sequential flooding: A query performs a sequential scan that reads every page.
<ul>
<li>This pollutes the buffer pool with pages that are read once and never again.</li>
</ul>
</li>
<li>Buffer pool bypass will not store fetched pages in the buffer pool. Insteach, the manager has a private pool where those pages will be stored temporarily and deleted once finished.</li>
<li>It works well if the operator needs to read a large sequence of contiguous pages on disk. It can also be used for temporary data (sorting, joins).</li>
</ol>
<h2 id="should-we-use-the-os-page-cache"><a class="markdownIt-Anchor" href="#should-we-use-the-os-page-cache"></a> Should we use the OS page cache?</h2>
<ol>
<li>Most disk operations go through the OS API. Unless the DBMS tells it not to, the OS maintains its filesystem cache.</li>
<li>Most DBMSs bypass the OS’s cache by using direct I/O (O_DIRECT).</li>
<li>The OS page cache can cause redundant copies of pages. OS and DBMS have different eviction policies, causing DBMS to lose control over file I/O.</li>
</ol>
<h1 id="buffer-replacement-policies"><a class="markdownIt-Anchor" href="#buffer-replacement-policies"></a> Buffer replacement policies</h1>
<h2 id="what-is-the-lru-least-recently-used-policy-and-clock-policy"><a class="markdownIt-Anchor" href="#what-is-the-lru-least-recently-used-policy-and-clock-policy"></a> What is the LRU (Least-Recently Used) policy and clock policy?</h2>
<ol>
<li>Managers maintain a single timestamp of when each page was last accessed.</li>
<li>When the DBMS needs to evict a page, select the one with the oldest timestamp.
<ul>
<li>It can keep the pages in sorted order to reduce the search time on eviction.</li>
</ul>
</li>
<li>An approximation of LRU that does not need a separate timestamp per page is the clock policy.
<ul>
<li>Each page has a reference bit. When a page is accessed, set it to <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1</mn></mrow><annotation encoding="application/x-tex">1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">1</span></span></span></span>.</li>
<li>Organize the pages in a circular buffer with a “clock hand.”: Upon sweeping, check if a page’s bit is set<br />
to 1. If yes, set it to zero. If no, then evict.</li>
</ul>
</li>
</ol>
<h2 id="what-is-the-problem-with-lru-and-the-clock-and-how-can-it-be-alleviated"><a class="markdownIt-Anchor" href="#what-is-the-problem-with-lru-and-the-clock-and-how-can-it-be-alleviated"></a> What is the problem with LRU and the clock, and how can it be alleviated?</h2>
<ol>
<li>LRU and CLOCK replacement policies are susceptible to sequential flooding. In some workloads, the most recently used page is the most unneeded.</li>
<li><strong>LRU-K</strong> policy can alleviate the problem.
<ul>
<li>Track the history of the last K references to each page as timestamps and compute the average interval between subsequent accesses. And evict the one that will be accessed at the latest, according to the prediction.</li>
<li>In the implementation, the manager only needs to maintain a queue of size K. Pop out the oldest timestamp when a new timestamp arrives.</li>
</ul>
</li>
<li>Another policy is <strong>localization</strong>: The DBMS chooses which pages to evict on a per transaction/query basis, e.g., it allocates private frames to the query.</li>
<li><strong>Priority hints</strong>: The DBMS knows about the context of each page during query execution. It can provide hints to the buffer pool on whether a page is important.</li>
</ol>
<h2 id="how-do-we-deal-with-evicted-pages"><a class="markdownIt-Anchor" href="#how-do-we-deal-with-evicted-pages"></a> How do we deal with evicted pages?</h2>
<ol>
<li>Fast Path: If a page in the buffer pool is not dirty, the DBMS can drop it.</li>
<li>Slow Path: If a page is dirty, the DBMS must write back to disk to ensure its changes persist.
<ul>
<li>The DBMS can periodically walk through the page table and write dirty pages to disk.</li>
<li>When a dirty page is safely written, the DBMS can either evict the page or just unset the dirty flag.</li>
<li>Need to be careful that the system doesn’t write dirty pages before their log records are written.</li>
</ul>
</li>
<li>The Trade-off is between fast evictions versus dirty writing pages that will not be read again.</li>
</ol>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://liyun-zhang.github.io/2023/06/24/Courses/15445/02-Storage/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="LiyunZhang">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="LiyunZhang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | LiyunZhang">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2023/06/24/Courses/15445/02-Storage/" class="post-title-link" itemprop="url">02 Storage</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2023-06-24 17:10:07" itemprop="dateCreated datePublished" datetime="2023-06-24T17:10:07+08:00">2023-06-24</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">Edited on</span>
      <time title="Modified: 2024-03-16 12:28:09" itemprop="dateModified" datetime="2024-03-16T12:28:09+08:00">2024-03-16</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">In</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Open-Courses/" itemprop="url" rel="index"><span itemprop="name">Open Courses</span></a>
        </span>
          , 
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Open-Courses/CMU-15-445-645-Database-System/" itemprop="url" rel="index"><span itemprop="name">CMU 15-445/645 Database System</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p><ul class="markdownIt-TOC">
<li><a href="#disk-based-architecture">Disk-based architecture</a>
<ul>
<li><a href="#what-are-the-storage-devices">What are the storage devices?</a></li>
<li><a href="#what-is-disk-oriented-dmbs">What is disk-oriented DMBS?</a></li>
<li><a href="#why-not-use-the-os-memory-mapping-virtual-memory">Why not use the OS memory mapping (virtual memory)?</a></li>
</ul>
</li>
<li><a href="#page-oriented-architecture">Page-oriented architecture</a>
<ul>
<li><a href="#file-storage">File storage</a>
<ul>
<li><a href="#how-does-dbms-store-files">How does DBMS store files?</a></li>
<li><a href="#how-does-dbms-manage-pages-in-files-on-disk">How does DBMS manage pages in files on disk?</a></li>
</ul>
</li>
<li><a href="#page-layout">Page layout</a>
<ul>
<li><a href="#what-is-stored-on-each-page">What is stored on each page?</a></li>
<li><a href="#how-to-organize-tuple-oriented-data">How to organize tuple-oriented data?</a></li>
<li><a href="#how-do-we-find-the-tuple-we-need-on-a-page">How do we find the tuple we need on a page?</a></li>
</ul>
</li>
<li><a href="#tuple-layout">Tuple layout</a>
<ul>
<li><a href="#what-is-stored-in-a-tuple">What is stored in a tuple?</a></li>
<li><a href="#what-is-denormalized-data">What is denormalized data?</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#log-structured-storage">Log-structured storage</a>
<ul>
<li><a href="#what-is-stored-in-log-structured-storage">What is stored in log-structured storage?</a></li>
<li><a href="#how-to-read-in-a-log-structured-storage">How to read in a log-structured storage?</a></li>
<li><a href="#how-to-solve-that-the-log-will-become-larger-and-larger">How to solve that the log will become larger and larger?</a></li>
</ul>
</li>
<li><a href="#tuple-storage">Tuple storage</a>
<ul>
<li><a href="#how-to-store-data-in-a-tuple">How to store data in a tuple?</a></li>
<li><a href="#what-are-supported-data-types">What are supported data types?</a></li>
</ul>
</li>
<li><a href="#data-storage-models">Data storage models</a>
<ul>
<li><a href="#what-kind-of-database-workloads-are-there">What kind of database workloads are there?</a></li>
<li><a href="#how-does-dbms-store-tuples">How does DBMS store tuples?</a></li>
<li><a href="#database-compression">Database compression</a>
<ul>
<li><a href="#why-do-we-need-database-compression-and-what-is-the-trade-off">Why do we need database compression, and what is the trade-off?</a></li>
<li><a href="#why-can-we-compress-data">Why can we compress data?</a></li>
<li><a href="#what-are-the-goals-of-compression">What are the goals of compression?</a></li>
<li><a href="#what-are-the-compression-granularities">What are the compression granularities?</a></li>
<li><a href="#what-is-naive-compression">What is naive compression?</a></li>
<li><a href="#how-can-we-do-better-with-the-high-level-meaning-or-semantics-of-the-data">How can we do better with the high-level meaning or semantics of the data?</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</p>
<h1 id="disk-based-architecture"><a class="markdownIt-Anchor" href="#disk-based-architecture"></a> Disk-based architecture</h1>
<h2 id="what-are-the-storage-devices"><a class="markdownIt-Anchor" href="#what-are-the-storage-devices"></a> What are the storage devices?</h2>
<ol>
<li>The first type is volatile memory: CPU registers, CPU caches, and DRAM.
<ul>
<li>They provide random access, and they are byte-addressable.</li>
</ul>
</li>
<li>The second type is the non-volatile disks: SSD, HDD, and network storage.
<ul>
<li>They only provide sequential access.
<ul>
<li>Random access on non-volatile storage is almost always much slower than sequential access.</li>
<li>DBMS will want to maximize sequential access.</li>
</ul>
</li>
<li>They are block-addressable.</li>
</ul>
</li>
<li>The access times of each storage are as follows:<br />
<img src="/imgs/15445/Storage/access_times.png" width="50%"></li>
</ol>
<h2 id="what-is-disk-oriented-dmbs"><a class="markdownIt-Anchor" href="#what-is-disk-oriented-dmbs"></a> What is disk-oriented DMBS?</h2>
<ol>
<li>The DBMS assumes that the primary storage location of the database is on a non-volatile disk.</li>
<li>DBMS manages a buffer pool in memory where directory and data pages are stored.</li>
<li>When the execution engine asks DBMS for a certain page:
<ul>
<li>If that page is not in memory already, DBMS will look up the directory first (if also not in memory, load from disk) to find the disk position of that page.</li>
<li>Then, DBMS will load that page from the disk and return a pointer to the buffer pool to the execution engine.</li>
</ul>
</li>
</ol>
<h2 id="why-not-use-the-os-memory-mapping-virtual-memory"><a class="markdownIt-Anchor" href="#why-not-use-the-os-memory-mapping-virtual-memory"></a> Why not use the OS memory mapping (virtual memory)?</h2>
<ol>
<li>Transaction safety: OS can flush dirty pages at any time, causing dirty data to corrupt the database. OS doesn’t know anything about transactions. Hence, it doesn’t care whether writing a page to disk is safe.</li>
<li>IO stalls: When a page miss happens, the thread will be stalled, and DBMS can do nothing about it.
<ul>
<li>Allowing multiple threads to access the <code>mmap</code> files to hide page fault stalls is good enough for read-only access. But it is complicated when there are multiple writers.</li>
</ul>
</li>
<li>Error handling: Any access can cause a <code>SIGBUS</code> that the DBMS must handle. However, DBMS may isolate and handle the error only in the storage layer.</li>
<li>Performance issues: Like OS data structure contention or TLB shootdowns.</li>
<li>In conclusion, DBMS always knows better than OS. Thus, DBMS almost always wants to control things and can do a better job than the OS.
<ul>
<li>Like how to flush dirty pages to disk in the correct order, provide specialized prefetching, better buffer replacement policy, and thread/process scheduling.</li>
</ul>
</li>
</ol>
<h1 id="page-oriented-architecture"><a class="markdownIt-Anchor" href="#page-oriented-architecture"></a> Page-oriented architecture</h1>
<h2 id="file-storage"><a class="markdownIt-Anchor" href="#file-storage"></a> File storage</h2>
<h3 id="how-does-dbms-store-files"><a class="markdownIt-Anchor" href="#how-does-dbms-store-files"></a> How does DBMS store files?</h3>
<ol>
<li>The DBMS stores a database as one or more files on disk, typically in a proprietary format.</li>
<li>The storage manager is responsible for maintaining a database’s files.
<ul>
<li>It organizes the files as a collection of pages.</li>
<li>It also tracks data read/written to pages and the available space.</li>
<li>Some do their scheduling for reads and writes to improve pages’ spatial and temporal locality.</li>
</ul>
</li>
<li>A database page is a fixed-size block of data.
<ul>
<li>Most systems do not mix page types, i.e., data on a page belong to the same table.</li>
<li>Some systems require a page to be self-contained, i.e., all metadata we need to interpret the page has to be contained in the page.</li>
<li>Hardware pages and OS pages are usually <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>4</mn><mtext> </mtext><mi>K</mi><mi>B</mi></mrow><annotation encoding="application/x-tex">4\ KB</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord">4</span><span class="mspace"> </span><span class="mord mathnormal" style="margin-right:0.07153em;">K</span><span class="mord mathnormal" style="margin-right:0.05017em;">B</span></span></span></span>. But database pages may be <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>512</mn><mtext> </mtext><mi>B</mi><mo>−</mo><mn>16</mn><mtext> </mtext><mi>K</mi><mi>B</mi></mrow><annotation encoding="application/x-tex">512\ B-16\ KB</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.76666em;vertical-align:-0.08333em;"></span><span class="mord">5</span><span class="mord">1</span><span class="mord">2</span><span class="mspace"> </span><span class="mord mathnormal" style="margin-right:0.05017em;">B</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord">1</span><span class="mord">6</span><span class="mspace"> </span><span class="mord mathnormal" style="margin-right:0.07153em;">K</span><span class="mord mathnormal" style="margin-right:0.05017em;">B</span></span></span></span> depending on DBMS and configuration.
<ul>
<li>A larger page size can increase sequential IO, issue fewer system calls, and have a smaller page table.</li>
<li>Smaller page sizes only need to maintain less memory when only a small amount of data is needed.</li>
</ul>
</li>
</ul>
</li>
</ol>
<h3 id="how-does-dbms-manage-pages-in-files-on-disk"><a class="markdownIt-Anchor" href="#how-does-dbms-manage-pages-in-files-on-disk"></a> How does DBMS manage pages in files on disk?</h3>
<ol>
<li>There are different ways to manage: Heap File Organization, Tree File Organization, Sequential / Sorted File Organization (ISAM), or Hashing File Organization.</li>
<li>A heap file is an unordered collection of pages with tuples stored in random order.</li>
<li>The DBMS maintains a directory in special pages that track the location of data pages in the database files.
<ul>
<li>Ensure that the directory pages are in sync with the data pages.</li>
<li>The directory also records meta-data about available space: the number of free slots per page and the list of free/empty pages.</li>
</ul>
</li>
</ol>
<h2 id="page-layout"><a class="markdownIt-Anchor" href="#page-layout"></a> Page layout</h2>
<h3 id="what-is-stored-on-each-page"><a class="markdownIt-Anchor" href="#what-is-stored-on-each-page"></a> What is stored on each page?</h3>
<ol>
<li>Every page contains a header of meta-data about the page’s contents.
<ul>
<li>Page Size</li>
<li>Checksum to check whether data is corrupted.</li>
<li>The DBMS version of the creator of this page is used to provide compatibility even when the DBMS update changes the page layout. With this, the data can be corrected and re-layout when the DBMS is updated.</li>
<li>Transaction Visibility</li>
<li>Compression Information</li>
</ul>
</li>
<li>The data in a page can be organized in tuple-oriented or log-structured.</li>
</ol>
<h3 id="how-to-organize-tuple-oriented-data"><a class="markdownIt-Anchor" href="#how-to-organize-tuple-oriented-data"></a> How to organize tuple-oriented data?</h3>
<ol>
<li>A naive strategy is to store the number of tuples in the header and append a new tuple to the end.
<ul>
<li>What if we delete a tuple?
<ul>
<li>How do we know there is available space?</li>
<li>What do we do to the following tuples? Do we move them forward, or leave them there?</li>
</ul>
</li>
<li>A more severe problem is what happens if we have a variable-length attribute.
<ul>
<li>How can we know the beginning and end of a tuple?</li>
</ul>
</li>
</ul>
</li>
<li>We store a slot array at the header in the slotted pages scheme.
<ul>
<li>The slot array maps “slots” to the tuples’ starting position offsets.</li>
<li>The header keeps track of the number of used slots and the offset of the starting location of the last slot used.</li>
<li>The space used to store tuples grows from tail to head, while the slot array grows from head to tail.</li>
<li>When a tuple is deleted, we must invalidate its value in a slot array where we can know available space.
<ul>
<li>As for its following tuples, we can either leave them as-is or compact the space.</li>
<li>As modification goes in memory, and deleting usually holds a lock, compacting the space can be fast, and there is no need to inform the rest of the system.</li>
</ul>
</li>
<li>
<img src="/imgs/15445/Storage/slot-array.png" width="25%">
</li>
</ul>
</li>
</ol>
<h3 id="how-do-we-find-the-tuple-we-need-on-a-page"><a class="markdownIt-Anchor" href="#how-do-we-find-the-tuple-we-need-on-a-page"></a> How do we find the tuple we need on a page?</h3>
<ol>
<li>Each tuple is assigned a unique record identifier.</li>
<li>The most commonly used is <code>page_id + offset/slot</code>.</li>
</ol>
<h2 id="tuple-layout"><a class="markdownIt-Anchor" href="#tuple-layout"></a> Tuple layout</h2>
<h3 id="what-is-stored-in-a-tuple"><a class="markdownIt-Anchor" href="#what-is-stored-in-a-tuple"></a> What is stored in a tuple?</h3>
<ol>
<li>A tuple is essentially a sequence of bytes. It’s the job of the DBMS to interpret those bytes into attribute types and values.</li>
<li>Each tuple is prefixed with a header containing meta-data, e.g., visibility info for concurrency control, Bit Map for NULL values.
<ul>
<li>We do not need to store meta-data about the schema.</li>
</ul>
</li>
<li>Attributes are typically stored in the order you specify when creating the table.</li>
</ol>
<h3 id="what-is-denormalized-data"><a class="markdownIt-Anchor" href="#what-is-denormalized-data"></a> What is denormalized data?</h3>
<ol>
<li>DBMS can physically denormalize (pre-join) related tuples and store them together on the same page.
<ul>
<li>For two tables, one table has an attribute referenced to another table, DBMS can store the tuples and their referenced tuples in the same slot.</li>
<li>
<img src="/imgs/15445/Storage/denorm_declare.png" width="25%">
</li>
<li>
<img src="/imgs/15445/Storage/denorm_diagram.png" width="25%">
</li>
</ul>
</li>
<li>This can potentially reduce the amount of I/O for common workload patterns and make updates more expensive.</li>
</ol>
<h1 id="log-structured-storage"><a class="markdownIt-Anchor" href="#log-structured-storage"></a> Log-structured storage</h1>
<h2 id="what-is-stored-in-log-structured-storage"><a class="markdownIt-Anchor" href="#what-is-stored-in-log-structured-storage"></a> What is stored in log-structured storage?</h2>
<ol>
<li>DBMS stores log records that contain changes to tuples (PUT, DELETE).
<ul>
<li>Each log record must contain the tuple’s unique identifier. In this case, the identifier is not <code>page_id + offset/slot</code> mentioned above since the page doesn’t exist in this scheme.</li>
</ul>
</li>
<li>As the application changes the database, the DBMS appends log records to the end of the file without checking previous log records.</li>
<li>When the page gets full, the DBMS writes it out of the disk and fills the next page with records.
<ul>
<li>All on-disk pages are immutable.</li>
<li>All disk writes are sequential.</li>
</ul>
</li>
</ol>
<h2 id="how-to-read-in-a-log-structured-storage"><a class="markdownIt-Anchor" href="#how-to-read-in-a-log-structured-storage"></a> How to read in a log-structured storage?</h2>
<ol>
<li>To read a tuple with a given ID, the DBMS finds the newest log record corresponding to that ID. It needs to scan the log from newest to oldest.
<ul>
<li>DBMS can maintain an index that maps a tuple ID to the newest log record to optimize the linear scan.</li>
</ul>
</li>
<li>If the log record is in memory, just read it. If the log record is on a disk page, retrieve it.</li>
</ol>
<h2 id="how-to-solve-that-the-log-will-become-larger-and-larger"><a class="markdownIt-Anchor" href="#how-to-solve-that-the-log-will-become-larger-and-larger"></a> How to solve that the log will become larger and larger?</h2>
<ol>
<li>The DBMS can periodically compact pages to reduce wasted space.
<ul>
<li>It can take two continuous pages and scan from newest to oldest, leaving one newest log for each tuple.</li>
</ul>
</li>
<li>The DBMS can sort the page based on ID order to improve future look-up efficiency.
<ul>
<li>This sorted table is called a <strong>Sorted String Table</strong>, <strong>SSTable</strong>.</li>
<li>After a page is compacted, the DBMS does need to maintain the temporal ordering of records within the page since each tuple ID is guaranteed to appear at most once on the page.</li>
</ul>
</li>
<li>There are two strategies to choose which pages to compact:
<ul>
<li>The Universal compaction chooses any two continuous pages.</li>
<li>The level compaction chooses two continuous pages on the same level and compacts them into the next level.</li>
</ul>
</li>
<li>The downside of compaction is write-amplification caused by duplicate writing to the newest record of a tuple, and compacting itself is expensive.</li>
</ol>
<h1 id="tuple-storage"><a class="markdownIt-Anchor" href="#tuple-storage"></a> Tuple storage</h1>
<h2 id="how-to-store-data-in-a-tuple"><a class="markdownIt-Anchor" href="#how-to-store-data-in-a-tuple"></a> How to store data in a tuple?</h2>
<ol>
<li>A tuple is essentially a sequence of bytes. It’s the job of the DBMS to interpret those bytes into attribute types and values.</li>
<li>The DBMS’s catalogs contain the schema information about tables that the system uses to figure out the tuple’s layout.
<ul>
<li>A DBMS stores meta-data about databases in its internal catalogs.
<ul>
<li>Tables, columns, indexes, views</li>
<li>Users, permissions</li>
<li>Internal statistics</li>
</ul>
</li>
</ul>
</li>
</ol>
<h2 id="what-are-supported-data-types"><a class="markdownIt-Anchor" href="#what-are-supported-data-types"></a> What are supported data types?</h2>
<ol>
<li>The basic types are supported: <code>INTEGER</code>/<code>BIGINT</code>/<code>SMALLINT</code>/<code>TINYINT</code>, <code>FLOAT</code>/<code>REAL</code>, <code>VARCHAR</code>/<code>VARBINARY</code>/<code>TEXT</code>/<code>BLOB</code>, <code>TIME</code>/<code>DATE</code>/<code>TIMESTAMP</code>.</li>
<li>Since IEEE 754 floating points may be inaccurate, fixed-point decimals are also supported as <code>NUMERIC</code>/<code>DECIMAL</code>. But their execution is way slower than floating points.</li>
<li>Most DBMSs don’t allow a tuple to exceed the size of a single page.
<ul>
<li>The DBMS uses separate overflow storage pages to store values that are larger than a page.</li>
<li>Some systems allow you to store a large value in an external file. And treat the data as a BLOB type. Then, the DBMS cannot manipulate the contents of an external file.
<ul>
<li>No durability protections. No transaction protections.</li>
<li>They are outside of DBMS. Hence, we cannot update it through DBMS either.</li>
</ul>
</li>
</ul>
</li>
</ol>
<h1 id="data-storage-models"><a class="markdownIt-Anchor" href="#data-storage-models"></a> Data storage models</h1>
<h2 id="what-kind-of-database-workloads-are-there"><a class="markdownIt-Anchor" href="#what-kind-of-database-workloads-are-there"></a> What kind of database workloads are there?</h2>
<ol>
<li>On-Line Transaction Processing (OLTP): In this situation, commands are fast operations that only read/update a small amount of data each time. The data accessed in a query is related to a single entity in the database.</li>
<li>On-Line Analytical Processing (OLAP): Here, commands are complex queries that read a lot of data to compute aggregates, i.e., they will execute complex writes and complex reads.</li>
<li>Hybrid Transaction + Analytical Processing: OLTP + OLAP together on the same database instance.</li>
</ol>
<h2 id="how-does-dbms-store-tuples"><a class="markdownIt-Anchor" href="#how-does-dbms-store-tuples"></a> How does DBMS store tuples?</h2>
<ol>
<li><strong>N-ary storage model</strong> (<strong>row storage</strong>): The DBMS contiguously stores all attributes for a single tuple on a page.
<ul>
<li>This model is ideal for OLTP workloads where queries operate only on an individual entity and insert-heavy workloads.</li>
<li>The advantage is fast inserts, updates, and deletes. It is also suitable for queries that need the entire tuple.</li>
<li>However, it is not good for scanning large portions of the table and a subset of the attributes.</li>
</ul>
</li>
<li><strong>Decomposition storage model</strong> (<strong>DSM</strong>, <strong>Column storage</strong>): The DBMS stores the values of a single attribute for all tuples contiguously on a page.
<ul>
<li>This model is ideal for OLAP workloads where read-only queries perform large scans over a subset of the table’s attributes.</li>
<li>DBMS can identify tuples in two choices:
<ul>
<li>The first is using fixed-length offsets when each value is the same length for an attribute. It does not require each attribute to have the same length. This is the most used scheme.</li>
<li>The second is using embedded tuple IDs. Each value is stored in a column with its tuple ID.</li>
</ul>
</li>
<li>The advantage of DSM is that it reduces the amount wasted I/O because the DBMS only reads the data it needs and provides better query processing and data compression.</li>
<li>The disadvantage is that it is slow for point queries, inserts, updates, and deletes because of tuple splitting/stitching.</li>
</ul>
</li>
</ol>
<h2 id="database-compression"><a class="markdownIt-Anchor" href="#database-compression"></a> Database compression</h2>
<h3 id="why-do-we-need-database-compression-and-what-is-the-trade-off"><a class="markdownIt-Anchor" href="#why-do-we-need-database-compression-and-what-is-the-trade-off"></a> Why do we need database compression, and what is the trade-off?</h3>
<ol>
<li>I/O is the main bottleneck if the DBMS fetches data from the disk during query execution.</li>
<li>The DBMS can compress pages to increase the utility of the data moved per I/O operation.</li>
<li>The fundamental trade-off is between speed and compression ratio.
<ul>
<li>Compressing and decompressing will take higher CPU costs to get a better compression ratio. But it can reduce DRAM requirements.</li>
<li>Some engines work with compressed data, which can reduce CPU costs.</li>
</ul>
</li>
</ol>
<h3 id="why-can-we-compress-data"><a class="markdownIt-Anchor" href="#why-can-we-compress-data"></a> Why can we compress data?</h3>
<ol>
<li>Data sets tend to have highly skewed distributions for attribute values.</li>
<li>Data sets tend to have a high correlation between attributes of the same tuple.</li>
</ol>
<h3 id="what-are-the-goals-of-compression"><a class="markdownIt-Anchor" href="#what-are-the-goals-of-compression"></a> What are the goals of compression?</h3>
<ol>
<li>It must produce fixed-length values. The only exception is var-length data stored in a separate pool.</li>
<li>Late materialization: Postpone decompression for as long as possible during query execution.</li>
<li>It must be a lossless scheme.
<ul>
<li>When a DBMS uses compression, it is always lossless because people don’t like losing data.</li>
<li>Any lossy compression must be performed at the application level.</li>
</ul>
</li>
</ol>
<h3 id="what-are-the-compression-granularities"><a class="markdownIt-Anchor" href="#what-are-the-compression-granularities"></a> What are the compression granularities?</h3>
<ol>
<li>Block-level: Compression is performed on a block of tuples for the same table.</li>
<li>Tuple-level: Compression is performed on the contents of the entire tuple (NSM-only).</li>
<li>Attribute-level: Compression is performed on a single attribute within one tuple (overflow). It can target multiple attributes for the same tuple.</li>
<li>Column-level: Compression is performed on multiple values for one or more attributes stored for multiple tuples (DSM-only).</li>
</ol>
<h3 id="what-is-naive-compression"><a class="markdownIt-Anchor" href="#what-is-naive-compression"></a> What is naive compression?</h3>
<ol>
<li>Naive means that the data system does not understand the bits after compression.</li>
<li>We can compress data using a general-purpose algorithm. The scope of compression is only based on the data provided as input.</li>
<li>In disk, each page stores the compressed data and the modification log of this page.</li>
<li>When DBMS reads a page into the buffer pool
<ul>
<li>It won’t decompress until queries need to return the whole tuple.</li>
<li>Every update will only append an entry in the mod log. Hence no need to decompress data when only updating tuples. The only thing we need to know in updating is which page this tuple is.</li>
<li>DBMS will decompress the page and apply changes when the mod log is full.</li>
</ul>
</li>
</ol>
<h3 id="how-can-we-do-better-with-the-high-level-meaning-or-semantics-of-the-data"><a class="markdownIt-Anchor" href="#how-can-we-do-better-with-the-high-level-meaning-or-semantics-of-the-data"></a> How can we do better with the high-level meaning or semantics of the data?</h3>
<ol>
<li>This is performed on the column level.</li>
<li>Run-length encoding:
<ul>
<li>Compress runs of continuous same value in a single column into triplets <code>(value, offset, length) </code>.
<ul>
<li><code>Value</code> is the value of the attribute.</li>
<li><code>Offset</code> is the start position in the column segment of the continuous save value run.</li>
<li><code>Length</code> is the number of elements in the run.</li>
</ul>
</li>
<li>It requires the columns to be sorted intelligently to maximize compression opportunities.</li>
</ul>
</li>
<li>Bit-packing encoding:
<ul>
<li>When values for an attribute are always less than the value’s declared largest size, store them as a smaller data type.</li>
<li>Mostly, encoding uses a special marker to indicate when a value exceeds the largest size and maintains a look-up table to store them.</li>
</ul>
</li>
<li>Bitmap encoding:
<ul>
<li>Store a separate bitmap for <strong>each unique value</strong> for an attribute where an offset in the vector corresponds to a tuple.</li>
<li>When reading, DBMS needs looks into the bits in the tuple to find which bit is <code>1</code> to know which value is stored in this attribute of this tuple.</li>
<li>We need to store the value for each bitmap. So, the total space required is the total length of possible values, and the number of bits is the same as the number of tuples for each value.</li>
</ul>
</li>
<li>Delta encoding:
<ul>
<li>Recording the difference between this tuple and its last tuple.</li>
<li>Store base value in-line or in a separate look-up table.</li>
<li>Combine with RLE to get even better compression ratios.</li>
</ul>
</li>
<li>Incremental encoding:
<ul>
<li>Delta encoding is for numbers, while incremental encoding is for strings.</li>
<li>It stores the length of common prefixes between this tuple and its last tuple and the extra suffixes of this tuple.</li>
<li>When there is no common prefix, the length is <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>0</mn></mrow><annotation encoding="application/x-tex">0</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">0</span></span></span></span>. It performed better when we sorted tuples according to the strings.</li>
</ul>
</li>
<li>Dictionary compression (most widely used):
<ul>
<li>Build a data structure that maps variable-length values to a smaller integer identifier. And replace those values with their corresponding identifier in the dictionary data structure.</li>
<li>A dictionary is required to support fast encoding, decoding, and a range of queries.</li>
<li>The hash function can not be used due to key confliction, and decoding cannot be provided.</li>
<li>When the dictionary encodes values in a certain order (e.g., alphabetic order), the execution engine can be optimized to do some queries only access the dictionary, especially for those <code>DISTINCT</code> queries.</li>
</ul>
</li>
</ol>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://liyun-zhang.github.io/2023/06/24/Courses/15445/01-Relational-Model/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="LiyunZhang">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="LiyunZhang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | LiyunZhang">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2023/06/24/Courses/15445/01-Relational-Model/" class="post-title-link" itemprop="url">01 Relational Model</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2023-06-24 15:14:56" itemprop="dateCreated datePublished" datetime="2023-06-24T15:14:56+08:00">2023-06-24</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">Edited on</span>
      <time title="Modified: 2024-03-16 12:05:06" itemprop="dateModified" datetime="2024-03-16T12:05:06+08:00">2024-03-16</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">In</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Open-Courses/" itemprop="url" rel="index"><span itemprop="name">Open Courses</span></a>
        </span>
          , 
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Open-Courses/CMU-15-445-645-Database-System/" itemprop="url" rel="index"><span itemprop="name">CMU 15-445/645 Database System</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p><ul class="markdownIt-TOC">
<li><a href="#database">Database</a>
<ul>
<li><a href="#why-shouldnt-we-store-the-database-in-a-flat-file-like-csv-which-we-manage-ourselves-in-our-application-code">Why shouldn’t we store the database in a flat file like CSV, which we manage ourselves in our application code?</a></li>
<li><a href="#what-do-dbms-and-data-models-do">What do DBMS and data models do?</a></li>
<li><a href="#what-kinds-of-data-models-are-there">What kinds of data models are there?</a></li>
<li><a href="#how-does-the-document-data-model-store-data">How does the document data model store data?</a></li>
</ul>
</li>
<li><a href="#relational-model">Relational model</a>
<ul>
<li><a href="#how-are-data-stored">How are data stored?</a></li>
<li><a href="#what-are-primary-keys-and-foreign-keys">What are primary keys and foreign keys?</a></li>
<li><a href="#what-is-supported-in-relational-algebra">What is supported in relational algebra?</a></li>
</ul>
</li>
<li><a href="#morden-sql">Morden SQL</a>
<ul>
<li><a href="#what-is-provided-in-a-relational-language">What is provided in a relational language?</a></li>
<li><a href="#aggregations-and-group-by">Aggregations and Group By</a>
<ul>
<li><a href="#what-are-aggregations">What are aggregations?</a></li>
<li><a href="#how-to-output-other-columns-with-aggregations">How to output other columns with aggregations?</a></li>
</ul>
</li>
<li><a href="#what-string-operations-are-supported">What string operations are supported?</a></li>
<li><a href="#output">Output</a>
<ul>
<li><a href="#where-can-we-redirect-outputs">Where can we redirect outputs?</a></li>
<li><a href="#how-can-we-control-the-outputs">How can we control the outputs?</a></li>
</ul>
</li>
<li><a href="#what-if-we-need-a-temporary-relation-in-a-query">What if we need a temporary relation in a query?</a></li>
<li><a href="#how-do-window-functions-work">How do window functions work?</a></li>
</ul>
</li>
</ul>
</p>
<h1 id="database"><a class="markdownIt-Anchor" href="#database"></a> Database</h1>
<h2 id="why-shouldnt-we-store-the-database-in-a-flat-file-like-csv-which-we-manage-ourselves-in-our-application-code"><a class="markdownIt-Anchor" href="#why-shouldnt-we-store-the-database-in-a-flat-file-like-csv-which-we-manage-ourselves-in-our-application-code"></a> Why shouldn’t we store the database in a flat file like CSV, which we manage ourselves in our application code?</h2>
<ol>
<li>The first concern is data integrity:
<ul>
<li>How to ensure that the data makes sense to the design schema?</li>
<li>How to prevent invalid data and malicious attacks?</li>
<li>The management of deleting some entries causing deleting entries in other databases is a pain.</li>
</ul>
</li>
<li>Another problem is implementation:
<ul>
<li>How to find a record?</li>
<li>How to share a database between applications?</li>
<li>How to handle concurrent writes?</li>
</ul>
</li>
<li>Also concerned about durability:
<ul>
<li>What if the machine crashed?</li>
<li>How to replicate the database?</li>
</ul>
</li>
</ol>
<h2 id="what-do-dbms-and-data-models-do"><a class="markdownIt-Anchor" href="#what-do-dbms-and-data-models-do"></a> What do DBMS and data models do?</h2>
<ol>
<li>DBMS supports the definition, creation, querying, update, and administration of databases in accordance with some data model.
<ul>
<li>The physical storage is left up to the DBMS implementation.</li>
<li>Programmers access data through high-level language, and DBMS figures out the best execution strategy.</li>
</ul>
</li>
<li>A data model is a collection of concepts describing the data in a database.
<ul>
<li>A schema describes a particular collection of data using a given data model.</li>
</ul>
</li>
</ol>
<h2 id="what-kinds-of-data-models-are-there"><a class="markdownIt-Anchor" href="#what-kinds-of-data-models-are-there"></a> What kinds of data models are there?</h2>
<ol>
<li>The most used is the Relational model.</li>
<li>One class called NoSQL:
<ul>
<li>Key/Value</li>
<li>Graph</li>
<li>Document / Object</li>
<li>Wide-Column / Column-family</li>
</ul>
</li>
<li>For machine learning, there are Array / Matrix / Vectors.</li>
<li>The obsolete or legacy ones are:
<ul>
<li>Hierarchical</li>
<li>Network</li>
<li>Multi-Value</li>
</ul>
</li>
</ol>
<h2 id="how-does-the-document-data-model-store-data"><a class="markdownIt-Anchor" href="#how-does-the-document-data-model-store-data"></a> How does the document data model store data?</h2>
<ol>
<li>It embeds data hierarchy into a single object like JSON, XML, etc.</li>
<li>The problem is similar to the aforementioned store database in a flat file like CSV.</li>
</ol>
<h1 id="relational-model"><a class="markdownIt-Anchor" href="#relational-model"></a> Relational model</h1>
<h2 id="how-are-data-stored"><a class="markdownIt-Anchor" href="#how-are-data-stored"></a> How are data stored?</h2>
<ol>
<li>Data are stored in simple data structures called relations.</li>
<li>A relation is an <strong>unordered set</strong> that contains the relationship of attributes that represent entities.
<ul>
<li>A n-ary relation is a table with n columns.</li>
</ul>
</li>
<li>A tuple is a set of attribute values (domain) in the relation.
<ul>
<li>NULL is a member of every domain if allowed.</li>
</ul>
</li>
</ol>
<h2 id="what-are-primary-keys-and-foreign-keys"><a class="markdownIt-Anchor" href="#what-are-primary-keys-and-foreign-keys"></a> What are primary keys and foreign keys?</h2>
<ol>
<li>A relation’s primary key uniquely identifies a single tuple.
<ul>
<li>In defining a relation, primary keys are usually marked with an underline.</li>
</ul>
</li>
<li>A foreign key specifies that an attribute from one relation must map to a tuple in another.
<ul>
<li>Normally, foreign keys must be primary keys in another relation.</li>
</ul>
</li>
</ol>
<h2 id="what-is-supported-in-relational-algebra"><a class="markdownIt-Anchor" href="#what-is-supported-in-relational-algebra"></a> What is supported in relational algebra?</h2>
<ol>
<li>Select: <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>σ</mi><mrow><mi>p</mi><mi>r</mi><mi>e</mi><mi>d</mi><mi>i</mi><mi>c</mi><mi>a</mi><mi>t</mi><mi>e</mi></mrow></msub><mo stretchy="false">(</mo><mi>R</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\sigma_{predicate}(R)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.036108em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">σ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361079999999999em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">p</span><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span><span class="mord mathnormal mtight">e</span><span class="mord mathnormal mtight">d</span><span class="mord mathnormal mtight">i</span><span class="mord mathnormal mtight">c</span><span class="mord mathnormal mtight">a</span><span class="mord mathnormal mtight">t</span><span class="mord mathnormal mtight">e</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="mclose">)</span></span></span></span>
<ul>
<li>Choose a subset of the tuples from a relation that satisfies the selection predicate.<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> R</span><br><span class="line"> <span class="keyword">WHERE</span> predicate;</span><br></pre></td></tr></table></figure>
</li>
</ul>
</li>
<li>Projection: <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="normal">Π</mi><mrow><msub><mi>A</mi><mn>1</mn></msub><mo separator="true">,</mo><msub><mi>A</mi><mn>2</mn></msub><mo separator="true">,</mo><mo>…</mo><mo separator="true">,</mo><msub><mi>A</mi><mi>n</mi></msub></mrow></msub><mo stretchy="false">(</mo><mi>R</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\Pi_{A_1,A_2,\dots,A_n}(R)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.036108em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord">Π</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.328331em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight">A</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31731428571428577em;"><span style="top:-2.357em;margin-left:0em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em;"><span></span></span></span></span></span></span><span class="mpunct mtight">,</span><span class="mord mtight"><span class="mord mathnormal mtight">A</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31731428571428577em;"><span style="top:-2.357em;margin-left:0em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em;"><span></span></span></span></span></span></span><span class="mpunct mtight">,</span><span class="minner mtight">…</span><span class="mpunct mtight">,</span><span class="mord mtight"><span class="mord mathnormal mtight">A</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.16454285714285719em;"><span style="top:-2.357em;margin-left:0em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight">n</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em;"><span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="mclose">)</span></span></span></span>
<ul>
<li>Generate a relation with tuples that contain only the specified attributes.</li>
<li>It can be used to rearrange attributes’ ordering and manipulate the values.<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> A1, A2, ..., An <span class="keyword">FROM</span> R;</span><br></pre></td></tr></table></figure>
</li>
</ul>
</li>
<li>Union: <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>R</mi><mo>∪</mo><mi>S</mi></mrow><annotation encoding="application/x-tex">R\cup S</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">∪</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.05764em;">S</span></span></span></span>
<ul>
<li>Two relations must have identical attributes.</li>
<li>The result may be duplicated if some tuples appear in both relations.<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">(<span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> R) <span class="keyword">UNION</span> <span class="keyword">ALL</span> (<span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> S);</span><br></pre></td></tr></table></figure>
</li>
</ul>
</li>
<li>Intersection: <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>R</mi><mo>∩</mo><mi>S</mi></mrow><annotation encoding="application/x-tex">R\cap S</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">∩</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.05764em;">S</span></span></span></span>
<ul>
<li>Two relations must have the same attributes.<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">(<span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> R) <span class="keyword">INTERSECT</span> (<span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> S);</span><br></pre></td></tr></table></figure>
</li>
</ul>
</li>
<li>Difference: <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>R</mi><mo>−</mo><mi>S</mi></mrow><annotation encoding="application/x-tex">R-S</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.76666em;vertical-align:-0.08333em;"></span><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.05764em;">S</span></span></span></span>
<ul>
<li>Two relations must have identical attributes.<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">(<span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> R) <span class="keyword">EXCEPT</span> (<span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> S);</span><br></pre></td></tr></table></figure>
</li>
</ul>
</li>
<li>Product: <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>R</mi><mo>×</mo><mi>S</mi></mrow><annotation encoding="application/x-tex">R\times S</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.76666em;vertical-align:-0.08333em;"></span><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.05764em;">S</span></span></span></span>
<ul>
<li>Generate a relation that contains all possible combinations of tuples from the input relations, i.e., Cartesian product.<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> R <span class="keyword">CROSS</span> <span class="keyword">JOIN</span> S;</span><br><span class="line"># <span class="keyword">Or</span></span><br><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> R, S;</span><br></pre></td></tr></table></figure>
</li>
</ul>
</li>
<li>Join: <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>R</mi><mo>⋈</mo><mi>S</mi></mrow><annotation encoding="application/x-tex">R\bowtie S</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68833em;vertical-align:-0.005em;"></span><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">⋈</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.05764em;">S</span></span></span></span>
<ul>
<li>The difference between join and intersection is that join can match attributes’ names automatically, while intersection requires that two relations have the same attribute order.</li>
<li>It does product first, then compare attributes.<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> R <span class="keyword">NATURAL</span> <span class="keyword">JOIN</span> S;</span><br><span class="line"># <span class="keyword">Or</span></span><br><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> R <span class="keyword">JOIN</span> S <span class="keyword">USING</span> (A1, A2, ..., An);</span><br></pre></td></tr></table></figure>
</li>
<li>In the broad sense, join can have a predicate <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>R</mi><msub><mo>⋈</mo><mrow><mi>p</mi><mi>r</mi><mi>e</mi><mi>d</mi><mi>i</mi><mi>c</mi><mi>a</mi><mi>t</mi><mi>e</mi></mrow></msub><mi>S</mi></mrow><annotation encoding="application/x-tex">R\bowtie_{predicate}S</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.969438em;vertical-align:-0.286108em;"></span><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel"><span class="mrel">⋈</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361079999999999em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">p</span><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span><span class="mord mathnormal mtight">e</span><span class="mord mathnormal mtight">d</span><span class="mord mathnormal mtight">i</span><span class="mord mathnormal mtight">c</span><span class="mord mathnormal mtight">a</span><span class="mord mathnormal mtight">t</span><span class="mord mathnormal mtight">e</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.05764em;">S</span></span></span></span> which is the same as <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>σ</mi><mrow><mi>p</mi><mi>r</mi><mi>e</mi><mi>d</mi><mi>i</mi><mi>c</mi><mi>a</mi><mi>t</mi><mi>e</mi></mrow></msub><mo stretchy="false">(</mo><mi>R</mi><mo>×</mo><mi>S</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\sigma_{predicate}(R\times S)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.036108em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">σ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361079999999999em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">p</span><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span><span class="mord mathnormal mtight">e</span><span class="mord mathnormal mtight">d</span><span class="mord mathnormal mtight">i</span><span class="mord mathnormal mtight">c</span><span class="mord mathnormal mtight">a</span><span class="mord mathnormal mtight">t</span><span class="mord mathnormal mtight">e</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.05764em;">S</span><span class="mclose">)</span></span></span></span>.</li>
</ul>
</li>
<li>Different orders of steps can have the same result with varying amounts of computation.
<ul>
<li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>R</mi><mo>⋈</mo><mo stretchy="false">(</mo><msub><mi>σ</mi><mrow><mi>p</mi><mi>r</mi><mi>e</mi><mi>d</mi><mi>i</mi><mi>c</mi><mi>a</mi><mi>t</mi><mi>e</mi></mrow></msub><mo stretchy="false">(</mo><mi>S</mi><mo stretchy="false">)</mo><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">R\bowtie(\sigma_{predicate}(S))</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68833em;vertical-align:-0.005em;"></span><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">⋈</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.036108em;vertical-align:-0.286108em;"></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">σ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361079999999999em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">p</span><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span><span class="mord mathnormal mtight">e</span><span class="mord mathnormal mtight">d</span><span class="mord mathnormal mtight">i</span><span class="mord mathnormal mtight">c</span><span class="mord mathnormal mtight">a</span><span class="mord mathnormal mtight">t</span><span class="mord mathnormal mtight">e</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.05764em;">S</span><span class="mclose">)</span><span class="mclose">)</span></span></span></span> is much more efficient than <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>σ</mi><mrow><mi>p</mi><mi>r</mi><mi>e</mi><mi>d</mi><mi>i</mi><mi>c</mi><mi>a</mi><mi>t</mi><mi>e</mi></mrow></msub><mo stretchy="false">(</mo><mi>R</mi><mo>⋈</mo><mi>S</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\sigma_{predicate}(R\bowtie S)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.036108em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">σ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361079999999999em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">p</span><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span><span class="mord mathnormal mtight">e</span><span class="mord mathnormal mtight">d</span><span class="mord mathnormal mtight">i</span><span class="mord mathnormal mtight">c</span><span class="mord mathnormal mtight">a</span><span class="mord mathnormal mtight">t</span><span class="mord mathnormal mtight">e</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">⋈</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.05764em;">S</span><span class="mclose">)</span></span></span></span>.</li>
</ul>
</li>
</ol>
<h1 id="morden-sql"><a class="markdownIt-Anchor" href="#morden-sql"></a> Morden SQL</h1>
<h2 id="what-is-provided-in-a-relational-language"><a class="markdownIt-Anchor" href="#what-is-provided-in-a-relational-language"></a> What is provided in a relational language?</h2>
<ol>
<li>Data Manipulation Language (DML)</li>
<li>Data Definition Language (DDL)</li>
<li>Data Control Language (DCL)</li>
<li>Also, view definition, integrity, and referential constraints, transactions.</li>
</ol>
<h2 id="aggregations-and-group-by"><a class="markdownIt-Anchor" href="#aggregations-and-group-by"></a> Aggregations and Group By</h2>
<h3 id="what-are-aggregations"><a class="markdownIt-Anchor" href="#what-are-aggregations"></a> What are aggregations?</h3>
<ol>
<li>They are functions that return a single value from a bag of tuples.</li>
<li><code>AVG(col)</code>, <code>MIN(col)</code>, <code>MAX(col)</code>, <code>SUM(col)</code>, <code>COUNT(col)</code>
<ul>
<li>For <code>COUNT</code>, the passed argument does not matter since it only returns the number of rows.</li>
</ul>
</li>
<li>Aggregate functions can almost only be used in the <code>SELECT</code> output list.</li>
<li><code>COUNT</code>, <code>SUM</code>, and <code>AVG</code> support <code>DISTINCT</code>.
<ul>
<li>In this case, the columns passed to <code>COUNT</code> matters.</li>
</ul>
</li>
<li>The output of other columns outside of an aggregate is undefined.
<ul>
<li>Aggregations create a new relation with a different number of tuples.</li>
<li>If we directly ask for other columns, the number of tuples won’t match the output of aggregations.</li>
<li>We don’t know the relation between the output of aggregations and values from other columns (some languages may allow this but with chaotic order).</li>
</ul>
</li>
<li>We also cannot filter output tuples based on aggregation column names.
<ul>
<li>Since <code>SELECT</code> happens at last, when <code>WHERE</code> or <code>HAVING </code> is calculated, the aggregation columns haven’t been calculated yet.</li>
</ul>
</li>
</ol>
<h3 id="how-to-output-other-columns-with-aggregations"><a class="markdownIt-Anchor" href="#how-to-output-other-columns-with-aggregations"></a> How to output other columns with aggregations?</h3>
<ol>
<li><code>GROUP BY</code> projects tuples into subsets and calculates aggregates against each subset.</li>
<li>Non-aggregated values in the SELECT output clause must appear in the <code>GROUP BY</code> clause.</li>
<li>With group-by, each aggregation output has the same values in those grouped columns. So <code>SELECT</code> knows their relation.</li>
<li><code>HAVING</code> like a <code>WHERE</code> clause for a <code>GROUP BY</code>.
<ul>
<li>It can filter results based on aggregation computation. But it also shouldn’t use the column names of aggregation in <code>SELECT</code>.</li>
<li>Instead, it should directly use the aggregation function. Although the execution engine knows these two are the same and doesn’t do the repeat calculation.</li>
</ul>
</li>
</ol>
<h2 id="what-string-operations-are-supported"><a class="markdownIt-Anchor" href="#what-string-operations-are-supported"></a> What string operations are supported?</h2>
<ol>
<li>Predicate of string matching can be done with <code>=</code>
<ul>
<li>Some DBMSs are case-sensitive, while others are not.</li>
<li>We can also use <code>LIKE</code> to match with string-match operators.
<ul>
<li><code>%</code> matches any substring (including empty strings)</li>
<li><code>_</code> match any one character.</li>
</ul>
</li>
</ul>
</li>
<li>Other string functions are provided:
<ul>
<li><code>UPPER</code> and <code>LOWER</code></li>
<li><code>SUBSTRING(str, start_index, end_index)</code></li>
</ul>
</li>
<li>Different languages have different ways to concatenate strings: <code>str1 || str2</code>, <code>str1 + str2</code> or <code>CONCAT(str1, str2)</code>.</li>
</ol>
<h2 id="output"><a class="markdownIt-Anchor" href="#output"></a> Output</h2>
<h3 id="where-can-we-redirect-outputs"><a class="markdownIt-Anchor" href="#where-can-we-redirect-outputs"></a> Where can we redirect outputs?</h3>
<ol>
<li>We can store query results in another table.
<ul>
<li>That table must not already be defined.</li>
<li>It will have the same number of columns and types as the input.</li>
</ul>
</li>
<li>We can also insert tuples from a query into another table.
<ul>
<li>The inner select must generate the same columns as the target table.</li>
<li>DMBSs have different options/syntax on what to do with integrity violations.</li>
</ul>
</li>
</ol>
<h3 id="how-can-we-control-the-outputs"><a class="markdownIt-Anchor" href="#how-can-we-control-the-outputs"></a> How can we control the outputs?</h3>
<ol>
<li>We can order the output tuples by the values in one or more of their columns with <code>ORDER BY &lt;column*&gt; [ASC|DESC]</code>.</li>
<li>We can also limit the number of tuples returned in output with <code>LIMIT &lt;count&gt; [OFFSET &lt;count2&gt;]</code>.
<ul>
<li>Although this limits the number of outputs, its execution may still need to compute the whole relation, e.g., to output the top-10 largest numbers, it still needs to sort all numbers.</li>
</ul>
</li>
</ol>
<h2 id="what-if-we-need-a-temporary-relation-in-a-query"><a class="markdownIt-Anchor" href="#what-if-we-need-a-temporary-relation-in-a-query"></a> What if we need a temporary relation in a query?</h2>
<ol>
<li>The first solution is nested queries.
<ul>
<li>Inner queries can appear almost anywhere in a query.</li>
<li>In the WHERE clause, we can perform a predicate between the tuples from the current relation and the result of the subqueries.
<ul>
<li><code>ALL</code> must satisfy expressions for all rows in the subquery.</li>
<li><code>ANY</code> must satisfy the expression for at least one row in the subquery.</li>
<li><code>IN</code> is equivalent to <code>=ANY()</code>.</li>
<li><code>EXISTS</code> returns true if the relation is not empty.</li>
<li><code>NOT</code></li>
</ul>
</li>
</ul>
</li>
<li>Another choice is a common table expression using <code>WITH cteName AS (query)</code>.
<ul>
<li>It also supports bind/alias output columns to names <code>WITH cteName (col1, ..., coln) AS (query)</code></li>
<li>In the next query, we can reference this temporary relation with <code>cteName</code>.</li>
<li>We can enable recursive calculation using <code>WITH RECURSIVE</code>.</li>
</ul>
</li>
</ol>
<h2 id="how-do-window-functions-work"><a class="markdownIt-Anchor" href="#how-do-window-functions-work"></a> How do window functions work?</h2>
<ol>
<li>Window functions perform a sliding calculation across a set of related tuples.</li>
<li>Like an aggregation, they only appear in the <code>SELECT</code> clause. However, tuples are not grouped into a single output tuples. Instead, the number of rows of the output is the same as the input.</li>
<li>In the SELECT clause, the syntax of the window functions is <code>FUNC-NAME(...) OVER(...)</code>.
<ul>
<li>The <code>FUNC-NAME</code> can be aggregation functions or special functions (<code>ROW_NUMBER</code> and <code>RANK</code>)
<ul>
<li><code>ROW_NUMBER</code> assigns the number of the current rows in a certain order.</li>
<li><code>RANK</code> assigns the order position of the current row.</li>
<li>When two rows tie, <code>RANK</code> will assign the same number to them and skip the next number, while ROW_NUMBER will assign a different number.</li>
</ul>
</li>
<li>The <code>OVER</code> parameter controls how to slice up data.
<ul>
<li>It controls how to group tuples when computing the window function with <code>PARTITION BY</code>.</li>
<li>It also controls the computing order with <code>ORDER BY ... [ASC|DESC]</code>.</li>
</ul>
</li>
</ul>
</li>
</ol>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://liyun-zhang.github.io/2023/03/27/OpenSource/6.824/Lab-4-ShardKV/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="LiyunZhang">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="LiyunZhang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | LiyunZhang">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2023/03/27/OpenSource/6.824/Lab-4-ShardKV/" class="post-title-link" itemprop="url">Lab 4: ShardKV</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2023-03-27 14:35:51" itemprop="dateCreated datePublished" datetime="2023-03-27T14:35:51+08:00">2023-03-27</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">Edited on</span>
      <time title="Modified: 2024-03-17 11:28:55" itemprop="dateModified" datetime="2024-03-17T11:28:55+08:00">2024-03-17</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">In</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Open-Source-Code/" itemprop="url" rel="index"><span itemprop="name">Open Source Code</span></a>
        </span>
          , 
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Open-Source-Code/6-824/" itemprop="url" rel="index"><span itemprop="name">6.824</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p><ul class="markdownIt-TOC">
<li><a href="#how-to-shard-key-value-pairs">How to shard key-value pairs?</a></li>
<li><a href="#how-to-install-a-new-configuration">How to install a new configuration?</a></li>
<li><a href="#how-to-reduce-the-pauses-for-clients-when-installing-new-configurations">How to reduce the pauses for clients when installing new configurations?</a></li>
<li><a href="#how-does-garbage-collect-past-configurations">How does garbage collect past configurations?</a></li>
</ul>
</p>
<h1 id="how-to-shard-key-value-pairs"><a class="markdownIt-Anchor" href="#how-to-shard-key-value-pairs"></a> How to shard key-value pairs?</h1>
<ol>
<li>The total number of shards is fixed to be <code>NShards</code>. The keys are mapped into shards by a hash function mod by <code>NShards</code>.</li>
<li>Each KV group in the cluster needs to be responsible for some shards. An additional Raft group named Shard Controller is responsible for the cluster configurations.
<ul>
<li>Each KV group would acquire the latest configuration from the Shard Controller.</li>
<li>When a new configuration is found, it will be proposed to the Raft group. It is installed until it has been committed.</li>
</ul>
</li>
<li>Administrators can modify the configuration of the Raft groups in the cluster by giving commands to the Shard Controllers. <code>Leave</code>, <code>Join</code>, and <code>Move</code> are provided.
<ul>
<li>When a command comes from administrators, a Raft entry is proposed. A new configuration will only be created when that entry is committed.</li>
<li>When creating new configurations, <code>Leave</code> and <code>Join</code> will try to rebalance the distribution of shards as evenly as possible or move as few shards as possible.</li>
</ul>
</li>
</ol>
<h1 id="how-to-install-a-new-configuration"><a class="markdownIt-Anchor" href="#how-to-install-a-new-configuration"></a> How to install a new configuration?</h1>
<ol>
<li>For the shards in the last config, not in the new config, we cannot simply discard them. When we give up a shard, some other group must be responsible for it, and they do not have it now. Therefore, we need to transmit the data to them.
<ul>
<li>One way is to push the data to the new owner of the shards. However, they may not be online now; they are partitioned from this node, or they may not have installed this new configuration, causing waste RPC flows.</li>
<li>Another way is to keep all data from past configurations and separate them from the current configuration data, waiting for other nodes to pull the shards they want.</li>
</ul>
</li>
<li>We must acquire the shards in the new configuration and not in the last configuration from somewhere.
<ul>
<li>As aforementioned, when a new configuration is installed, this peer will issue an RPC to pull the missing shards from other groups.</li>
<li>To avoid that the target host of missing shards only executes part of commands of the last config causing missing values, a host is allowed to transmit shards only if it has installed the next configuration of the requested configuration.</li>
</ul>
</li>
<li>The executed index records also need to be separated between configurations to prevent lagged groups from rejecting to execute commands from clients.</li>
<li>When installing a new configuration from a snapshot, remember to initiate the goroutines to fetch the missing shards from the snapshot.</li>
</ol>
<h1 id="how-to-reduce-the-pauses-for-clients-when-installing-new-configurations"><a class="markdownIt-Anchor" href="#how-to-reduce-the-pauses-for-clients-when-installing-new-configurations"></a> How to reduce the pauses for clients when installing new configurations?</h1>
<ol>
<li>In the naive schema, we must wait until all shards are received before executing any client commands. However, receiving all shards could take a long time.</li>
<li>Executing the commands that only need the received shards is reasonable, even if some shards remain missing.</li>
<li>We can add a data structure to record the state of each shard in a configuration. If the state is received, we can execute the commands on that shard.</li>
<li>To execute the commands in commit order, we will still be stalled by the commands requesting missing shards.</li>
<li>Nevertheless, this schema can push the process forward as much as possible and parallel executing commands of received shards and waiting for missing shards.</li>
</ol>
<h1 id="how-does-garbage-collect-past-configurations"><a class="markdownIt-Anchor" href="#how-does-garbage-collect-past-configurations"></a> How does garbage collect past configurations?</h1>
<ol>
<li>In the naive schema, the redundant data would grow larger and larger since we cannot delete data from past configurations.</li>
<li>We can notice that a shard in the past configuration can be deleted when it is received by the group that needs to request it.
<ul>
<li>A peer can ask the corresponding peers whether they have received the shards. Similar to why we do not push shards, it will waste a lot of RPC flows.</li>
<li>When a peer receives a shard, whether requesting from another group or installing a snapshot, it will inform the groups that host shards from the previous configuration.</li>
<li>The shard can be deleted from the host of the last configuration when all peers who host a shard in the next configuration have received it.</li>
</ul>
</li>
<li>A garbage collection goroutine is initiated when the next configuration is installed.</li>
<li>A snapshot must persist before informing other groups of receiving shards to prevent recovery from a snapshot without shards while the host has already deleted due to received acknowledgment.</li>
<li>When a shard can be deleted, snapshot installation becomes more tricky.
<ul>
<li>We should not copy the deleted shards and deleted configurations from the snapshot. We can also delete the shads that are deleted in the snapshot.</li>
<li>When a new configuration is created from a snapshot, a garbage collection of the former configuration needs to be started.</li>
</ul>
</li>
</ol>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://liyun-zhang.github.io/2023/03/27/OpenSource/6.824/Lab-3-Fault-tolerant-Key-Value-Service/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="LiyunZhang">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="LiyunZhang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | LiyunZhang">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2023/03/27/OpenSource/6.824/Lab-3-Fault-tolerant-Key-Value-Service/" class="post-title-link" itemprop="url">Lab 3: Fault-tolerant Key/Value Service</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2023-03-27 14:35:11" itemprop="dateCreated datePublished" datetime="2023-03-27T14:35:11+08:00">2023-03-27</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">Edited on</span>
      <time title="Modified: 2024-03-17 11:28:16" itemprop="dateModified" datetime="2024-03-17T11:28:16+08:00">2024-03-17</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">In</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Open-Source-Code/" itemprop="url" rel="index"><span itemprop="name">Open Source Code</span></a>
        </span>
          , 
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Open-Source-Code/6-824/" itemprop="url" rel="index"><span itemprop="name">6.824</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p><ul class="markdownIt-TOC">
<li><a href="#how-does-the-keyvalue-server-execute-a-command-from-the-clerk">How does the Key/Value server execute a command from the clerk?</a>
<ul>
<li><a href="#how-can-we-take-advantage-of-follower-nodes">How can we take advantage of follower nodes?</a></li>
</ul>
</li>
<li><a href="#how-can-we-prevent-re-execution-of-an-executed-command">How can we prevent re-execution of an executed command?</a></li>
<li><a href="#how-many-kinds-of-errors-could-occur-when-a-client-issues-a-command">How many kinds of errors could occur when a client issues a command?</a></li>
<li><a href="#what-should-be-stored-in-a-snapshot">What should be stored in a snapshot?</a></li>
<li><a href="#what-needs-to-be-done-to-recover-the-state-after-a-crash">What needs to be done to recover the state after a crash?</a></li>
<li><a href="#execution-speed-of-get-operation">Execution speed of Get operation:</a></li>
<li><a href="#execution-speed-of-putappend-operation">Execution speed of PutAppend operation:</a></li>
</ul>
</p>
<h1 id="how-does-the-keyvalue-server-execute-a-command-from-the-clerk"><a class="markdownIt-Anchor" href="#how-does-the-keyvalue-server-execute-a-command-from-the-clerk"></a> How does the Key/Value server execute a command from the clerk?</h1>
<ol>
<li>It will call the <code>Start()</code> function of its associated Raft server. It can safely execute the command until the Raft server commits that command.</li>
<li>Only the KV server associated with the leader Raft server can successfully use Start() to append commands to logs.</li>
<li>However, there could be a situation in which the network is partitioned, and the clerk connects to a partition leader whose log entry can never be successfully committed. So, we need to set a timeout for each command. The clerk should be informed to find another server if it cannot be committed in time.</li>
</ol>
<h2 id="how-can-we-take-advantage-of-follower-nodes"><a class="markdownIt-Anchor" href="#how-can-we-take-advantage-of-follower-nodes"></a> How can we take advantage of follower nodes?</h2>
<ol>
<li>
<p>To achieve linearizability, there is no chance for the follower to improve the performance of the Put/Append operation. However, we can allow them to handle read-only requests to enhance the cluster’s throughput.</p>
</li>
<li>
<p>The key idea is to make the follower know it is up-to-date to handle the read. To confirm that, we must consult the leader of the current commit index.</p>
</li>
<li>
<p>A case is a partitioned follower and leader when another true leader connects to the majority.</p>
<ul>
<li>The solution is that the leader must check whether it is a legitimate leader before authorizing the followers to execute the read.</li>
</ul>
</li>
<li>
<p>The whole process is as follows:</p>
<ul>
<li>When a follower received a read from the client, it would consult the leader for a <code>readIndex</code>.</li>
<li>The leader then needs to send heartbeats to all peers in the group to ensure it is still the leader.</li>
<li>When the leader receives from the majority, the current commit index can be returned to the follower as <code>readIndex</code>.</li>
<li>The follower can execute the read request if it has at least applied up to <code>readIndex</code>.</li>
</ul>
</li>
<li>
<p>In the Raft protocol, a leader can only commit the entries appended in its term. Similarly, a leader can only grant <code>ReadIndex</code>, pointing to an entry in its term. Or the result of the reading may become unlinearizable.</p>
<ul>
<li>
<p>Consider that a leader committed an index of <em>x</em> and granted a ReadIndex of <em>x</em> to its associated KV server. So, the KV server returned the result up to index <em>x</em>.</p>
</li>
<li>
<p>But it crashed before sending a commit message to other followers. Then, a new leader is elected who receives a request for ReadIndex. It does not know anything about committing entry <em>x</em>, thus granting a ReadIndex lower than <em>x</em>.</p>
</li>
<li>
<p>Hence, the read will return a result unseeing the execution result of the entry of index x, which violates the linearizability scheme.</p>
</li>
<li>
<p>So, the solution is to append an empty entry to the log if the leader hasn’t appended any entry in its term.</p>
</li>
</ul>
</li>
</ol>
<h1 id="how-can-we-prevent-re-execution-of-an-executed-command"><a class="markdownIt-Anchor" href="#how-can-we-prevent-re-execution-of-an-executed-command"></a> How can we prevent re-execution of an executed command?</h1>
<ol>
<li>Each clerk needs to maintain a monotonically increasing index to mark the command it issued.</li>
<li>Each Key/Value server needs to track the highest index executed for each clerk.</li>
<li>When a Key/Value server receives a new command, it compares the new command’s index with that clerk’s highest executed index. If the command’s index is lower, it can know that this is an executed command and return the result directly.</li>
</ol>
<h1 id="how-many-kinds-of-errors-could-occur-when-a-client-issues-a-command"><a class="markdownIt-Anchor" href="#how-many-kinds-of-errors-could-occur-when-a-client-issues-a-command"></a> How many kinds of errors could occur when a client issues a command?</h1>
<ol>
<li>For read-only operations, there could be a key error.</li>
<li>Except for the read-only operation with follower read, the client may connect to a follower who cannot append a command.</li>
<li>The client may connect to a server in a minority partition of servers.
<ul>
<li>The PutAppend command is appended to the log but cannot commit.</li>
<li>For the read-only operation with follower read, it connects to its leader, but its leader cannot receive a majority response. Hence, it cannot acquire a ReadIndex.</li>
</ul>
</li>
<li>For read-only operations with follower read,
<ul>
<li>The KV Server is associated with a leader, and its leader sets a higher commit index when communicating with the majority. But the Raft leader crashed before committing that entry, leaving the KV server waiting to apply as up-to-date as the ReadIndex.</li>
<li>The client may connect to a partition without a leader and, hence, cannot acquire ReadIndex.</li>
</ul>
</li>
</ol>
<h1 id="what-should-be-stored-in-a-snapshot"><a class="markdownIt-Anchor" href="#what-should-be-stored-in-a-snapshot"></a> What should be stored in a snapshot?</h1>
<ol>
<li>Of course, we need to store the state of all key-value pairs.</li>
<li>We must also store the last index executed for each client so far to recognize duplicated commands even after a crash.</li>
<li>The index of the last applied entry is also stored to prevent the first command after recovery is a read-only operation.</li>
</ol>
<h1 id="what-needs-to-be-done-to-recover-the-state-after-a-crash"><a class="markdownIt-Anchor" href="#what-needs-to-be-done-to-recover-the-state-after-a-crash"></a> What needs to be done to recover the state after a crash?</h1>
<ol>
<li>First, we need to install the latest snapshot persisted.</li>
<li>But that is not enough if only the KV server crashes while the associated Raft server is still running since there might still be some committed entries not included in the snapshot yet applied before the crash. The KV server needs to acquire those committed entries to truly bring itself back to the state right before the crash.</li>
</ol>
<h1 id="execution-speed-of-get-operation"><a class="markdownIt-Anchor" href="#execution-speed-of-get-operation"></a> Execution speed of Get operation:</h1>
<ol>
<li>When running the test without enabling snapshot:
<ul>
<li>The time spent for each operation of the un-optimized implementation will become slower as the number of operations grows. This is because each Raft server’s log becomes larger and slower to persist.</li>
<li>When executing the Get operation, the log of optimized implementation won’t increase. Hence, it won’t slow down the execution.</li>
<li>When executing <em>3000</em> Get operations, the un-optimized implementation needs about <em>50 ms/op</em>, while the optimized implementation only needs <em>1.7 ms/op</em>, about 29 times the speedup.</li>
</ul>
</li>
<li>When running the test enabling snapshot:
<ul>
<li>The time spent on the un-optimized implementation has become stable since the log size has become stable. However, when only executing the Get operation, the optimized implementation does not need the benefit of trimming logs.</li>
<li>When executing <em>3000</em> Get operations, the un-optimized implementation needs about <em>14.7 ms/op</em>, while the optimized implementation is still <em>1.7 ms/op</em>, about <em>8.6</em> times speedup.</li>
<li>I think that the speedup of the optimized read-only scheme comes from two parts: follower concurrency that increased the total bandwidth between clients and servers and the persisting time saved by eliminating Get operation entries from logs.</li>
</ul>
</li>
</ol>
<h1 id="execution-speed-of-putappend-operation"><a class="markdownIt-Anchor" href="#execution-speed-of-putappend-operation"></a> Execution speed of PutAppend operation:</h1>
<ol>
<li>When executing <em>1000</em> Put operations without enabling snapshots, both implementations need about <em>29.5 ms/op</em>. Executing Append operations needs about the same amount of time.</li>
<li>When executing <em>1000</em> Put operations enabling snapshot, both implementations need about <em>13.9 ms/op</em>. Executing Append operations needs about the same amount of time.</li>
<li>Thus, with snapshot enabled, it can achieve about <em>2.1</em> times speedup. I think the speedup mainly comes from the persisting time saved by shrinking the log.</li>
</ol>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://liyun-zhang.github.io/2023/03/26/OpenSource/6.824/Lab-2-Raft/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="LiyunZhang">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="LiyunZhang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | LiyunZhang">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2023/03/26/OpenSource/6.824/Lab-2-Raft/" class="post-title-link" itemprop="url">Lab 2: Raft</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2023-03-26 13:57:11" itemprop="dateCreated datePublished" datetime="2023-03-26T13:57:11+08:00">2023-03-26</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">Edited on</span>
      <time title="Modified: 2024-03-17 11:28:50" itemprop="dateModified" datetime="2024-03-17T11:28:50+08:00">2024-03-17</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">In</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Open-Source-Code/" itemprop="url" rel="index"><span itemprop="name">Open Source Code</span></a>
        </span>
          , 
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Open-Source-Code/6-824/" itemprop="url" rel="index"><span itemprop="name">6.824</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p><ul class="markdownIt-TOC">
<li><a href="#leader-election">Leader election</a>
<ul>
<li><a href="#how-to-count-the-votes-a-candidate-gets">How to count the votes a candidate gets?</a></li>
<li><a href="#how-does-each-server-initial-an-election">How does each server initial an election?</a></li>
<li><a href="#how-can-we-prevent-partitioned-followers-from-ending-up-in-a-high-term">How can we prevent partitioned followers from ending up in a high term?</a></li>
</ul>
</li>
<li><a href="#log-replication">Log Replication</a>
<ul>
<li><a href="#how-does-the-leader-send-log-entries-to-followers">How does the leader send log entries to followers?</a></li>
<li><a href="#how-to-optimize-the-consistency-check-protocol">How to optimize the consistency check protocol?</a></li>
<li><a href="#how-should-a-follower-accept-log-entries-after-passing-all-consistency-checks">How should a follower accept log entries after passing all consistency checks?</a></li>
<li><a href="#how-will-each-server-commit-an-index">How will each server commit an index?</a></li>
<li><a href="#how-does-the-leader-check-which-entries-can-be-committed">How does the leader check which entries can be committed?</a></li>
<li><a href="#what-is-the-constraint-of-committing-uncommitted-entries-of-earlier-terms">What is the constraint of committing uncommitted entries of earlier terms?</a></li>
</ul>
</li>
<li><a href="#persistence">Persistence</a>
<ul>
<li><a href="#when-a-server-restarts-what-information-should-it-restore">When a server restarts, what information should it restore?**</a></li>
<li><a href="#when-will-invoke-persist">When will invoke persist()?</a></li>
</ul>
</li>
<li><a href="#log-compaction">Log compaction</a>
<ul>
<li><a href="#how-to-deal-with-those-deleted-entries-when-a-server-restarts">How to deal with those deleted entries when a server restarts?</a></li>
<li><a href="#how-to-take-a-snapshot">How to take a snapshot?</a></li>
<li><a href="#how-to-install-a-snapshot">How to install a snapshot?</a></li>
</ul>
</li>
</ul>
</p>
<h1 id="leader-election"><a class="markdownIt-Anchor" href="#leader-election"></a> Leader election</h1>
<h2 id="how-to-count-the-votes-a-candidate-gets"><a class="markdownIt-Anchor" href="#how-to-count-the-votes-a-candidate-gets"></a> How to count the votes a candidate gets?</h2>
<ol>
<li>The candidate begins a new goroutine to request votes from each server.</li>
<li>Use a shared variable to track how many votes the candidate has gotten. After this vote, each goroutine monitors that the candidate has gotten enough votes to become a leader independently.</li>
<li>When each goroutine receives a reply from other peers, it needs to check whether the reply is still in the same term as the term where it is now and whether it is still a candidate.
<ul>
<li>Only checking its state is insufficient. The check of the term is in case delayed replies arrive in the future election initialed by this server.</li>
</ul>
</li>
<li>My initial thought
<ul>
<li>The election goroutine will monitor the process of votes instead of the request goroutines.</li>
<li>Then the check loop in the election goroutine needs to sleep after each time it fails. Or the election would be hard to converge.</li>
<li>I GUESS that the reason is the for-loop never ends and takes too many resources, causing the CPU to not schedule the RequestVote goroutine and later election goroutines in time.</li>
</ul>
</li>
</ol>
<h2 id="how-does-each-server-initial-an-election"><a class="markdownIt-Anchor" href="#how-does-each-server-initial-an-election"></a> How does each server initial an election?</h2>
<ol>
<li>A timestamp records the last time heard from a leader or candidate. And <code>electionTimeout</code> is set randomly at the startup and beginning of the election.
<ul>
<li>Each time the server wants to change its state into a follower, it must reset the timestamp before switching, or it may trigger a new election due to the stale timestamp.</li>
<li>When the replied term is larger than the term of sending <code>AppendEntries</code>, the leader should know that itself is out-of-date. But before any further settings, it should check whether the replied term is larger than the term where it is now to prevent this being a stale reply processed with a stale term, causing currectTerm to decrease.</li>
</ul>
</li>
<li><code>ticker()</code> will check periodically whether the time since the timestamp is larger than the <code>electionTimeout</code> and if so, a new election is initiated.
<ul>
<li>When the checking is failed, this goroutine should sleep for a short time. However, it cannot simply sleep as long as <code>electionTimeout</code> because the next sleep may be shorter than <code>electionTimeout</code>.</li>
</ul>
</li>
<li>Another way is to set the <code>electionTimeout </code> when checking the condition instead of fixing the electionTimeout`` between two elections.
<ul>
<li>But this will cause multiple peers to initiate an election in a short gap. In addition to the unreliable network and the burden of scheduling goroutines, the <code>RequestVote()</code> may not be executed by others immediately, causing severe brain split and re-elections.</li>
<li>The reason, I GUESS, is that it only needs one short sleep time to kick off the election. And with a new random sleep time every <code>CHECKTIMEOUT</code> ms, there is a greater probability that one sleep time is short, which shortens the <code>electionTimeout</code> I want.</li>
</ul>
</li>
</ol>
<h2 id="how-can-we-prevent-partitioned-followers-from-ending-up-in-a-high-term"><a class="markdownIt-Anchor" href="#how-can-we-prevent-partitioned-followers-from-ending-up-in-a-high-term"></a> How can we prevent partitioned followers from ending up in a high term?</h2>
<ol>
<li>The problem is that when a follower is partitioned, it cannot receive from the leader. It will try to be elected to be the leader. Yet, because it cannot connect to the majority of its peers, it can never succeed, causing it to keep increasing its term.</li>
<li>To solve the problem, we need to make a peer realize that it has no chance to be elected to be the leader and gives up increasing their term.
<ul>
<li>Before truly increasing its term, we can ask it to simulate the election, i.e., pre-vote.</li>
<li>During the pre-vote, the candidate will send the same data as the true election, and other peers will reply whether they will vote for a candidate.</li>
<li>An actual election is initiated until a peer has received a pre-vote from the majority.</li>
</ul>
</li>
<li>The difference between a pre-vote and an actual election:
<ul>
<li>The pre-vote can grant votes to different peers in the same term.</li>
<li>The pre-vote will not cause voters to increase the term and become followers.</li>
<li>The pre-vote happens before increasing the term.</li>
</ul>
</li>
<li>The disadvantage of the pre-vote is that it requires an extra round of RPC for an election.
<ul>
<li>This cost is significantly unacceptable when the network is too unreliable, causing many elections.</li>
<li>When the network is more stable, the elections are rare, and it can prevent partitioned followers from interrupting the current term.</li>
</ul>
</li>
</ol>
<h1 id="log-replication"><a class="markdownIt-Anchor" href="#log-replication"></a> Log Replication</h1>
<h2 id="how-does-the-leader-send-log-entries-to-followers"><a class="markdownIt-Anchor" href="#how-does-the-leader-send-log-entries-to-followers"></a> How does the leader send log entries to followers?</h2>
<ol>
<li><code>nextIndex</code> is the lowest index of entries missed by each peer known by the leader.</li>
<li>There are two situations for sending log entries: the first is when there are some un-replicated entries for some followers, and the second is the heartbeat message.
<ul>
<li><code>SyncLogWithFollower(x int)</code> is implemented to check whether server x has some missing entries.</li>
<li><code>Heartbeat()</code> is implemented to send a heartbeat message.</li>
<li><code>SendEntriesOnceTo(x int)</code> is implemented actually to send log entries to server x.</li>
<li>The <code>SyncLogWIthFollower()</code> goroutine for each server and the <code>Heartbeat()</code> goroutine is initiated when the server is elected leader.</li>
</ul>
</li>
<li>The difference between <code>SyncLogWithFollower()</code> and <code>Heartbeat()</code>
<ul>
<li><code>SyncLogWithFollower()</code> sends entries only when there are missing entries in server x. But <code>Heartbeat()</code> always sends entries even when there are no missing entries, in which case an empty log is sent.</li>
<li>The check cycle in <code>SyncLogWithFollower()</code> is way shorter than the sending cycle in <code>Heartbeat()</code> to ensure the missing entries can be replicated as soon as possible.</li>
</ul>
</li>
<li>When <code>SyncLogWithFollower()</code> calls <code>SendEntriesOnceTo()</code>, it cannot create a goroutine.
<ul>
<li>Because the check cycle in <code>SyncLogWithFollower()</code> is quite short, if the <code>SyncLogWithFollower()</code> goroutine keeps being scheduled, the <code>SendEntriesOnceTo()</code> cannot send entries to the follower. Thus, the <code>SyncLogWithFollower()</code> goroutine keeps creating too many <code>SendEntriesOnceTo()</code> goroutine.</li>
</ul>
</li>
<li>My initial thought
<ul>
<li>Start a <code>SendEntriesOnceTo()</code> goroutine for every follower after <code>Start()</code> has added a new log entry to the leader’s logs instead of using <code>SyncLogWithFollower()</code> goroutine.</li>
<li>But concurrent Start() may cause multiple <code>SendEntriesOnceTo()</code> goroutines to send the same RPC to the same follower.</li>
</ul>
</li>
</ol>
<h2 id="how-to-optimize-the-consistency-check-protocol"><a class="markdownIt-Anchor" href="#how-to-optimize-the-consistency-check-protocol"></a> How to optimize the consistency check protocol?</h2>
<ol>
<li>Additional AppenEntries RPC results for fast rollback:
<ul>
<li><code>Xterm</code>: the term of the conflicting entry.</li>
<li><code>Xindex</code>: the first index in <code>Xterm</code>.</li>
<li><code>Xlen</code>: the length of the log</li>
</ul>
</li>
<li>Fast rollback implementation:
<ul>
<li>If the leader doesn’t have <code>Xterm</code>, then every entry of Xterm in the follower’s log will cause conflict. Hence, the <code>nextIndex</code> can back up to <code>Xindex</code>.</li>
<li>If the leader has <code>Xterm</code>, the matching entry in the leader’s log must have a term no larger than <code>Xterm</code>. Hence, the <code>nextIndex</code> should go back to the next entry of the last Xterm in the leader’s log.</li>
<li>If the follower’s conflict is due to empty in <code>prevLogTerm</code>, then <code>Xterm</code> is set to <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>−</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">-1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.72777em;vertical-align:-0.08333em;"></span><span class="mord">−</span><span class="mord">1</span></span></span></span>, and the leader should back up to <code>Xlen</code>.</li>
</ul>
</li>
</ol>
<h2 id="how-should-a-follower-accept-log-entries-after-passing-all-consistency-checks"><a class="markdownIt-Anchor" href="#how-should-a-follower-accept-log-entries-after-passing-all-consistency-checks"></a> How should a follower accept log entries after passing all consistency checks?</h2>
<ol>
<li>The <code>nextIndex</code> and <code>logs</code> of the leader can be updated by different goroutines of <code>SendEntriesOnce()</code> and <code>Start()</code>. So it is possible that <code>args.Entries</code> are chosen through a stale <code>nextIndex</code> and an up-to-date <code>log</code> or even a stale <code>nextIndex</code> and a stale <code>log</code>.</li>
<li>If the <code>nextIndex</code> is stale while the <code>log</code> is up-to-date, i.e., there are some entries after the nextIndex is already replicated by the follower.
<ul>
<li>Then we need to drop those replicated entries, but not all, since there could still be some new entries.</li>
<li>We need to drop those entries with the same index and the same term according to the Log Matching property and append only those different entries.</li>
<li>I didn’t consider the case of <code>nextIndex</code> being larger than the follower’s replicated indices. Transmission won’t succeed, and a fast backup will be triggered.</li>
</ul>
</li>
<li>If both the <code>nextIndex</code> and <code>logs</code> are stale, it is similar to the former situation since the only additional problem is that it cannot be brought up-to-date by one <code>AppendEntries</code>.</li>
</ol>
<h2 id="how-will-each-server-commit-an-index"><a class="markdownIt-Anchor" href="#how-will-each-server-commit-an-index"></a> How will each server commit an index?</h2>
<ol>
<li><code>commitIndex</code> is the highest index of entries that can commit now. This is included in the <code>AppendEntries</code> arguments from leader to followers.</li>
<li><code>lastApplied</code> is the highest index of committed entries. If <code>lastApplied</code> is no larger than <code>commitIndex</code>, a server can commit the entry next to <code>lastApplied</code>.</li>
<li>Followers cannot modify <code>commitIndex</code> before the logs are synchronized since there may be some entries that need to be wiped out by the leader.</li>
</ol>
<h2 id="how-does-the-leader-check-which-entries-can-be-committed"><a class="markdownIt-Anchor" href="#how-does-the-leader-check-which-entries-can-be-committed"></a> How does the leader check which entries can be committed?</h2>
<ol>
<li>My solution
<ul>
<li><code>matchIndex</code> tracks the highest indices of entries replicated by each peer.</li>
<li>When a group of entries that ends with index <code>i</code> is accepted by one peer, the leader first sets the corresponding <code>matchIndex</code> to <code>i</code>.</li>
<li>Then, check whether a majority of <code>matchIndex</code> is larger than <code>i</code>. If so, the leader can commit at least until <code>i</code>, or it won’t commit any entry.</li>
</ul>
</li>
<li>Improvement
<ul>
<li>When a lagged peer replicated a lot of entries, it may be insufficient to commit the last entry it replicated. It could be sufficient to commit some earlier entries.</li>
<li>We only need to commit the k-th largest index in <code>matchIndex</code>.</li>
</ul>
</li>
<li>My initial thought
<ul>
<li>Track the replication state of each entry instead of each peer.</li>
<li>However, the entries are a lot more than peers, causing higher time complexity to maintain when a lot of entries are by peers.</li>
</ul>
</li>
</ol>
<h2 id="what-is-the-constraint-of-committing-uncommitted-entries-of-earlier-terms"><a class="markdownIt-Anchor" href="#what-is-the-constraint-of-committing-uncommitted-entries-of-earlier-terms"></a> What is the constraint of committing uncommitted entries of earlier terms?</h2>
<ol>
<li>A constraint on commit entries is that each leader can only commit entries added to the term. And by committing such entries, they also commit all entries before it. Hence, the entries of earlier terms are committed indirectly.</li>
<li>But there is a corner case where a leader doesn’t receive any entry at the beginning of its term, causing those uncommitted entries of earlier terms not to be committed.</li>
<li>My solution is that when a server becomes the leader, it will add an empty entry, and by this empty entry, those uncommitted entries can be committed.</li>
<li>However, the test system of 6.824 didn’t consider this case. This implementation will cause all tests to fail.</li>
</ol>
<h1 id="persistence"><a class="markdownIt-Anchor" href="#persistence"></a> Persistence</h1>
<h2 id="when-a-server-restarts-what-information-should-it-restore"><a class="markdownIt-Anchor" href="#when-a-server-restarts-what-information-should-it-restore"></a> When a server restarts, what information should it restore?**</h2>
<ol>
<li>Naturally, it must restore its <code>currentTerm</code>, <code>votedFor</code>, and <code>logs</code> from the persisted state.</li>
<li>Then, it needs to set its <code>lastLogIndex</code> and <code>lastLogTerm</code> appropriately.</li>
<li>The <code>lastApplied</code>, <code>commitIndex</code>, and <code>lastIncludedIndex</code> will be set to the index of the sentinel entry.
<ul>
<li>Because the current state is the same state executed until the sentinel entry.</li>
<li>In the future, if the server finds that other peers have committed later entries, it needs to re-execute those entries to achieve the same state.</li>
</ul>
</li>
<li>It should update its <code>lastApplied</code> to the last committed entry according to the commit state in each log entry.</li>
</ol>
<h2 id="when-will-invoke-persist"><a class="markdownIt-Anchor" href="#when-will-invoke-persist"></a> When will invoke persist()?</h2>
<ol>
<li><code>persist()</code> is called only when <code>rf.currentTerm</code>, <code>rf.votedFor</code>, or <code>rf.logs</code> is changed.</li>
<li>When they’re changed, the <code>rf.mu</code> lock must be held by the caller of <code>persist()</code>. I won’t release the lock until the <code>persist()</code> is finished to store the states as soon as possible.</li>
<li>Modifying the three variables several times before communicating with outside or releasing the lock is possible. In that case, we use a variable to mark whether persist is needed instead of really calling <code>persist()</code> each time. And only call the <code>persist()</code> at the end.</li>
</ol>
<h1 id="log-compaction"><a class="markdownIt-Anchor" href="#log-compaction"></a> Log compaction</h1>
<h2 id="how-to-deal-with-those-deleted-entries-when-a-server-restarts"><a class="markdownIt-Anchor" href="#how-to-deal-with-those-deleted-entries-when-a-server-restarts"></a> How to deal with those deleted entries when a server restarts?</h2>
<ol>
<li>When a server restores its state from <code>readPersist()</code>, we want it to re-execute those persisted logs.</li>
<li>But we don’t need to re-execute those deleted entries since we can get to the state of the last deleted log by restoring the snapshot without execution.</li>
<li>The effect is the same as we have committed those missing entries. So, we also need to modify the <code>lastApplied</code> and <code>commitIndex</code> to the last deleted log index before re-executing.</li>
</ol>
<h2 id="how-to-take-a-snapshot"><a class="markdownIt-Anchor" href="#how-to-take-a-snapshot"></a> How to take a snapshot?</h2>
<ol>
<li>In this lab, the snapshot is naive. It simply stores all the log entries.</li>
<li>Hence, the server must set <code>lastIncludedIndex</code> and <code>lastIncludedTerm</code> appropriately, and all the snapshotted entries must be removed.</li>
<li>Also, if the log is empty after removal, we need to insert the sentinel entry back into the entry. Its command is still unimportant.</li>
</ol>
<h2 id="how-to-install-a-snapshot"><a class="markdownIt-Anchor" href="#how-to-install-a-snapshot"></a> How to install a snapshot?</h2>
<ol>
<li>The snapshot data only contains commands in log entries, so we need to recover the log entries with the snapshot.
<ul>
<li>Their indices and commands are easy to understand.</li>
<li>We only know the <code>lastIncludedterm</code>. Also, the leader has already committed to these entries. Thus, no matter what happens, these entries will not be overwritten, and no <code>AppendEntry</code> will need to compare with these entries except for the last one. Hence, for convenience, I set all their terms to the <code>LastIncludedTerm</code>.</li>
<li>As aforementioned, these entries are already reflected in the snapshot. Thus, there is no need to re-commit them again.</li>
</ul>
</li>
<li>Then, we need to determine whether the snapshot contains new information.
<ul>
<li><code>FirstUncover</code> indicates the first entry in <code>logs</code> that is more up-to-date than the last entry in the snapshot.
<ul>
<li>If the snapshot contains new information not already in the recipient’s log, then <code>firstUncover == len(rf.logs)</code>.</li>
<li>If the snapshot describes a prefix of its log, then <code>firstUncover &lt; len(rf.logs)</code>, we only need to delete the former entries.</li>
</ul>
</li>
<li>I thought that maybe I needed to compare the <code>lastLogIndex</code> in the server and the <code>LastIncludedIndex</code> in the snapshot, but this is insufficient.
<ul>
<li>Some servers need to discard the last few entries from earlier leaders, yet they are not in the current leader’s logs.</li>
<li>We need to remove the entries whose term is smaller than the <code>LastIncludedTerm</code> of the snapshot and whose index is larger than the <code>LastIncludedIndex</code>.</li>
</ul>
</li>
</ul>
</li>
<li>If the snapshot contains new information
<ul>
<li>We will discard all log entries and insert a new sentinel entry with an index equal to <code>LastIncludedIndex</code> and a term equal to <code>LastIncludedTerm</code>.</li>
<li>Then <code>commitIndex</code> and <code>lastApplied</code> need to be updated to <code>LastIncludedIndex</code> since we won’t re-execute those new entries in the snapshot.</li>
<li>It needs to be persisted.</li>
</ul>
</li>
<li>If the snapshot describes only a prefix of logs, then discard the covered entries. But don’t discard those covered yet uncommitted entries, and leave one entry as a dummy entry.</li>
<li>If PrevLog is already trimmed, we should find the entry with the same index as the sentinel. Make it the new <code>PrevLog</code>, and only accept the entries following it.</li>
</ol>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://liyun-zhang.github.io/2022/07/24/Courses/CS149/16-Heterogeneous-Parallelism-and-Hardware-Specialization/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="LiyunZhang">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="LiyunZhang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | LiyunZhang">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2022/07/24/Courses/CS149/16-Heterogeneous-Parallelism-and-Hardware-Specialization/" class="post-title-link" itemprop="url">16. Heterogeneous Parallelism and Hardware Specialization</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2022-07-24 15:20:29" itemprop="dateCreated datePublished" datetime="2022-07-24T15:20:29+08:00">2022-07-24</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">Edited on</span>
      <time title="Modified: 2024-03-16 23:01:34" itemprop="dateModified" datetime="2024-03-16T23:01:34+08:00">2024-03-16</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">In</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Open-Courses/" itemprop="url" rel="index"><span itemprop="name">Open Courses</span></a>
        </span>
          , 
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Open-Courses/CMU-15-418-Stanford-CS149-Parallel-Computing/" itemprop="url" rel="index"><span itemprop="name">CMU 15-418 / Stanford CS149 Parallel Computing</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <ol>
<li>Amdahl’s law in terms of resource limits: <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>s</mi><mi>p</mi><mi>e</mi><mi>e</mi><mi>d</mi><mi>u</mi><mi>p</mi><mo stretchy="false">(</mo><mi>f</mi><mo separator="true">,</mo><mi>n</mi><mo separator="true">,</mo><mi>r</mi><mo stretchy="false">)</mo><mo>=</mo><mfrac><mn>1</mn><mrow><mfrac><mrow><mn>1</mn><mo>−</mo><mi>f</mi></mrow><mrow><mi>p</mi><mi>e</mi><mi>r</mi><mi>f</mi><mo stretchy="false">(</mo><mi>r</mi><mo stretchy="false">)</mo></mrow></mfrac><mo>+</mo><mfrac><mi>f</mi><mrow><mi>p</mi><mi>e</mi><mi>r</mi><mi>f</mi><mo stretchy="false">(</mo><mi>r</mi><mo stretchy="false">)</mo><mo>⋅</mo><mfrac><mi>n</mi><mi>r</mi></mfrac></mrow></mfrac></mrow></mfrac></mrow><annotation encoding="application/x-tex">speedup(f, n, r)=\frac{1}{\frac{1-f}{perf(r)}+\frac{f}{perf(r)\cdot\frac{n}{r}}}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">s</span><span class="mord mathnormal">p</span><span class="mord mathnormal">e</span><span class="mord mathnormal">e</span><span class="mord mathnormal">d</span><span class="mord mathnormal">u</span><span class="mord mathnormal">p</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal">n</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.877228em;vertical-align:-1.03212em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.845108em;"><span style="top:-2.51911em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mopen nulldelimiter sizing reset-size3 size6"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.9584142857142857em;"><span style="top:-2.640785714285714em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">p</span><span class="mord mathnormal mtight">e</span><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span><span class="mord mathnormal mtight" style="margin-right:0.10764em;">f</span><span class="mopen mtight">(</span><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span><span class="mclose mtight">)</span></span></span></span><span style="top:-3.2255000000000003em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line mtight" style="border-bottom-width:0.049em;"></span></span><span style="top:-3.4623857142857144em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight">1</span><span class="mbin mtight">−</span><span class="mord mathnormal mtight" style="margin-right:0.10764em;">f</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.5377857142857143em;"><span></span></span></span></span></span><span class="mclose nulldelimiter sizing reset-size3 size6"></span></span><span class="mbin mtight">+</span><span class="mord mtight"><span class="mopen nulldelimiter sizing reset-size3 size6"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.9584142857142857em;"><span style="top:-2.5925285714285713em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">p</span><span class="mord mathnormal mtight">e</span><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span><span class="mord mathnormal mtight" style="margin-right:0.10764em;">f</span><span class="mopen mtight">(</span><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span><span class="mclose mtight">)</span><span class="mbin mtight">⋅</span><span class="mord mtight"><span class="mopen nulldelimiter sizing reset-size1 size6"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8175600000000001em;"><span style="top:-2.468em;"><span class="pstrut" style="height:3em;"></span><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span></span></span><span style="top:-3.2255000000000003em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line mtight" style="border-bottom-width:0.049em;"></span></span><span style="top:-3.387em;"><span class="pstrut" style="height:3em;"></span><span class="mord mtight"><span class="mord mathnormal mtight">n</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.532em;"><span></span></span></span></span></span><span class="mclose nulldelimiter sizing reset-size1 size6"></span></span></span></span></span><span style="top:-3.2255000000000003em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line mtight" style="border-bottom-width:0.049em;"></span></span><span style="top:-3.4623857142857144em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.10764em;">f</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.7874714285714286em;"><span></span></span></span></span></span><span class="mclose nulldelimiter sizing reset-size3 size6"></span></span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.03212em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span>. Here, <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>f</mi><mo>=</mo></mrow><annotation encoding="application/x-tex">f =</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span></span></span></span> fraction of a program that is parallelizable, <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi><mo>=</mo></mrow><annotation encoding="application/x-tex">n =</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathnormal">n</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span></span></span></span> total processing resources, <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>r</mi><mo>=</mo></mrow><annotation encoding="application/x-tex">r =</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span></span></span></span> resources dedicated to each processing core, each of the <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mi>n</mi><mi>r</mi></mfrac></mrow><annotation encoding="application/x-tex">\frac{n}{r}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.040392em;vertical-align:-0.345em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.695392em;"><span style="top:-2.6550000000000002em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">n</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.345em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span> cores have sequential performance <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi><mi>e</mi><mi>r</mi><mi>f</mi><mo stretchy="false">(</mo><mi>r</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">perf(r)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">p</span><span class="mord mathnormal">e</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mclose">)</span></span></span></span>.</li>
<li>If a processor has one <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi><mi>e</mi><mi>r</mi><mi>f</mi><mo stretchy="false">(</mo><mi>r</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">perf(r)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">p</span><span class="mord mathnormal">e</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mclose">)</span></span></span></span> core and <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi><mo>−</mo><mi>r</mi></mrow><annotation encoding="application/x-tex">n-r</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.66666em;vertical-align:-0.08333em;"></span><span class="mord mathnormal">n</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span></span></span></span> <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi><mi>e</mi><mi>r</mi><mi>f</mi><mo stretchy="false">(</mo><mn>1</mn><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">perf(1)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">p</span><span class="mord mathnormal">e</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="mopen">(</span><span class="mord">1</span><span class="mclose">)</span></span></span></span> cores, its <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>s</mi><mi>p</mi><mi>e</mi><mi>e</mi><mi>d</mi><mi>u</mi><mi>p</mi><mo stretchy="false">(</mo><mi>f</mi><mo separator="true">,</mo><mi>n</mi><mo separator="true">,</mo><mi>r</mi><mo stretchy="false">)</mo><mo>=</mo><mfrac><mn>1</mn><mrow><mfrac><mrow><mn>1</mn><mo>−</mo><mi>f</mi></mrow><mrow><mi>p</mi><mi>e</mi><mi>r</mi><mi>f</mi><mo stretchy="false">(</mo><mi>r</mi><mo stretchy="false">)</mo></mrow></mfrac><mo>+</mo><mfrac><mi>f</mi><mrow><mi>p</mi><mi>e</mi><mi>r</mi><mi>f</mi><mo stretchy="false">(</mo><mi>r</mi><mo stretchy="false">)</mo><mo>+</mo><mo stretchy="false">(</mo><mi>n</mi><mo>−</mo><mi>r</mi><mo stretchy="false">)</mo><mi>p</mi><mi>e</mi><mi>r</mi><mi>f</mi><mo stretchy="false">(</mo><mn>1</mn><mo stretchy="false">)</mo></mrow></mfrac></mrow></mfrac></mrow><annotation encoding="application/x-tex">speedup(f, n, r)=\frac{1}{\frac{1-f}{perf(r)}+\frac{f}{perf(r)+(n-r)perf(1)}}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">s</span><span class="mord mathnormal">p</span><span class="mord mathnormal">e</span><span class="mord mathnormal">e</span><span class="mord mathnormal">d</span><span class="mord mathnormal">u</span><span class="mord mathnormal">p</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal">n</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.702448em;vertical-align:-0.8573399999999999em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.845108em;"><span style="top:-2.5191100000000004em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mopen nulldelimiter sizing reset-size3 size6"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.9584142857142857em;"><span style="top:-2.640785714285714em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">p</span><span class="mord mathnormal mtight">e</span><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span><span class="mord mathnormal mtight" style="margin-right:0.10764em;">f</span><span class="mopen mtight">(</span><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span><span class="mclose mtight">)</span></span></span></span><span style="top:-3.2255000000000003em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line mtight" style="border-bottom-width:0.049em;"></span></span><span style="top:-3.4623857142857144em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight">1</span><span class="mbin mtight">−</span><span class="mord mathnormal mtight" style="margin-right:0.10764em;">f</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.5377857142857143em;"><span></span></span></span></span></span><span class="mclose nulldelimiter sizing reset-size3 size6"></span></span><span class="mbin mtight">+</span><span class="mord mtight"><span class="mopen nulldelimiter sizing reset-size3 size6"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.9584142857142857em;"><span style="top:-2.640785714285714em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">p</span><span class="mord mathnormal mtight">e</span><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span><span class="mord mathnormal mtight" style="margin-right:0.10764em;">f</span><span class="mopen mtight">(</span><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span><span class="mclose mtight">)</span><span class="mbin mtight">+</span><span class="mopen mtight">(</span><span class="mord mathnormal mtight">n</span><span class="mbin mtight">−</span><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span><span class="mclose mtight">)</span><span class="mord mathnormal mtight">p</span><span class="mord mathnormal mtight">e</span><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span><span class="mord mathnormal mtight" style="margin-right:0.10764em;">f</span><span class="mopen mtight">(</span><span class="mord mtight">1</span><span class="mclose mtight">)</span></span></span></span><span style="top:-3.2255000000000003em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line mtight" style="border-bottom-width:0.049em;"></span></span><span style="top:-3.4623857142857144em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.10764em;">f</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.5377857142857143em;"><span></span></span></span></span></span><span class="mclose nulldelimiter sizing reset-size3 size6"></span></span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.8573399999999999em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span>.</li>
<li>Most “real world” applications have complex workload characteristics. The most efficient processor is a heterogeneous mixture of resources, namely use the most efficient tool for the job.</li>
<li>Supercomputers are energy constrained due to shear scale and overall cost to operate (power for machine and cooling)<br />
Datacenters are energy-constrained to reduce cooling costs and physical space requirements.<br />
Mobile devices are energy constrained due to limited battery life and heat dissipation.</li>
<li>The challenge of heterogeneous for system designers: what is the right mixture of resources to meet performance, cost, and energy goals?<br />
Too few throughput-oriented resources would lower peak throughput for parallel workloads. Too few sequential processing resources limit the overall system by sequential part of the workload. How much chip area should be dedicated to a specific function? (these resources are taken away from general-purpose processing) Work balance must be anticipated at chip design time</li>
<li>The challenge to software developers: how to map programs onto a heterogeneous collection of resources?<br />
Wish to design algorithms that decompose well into components that each map well to different processing components of the machine. The scheduling problem is more complex in a heterogeneous system. An available mixture of resources can dictate the choice of algorithm: software portability and maintenance nightmare.</li>
<li>Reducing energy consumption should use specialized processing and moving less data.</li>
</ol>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://liyun-zhang.github.io/2022/07/21/Courses/CS149/15-Transactional-Memory/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="LiyunZhang">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="LiyunZhang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | LiyunZhang">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2022/07/21/Courses/CS149/15-Transactional-Memory/" class="post-title-link" itemprop="url">15. Transactional Memory</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2022-07-21 22:53:19" itemprop="dateCreated datePublished" datetime="2022-07-21T22:53:19+08:00">2022-07-21</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">Edited on</span>
      <time title="Modified: 2024-03-16 22:58:55" itemprop="dateModified" datetime="2024-03-16T22:58:55+08:00">2024-03-16</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">In</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Open-Courses/" itemprop="url" rel="index"><span itemprop="name">Open Courses</span></a>
        </span>
          , 
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Open-Courses/CMU-15-418-Stanford-CS149-Parallel-Computing/" itemprop="url" rel="index"><span itemprop="name">CMU 15-418 / Stanford CS149 Parallel Computing</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="transactional-memory"><a class="markdownIt-Anchor" href="#transactional-memory"></a> Transactional memory</h1>
<ol>
<li>
<p>Declarative programming is when the programmer states what to do, not how to do it. The system implements synchronization as necessary to ensure atomicity.</p>
</li>
<li>
<p>In transaction memory, the atomic construct is declarative, which means that the programmer states what to do, not how to do it. The system implements synchronization as necessary to ensure atomicity.<br />
The system could implement <code>atomic&#123;&#125;</code> using a lock. However, the programmer has no explicit use or management of locks.</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Traditional method</span></span><br><span class="line"><span class="built_in">lock</span>(mutex);</span><br><span class="line"><span class="comment">//critical code</span></span><br><span class="line"><span class="built_in">unlock</span>(mutex);</span><br><span class="line"></span><br><span class="line"><span class="comment">// Transaction memory</span></span><br><span class="line">atomic &#123;</span><br><span class="line">  <span class="comment">// critical code</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
<li>
<p>Memory transaction is an atomic and isolated sequence of memory accesses inspired by database transactions.<br />
Atomicity requires that upon transaction commit, all memory writes in the transaction take effect at once, and on transaction abort, none of the writes appear to take effect as if the transaction never happened.<br />
Isolation means that no other processor can observe writes before committing the transaction.<br />
Serializability is that transactions appear to commit in a single serial order, but transaction semantics does not guarantee the exact order of commits.</p>
</li>
<li>
<p>Load-linked, store conditional (LL/SC) is a light version of transactional memory. It has a pair of corresponding instructions (not a single atomic instruction)<br />
<code>load_linked(x)</code>: load value from address<br />
<code>store_conditional(x, value)</code>: store value to x, if x hasn’t been written to since<br />
corresponding LL</p>
</li>
<li>
<p>Two read operations won’t cause true contention. In TM, we can allow the parallelism between two read operations. However, serialization must be ensured when at least one write operation occurs.</p>
</li>
<li>
<p>The transactional memory system is also responsible for processing exceptions, decreasing the complexity of manually using try-catch statements to catch exceptions.<br />
When an exception inside the atomic block occurs, the transaction is aborted, and memory updates are undone.</p>
</li>
<li>
<p>A transactional memory system needs composable locks.<br />
Composing lock-based code can be tricky, requiring system-wide policies to get correct, and can break software modularity.<br />
The following code can end up in a deadlock. TM system should be able to compose the two synchronizations together to avoid the possible deadlock. A programmer can use an <code>atomic&#123;&#125;</code> to correctly represent the two <code>synchronized &#123;&#125;</code> structures.</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">void</span> <span class="title">function</span><span class="params">(A, B)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">  <span class="built_in">synchronized</span>(A)</span><br><span class="line">  &#123;</span><br><span class="line">    <span class="built_in">synchronized</span>(B)</span><br><span class="line">    &#123;</span><br><span class="line">      <span class="comment">// critical code</span></span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// thread 0</span></span><br><span class="line"><span class="built_in">function</span>(x, y);</span><br><span class="line"></span><br><span class="line"><span class="comment">//thread 1</span></span><br><span class="line"><span class="built_in">function</span>(y, x);</span><br></pre></td></tr></table></figure>
</li>
<li>
<p><code>Atomic&#123;&#125;</code> is not the same as <code>lock()/unlock()</code>. Atomic is a high-level declaration of atomicity, which does not specify the implementation of atomicity. The lock is a low-level blocking primitive that does not provide atomicity or isolation on its own.<br />
Locks can be used to implement an atomic block. Also, locks can be used for purposes beyond atomicity. Namely, we cannot replace all uses of locks with atomic regions.<br />
Atomic eliminates many data races, but programming with atomic blocks can still suffer from atomicity violations.</p>
</li>
<li>
<p>Atomicity violation due to programmer error: Logically, the atomic code sequence is erroneously separated into two atomic blocks.</p>
</li>
</ol>
<h1 id="implementing-transactional-memory"><a class="markdownIt-Anchor" href="#implementing-transactional-memory"></a> Implementing transactional memory</h1>
<h2 id="data-versioning"><a class="markdownIt-Anchor" href="#data-versioning"></a> Data versioning</h2>
<ol>
<li>Data versioning manages uncommitted (new) and previously committed (old) versions of data for concurrent transactions. This is used to allow transaction abort.</li>
<li>Eager versioning updates memory immediately and maintains “undo log” in case of abort.<br />
When a write happens, the old value is pushed into the undo log, and the new value is to memory.<br />
When a transaction is aborted, we can search the undo log to recover the corresponding state.<br />
When the transaction is committed, we can discard the undo log of those committed contents.</li>
<li>Lazy versioning is a deferred update. Namely, it logs memory updates in the transaction write buffer and flushes the buffer on commit.<br />
When a write happens, the new value is pushed into the write buffer, and we don’t write the new value in memory.<br />
When a transaction is aborted, we discard the write buffer, and there is no need to modify the memory since we haven’t written anything to it yet.<br />
When a transaction is committed, we write the data in the write buffer to memory and discard the write buffer.</li>
<li>Eager versioning is faster in commit since data is already in memory. But it is slower in aborts and has fault tolerance issues (crashes in the middle of a transaction). It writes to memory immediately, hoping the transaction won’t abort, but deals with aborts when necessary.</li>
<li>Lazy versioning is faster in abort, clears the log, and has no fault tolerance issues. But it is slower in commits. It only writes to memory when you have to.</li>
</ol>
<h2 id="conflict-detection-and-resolution"><a class="markdownIt-Anchor" href="#conflict-detection-and-resolution"></a> Conflict detection and resolution</h2>
<ol>
<li>This is to decide when to abort. It must detect and handle transaction conflicts, including read-write and write-write conflicts. The system must track a transaction’s read set and write set.</li>
<li>Pessimistic detection checks for conflicts during loads or stores. A hardware implementation will check for conflicts through coherent actions.<br />
The philosophy is, &quot;I suspect conflicts might happen, so let’s always check to see if one has occurred after each memory operation… if I’m going to have to roll back, might as well do it now to avoid wasted work.”</li>
<li>The contention manager decides to stall or abort the transaction when a conflict is detected. A conflict can be stalled when detected before executing (early detection). When a conflict is detected after execution, then it can only restart.<br />
When two writes cause the conflict, it may raise a livelock if both threads restart before the other one has finished.</li>
<li>Optimistic detection detects conflicts when a transaction attempts to commit. Hardware validates the write set using coherence actions and gets exclusive access to cache lines in the write set.<br />
The intuition is, “Let’s hope for the best and sort out all the conflicts only when the transaction tries to commit.”<br />
In a conflict, it gives priority to committing the transactions. Other transactions may be aborted later on. In conflicts between committing transactions, use the contention manager to decide priorities. Optimistic detection won’t cause livelock.</li>
<li>We can use optimistic and pessimistic schemes together. Several STM systems use optimistic for reads and pessimistic for writes.</li>
<li>Pessimistic conflict detection (“eager”) can detect conflicts early and thus undo less work, turning some aborts into stalls. It has no forward progress guarantees, and there are more aborts in some cases. Also, fine-grained communication is required to check on each load/store.<br />
Bad: detection on the critical path</li>
<li>Optimistic conflict detection (“lazy” or “commit”) has forward progress guarantees. It requires bulk communication and conflict detection. It detects conflicts late and can still have fairness problems.</li>
<li>Conflict detection granularity<br />
Object granularity is a software-based technique. It reduces time and space overhead and is close to the programmer’s reasoning. But there might be false sharing on large objects.<br />
Machine word granularity can minimize false sharing but increases the overhead of time and space.<br />
Cache-line granularity is a compromise between an object and a word.</li>
</ol>
<h2 id="hardware-transactional-memory"><a class="markdownIt-Anchor" href="#hardware-transactional-memory"></a> Hardware transactional memory</h2>
<ol>
<li>Data versioning is implemented in caches. Cache the write buffer or the undo log. And add new cache line metadata to track transaction read and write sets.<br />
Conflict detection is implemented through cache coherence protocol. Coherence lookups detect conflicts between transactions. It works with snooping and directory coherence.</li>
<li>Register checkpoint must also be taken at the transaction begins to restore the execution context state on abort.</li>
<li>Cache lines need extra bits to track the read set and write set.<br />
<strong>R bit</strong> indicates data read by transaction and is set on loads, while <strong>W bit</strong> indicates data written by transaction and is set on stores. R/W bits gang-cleared on transaction commit or abort.<br />
R/W bits can be a work or cache-line granularity.<br />
We need a 2nd cache write for the undo log for eager versioning.</li>
<li>Coherence requests check R/W bits to detect conflicts.<br />
Observing shared requests to W-word is a read-write conflict.<br />
Observing exclusive (intent to write) requests to R-word is a write-read conflict.<br />
Observing exclusive (intent to write) requests to W-word is a write-write conflict.</li>
<li>Fast two-phase commit<br />
Validate: request RdX access to write set lines (if needed)<br />
Commit: gang-reset R and W bits, turns to write set data to valid (dirty) data.</li>
<li>Fast conflict detection and abort<br />
Check: lookup exclusive requests in the read set and write set<br />
Abort: invalidate write set, gang-reset R and W bits, restore to register checkpoint</li>
</ol>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://liyun-zhang.github.io/2022/07/17/Courses/CS149/14-Fine-grained-Synchronization-and-Lock-free-Programming/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="LiyunZhang">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="LiyunZhang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | LiyunZhang">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2022/07/17/Courses/CS149/14-Fine-grained-Synchronization-and-Lock-free-Programming/" class="post-title-link" itemprop="url">14. Fine-grained Synchronization and Lock-free Programming</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2022-07-17 11:22:54" itemprop="dateCreated datePublished" datetime="2022-07-17T11:22:54+08:00">2022-07-17</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">Edited on</span>
      <time title="Modified: 2024-03-16 22:13:45" itemprop="dateModified" datetime="2024-03-16T22:13:45+08:00">2024-03-16</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">In</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Open-Courses/" itemprop="url" rel="index"><span itemprop="name">Open Courses</span></a>
        </span>
          , 
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Open-Courses/CMU-15-418-Stanford-CS149-Parallel-Computing/" itemprop="url" rel="index"><span itemprop="name">CMU 15-418 / Stanford CS149 Parallel Computing</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="fine-grained-synchronization-and-fine-grained-lock"><a class="markdownIt-Anchor" href="#fine-grained-synchronization-and-fine-grained-lock"></a> Fine-grained synchronization and fine-grained lock</h1>
<ol>
<li>Data structures are often larger than a single memory location. One solution is to protect the structure with a single lock.<br />
It is relatively simple to implement correct mutual exclusion for data structure operations. However, the operations on the data structure are serialized, which may limit parallel application performance.</li>
<li>Another solution is “hand-over-hand” locking. We set a lock for each element in the data structure. Each thread only keeps as little as the lock they need, and every time a thread moves forward, it unlocks the locks they don’t need anymore and locks the locks they need now.</li>
<li>Fine-grained lock aims to enable parallelism in data structure operations by Reducing contention for global data structure lock.<br />
It is tricky to ensure correctness (how to determine when mutual exclusion is required, how to avoid deadlock or livelock).</li>
<li>It has an overhead of taking a lock on each traversal step. There are extra instructions, and traversal now involves memory writes. Also, it has extra storage costs, namely a lock per node.</li>
<li>C++11 has an <code>atomic&lt;T&gt;</code>. It provides atomic read, write, read-modify-write of entire objects. Atomicity may be implemented by mutex or efficiently by processor-supported atomic instructions if <code>T</code> is a basic type.<br />
It also provides memory ordering semantics for operations before and after atomic operations.</li>
</ol>
<h1 id="lock-free-programming"><a class="markdownIt-Anchor" href="#lock-free-programming"></a> Lock-free programming</h1>
<ol>
<li>
<p>Single reader, single writer bounded queue: Only two threads (one producer, one consumer) accessing the queue simultaneously.</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">struct</span> <span class="title class_">Queue</span> &#123;</span><br><span class="line">  <span class="type">int</span> data[N];</span><br><span class="line">  <span class="type">unsigned</span> head; <span class="comment">// head of queue</span></span><br><span class="line">  <span class="type">unsigned</span> tail; <span class="comment">// next free element</span></span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">init</span><span class="params">(Queue* q)</span> </span>&#123;</span><br><span class="line">  q-&gt;head = q-&gt;tail = <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// return false if queue is full</span></span><br><span class="line"><span class="function"><span class="type">bool</span> <span class="title">push</span><span class="params">(Queue* q, <span class="type">int</span> value)</span> </span>&#123;</span><br><span class="line">  <span class="comment">// queue is full if tail is element before head</span></span><br><span class="line">  <span class="keyword">if</span> (q-&gt;tail == <span class="built_in">MOD_N</span>(q-&gt;head - <span class="number">1</span>))</span><br><span class="line">    <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">  q.data[q-&gt;tail] = value;</span><br><span class="line">  q-&gt;tail = <span class="built_in">MOD_N</span>(q-&gt;tail + <span class="number">1</span>);</span><br><span class="line">  <span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// returns false if queue is empty</span></span><br><span class="line"><span class="function"><span class="type">bool</span> <span class="title">pop</span><span class="params">(Queue* q, <span class="type">int</span>* value)</span> </span>&#123;</span><br><span class="line">  <span class="comment">// if not empty</span></span><br><span class="line">  <span class="keyword">if</span> (q-&gt;head != q-&gt;tail) &#123;</span><br><span class="line">    *value = q-&gt;data[q-&gt;head];</span><br><span class="line">    q-&gt;head = <span class="built_in">MOD_N</span>(q-&gt;head + <span class="number">1</span>);</span><br><span class="line">    <span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
<li>
<p>Single reader, single writer unbounded queue: Only push modifies <code>tail</code> and <code>reclaim</code>; only pop modifies <code>head</code>.</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">struct</span> <span class="title class_">Node</span> &#123;</span><br><span class="line">  Node* next;</span><br><span class="line">  <span class="type">int</span> value;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="keyword">struct</span> <span class="title class_">Queue</span> &#123;</span><br><span class="line">  Node* head;    <span class="comment">// the element before head of queue</span></span><br><span class="line">  Node* tail;    <span class="comment">// the last element added</span></span><br><span class="line">  Node* reclaim; <span class="comment">// the head of undeleted nodes</span></span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">init</span><span class="params">(Queue* q)</span> </span>&#123;</span><br><span class="line">  q-&gt;head = q-&gt;tail = q-&gt;reclaim = <span class="keyword">new</span> Node;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">push</span><span class="params">(Queue* q, <span class="type">int</span> value)</span> </span>&#123;</span><br><span class="line">  Node* n = <span class="keyword">new</span> Node;</span><br><span class="line">  n-&gt;next = <span class="literal">NULL</span>;</span><br><span class="line">  n-&gt;value = value;</span><br><span class="line">  q-&gt;tail-&gt;next = n;</span><br><span class="line">  q-&gt;tail = q-&gt;tail-&gt;next;</span><br><span class="line">  <span class="comment">// delete all nodes between reclaim and head</span></span><br><span class="line">  <span class="keyword">while</span> (q-&gt;reclaim != q-&gt;head) &#123;</span><br><span class="line">    Node* tmp = q-&gt;reclaim;</span><br><span class="line">    q-&gt;reclaim = q-&gt;reclaim-&gt;next;</span><br><span class="line">    <span class="keyword">delete</span> tmp;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// returns false if queue is empty</span></span><br><span class="line"><span class="function"><span class="type">bool</span> <span class="title">pop</span><span class="params">(Queue* q, <span class="type">int</span>* value)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">if</span> (q-&gt;head != q-&gt;tail) &#123;</span><br><span class="line">    *value = q-&gt;head-&gt;next-&gt;value;</span><br><span class="line">    q-&gt;head = q-&gt;head-&gt;next;</span><br><span class="line">    <span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
<li>
<p>Lock-free stack: the main idea is that a thread’s modification can proceed as long as no other thread has modified the stack. The <code>compare_and_swap</code> operation is atomic, but doesn’t need to hold any other lock on data structure.</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">struct</span> <span class="title class_">Node</span> &#123;</span><br><span class="line">  Node* next;</span><br><span class="line">  <span class="type">int</span> value;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="keyword">struct</span> <span class="title class_">Stack</span> &#123;</span><br><span class="line">  Node* top;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">init</span><span class="params">(Stack* s)</span> </span>&#123;</span><br><span class="line">  s-&gt;top = <span class="literal">NULL</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">push</span><span class="params">(Stack* s, Node* n)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">while</span> (<span class="number">1</span>) &#123;</span><br><span class="line">    Node* old_top = s-&gt;top;</span><br><span class="line">    n-&gt;next = old_top;</span><br><span class="line">    <span class="comment">// Check whether the current top is the old top, </span></span><br><span class="line">    <span class="comment">// if true, set the current top to n; or get a new top</span></span><br><span class="line">    <span class="keyword">if</span> (<span class="built_in">compare_and_swap</span>(&amp;s-&gt;top, old_top, n) == old_top)</span><br><span class="line">      <span class="keyword">return</span>;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function">Node* <span class="title">pop</span><span class="params">(Stack* s)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">while</span> (<span class="number">1</span>) &#123;</span><br><span class="line">    Node* old_top = s-&gt;top;</span><br><span class="line">    <span class="keyword">if</span> (old_top == <span class="literal">NULL</span>)</span><br><span class="line">      <span class="keyword">return</span> <span class="literal">NULL</span>;</span><br><span class="line">    Node* new_top = old_top-&gt;next;</span><br><span class="line">    <span class="comment">// if the top is still the old top, return old top and set to new top</span></span><br><span class="line">    <span class="comment">// or get a new top</span></span><br><span class="line">    <span class="keyword">if</span> (<span class="built_in">compare_and_swap</span>(&amp;s-&gt;top, old_top, new_top) == old_top)</span><br><span class="line">      <span class="keyword">return</span> old_top;  <span class="comment">// Assume that consumer then recycles old_top</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
<li>
<p>The above push operation is fine, but the pop operation may have some error.<br />
After thread0 stores the old_top, if thread1 pops the old_top out, modifies the stack, and pushes the old_top into the stack again, then the <code>compare_and_swap</code> operation of thread0 will pass. Namely, thread0 cannot realize that the stack has already been modified.</p>
</li>
<li>
<p>One solution is adding a <code>pop_counter</code> to check whether other pop operations happened.</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">struct</span> <span class="title class_">Node</span> &#123;</span><br><span class="line">  Node* next;</span><br><span class="line">  <span class="type">int</span> value;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="keyword">struct</span> <span class="title class_">Stack</span> &#123;</span><br><span class="line">  Node* top;</span><br><span class="line">  <span class="type">int</span> pop_count;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">init</span><span class="params">(Stack* s)</span> </span>&#123;</span><br><span class="line">  s-&gt;top = <span class="literal">NULL</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">push</span><span class="params">(Stack* s, Node* n)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">while</span> (<span class="number">1</span>) &#123;</span><br><span class="line">    Node* old_top = s-&gt;top;</span><br><span class="line">    n-&gt;next = old_top;</span><br><span class="line">    <span class="keyword">if</span> (<span class="built_in">compare_and_swap</span>(&amp;s-&gt;top, old_top, n) == old_top)</span><br><span class="line">      <span class="keyword">return</span>;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function">Node* <span class="title">pop</span><span class="params">(Stack* s)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">while</span> (<span class="number">1</span>) &#123;</span><br><span class="line">    <span class="type">int</span> pop_count = s-&gt;pop_count;</span><br><span class="line">    Node* top = s-&gt;top;</span><br><span class="line">    <span class="keyword">if</span> (top == <span class="literal">NULL</span>)</span><br><span class="line">      <span class="keyword">return</span> <span class="literal">NULL</span>;</span><br><span class="line">    Node* new_top = top-&gt;next;</span><br><span class="line">    <span class="keyword">if</span> (<span class="built_in">double_compare_and_swap</span>(&amp;s-&gt;top, top, new_top,</span><br><span class="line">                                &amp;s-&gt;pop_count, pop_count, pop_count+<span class="number">1</span>))</span><br><span class="line">    &#123;</span><br><span class="line">      <span class="keyword">return</span> top;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure>
</li>
<li>
<p>Another solution to the ABA problem is hazard pointers. The reuse of the <code>old_top</code> causes the ABA problem. We can use the hazard pointers to track all <code>old_top</code>s, and they cannot be recycled or reused if they match any hazard pointers.</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">struct</span> <span class="title class_">Node</span> &#123;</span><br><span class="line">  Node* next;</span><br><span class="line">  <span class="type">int</span> value;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="keyword">struct</span> <span class="title class_">Stack</span> &#123;</span><br><span class="line">  Node* top;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line">Node *hazard[NUM_THREADS];</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">init</span><span class="params">(Stack* s)</span> </span>&#123;</span><br><span class="line">  s-&gt;top = <span class="literal">NULL</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">push</span><span class="params">(Stack* s, Node* n)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">while</span> (<span class="number">1</span>) &#123;</span><br><span class="line">    Node* old_top = s-&gt;top;</span><br><span class="line">    n-&gt;next = old_top;</span><br><span class="line">    <span class="keyword">if</span> (<span class="built_in">compare_and_swap</span>(&amp;s-&gt;top, old_top, n) == old_top)</span><br><span class="line">      <span class="keyword">return</span>;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function">Node* <span class="title">pop</span><span class="params">(Stack* s)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">while</span> (<span class="number">1</span>) &#123;</span><br><span class="line">    hazard[t] = s-&gt;top;</span><br><span class="line">    Node* top = hazard[t];</span><br><span class="line">    <span class="keyword">if</span> (top == <span class="literal">NULL</span>)</span><br><span class="line">      <span class="keyword">return</span> <span class="literal">NULL</span>;</span><br><span class="line">    Node* new_top = top-&gt;next;</span><br><span class="line">    <span class="keyword">if</span> (<span class="built_in">compare_and_swap</span>(&amp;s-&gt;top, top, new_top))</span><br><span class="line">      <span class="keyword">return</span> top;  <span class="comment">// Caller must clear hazard[t] when it’s done with top</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
<li>
<p>Lock-free linked list insertion assumes the only operation on the list is inserting. Supporting lock-free deletion significantly complicates data structure.</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">struct</span> <span class="title class_">Node</span> &#123;</span><br><span class="line">  <span class="type">int</span> value;</span><br><span class="line">  Node* next;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="keyword">struct</span> <span class="title class_">List</span> &#123;</span><br><span class="line">  Node* head;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="comment">// insert new node after specified node</span></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">insert_after</span><span class="params">(List* list, Node* after, <span class="type">int</span> value)</span> </span>&#123;</span><br><span class="line">  Node* n = <span class="keyword">new</span> Node;</span><br><span class="line">  n-&gt;value = value;</span><br><span class="line">  <span class="comment">// assume case of insert into empty list handled</span></span><br><span class="line">  <span class="comment">// here (keep code on slide simple for class discussion)</span></span><br><span class="line">  Node* prev = list-&gt;head;</span><br><span class="line">  <span class="keyword">while</span> (prev-&gt;next) &#123;</span><br><span class="line">    <span class="keyword">if</span> (prev == after) &#123;</span><br><span class="line">      <span class="keyword">while</span> (<span class="number">1</span>) &#123;</span><br><span class="line">        Node* old_next = prev-&gt;next;</span><br><span class="line">        n-&gt;next = old_next;</span><br><span class="line">        <span class="keyword">if</span> (<span class="built_in">compare_and_swap</span>(&amp;prev-&gt;next, old_next, n) == old_next)</span><br><span class="line">          <span class="keyword">return</span>;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    prev = prev-&gt;next;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
<li>
<p>If your program only uses the machine, well-written code with locks can be as fast (or faster) than lock-free code.<br />
However, there are situations where code with locks can suffer from tricky performance problems. Like multi-programmed situations where page faults, pre-emption, etc., can occur while the thread is in a critical section</p>
</li>
</ol>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://liyun-zhang.github.io/2022/07/16/Courses/CS149/13-Implementing-Synchronization/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="LiyunZhang">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="LiyunZhang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | LiyunZhang">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2022/07/16/Courses/CS149/13-Implementing-Synchronization/" class="post-title-link" itemprop="url">13. Implementing Synchronization</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2022-07-16 11:05:13" itemprop="dateCreated datePublished" datetime="2022-07-16T11:05:13+08:00">2022-07-16</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">Edited on</span>
      <time title="Modified: 2024-03-16 22:07:26" itemprop="dateModified" datetime="2024-03-16T22:07:26+08:00">2024-03-16</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">In</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Open-Courses/" itemprop="url" rel="index"><span itemprop="name">Open Courses</span></a>
        </span>
          , 
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Open-Courses/CMU-15-418-Stanford-CS149-Parallel-Computing/" itemprop="url" rel="index"><span itemprop="name">CMU 15-418 / Stanford CS149 Parallel Computing</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="implementing-locks"><a class="markdownIt-Anchor" href="#implementing-locks"></a> Implementing locks</h1>
<ol>
<li>Three phases of a synchronization event：<br />
Acquire method: How does a thread attempt to access protected resources?<br />
Waiting algorithm: How does a thread wait for access shared resources?<br />
Release method: How does a thread enable other threads to gain resources when its work in the synchronized region is complete?</li>
<li>Busy waiting (spinning): <code>while (condition X not true) ;</code></li>
<li>Blocking synchronization: <code>if (condition X not true) block until true;</code><br />
If progress cannot be made because a resource cannot be acquired, it is desirable to free up execution resources for another thread and preempt the running thread.</li>
<li>Busy waiting can be preferable to blocking if scheduling overhead is larger than the expected wait time or the processor’s resources are not needed for other tasks.<br />
The latter situation is often the case in a parallel program since we usually don’t oversubscribe a system when running a performance-critical parallel app.</li>
<li>Desirable lock performance characteristics:<br />
<strong>Low latency</strong>: If the lock is free and no other processors are trying to acquire it, a processor should be able to acquire the lock quickly<br />
<strong>Low interconnect traffic</strong>: If all processors are trying to acquire the lock at once, they should acquire the lock in succession with as little traffic as possible<br />
<strong>Scalability</strong>: Latency/traffic should scale reasonably with the number of processors<br />
<strong>Low storage cost</strong><br />
<strong>Fairness</strong>: Avoid starvation or substantial unfairness. One idea is that processors should acquire the lock in the order they request access to it.</li>
</ol>
<h2 id="test-and-set-lock"><a class="markdownIt-Anchor" href="#test-and-set-lock"></a> Test-and-set lock</h2>
<h3 id="simple-test-and-set-lock"><a class="markdownIt-Anchor" href="#simple-test-and-set-lock"></a> Simple test-and-set lock</h3>
<ol>
<li>The following spin lock has data race because LOAD-TEST-STORE is not atomic.<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">// Lock</span><br><span class="line">ld   R0, mem[addr]  // load word into R0</span><br><span class="line">cmp  R0, #0          // compare R0 to 0</span><br><span class="line">bnz  lock            // if nonzero jump to top</span><br><span class="line">st   mem[addr], #1  // set lock to 1</span><br><span class="line"></span><br><span class="line">// Unlock</span><br><span class="line">st   mem[addr], #0  // set lock to 0</span><br></pre></td></tr></table></figure>
</li>
<li>So, we need an atomic test-and-set instruction<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">ts R0, mem[addr]  // load mem[addr] into R0</span><br><span class="line">                  // if mem[addr] is 0, set mem[addr] to 1</span><br><span class="line">                  </span><br><span class="line">// Lock</span><br><span class="line">ts   R0, mem[addr]  // load word into R0</span><br><span class="line">bnz  R0, lock        // if nonzero jump to top</span><br><span class="line"></span><br><span class="line">// Unlock</span><br><span class="line">st   mem[addr], #0  // store 0 to address</span><br></pre></td></tr></table></figure>
</li>
<li>Every time a processor executes the ts instruction, it will send a BusRdX signal and invalidate the lock in all other processors’ caches. The coherence traffic may be heavy when many processors try to execute on the same lock.<br />
This lock generates one invalidation per waiting processor per test.</li>
<li>Bus contention increases the time to transfer the lock since the lock holder must wait to acquire the bus to release. Bus contention also slows down the execution of critical sections.</li>
<li>In x86, we can do the atomic compare and exchange by <code>lock cmpxchg src, dst</code> instruction. The <code>lock</code> prefix makes the operation atomic. The logic of the instruction is as follows:<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> (dst == %eax)  <span class="comment">// eax is the x86 accumulator register</span></span><br><span class="line">  ZF = <span class="number">1</span>          <span class="comment">// ZF is a flag registor</span></span><br><span class="line">dst = src <span class="keyword">else</span></span><br><span class="line">  ZF = <span class="number">0</span></span><br><span class="line">  %eax = dst</span><br></pre></td></tr></table></figure>
</li>
<li>Simple test-and-set lock has low latency (under low contention), high traffic, poor scaling, low storage cost (one int), and no provisions for fairness.</li>
</ol>
<h3 id="test-and-set-lock-with-back-off"><a class="markdownIt-Anchor" href="#test-and-set-lock-with-back-off"></a> Test-and-set lock with back off</h3>
<ol>
<li>
<p>Upon failure to acquire the lock, delay for a while before retrying.</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">void</span> <span class="title">Lock</span><span class="params">(<span class="keyword">volatile</span> <span class="type">int</span>* lock)</span> </span>&#123;</span><br><span class="line">  <span class="type">int</span> amount = <span class="number">1</span>;</span><br><span class="line">  <span class="keyword">while</span> (<span class="number">1</span>) &#123;</span><br><span class="line">    <span class="keyword">if</span> (<span class="built_in">test_and_set</span>(lock) == <span class="number">0</span>)</span><br><span class="line">      <span class="keyword">return</span>;</span><br><span class="line">    <span class="built_in">delay</span>(amount);</span><br><span class="line">    amount *= <span class="number">2</span>;</span><br><span class="line">  &#125; </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
<li>
<p>It has the same uncontended latency as test-and-set but potentially higher latency under contention because the waiting processor may still delay even when the lock is available.</p>
</li>
<li>
<p>It generates less traffic than test-and-set since it does not continually attempt to acquire a lock. It improves scalability due to less traffic.</p>
</li>
<li>
<p>Storage cost unchanged (still one int for lock)</p>
</li>
<li>
<p>Exponential back-off can cause severe unfairness. Newer requesters back off for shorter intervals</p>
</li>
</ol>
<h3 id="test-and-test-and-set-lock"><a class="markdownIt-Anchor" href="#test-and-test-and-set-lock"></a> Test-and-test-and-set lock</h3>
<ol>
<li>
<p>To prevent the coherence traffic problem, we can test first and do the test-and-set only if the earlier test has passed.</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">void</span> <span class="title">Lock</span><span class="params">(<span class="keyword">volatile</span> <span class="type">int</span>* lock)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">while</span> (<span class="number">1</span>) &#123;</span><br><span class="line">    <span class="keyword">while</span> (*lock != <span class="number">0</span>) ;</span><br><span class="line">    <span class="keyword">if</span> (<span class="built_in">test_and_set</span>(lock) == <span class="number">0</span>)</span><br><span class="line">      <span class="keyword">return</span>;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">Unlock</span><span class="params">(<span class="keyword">volatile</span> <span class="type">int</span>* lock)</span> </span>&#123;</span><br><span class="line">  *lock = <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
<li>
<p>This lock has slightly higher latency than test-and-set in uncontended cases but generates much less interconnect traffic. Only One invalidation is generated per waiting processor per lock release.<br />
Namely, only <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>O</mi><mo stretchy="false">(</mo><mi>P</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">O(P)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">O</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="mclose">)</span></span></span></span> invalidation and <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>O</mi><mo stretchy="false">(</mo><msup><mi>P</mi><mn>2</mn></msup><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">O(P^2)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.064108em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">O</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141079999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span> interconnect traffic.</p>
</li>
<li>
<p>It is more scalable due to less traffic, storage cost unchanged (still one int), and no fairness provisions.</p>
</li>
</ol>
<h2 id="ticket-lock"><a class="markdownIt-Anchor" href="#ticket-lock"></a> Ticket lock</h2>
<ol>
<li>The test-and-set style locks cannot provide for fairness because all waiting processors attempt to acquire a lock using test-and-set upon release.</li>
<li>We can assign each thread a number when they try to acquire the lock. We give the lock to the waiting thread with the smallest number every time.<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">struct</span> <span class="title class_">lock</span> &#123;</span><br><span class="line">  <span class="keyword">volatile</span> <span class="type">int</span> next_ticket;</span><br><span class="line">  <span class="keyword">volatile</span> <span class="type">int</span> now_serving;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">Lock</span><span class="params">(lock* lock)</span> </span>&#123;</span><br><span class="line">  <span class="type">int</span> my_ticket = <span class="built_in">atomic_increment</span>(&amp;lock-&gt;next_ticket);  <span class="comment">// take a “ticket”</span></span><br><span class="line">  <span class="keyword">while</span> (my_ticket != lock-&gt;now_serving);                <span class="comment">//wait for number</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">unlock</span><span class="params">(lock* lock)</span> </span>&#123;</span><br><span class="line">  lock-&gt;now_serving++;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
<li>No atomic operation is needed to acquire the lock. Only a read is necessary when acquiring the lock, and write only happens when the lock is released. So, only one invalidation is generated per lock release, namely <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>O</mi><mo stretchy="false">(</mo><mi>P</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">O(P)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">O</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="mclose">)</span></span></span></span> interconnect traffic.</li>
</ol>
<h2 id="array-based-lock"><a class="markdownIt-Anchor" href="#array-based-lock"></a> Array-based lock</h2>
<ol>
<li>
<p>Each processor spins on a different memory address. It also utilizes atomic operations to assign an address to acquire it.<br />
If there are two barriers, after some threads pass the first barrier, they might set the flag to 0 even if some other threads haven’t passed the first barrier yet, causing those slower threads to wait.</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">struct</span> <span class="title class_">lock</span> &#123;</span><br><span class="line">  <span class="keyword">volatile</span> padded_int status[P];  <span class="comment">// padded to keep off same cache line</span></span><br><span class="line">  <span class="keyword">volatile</span> <span class="type">int</span> head;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="type">int</span> my_element;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">Lock</span><span class="params">(lock* lock)</span> </span>&#123;</span><br><span class="line">  my_element = <span class="built_in">atomic_circ_increment</span>(&amp;lock-&gt;head);  <span class="comment">// assume modular increment </span></span><br><span class="line">  <span class="keyword">while</span> (lock-&gt;status[my_element] == <span class="number">1</span>);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">unlock</span><span class="params">(lock* lock)</span> </span>&#123;</span><br><span class="line">  lock-&gt;status[my_element] = <span class="number">1</span>;</span><br><span class="line">  lock-&gt;status[<span class="built_in">circ_next</span>(my_element)] = <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
<li>
<p>The lock only requires <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>O</mi><mo stretchy="false">(</mo><mn>1</mn><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">O(1)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">O</span><span class="mopen">(</span><span class="mord">1</span><span class="mclose">)</span></span></span></span> interconnect traffic per release but requires linear space in <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>O</mi><mo stretchy="false">(</mo><mi>P</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">O(P)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">O</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="mclose">)</span></span></span></span>.</p>
</li>
<li>
<p>The atomic circular increment is a more complex operation. So, the lock has a higher overhead.</p>
</li>
<li>
<p>Queue-based Lock (MCS lock): Create a queue of waiters. Each thread allocates a local space on which to wait.</p>
</li>
</ol>
<h1 id="implementing-barrier"><a class="markdownIt-Anchor" href="#implementing-barrier"></a> Implementing barrier</h1>
<ol>
<li>The following code uses a <code>counter</code> to count how many threads have hit the barrier. The last thread hit the barrier and will release all of them.<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">struct</span> <span class="title class_">Barrier_t</span> &#123;</span><br><span class="line">   LOCK lock;</span><br><span class="line">  <span class="type">int</span> counter;  <span class="comment">// initialize to 0</span></span><br><span class="line">  <span class="type">int</span> flag;      <span class="comment">// the flag field should probably be padded to </span></span><br><span class="line">                <span class="comment">// sit on its own cache line. </span></span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="comment">// barrier for p processors</span></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">Barrier</span><span class="params">(Barrier_t* b, <span class="type">int</span> p)</span> </span>&#123;</span><br><span class="line">  <span class="built_in">lock</span>(b-&gt;lock);</span><br><span class="line">  <span class="keyword">if</span> (b-&gt;counter == <span class="number">0</span>) &#123;</span><br><span class="line">    b-&gt;flag = <span class="number">0</span>; <span class="comment">// first thread arriving at barrier clears flag </span></span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="type">int</span> num_arrived = ++(b-&gt;counter);</span><br><span class="line">  <span class="built_in">unlock</span>(b-&gt;lock);</span><br><span class="line"></span><br><span class="line">  <span class="keyword">if</span> (num_arrived == p) &#123; <span class="comment">// last arriver sets flag b-&gt;counter = 0;</span></span><br><span class="line">    b-&gt;flag = <span class="number">1</span>;</span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    <span class="keyword">while</span> (b-&gt;flag == <span class="number">0</span>); <span class="comment">// wait for flag</span></span><br><span class="line">  &#125; </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
<li>To solve the problem, we should wait for all processes to leave the first barrier, before clearing the flag for entry into the second.<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Centralized barrier</span></span><br><span class="line"> </span><br><span class="line"><span class="keyword">struct</span> <span class="title class_">Barrier_t</span> &#123;</span><br><span class="line">  LOCK lock;</span><br><span class="line">  <span class="type">int</span> arrive_counter;  <span class="comment">// initialize to 0 (number of threads that have arrived)</span></span><br><span class="line">  <span class="type">int</span> leave_counter;  <span class="comment">// initialize to P (number of threads that have left barrier)</span></span><br><span class="line">  <span class="type">int</span> flag;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="comment">// barrier for p processors</span></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">Barrier</span><span class="params">(Barrier_t* b, <span class="type">int</span> p)</span> </span>&#123;</span><br><span class="line">  <span class="built_in">lock</span>(b-&gt;lock);</span><br><span class="line">  <span class="keyword">if</span> (b-&gt;arrive_counter == <span class="number">0</span>) &#123;   <span class="comment">// if first to arrive...</span></span><br><span class="line">    <span class="keyword">if</span> (b-&gt;leave_counter == P) &#123;  <span class="comment">// check to make sure no other threads “still in barrier”</span></span><br><span class="line">      b-&gt;flag = <span class="number">0</span>;               <span class="comment">// first arriving thread clears flag</span></span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">      <span class="built_in">unlock</span>(lock);</span><br><span class="line">      <span class="keyword">while</span> (b-&gt;leave_counter != P);  <span class="comment">// wait for all threads to leave before clearing</span></span><br><span class="line">      <span class="built_in">lock</span>(lock);</span><br><span class="line">      b-&gt;flag = <span class="number">0</span>;                <span class="comment">// first arriving thread clears flag</span></span><br><span class="line">    &#125; </span><br><span class="line">  &#125;</span><br><span class="line">  <span class="type">int</span> num_arrived = ++(b-&gt;arrive_counter);</span><br><span class="line">  <span class="built_in">unlock</span>(b-&gt;lock);</span><br><span class="line">  <span class="keyword">if</span> (num_arrived == p) &#123;  <span class="comment">// last arriver sets flag</span></span><br><span class="line">    b-&gt;arrive_counter = <span class="number">0</span>;</span><br><span class="line">    b-&gt;leave_counter = <span class="number">1</span>;</span><br><span class="line">    b-&gt;flag = <span class="number">1</span>;</span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    <span class="keyword">while</span> (b-&gt;flag == <span class="number">0</span>);  <span class="comment">// wait for flag</span></span><br><span class="line">    <span class="built_in">lock</span>(b-&gt;lock);</span><br><span class="line">    b-&gt;leave_counter++;</span><br><span class="line">    <span class="built_in">unlock</span>(b-&gt;lock);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
<li>We can save one variable by sense reversal. Processors wait for the flag to be equal to the local sense.<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">struct</span> <span class="title class_">Barrier_t</span> &#123;</span><br><span class="line">  LOCK lock;</span><br><span class="line">  <span class="type">int</span> counter; <span class="comment">// initialize to 0</span></span><br><span class="line">  <span class="type">int</span> flag; <span class="comment">// initialize to 0</span></span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="type">int</span> local_sense = <span class="number">0</span>;  <span class="comment">// private per processor</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// barrier for p processors</span></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">Barrier</span><span class="params">(Barrier_t* b, <span class="type">int</span> p)</span> </span>&#123;</span><br><span class="line">  local_sense = (local_sense == <span class="number">0</span>) ? <span class="number">1</span> : <span class="number">0</span>; <span class="built_in">lock</span>(b-&gt;lock);</span><br><span class="line">  <span class="type">int</span> num_arrived = ++(b-&gt;counter);</span><br><span class="line">  <span class="keyword">if</span> (b-&gt;counter == p) &#123; <span class="comment">// last arriver sets flag</span></span><br><span class="line">    <span class="built_in">unlock</span>(b-&gt;lock);</span><br><span class="line">    b-&gt;counter = <span class="number">0</span>;</span><br><span class="line">    b-&gt;flag = local_sense;</span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    <span class="built_in">unlock</span>(b-&gt;lock);</span><br><span class="line">    <span class="keyword">while</span> (b-&gt;flag != local_sense); <span class="comment">// wait for flag</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
<li>There are <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>O</mi><mo stretchy="false">(</mo><mi>P</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">O(P)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">O</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="mclose">)</span></span></span></span> traffic on interconnects per barrier.<br />
All threads have <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>2</mn><mi>P</mi></mrow><annotation encoding="application/x-tex">2P</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord">2</span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span></span></span></span> write transactions to obtain barrier lock and update the counter. <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>O</mi><mo stretchy="false">(</mo><mi>P</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">O(P)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">O</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="mclose">)</span></span></span></span> traffic assuming lock acquisition is implemented in <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>O</mi><mo stretchy="false">(</mo><mn>1</mn><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">O(1)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">O</span><span class="mopen">(</span><span class="mord">1</span><span class="mclose">)</span></span></span></span> manner<br />
Last thread has <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>2</mn></mrow><annotation encoding="application/x-tex">2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">2</span></span></span></span> write transactions to write to the flag and reset the counter. <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>O</mi><mo stretchy="false">(</mo><mi>P</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">O(P)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">O</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="mclose">)</span></span></span></span> traffic since there are many sharers of the flag<br />
<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>P</mi><mo>−</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">P-1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.76666em;vertical-align:-0.08333em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">1</span></span></span></span> transactions to read updated flag</li>
<li>In a centralized barrier, all threads share a single barrier lock and counter, which causes high contention.</li>
<li>Combining trees makes better use of parallelism in interconnect topologies, which has <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>l</mi><mi>o</mi><mi>g</mi><mi>P</mi></mrow><annotation encoding="application/x-tex">logP</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord mathnormal" style="margin-right:0.01968em;">l</span><span class="mord mathnormal">o</span><span class="mord mathnormal" style="margin-right:0.03588em;">g</span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span></span></span></span> span (latency). This strategy makes less sense on a bus where all traffic is still serialized on a shared bus.<br />
Barrier acquire: when the processor arrives at the barrier, performs increment of parent counter. Process recurses to root.<br />
Barrier release: beginning from the root, notify children of the release.</li>
</ol>
<h1 id="locks-in-cuda-assignment-3"><a class="markdownIt-Anchor" href="#locks-in-cuda-assignment-3"></a> Locks in CUDA (Assignment 3)</h1>
<ol>
<li>
<p>CUDA has provided <code>atomicCAS</code> and <code>atomicExch</code>. But if we use the following code to implement the mutex, threads will end up in a dead loop.<br />
All warps in a block need to execute the same instructions. However, only one thread can have the lock; at most, one thread in a block can leave the loop, and hence, the whole block, including the one with the lock, will keep executing the <code>atomicCAS</code>. The thread with a loop cannot execute anything in a critical area and unlock the lock, which causes all threads to end up in the dead loop of the <code>lock</code>.</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">__share__ <span class="type">int</span> mutex;</span><br><span class="line"></span><br><span class="line"><span class="function">__device__ <span class="type">void</span> <span class="title">lock</span><span class="params">(<span class="type">int</span>* mutex)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">  <span class="keyword">while</span>(<span class="built_in">atomicCAS</span>(mutex, <span class="number">0</span>, <span class="number">1</span>)) ;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function">__device__ <span class="type">void</span> <span class="title">unlock</span><span class="params">(<span class="type">int</span>* mutex)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">  <span class="built_in">atomicExch</span>(mutex, <span class="number">0</span>);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function">__global__ <span class="type">void</span> <span class="title">kernel</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">  <span class="built_in">lock</span>(&amp;mutex);</span><br><span class="line">  <span class="comment">// critical code</span></span><br><span class="line">  <span class="built_in">unlock</span>(&amp;mutex);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
<li>
<p>The method to solve the problem must also consider the special execution mode of condition instruction in CUDA. A loop is necessary, but we want to execute the instruction inside a condition body so that when one thread grabs the lock, it can execute and unlock the lock before the next iteration.<br />
So, we can have an <code>if</code> condition inside the loop, such as the following code.</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">__share__ <span class="type">int</span> mutex;</span><br><span class="line"></span><br><span class="line"><span class="function">__kernel__ <span class="type">void</span> <span class="title">kernel</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">  <span class="type">bool</span> leaveLoop = <span class="literal">false</span>;</span><br><span class="line">  <span class="keyword">while</span> (!leaveLoop)</span><br><span class="line">  &#123;</span><br><span class="line">    <span class="keyword">if</span> (<span class="built_in">atomicExch</span>(&amp;mutex, <span class="number">1</span>))</span><br><span class="line">    &#123;</span><br><span class="line">      <span class="comment">// critical cade</span></span><br><span class="line">      leaveLoop = <span class="literal">true</span>;      <span class="comment">// this thread can leave the loop, but it need to </span></span><br><span class="line">                             <span class="comment">// wait for other threads in its block</span></span><br><span class="line">      <span class="built_in">atomicExch</span>(&amp;mutex, <span class="number">0</span>); <span class="comment">// unlock the lock, so that in next iteration, </span></span><br><span class="line">                             <span class="comment">// some other threads can have the lock and finish</span></span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
</ol>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




  <nav class="pagination">
    <a class="extend prev" rel="prev" title="Previous page" aria-label="Previous page" href="/about/page/4/"><i class="fa fa-angle-left"></i></a><a class="page-number" href="/about/">1</a><span class="space">&hellip;</span><a class="page-number" href="/about/page/4/">4</a><span class="page-number current">5</span><a class="page-number" href="/about/page/6/">6</a><a class="page-number" href="/about/page/7/">7</a><a class="extend next" rel="next" title="Next page" aria-label="Next page" href="/about/page/6/"><i class="fa fa-angle-right"></i></a>
  </nav>

</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">


<div class="copyright">
  &copy; 
  <span itemprop="copyrightYear">2024</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">LiyunZhang</span>
</div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.js.org/mist/" rel="noopener" target="_blank">NexT.Mist</a>
  </div>

    </div>
  </footer>

  
  <div class="toggle sidebar-toggle" role="button">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>
  <div class="sidebar-dimmer"></div>
  <div class="back-to-top" role="button" aria-label="Back to top">
    <i class="fa fa-arrow-up fa-lg"></i>
    <span>0%</span>
  </div>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


  
  <script src="https://cdnjs.cloudflare.com/ajax/libs/animejs/3.2.1/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script>
<script src="/js/comments.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/schemes/muse.js"></script><script src="/js/next-boot.js"></script>

  <script src="https://cdnjs.cloudflare.com/ajax/libs/hexo-generator-searchdb/1.4.1/search.js" integrity="sha256-1kfA5uHPf65M5cphT2dvymhkuyHPQp5A53EGZOnOLmc=" crossorigin="anonymous"></script>
<script src="/js/third-party/search/local-search.js"></script>







  




  

  <script class="next-config" data-name="enableMath" type="application/json">true</script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.7/katex.min.css" integrity="sha256-hLTCMFlKxdNgPXyWlSSxYN0ykJmxxq9Yt3MNfdRGWeA=" crossorigin="anonymous">



</body>
</html>

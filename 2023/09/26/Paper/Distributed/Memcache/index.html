<!DOCTYPE html>
<html lang="zh-Hans">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222" media="(prefers-color-scheme: light)">
<meta name="theme-color" content="#222" media="(prefers-color-scheme: dark)"><meta name="generator" content="Hexo 6.3.0">

  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">



<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css" integrity="sha256-HtsXJanqjKTc8vVQjO4YMhiqFoXkfBsjBWcX91T1jr8=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/animate.css/3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">

<script class="next-config" data-name="main" type="application/json">{"hostname":"liyun-zhang.github.io","root":"/","images":"/images","scheme":"Mist","darkmode":true,"version":"8.17.0","exturl":false,"sidebar":{"position":"right","display":"hide","padding":18,"offset":12},"copycode":{"enable":false,"style":null},"bookmark":{"enable":false,"color":"#222","save":"auto"},"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"stickytabs":false,"motion":{"enable":true,"async":false,"transition":{"menu_item":"fadeInDown","post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"prism":false,"i18n":{"placeholder":"Searching...","empty":"We didn't find any results for the search: ${query}","hits_time":"${hits} results found in ${time} ms","hits":"${hits} results found"},"path":"/search.xml","localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false}}</script><script src="/js/config.js"></script>

    <meta name="description" content="Paper: Scaling Memcache at Facebook @[toc] Purpose Issues:   Users consume an order of magnitude more content than they create.  This behavior results in a workload dominated by fetching data and sugg">
<meta property="og:type" content="article">
<meta property="og:title" content="Memcache">
<meta property="og:url" content="http://liyun-zhang.github.io/2023/09/26/Paper/Distributed/Memcache/index.html">
<meta property="og:site_name" content="LiyunZhang">
<meta property="og:description" content="Paper: Scaling Memcache at Facebook @[toc] Purpose Issues:   Users consume an order of magnitude more content than they create.  This behavior results in a workload dominated by fetching data and sugg">
<meta property="og:locale">
<meta property="og:image" content="http://liyun-zhang.github.io/imgs/Distributed/Memcache/read.png">
<meta property="og:image" content="http://liyun-zhang.github.io/imgs/Distributed/Memcache/write.png">
<meta property="article:published_time" content="2023-09-26T05:52:21.000Z">
<meta property="article:modified_time" content="2024-03-15T12:21:54.559Z">
<meta property="article:author" content="LiyunZhang">
<meta property="article:tag" content="Distributed System">
<meta property="article:tag" content="Cache System">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://liyun-zhang.github.io/imgs/Distributed/Memcache/read.png">


<link rel="canonical" href="http://liyun-zhang.github.io/2023/09/26/Paper/Distributed/Memcache/">



<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":false,"isPost":true,"lang":"zh-Hans","comments":true,"permalink":"http://liyun-zhang.github.io/2023/09/26/Paper/Distributed/Memcache/","path":"2023/09/26/Paper/Distributed/Memcache/","title":"Memcache"}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>Memcache | LiyunZhang</title>
  








  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
</head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <div class="column">
      <header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar" role="button">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <p class="site-title">LiyunZhang</p>
      <i class="logo-line"></i>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger" aria-label="Search" role="button">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i>Home</a></li><li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>Tags</a></li><li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>Categories</a></li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>Search
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup"><div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off" maxlength="80"
           placeholder="Searching..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close" role="button">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div class="search-result-container no-result">
  <div class="search-result-icon">
    <i class="fa fa-spinner fa-pulse fa-5x"></i>
  </div>
</div>
    </div>
  </div>

</header>
        
  
  <aside class="sidebar">

    <div class="sidebar-inner sidebar-nav-active sidebar-toc-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
            <div class="post-toc animated"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#Purpose"><span class="nav-number">1.</span> <span class="nav-text">Purpose</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Model"><span class="nav-number">2.</span> <span class="nav-text">Model</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Overview"><span class="nav-number">2.1.</span> <span class="nav-text">Overview</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#How-are-queries-carried-out-with-memcache"><span class="nav-number">2.1.1.</span> <span class="nav-text">How are queries carried out with memcache?</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#How-does-writing-carry-out-with-memcache"><span class="nav-number">2.1.2.</span> <span class="nav-text">How does writing carry out with memcache?</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#What-are-the-stages-of-problems-when-users-increase"><span class="nav-number">2.1.3.</span> <span class="nav-text">What are the stages of problems when users increase?</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#What-are-the-consistent-requirements"><span class="nav-number">2.1.4.</span> <span class="nav-text">What are the consistent requirements?</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#In-a-cluster-latency-and-load"><span class="nav-number">2.2.</span> <span class="nav-text">In a cluster: latency and load</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#How-do-clients-communicate-with-memcached-servers"><span class="nav-number">2.2.1.</span> <span class="nav-text">How do clients communicate with memcached servers?</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#How-to-handle-incast-congestion"><span class="nav-number">2.2.2.</span> <span class="nav-text">How to handle incast congestion?</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#How-to-prevent-stale-sets-problem"><span class="nav-number">2.2.3.</span> <span class="nav-text">How to prevent stale sets problem?</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#How-to-prevent-thundering-herds"><span class="nav-number">2.2.4.</span> <span class="nav-text">How to prevent thundering herds?</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#How-to-prevent-hit-rates-from-decreasing-caused-by-different-client-access-patterns"><span class="nav-number">2.2.5.</span> <span class="nav-text">How to prevent hit rates from decreasing caused by different client access patterns?</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#How-to-handle-a-small-number-of-memcache-servers-inaccessible-due-to-network-or-server-failure"><span class="nav-number">2.2.6.</span> <span class="nav-text">How to handle a small number of memcache servers inaccessible due to network or server failure?</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#In-a-region-replication"><span class="nav-number">2.3.</span> <span class="nav-text">In a region: replication</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#What-is-the-problem-of-scaling-memcache"><span class="nav-number">2.3.1.</span> <span class="nav-text">What is the problem of scaling memcache?</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#How-to-mitigate-the-poor-hit-rates-when-a-cold-cluster-starts-up"><span class="nav-number">2.3.2.</span> <span class="nav-text">How to mitigate the poor hit rates when a cold cluster starts up?</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#How-to-solve-the-race-in-cold-cluster-warmup-caused-by-an-update-in-the-cold-cluster"><span class="nav-number">2.3.3.</span> <span class="nav-text">How to solve the race in cold cluster warmup caused by an update in the cold cluster?</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Across-regions-consistency"><span class="nav-number">2.4.</span> <span class="nav-text">Across regions: consistency</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#How-to-execute-a-write-operation"><span class="nav-number">2.4.1.</span> <span class="nav-text">How to execute a write operation?</span></a></li></ol></li></ol></li></ol></div>
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">LiyunZhang</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/archives/">
          <span class="site-state-item-count">62</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
          <a href="/categories/">
        <span class="site-state-item-count">10</span>
        <span class="site-state-item-name">categories</span></a>
      </div>
      <div class="site-state-item site-state-tags">
          <a href="/tags/">
        <span class="site-state-item-count">29</span>
        <span class="site-state-item-name">tags</span></a>
      </div>
  </nav>
</div>

        </div>
      </div>
    </div>

    
  </aside>


    </div>

    <div class="main-inner post posts-expand">

  
  


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="zh-Hans">
    <link itemprop="mainEntityOfPage" href="http://liyun-zhang.github.io/2023/09/26/Paper/Distributed/Memcache/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="LiyunZhang">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="LiyunZhang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="Memcache | LiyunZhang">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          Memcache
        </h1>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2023-09-26 13:52:21" itemprop="dateCreated datePublished" datetime="2023-09-26T13:52:21+08:00">2023-09-26</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">Edited on</span>
      <time title="Modified: 2024-03-15 20:21:54" itemprop="dateModified" datetime="2024-03-15T20:21:54+08:00">2024-03-15</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">In</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Paper-Notebook/" itemprop="url" rel="index"><span itemprop="name">Paper Notebook</span></a>
        </span>
          , 
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Paper-Notebook/Distributed-System/" itemprop="url" rel="index"><span itemprop="name">Distributed System</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody"><p>Paper: <a target="_blank" rel="noopener" href="http://nil.csail.mit.edu/6.824/2020/papers/memcache-fb.pdf">Scaling Memcache at Facebook</a></p>
<p>@[toc]</p>
<h1 id="Purpose"><a href="#Purpose" class="headerlink" title="Purpose"></a>Purpose</h1><ol>
<li><p>Issues: </p>
<ul>
<li>Users consume an order of magnitude more content than they create. <ul>
<li>This behavior results in a workload dominated by fetching data and suggests that caching can have significant advantages. </li>
</ul>
</li>
<li>Read operations fetch data from a variety of sources.<ul>
<li>This heterogeneity requires a flexible caching strategy to store data from disparate sources. </li>
</ul>
</li>
</ul>
</li>
<li><p>What is the requirement of a social network’s infrastructure?</p>
<ul>
<li>Allow near real-time communication.</li>
<li><p>Aggregate content on-the-fly from multiple sources</p>
</li>
<li><p>Be able to access and update very popular shared content.</p>
</li>
<li><p>Scale to process millions of user requests per second</p>
</li>
</ul>
</li>
<li><p>Memcached is an open-source implementation of an in-memory hash table, which provides low-latency access to a shared storage pool at a low cost. </p>
</li>
<li><p>Findings: </p>
<ul>
<li>While qualities like performance, efficiency, fault tolerance, and consistency are important at all scales and specific sizes, some qualities require more effort than others. </li>
<li>The importance of finding an optimal communication schedule increases as the number of servers increases and networking becomes the bottleneck. </li>
</ul>
</li>
</ol>
<h1 id="Model"><a href="#Model" class="headerlink" title="Model"></a>Model</h1><h2 id="Overview"><a href="#Overview" class="headerlink" title="Overview"></a>Overview</h2><h3 id="How-are-queries-carried-out-with-memcache"><a href="#How-are-queries-carried-out-with-memcache" class="headerlink" title="How are queries carried out with memcache?"></a>How are queries carried out with memcache?</h3><ol>
<li>When a web server needs data, it first requests the value from memcache by providing a string key. </li>
<li>If the item that the key addresses is not cached, the web server retrieves the data from the database or other backend service and populates the cache with the key-value pair. </li>
</ol>
<p><img src="/imgs/Distributed/Memcache/read.png" width="30%"></p>
<h3 id="How-does-writing-carry-out-with-memcache"><a href="#How-does-writing-carry-out-with-memcache" class="headerlink" title="How does writing carry out with memcache?"></a>How does writing carry out with memcache?</h3><ol>
<li>The web server issues SQL statements to the database for write requests and then sends a delete request to memcache that invalidates stale data. </li>
<li>We delete cached data instead of updating it because deletes are idempotent. <ul>
<li>Considering two concurrent writes, there is no guarantee that the update operation will be in the same order as the database updates. </li>
<li>If database updates write A first, then write B while the Memcache set write B first then write A, the Memcache would be inconsistent with the database.  </li>
</ul>
</li>
</ol>
<p><img src="/imgs/Distributed/Memcache/write.png" width="30%"></p>
<h3 id="What-are-the-stages-of-problems-when-users-increase"><a href="#What-are-the-stages-of-problems-when-users-increase" class="headerlink" title="What are the stages of problems when users increase?"></a>What are the stages of problems when users increase?</h3><ol>
<li>Initially, there were few users; the service could be provided with a single server running both scripts and the database. </li>
<li>As the number of users grows, the first problem is usually that the server runs out of CPU to execute scripts. <ul>
<li>Hence, the solution is to use multiple servers to run scripts and another server to run the database. </li>
</ul>
</li>
<li>If the number of users keeps growing, the next problem is that the database runs out of steam. <ul>
<li>The solution usually uses a distributed sharding database system. This is when all those consistent problems come. </li>
</ul>
</li>
<li>However, the MySQL cannot process reads and writes fast. And if some keys are the hot zone, no matter how delicate we shard, there is only one group for that key. <ul>
<li>Facebook uses Memcache to solve this situation when Memcache servers absorb most read requests; only a few are exposed to database servers. </li>
</ul>
</li>
</ol>
<h3 id="What-are-the-consistent-requirements"><a href="#What-are-the-consistent-requirements" class="headerlink" title="What are the consistent requirements?"></a>What are the consistent requirements?</h3><ol>
<li>When users only read data, they can barely notice the stale data for a few seconds, but not too long, like data from yesterday. </li>
<li>When users change something, if they immediately try to read it, they should see the data they changed. There should not be any stale in this case. </li>
</ol>
<h2 id="In-a-cluster-latency-and-load"><a href="#In-a-cluster-latency-and-load" class="headerlink" title="In a cluster: latency and load"></a>In a cluster: latency and load</h2><h3 id="How-do-clients-communicate-with-memcached-servers"><a href="#How-do-clients-communicate-with-memcached-servers" class="headerlink" title="How do clients communicate with memcached servers?"></a>How do clients communicate with memcached servers?</h3><ol>
<li>Client logic is provided as two components: a library that can be embedded into applications or a standalone proxy named <em>mcrouter</em>. <ul>
<li>This proxy presents a Memcached server interface and routes the requests/replies to/from other servers.</li>
</ul>
</li>
<li><code>Get</code> requests relies on UDP to reduce latency and overhead. <ul>
<li>Each thread in the web server is allowed to communicate with <em>Memcached</em> servers directly, bypassing <em>mcrouter</em> without establishing and maintaining a connection, thereby reducing the overhead. </li>
<li>The UDP implementation detects packets that are dropped or received out of order (using sequence numbers) and treats them as errors on the client side. It does not provide any mechanism to try to recover from them.</li>
</ul>
</li>
<li>For reliability, clients perform <code>set</code> and <code>delete</code> operations over TCP through an instance of <em>mcrouter</em> running on the same machine as the web server. <ul>
<li>For operations where we need to confirm a state change (<code>update</code>s and <code>delete</code>s), TCP alleviates the need to add a retry mechanism to our UDP implementation. </li>
</ul>
</li>
</ol>
<h3 id="How-to-handle-incast-congestion"><a href="#How-to-handle-incast-congestion" class="headerlink" title="How to handle incast congestion?"></a>How to handle incast congestion?</h3><ol>
<li>Web servers must routinely communicate with many memcached servers to satisfy user requests. <ul>
<li>As a result, all web servers communicate with every memcached server in a short period. </li>
<li>This all-to-all communication pattern can cause incast congestion or allow a single server to become the bottleneck for many web servers. </li>
</ul>
</li>
<li>Memcache clients implement flow control mechanisms to limit incast congestion. <ul>
<li>Clients use a sliding window mechanism to control the number of outstanding requests. </li>
<li>The size of this sliding window grows slowly upon a successful request and shrinks when a request goes unanswered. </li>
<li>With lower window sizes, the application will have to dispatch more groups of memcache requests serially, increasing the duration of the web request. </li>
<li>As the window size gets too large, the number of simultaneous memcache requests causes incast congestion. </li>
</ul>
</li>
</ol>
<h3 id="How-to-prevent-stale-sets-problem"><a href="#How-to-prevent-stale-sets-problem" class="headerlink" title="How to prevent stale sets problem?"></a>How to prevent stale sets problem?</h3><ol>
<li>A stale set occurs when a web server sets a value in <em>memcache</em> that does not reflect the latest value that should be cached. <ul>
<li>For example, when server A tried to read an entry <code>get(k)</code> and missed, it read a value <code>v1</code> from the database. But before its <code>set(k, v1)</code> is executed, another server updated <code>k=v2</code> and executed <code>delete(k)</code>. </li>
<li>The problem is that after <code>delete(k)</code> is executed, there is no mechanism to prevent the stale <code>set(k, v1)</code> from being executed. Hence, a stale entry will be left in the <em>memcache</em> for an indefinite long time. </li>
</ul>
</li>
<li>A memcached instance gives a lease to a client to set data back into the cache when that client experiences a cache miss. <ul>
<li>The lease is a 64-bit token bound to the specific key the client originally requested. </li>
<li>The client provides the lease token when setting the value in the cache. </li>
<li>Verification can fail if Memcached has invalidated the lease token due to receiving a delete request for that item. </li>
</ul>
</li>
</ol>
<h3 id="How-to-prevent-thundering-herds"><a href="#How-to-prevent-thundering-herds" class="headerlink" title="How to prevent thundering herds?"></a>How to prevent thundering herds?</h3><ol>
<li>A thundering herd happens when a specific key undergoes heavy read and write activity. <ul>
<li>If one client updates the database and deletes a key, many clients get() but miss, causing them to try to fetch from the database and all <code>set()</code>. </li>
</ul>
</li>
<li>Each memcached server regulates the rate at which it returns lease tokens. <ul>
<li>Each memcached server only returns a lease token every period. </li>
<li>Other cache misses during that period will receive a special notification telling the client to wait a short time. </li>
<li>Return a lease every period instead of only returning to the first cache miss to prevent the first client from acquiring data from the database. </li>
</ul>
</li>
</ol>
<h3 id="How-to-prevent-hit-rates-from-decreasing-caused-by-different-client-access-patterns"><a href="#How-to-prevent-hit-rates-from-decreasing-caused-by-different-client-access-patterns" class="headerlink" title="How to prevent hit rates from decreasing caused by different client access patterns?"></a>How to prevent hit rates from decreasing caused by different client access patterns?</h3><ol>
<li>A cluster’s memcached servers are partitioned into separate pools. <ul>
<li>One pool (named <em>wildcard</em>) is designated as the default. </li>
<li>Separate pools are provided for keys whose residence in wildcard is problematic. </li>
</ul>
</li>
<li>Within some pools, replication can be used to improve the latency and efficiency. <ul>
<li>Choose to replicate a category of keys within a pool when <ul>
<li>The application routinely fetches many keys simultaneously.</li>
<li>The entire data set fits in one or two Memcached servers.</li>
<li>The request rate is much higher than what a single server can manage.</li>
</ul>
</li>
<li>Favor replication in this instance over further dividing the key space due to the following reasons: <ul>
<li>The difference in memcached overhead for retrieving 100 keys per request instead of 1 key is small. </li>
<li>Replicating can reduce the requests that need to be processed by each server while dividing the key space can only reduce the keys retrieved from each server and increase the number of requests. </li>
</ul>
</li>
</ul>
</li>
</ol>
<h3 id="How-to-handle-a-small-number-of-memcache-servers-inaccessible-due-to-network-or-server-failure"><a href="#How-to-handle-a-small-number-of-memcache-servers-inaccessible-due-to-network-or-server-failure" class="headerlink" title="How to handle a small number of memcache servers inaccessible due to network or server failure?"></a>How to handle a small number of memcache servers inaccessible due to network or server failure?</h3><ol>
<li><p>For small outages, it relies on an automated remediation system. </p>
<ul>
<li>These actions are not instant and can take up to a few minutes. </li>
<li>This duration is long enough to cause the aforementioned cascading failures. </li>
</ul>
</li>
<li><p>A small set of machines, named <em>Gutter</em>, takes over the responsibilities of a few failed servers. </p>
<ul>
<li>Gutter accounts for approximately 1% of the memcached servers in a cluster. </li>
<li>When a Memcached client receives no response to its get request, the client assumes the server has failed and issues the request again to a special Gutter pool. </li>
<li><p>If this second request misses, the client will insert the appropriate key-value pair into the Gutter machine after querying the database.</p>
</li>
<li><p>Entries in the Gutter expire quickly to obviate Gutter invalidations. </p>
</li>
<li><p>Gutter limits the load on backend services at the cost of slightly stale data. </p>
</li>
</ul>
</li>
<li><p>This design differs from an approach in which a client rehashes keys among the remaining memcached servers. </p>
<ul>
<li>The server that becomes responsible for this hot key might also become overloaded. By shunting load to idle servers, we limit that risk. </li>
</ul>
</li>
</ol>
<h2 id="In-a-region-replication"><a href="#In-a-region-replication" class="headerlink" title="In a region: replication"></a>In a region: replication</h2><h3 id="What-is-the-problem-of-scaling-memcache"><a href="#What-is-the-problem-of-scaling-memcache" class="headerlink" title="What is the problem of scaling memcache?"></a>What is the problem of scaling memcache?</h3><ol>
<li><p>In communication traffic:</p>
<ul>
<li><p>Highly requested items will only become more popular as more web servers are added to cope with increased user traffic. </p>
</li>
<li><p>Incast congestion also worsens as the number of memcached servers increases.</p>
</li>
<li><p>Split web and Memcached servers into multiple <em>frontend</em> clusters. </p>
</li>
<li>These clusters, along with a storage cluster that contains the databases, define a region. </li>
</ul>
</li>
<li><p>The number of invalidations will increase.</p>
<ul>
<li>The storage cluster is responsible for invalidating cached data to keep frontend clusters consistent with the authoritative versions. </li>
<li>As an optimization, a web server that modifies data also sends invalidations to its cluster to provide read-after-write semantics for a single user request and reduce the time stale data is present in its local cache. </li>
<li>Also, batch invalidations can reduce packet rates. </li>
</ul>
</li>
<li><p>If users’ requests are randomly routed to all available frontend clusters, the cached data will be roughly the same across all the frontend clusters. </p>
<ul>
<li><p>Over-replicating the data can be memory inefficient, especially for large, rarely accessed items. </p>
</li>
<li><p>Reduce the number of replicas by having multiple frontend clusters share the same set of memcached servers called a regional pool. </p>
</li>
</ul>
</li>
</ol>
<h3 id="How-to-mitigate-the-poor-hit-rates-when-a-cold-cluster-starts-up"><a href="#How-to-mitigate-the-poor-hit-rates-when-a-cold-cluster-starts-up" class="headerlink" title="How to mitigate the poor hit rates when a cold cluster starts up?"></a>How to mitigate the poor hit rates when a cold cluster starts up?</h3><ol>
<li>When we bring a new cluster online, an existing one fails, or perform scheduled maintenance; the caches will have very poor hit rates, diminishing the ability to insulate backend services. </li>
<li>A system called Cold Cluster Warmup mitigates this by allowing clients in the “cold cluster” (i.e., the frontend cluster that has an empty cache) to retrieve data from the “warm cluster” (i.e., a cluster that has caches with normal hit rates) rather than the persistent storage. </li>
<li>Cold clusters can be brought back to full capacity in a few hours instead of a few days with this system. </li>
<li>The cold cluster warmup is turned off once the cold cluster’s hit rate stabilizes and the benefits diminish. </li>
</ol>
<h3 id="How-to-solve-the-race-in-cold-cluster-warmup-caused-by-an-update-in-the-cold-cluster"><a href="#How-to-solve-the-race-in-cold-cluster-warmup-caused-by-an-update-in-the-cold-cluster" class="headerlink" title="How to solve the race in cold cluster warmup caused by an update in the cold cluster?"></a>How to solve the race in cold cluster warmup caused by an update in the cold cluster?</h3><ol>
<li>If a client in the cold cluster does a database update, and a subsequent request from another client retrieves the stale value from the warm cluster before the warm cluster has received the invalidation, that item will be indefinitely inconsistent in the cold cluster. </li>
<li>Memcached deletes support nonzero hold-off times that reject add operations for the specified hold-off time. <ul>
<li>By default, all deletes to the cold cluster are issued with a two-second hold-off. </li>
<li>When a miss is detected in the cold cluster, the client re-requests the key from the warm cluster and adds it to the cold cluster. </li>
<li>The failure of the add indicates that newer data is available on the database, and thus, the client will refetch the value from the databases. </li>
</ul>
</li>
</ol>
<h2 id="Across-regions-consistency"><a href="#Across-regions-consistency" class="headerlink" title="Across regions: consistency"></a>Across regions: consistency</h2><h3 id="How-to-execute-a-write-operation"><a href="#How-to-execute-a-write-operation" class="headerlink" title="How to execute a write operation?"></a>How to execute a write operation?</h3><ol>
<li><p>Of many regions, one region is designated to hold the master databases, and the other regions contain read-only replicas. </p>
</li>
<li><p>For writes from a master region:</p>
<ul>
<li><p>The storage cluster of each region will send invalidations after they have replicated data. </p>
</li>
<li><p>It avoids a race condition in which an invalidation arrives before the data has been replicated from the master region. </p>
</li>
</ul>
</li>
<li><p>For writes from a non-master region: </p>
<ul>
<li>The user’s next request could be confused about whether his recent change is missing. </li>
<li>Employ a remote marker mechanism to minimize the probability of reading stale data. <ul>
<li>The marker indicates that data in the local replica database are potentially stale, and the query should be redirected to the master region. </li>
</ul>
</li>
<li>When a web server wishes to update data that affects a key $k$, that server<ul>
<li>sets a remote marker $r_k$ in the region</li>
<li>performs the write to the master embedding $k$ and $r_k$ to be invalidated in the SQL statement</li>
<li>deletes $k$ in the local cluster</li>
</ul>
</li>
<li>On a subsequent request for $k$, <ul>
<li>A web server will be unable to find the cached data.</li>
<li>Check whether $r_k$ exists</li>
<li>Direct its query to the master or local region depending on the presence of $r_k$. </li>
</ul>
</li>
<li>The remote markers are implemented by using a regional pool. </li>
<li>This mechanism may reveal stale information during concurrent modifications to the same key as one operation may delete a remote marker that should remain present for another in-flight operation. </li>
</ul>
</li>
</ol>

    </div>

    
    
    

    <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/Distributed-System/" rel="tag"><i class="fa fa-tag"></i> Distributed System</a>
              <a href="/tags/Cache-System/" rel="tag"><i class="fa fa-tag"></i> Cache System</a>
          </div>

        

          <div class="post-nav">
            <div class="post-nav-item">
                <a href="/2023/09/26/Paper/Distributed/Spark/" rel="prev" title="Spark">
                  <i class="fa fa-chevron-left"></i> Spark
                </a>
            </div>
            <div class="post-nav-item">
                <a href="/2023/09/26/Paper/Distributed/COPS/" rel="next" title="COPS">
                  COPS <i class="fa fa-chevron-right"></i>
                </a>
            </div>
          </div>
    </footer>
  </article>
</div>






</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">


<div class="copyright">
  &copy; 
  <span itemprop="copyrightYear">2024</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">LiyunZhang</span>
</div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.js.org/mist/" rel="noopener" target="_blank">NexT.Mist</a>
  </div>

    </div>
  </footer>

  
  <div class="toggle sidebar-toggle" role="button">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>
  <div class="sidebar-dimmer"></div>
  <div class="back-to-top" role="button" aria-label="Back to top">
    <i class="fa fa-arrow-up fa-lg"></i>
    <span>0%</span>
  </div>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


  
  <script src="https://cdnjs.cloudflare.com/ajax/libs/animejs/3.2.1/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script>
<script src="/js/comments.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/schemes/muse.js"></script><script src="/js/next-boot.js"></script>

  <script src="https://cdnjs.cloudflare.com/ajax/libs/hexo-generator-searchdb/1.4.1/search.js" integrity="sha256-1kfA5uHPf65M5cphT2dvymhkuyHPQp5A53EGZOnOLmc=" crossorigin="anonymous"></script>
<script src="/js/third-party/search/local-search.js"></script>







  




  

  <script class="next-config" data-name="enableMath" type="application/json">true</script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.7/katex.min.css" integrity="sha256-hLTCMFlKxdNgPXyWlSSxYN0ykJmxxq9Yt3MNfdRGWeA=" crossorigin="anonymous">



</body>
</html>

<!DOCTYPE html>
<html lang="zh-Hans">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222" media="(prefers-color-scheme: light)">
<meta name="theme-color" content="#222" media="(prefers-color-scheme: dark)"><meta name="generator" content="Hexo 6.3.0">

  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">



<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css" integrity="sha256-HtsXJanqjKTc8vVQjO4YMhiqFoXkfBsjBWcX91T1jr8=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/animate.css/3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">

<script class="next-config" data-name="main" type="application/json">{"hostname":"liyun-zhang.github.io","root":"/","images":"/images","scheme":"Mist","darkmode":true,"version":"8.17.0","exturl":false,"sidebar":{"position":"right","display":"hide","padding":18,"offset":12},"copycode":{"enable":false,"style":null},"bookmark":{"enable":false,"color":"#222","save":"auto"},"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"stickytabs":false,"motion":{"enable":true,"async":false,"transition":{"menu_item":"fadeInDown","post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"prism":false,"i18n":{"placeholder":"Searching...","empty":"We didn't find any results for the search: ${query}","hits_time":"${hits} results found in ${time} ms","hits":"${hits} results found"},"path":"/search.xml","localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false}}</script><script src="/js/config.js"></script>

    <meta name="description" content="Paper: Resilient Distributed Datasets: A Fault-Tolerant Abstraction for In-Memory Cluster Computing @[toc] Purpose Contribution:  Present Resilient Distributed Datasets (RDDs), a distributed memory ab">
<meta property="og:type" content="article">
<meta property="og:title" content="Spark">
<meta property="og:url" content="http://liyun-zhang.github.io/2023/09/26/Paper/Distributed/Spark/index.html">
<meta property="og:site_name" content="LiyunZhang">
<meta property="og:description" content="Paper: Resilient Distributed Datasets: A Fault-Tolerant Abstraction for In-Memory Cluster Computing @[toc] Purpose Contribution:  Present Resilient Distributed Datasets (RDDs), a distributed memory ab">
<meta property="og:locale">
<meta property="og:image" content="http://liyun-zhang.github.io/imgs/Distributed/Spark/runtime.png">
<meta property="og:image" content="http://liyun-zhang.github.io/imgs/Distributed/Spark/ml-base.png">
<meta property="og:image" content="http://liyun-zhang.github.io/imgs/Distributed/Spark/hadoop.png">
<meta property="og:image" content="http://liyun-zhang.github.io/imgs/Distributed/Spark/ml-scale.png">
<meta property="og:image" content="http://liyun-zhang.github.io/imgs/Distributed/Spark/fault-recovery.png">
<meta property="og:image" content="http://liyun-zhang.github.io/imgs/Distributed/Spark/mem-lim.png">
<meta property="article:published_time" content="2023-09-26T05:50:52.000Z">
<meta property="article:modified_time" content="2024-03-15T13:29:05.814Z">
<meta property="article:author" content="LiyunZhang">
<meta property="article:tag" content="Distributed System">
<meta property="article:tag" content="Distributed Computation">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://liyun-zhang.github.io/imgs/Distributed/Spark/runtime.png">


<link rel="canonical" href="http://liyun-zhang.github.io/2023/09/26/Paper/Distributed/Spark/">



<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":false,"isPost":true,"lang":"zh-Hans","comments":true,"permalink":"http://liyun-zhang.github.io/2023/09/26/Paper/Distributed/Spark/","path":"2023/09/26/Paper/Distributed/Spark/","title":"Spark"}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>Spark | LiyunZhang</title>
  








  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
</head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <div class="column">
      <header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar" role="button">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <p class="site-title">LiyunZhang</p>
      <i class="logo-line"></i>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger" aria-label="Search" role="button">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i>Home</a></li><li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>Tags</a></li><li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>Categories</a></li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>Search
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup"><div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off" maxlength="80"
           placeholder="Searching..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close" role="button">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div class="search-result-container no-result">
  <div class="search-result-icon">
    <i class="fa fa-spinner fa-pulse fa-5x"></i>
  </div>
</div>
    </div>
  </div>

</header>
        
  
  <aside class="sidebar">

    <div class="sidebar-inner sidebar-nav-active sidebar-toc-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
            <div class="post-toc animated"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#Purpose"><span class="nav-number">1.</span> <span class="nav-text">Purpose</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Model"><span class="nav-number">2.</span> <span class="nav-text">Model</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#RDDs"><span class="nav-number">2.1.</span> <span class="nav-text">RDDs</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#What-is-RDD"><span class="nav-number">2.1.1.</span> <span class="nav-text">What is RDD?</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#What-are-the-advantages-of-the-RDD-model-compared-with-distributed-shared-memory-DSM"><span class="nav-number">2.1.2.</span> <span class="nav-text">What are the advantages of the RDD model compared with distributed shared memory (DSM)?</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#What-kind-of-applications-are-suited-for-RDDs"><span class="nav-number">2.1.3.</span> <span class="nav-text">What kind of applications are suited for RDDs?</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Spark"><span class="nav-number">2.2.</span> <span class="nav-text">Spark</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#What-is-the-runtime-of-Spark"><span class="nav-number">2.2.1.</span> <span class="nav-text">What is the runtime of Spark?</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#What-is-the-Spark-programming-interface-of-RDDs"><span class="nav-number">2.2.2.</span> <span class="nav-text">What is the Spark programming interface of RDDs?</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#What-RDD-operations-are-supported-in-Spark"><span class="nav-number">2.2.3.</span> <span class="nav-text">What RDD operations are supported in Spark?</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#What-is-the-common-interface-of-each-RDD"><span class="nav-number">2.2.4.</span> <span class="nav-text">What is the common interface of each RDD?</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#What-is-the-interface-that-represents-dependencies-between-RDDs"><span class="nav-number">2.2.5.</span> <span class="nav-text">What is the interface that represents dependencies between RDDs?</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Implementation"><span class="nav-number">2.3.</span> <span class="nav-text">Implementation</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#How-does-Spark-schedule-computations"><span class="nav-number">2.3.1.</span> <span class="nav-text">How does Spark schedule computations?</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#How-does-Spark-handle-task-failures"><span class="nav-number">2.3.2.</span> <span class="nav-text">How does Spark handle task failures?</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#How-does-Spark-manage-the-storage-of-persistent-RDDs"><span class="nav-number">2.3.3.</span> <span class="nav-text">How does Spark manage the storage of persistent RDDs?</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#How-does-Spark-evict-RDDs-when-run-out-of-memory"><span class="nav-number">2.3.4.</span> <span class="nav-text">How does Spark evict RDDs when run out of memory?</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#When-will-checkpointing-be-useful"><span class="nav-number">2.3.5.</span> <span class="nav-text">When will checkpointing be useful?</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Experiment"><span class="nav-number">3.</span> <span class="nav-text">Experiment</span></a></li></ol></div>
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">LiyunZhang</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/archives/">
          <span class="site-state-item-count">62</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
          <a href="/categories/">
        <span class="site-state-item-count">10</span>
        <span class="site-state-item-name">categories</span></a>
      </div>
      <div class="site-state-item site-state-tags">
          <a href="/tags/">
        <span class="site-state-item-count">29</span>
        <span class="site-state-item-name">tags</span></a>
      </div>
  </nav>
</div>

        </div>
      </div>
    </div>

    
  </aside>


    </div>

    <div class="main-inner post posts-expand">

  
  


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="zh-Hans">
    <link itemprop="mainEntityOfPage" href="http://liyun-zhang.github.io/2023/09/26/Paper/Distributed/Spark/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="LiyunZhang">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="LiyunZhang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="Spark | LiyunZhang">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          Spark
        </h1>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2023-09-26 13:50:52" itemprop="dateCreated datePublished" datetime="2023-09-26T13:50:52+08:00">2023-09-26</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">Edited on</span>
      <time title="Modified: 2024-03-15 21:29:05" itemprop="dateModified" datetime="2024-03-15T21:29:05+08:00">2024-03-15</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">In</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Paper-Notebook/" itemprop="url" rel="index"><span itemprop="name">Paper Notebook</span></a>
        </span>
          , 
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Paper-Notebook/Distributed-System/" itemprop="url" rel="index"><span itemprop="name">Distributed System</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody"><p>Paper: <a target="_blank" rel="noopener" href="http://nil.csail.mit.edu/6.824/2020/papers/zaharia-spark.pdf">Resilient Distributed Datasets: A Fault-Tolerant Abstraction for In-Memory Cluster Computing</a></p>
<p>@[toc]</p>
<h1 id="Purpose"><a href="#Purpose" class="headerlink" title="Purpose"></a>Purpose</h1><ol>
<li><p>Contribution:</p>
<ul>
<li>Present Resilient Distributed Datasets (RDDs), a distributed memory abstraction, lets programmers perform in-memory computations on large clusters fault-tolerantly. </li>
<li>RDDs provide an interface based on coarse-grained transformations (e.g., map, filter, and join) that apply the same operation to many data items. </li>
</ul>
</li>
<li><p>Issues:</p>
<ul>
<li>Current computing frameworks handle two types of applications inefficiently: iterative algorithms and interactive data mining tools. </li>
<li><p>Current frameworks lack abstractions for leveraging distributed memory. </p>
<ul>
<li>In most current frameworks, the only way to reuse data between computations is to write it to an external stable storage system. </li>
<li>This makes them inefficient for those that reuse intermediate results across multiple computations. </li>
<li>This incurs substantial overheads due to data replication, disk I/O, and serialization. </li>
</ul>
</li>
<li><p>Some specialized frameworks have been developed for some applications that require data reuse. However, they do not provide abstractions for more general reuse. </p>
</li>
<li>Both replicating the data across machines and logging updates across machines are expensive for data-intensive workloads. </li>
</ul>
</li>
</ol>
<h1 id="Model"><a href="#Model" class="headerlink" title="Model"></a>Model</h1><h2 id="RDDs"><a href="#RDDs" class="headerlink" title="RDDs"></a>RDDs</h2><h3 id="What-is-RDD"><a href="#What-is-RDD" class="headerlink" title="What is RDD?"></a>What is RDD?</h3><ol>
<li>An RDD is a read-only, partitioned collection of records. <ul>
<li>Although individual RDDs are immutable, it is possible to implement mutable states with multiple RDDs representing multiple dataset versions. </li>
</ul>
</li>
<li>RDDs can only be created through deterministic operations on either data in stable storage or other RDDs. <ul>
<li>These operations are called transformations to differentiate them from other operations on RDDs. </li>
</ul>
</li>
<li>An RDD has enough information about how it was derived from other datasets (its lineage) to compute its partitions from data in stable storage. <ul>
<li>A program cannot reference an RDD that it cannot reconstruct after a failure. </li>
<li>RDDs do not need to be materialized at all times. </li>
</ul>
</li>
<li>Users can control two other aspects of RDDs: persistence and partitioning. <ul>
<li>Users can indicate which RDDs they will reuse and choose a storage strategy. </li>
<li>They can also ask that an RDD’s elements be partitioned across machines based on a key in each record. </li>
</ul>
</li>
</ol>
<h3 id="What-are-the-advantages-of-the-RDD-model-compared-with-distributed-shared-memory-DSM"><a href="#What-are-the-advantages-of-the-RDD-model-compared-with-distributed-shared-memory-DSM" class="headerlink" title="What are the advantages of the RDD model compared with distributed shared memory (DSM)?"></a>What are the advantages of the RDD model compared with distributed shared memory (DSM)?</h3><ol>
<li><p>The main difference between RDDs and DSM is that RDDs can only be created (“written”) through coarse-grained transformations, while DSM allows reads and writes to each memory location. </p>
<ul>
<li>This restricts RDDs to applications that perform bulk writes but allows for more efficient fault tolerance.</li>
<li>RDDs do not need to incur the overhead of checkpointing, as they can be recovered using lineage. </li>
<li>Only the lost partitions of an RDD need to be recomputed upon failure, and they can be recomputed in parallel on different nodes without having to roll back the whole program. </li>
</ul>
</li>
<li><p>RDDs’ immutable nature lets a system mitigate slow nodes (stragglers) by running backup copies of slow tasks, as in MapReduce. </p>
<ul>
<li>Backup tasks would be challenging to implement with DSM, as the two copies of a task would access the same memory locations and interfere with each other’s updates. </li>
</ul>
</li>
<li><p>In bulk operations on RDDs, a runtime can schedule tasks based on data locality to improve performance. </p>
</li>
<li><p>RDDs degrade gracefully when there is not enough memory to store them as long as they are only used in scan-based operations. </p>
<p>Partitions that do not fit in RAM can be stored on disk and provide performance similar to current data-parallel systems. </p>
</li>
</ol>
<h3 id="What-kind-of-applications-are-suited-for-RDDs"><a href="#What-kind-of-applications-are-suited-for-RDDs" class="headerlink" title="What kind of applications are suited for RDDs?"></a>What kind of applications are suited for RDDs?</h3><ol>
<li>RDDs are best suited for batch applications that apply the same operation to all dataset elements. <ul>
<li>RDDs can efficiently remember each transformation as one step in a lineage graph and recover lost partitions without logging large amounts of data. </li>
</ul>
</li>
<li>RDDs would be less suitable for applications that make asynchronous fine-grained updates to shared states. </li>
</ol>
<h2 id="Spark"><a href="#Spark" class="headerlink" title="Spark"></a>Spark</h2><h3 id="What-is-the-runtime-of-Spark"><a href="#What-is-the-runtime-of-Spark" class="headerlink" title="What is the runtime of Spark?"></a>What is the runtime of Spark?</h3><ol>
<li>Developers write a <strong>driver</strong> program that connects to a cluster of <strong>workers</strong>. <ul>
<li>The driver defines one or more RDDs and invokes actions on them. </li>
<li>Spark code on the driver also tracks the RDDs’ lineage. </li>
</ul>
</li>
<li>The workers are long-lived processes that can store RDD partitions in RAM across operations. </li>
</ol>
<p><img src="/imgs/Distributed/Spark/runtime.png" width="30%"></p>
<h3 id="What-is-the-Spark-programming-interface-of-RDDs"><a href="#What-is-the-Spark-programming-interface-of-RDDs" class="headerlink" title="What is the Spark programming interface of RDDs?"></a>What is the Spark programming interface of RDDs?</h3><ol>
<li>Each dataset is represented as an object, and transformations are invoked using methods for these objects. </li>
<li>Programmers start by defining one or more RDDs through transformations on data in stable storage. <ul>
<li>They can then use these RDDs in actions, which are operations that return a value to the application or export data to a storage system. </li>
</ul>
</li>
<li>Programmers can call a <code>persist()</code> method to indicate which RDDs they want to reuse in future operations. <ul>
<li>Spark keeps persistent RDDs in memory by default but can spill them to disk without enough RAM. </li>
<li>Users can set a persistence priority on each RDD to specify which in-memory data should spill to disk first. </li>
<li>The user can call <code>persist</code> with a <code>RELIABLE</code> flag to reliably replicate some of the versions of RDDs to reduce fault recovery times. </li>
</ul>
</li>
</ol>
<h3 id="What-RDD-operations-are-supported-in-Spark"><a href="#What-RDD-operations-are-supported-in-Spark" class="headerlink" title="What RDD operations are supported in Spark?"></a>What RDD operations are supported in Spark?</h3><ol>
<li>Users provide arguments to RDD operations by passing closures (function literals). </li>
<li>RDDs themselves are statically typed objects parametrized by an element type. </li>
<li>Transformations are <strong>lazy</strong> operations that define a new RDD. <ul>
<li>$map(f: T\Rightarrow U): RDD[T]\Rightarrow RDD[U]$</li>
<li>$filter(f: T\Rightarrow Bool): RDD[T]\Rightarrow RDD[T]$</li>
<li>$flatMap(f: T\Rightarrow Seq[U]): RDD[T]\Rightarrow RDD[U]$</li>
<li>$sample(fraction: Float): RDD[T]\Rightarrow RDD[T]$ (Deterministic sampling)</li>
<li>$groupByKey(): RDD[(K,V)]\Rightarrow RDD[(K,Seq[V])]$</li>
<li>$reduceByKey(f:(V,V)\Rightarrow V): RDD[(K,V)]\Rightarrow RDD[(K,V)]$</li>
<li>$union(): (RDD[T],RDD[T])\Rightarrow RDD[T]$</li>
<li>$join():(RDD[(K,V)],RDD[(K,W)])\Rightarrow RDD[(K,(V,W))]$</li>
<li>$cogroup():(RDD[(K,V)],RDD[(K,W)])\Rightarrow RDD[(K,(Seq[V],Seq[W]))]$</li>
<li>$crossProduct():(RDD[T],RDD[U])\Rightarrow RDD[(T,U)]$</li>
<li>$mapValues(f:V\Rightarrow W):RDD[(K,V)]\Rightarrow RDD[(K,W)]$ (Preserves partitioning)</li>
<li>$sort(c:Comparator[K]):RDD[(K,V)]\Rightarrow RDD[(K,V)]$</li>
<li>$partitionBy(p:Partitioner[K]):RDD[(K,V)]\Rightarrow RDD[(K,V)]$</li>
</ul>
</li>
<li>Actions launch a computation to return a value to the program or write data to external storage. <ul>
<li>$count(): RDD[T]\Rightarrow Long:$ Returns the number of elements in the dataset</li>
<li>$collect(): RDD[T]\Rightarrow Seq[T]:$ Returns the elements themselves</li>
<li>$reduce(f:(T,T)\Rightarrow T): RDD[T]\Rightarrow T$</li>
<li>$lookup(k:K):RDD[(K,V)]\Rightarrow Seq[V]$ (On hash/range partitioned RDDs)</li>
<li>$save(path:String):$ Outputs RDD to a storage system</li>
</ul>
</li>
</ol>
<h3 id="What-is-the-common-interface-of-each-RDD"><a href="#What-is-the-common-interface-of-each-RDD" class="headerlink" title="What is the common interface of each RDD?"></a>What is the common interface of each RDD?</h3><ol>
<li>A set of partitions, which are atomic pieces of the dataset<ul>
<li>$partitioner():$ Return metadata specifying whether the RDD is hash/range partitioned.</li>
</ul>
</li>
<li>A set of dependencies on parent RDDs<ul>
<li>$dependencies():$ Return a list of dependencies.</li>
</ul>
</li>
<li>A function for computing the dataset based on its parents<ul>
<li>$iterator(p, parentIters):$ Compute the elements of partition p given iterators for its parent partitions.</li>
</ul>
</li>
<li>Metadata about its partitioning scheme and data placement<ul>
<li>$partitions():$ Return a list of Partition objects.</li>
<li>$preferredLocations(p):$ List nodes where the partition $p$ can be accessed faster due to data locality</li>
</ul>
</li>
</ol>
<h3 id="What-is-the-interface-that-represents-dependencies-between-RDDs"><a href="#What-is-the-interface-that-represents-dependencies-between-RDDs" class="headerlink" title="What is the interface that represents dependencies between RDDs?"></a>What is the interface that represents dependencies between RDDs?</h3><ol>
<li><p>Classify dependencies into two types: </p>
<ul>
<li>Narrow dependencies: each partition of the parent RDD is used by at most one partition of the child RDD. </li>
<li>Wide dependencies: multiple child partitions may depend on it. </li>
</ul>
</li>
<li><p>Narrow dependencies allow pipelined execution on one cluster node, which can compute all the parent partitions. </p>
<p>Wide dependencies require data from all parent partitions to be available and shuffled across the nodes using a MapReduce-like operation. </p>
</li>
<li><p>Recovery after a node failure is more efficient with a narrow dependency, as only the lost parent partitions need to be recomputed, and they can be recomputed in parallel on different nodes. </p>
<p>In a lineage graph with wide dependencies, a single failed node might cause the loss of some partition from all the ancestors of an RDD, requiring a complete re-execution. </p>
</li>
</ol>
<h2 id="Implementation"><a href="#Implementation" class="headerlink" title="Implementation"></a>Implementation</h2><h3 id="How-does-Spark-schedule-computations"><a href="#How-does-Spark-schedule-computations" class="headerlink" title="How does Spark schedule computations?"></a>How does Spark schedule computations?</h3><ol>
<li><p>Whenever a user runs an action on an RDD, the scheduler examines that RDD’s lineage graph to build a DAG of stages to execute. </p>
<ul>
<li><p>Each stage contains as many pipelined transformations with narrow dependencies as possible. </p>
</li>
<li><p>The boundaries of the stages are the shuffle operations required for wide dependencies or any already computed partitions that can short-circuit the computation of a parent RDD. </p>
</li>
</ul>
</li>
<li><p>The scheduler then launches tasks to compute missing partitions from each stage until the target RDD is computed. </p>
<ul>
<li>The scheduler assigns tasks to machines based on data locality using delay scheduling. </li>
<li>If a task needs to process a partition available in memory on a node, we send it to that node. </li>
<li>Otherwise, if a task processes a partition for which the containing RDD provides preferred locations (e.g., an HDFS file), we send it to those. </li>
</ul>
</li>
</ol>
<h3 id="How-does-Spark-handle-task-failures"><a href="#How-does-Spark-handle-task-failures" class="headerlink" title="How does Spark handle task failures?"></a>How does Spark handle task failures?</h3><ol>
<li><p>For wide dependencies, it is possible that those alive workers have long passed the wide-dependent points and already discard intermediate results, causing the stage to become unavailable. In that case, all the dependencies must be re-calculated, which is costly. </p>
</li>
<li><p>Hence, intermediate records are materialized on the nodes holding parent partitions to simplify fault recovery. </p>
<ul>
<li><p>If a task fails, it will be re-run on another node if its stage’s parents are still available. </p>
</li>
<li><p>If some stages have become unavailable, a limited number of tasks to compute the missing partitions are resubmitted in parallel. </p>
</li>
</ul>
</li>
</ol>
<h3 id="How-does-Spark-manage-the-storage-of-persistent-RDDs"><a href="#How-does-Spark-manage-the-storage-of-persistent-RDDs" class="headerlink" title="How does Spark manage the storage of persistent RDDs?"></a>How does Spark manage the storage of persistent RDDs?</h3><ol>
<li>In-memory storage as deserialized Java objects<ul>
<li>It provides the fastest performance because the Java VM can access each RDD element natively. </li>
</ul>
</li>
<li>In-memory storage as serialized data<ul>
<li>It lets users choose a more memory-efficient representation than Java object graphs when space is limited, at the cost of lower performance. </li>
</ul>
</li>
<li>On-disk storage<ul>
<li>It is useful for RDDs that are too large to keep in RAM but costly to recompute on each use. </li>
</ul>
</li>
</ol>
<h3 id="How-does-Spark-evict-RDDs-when-run-out-of-memory"><a href="#How-does-Spark-evict-RDDs-when-run-out-of-memory" class="headerlink" title="How does Spark evict RDDs when run out of memory?"></a>How does Spark evict RDDs when run out of memory?</h3><ol>
<li>The LRU eviction policy is used at the RDD level. </li>
<li>Unless the LRU RDD is the same RDD as the one with the new partition. <ul>
<li>The old partition is kept in memory to prevent cycling partitions from the same RDD in and out. </li>
<li>This is important because most operations will run tasks over an entire RDD, so it is likely that the partition already in memory will be needed in the future. </li>
</ul>
</li>
</ol>
<h3 id="When-will-checkpointing-be-useful"><a href="#When-will-checkpointing-be-useful" class="headerlink" title="When will checkpointing be useful?"></a>When will checkpointing be useful?</h3><ol>
<li>Checkpointing is useful for RDDs with long lineage graphs containing wide dependencies. <ul>
<li>A node failure in the cluster may result in the loss of some slice of data from each parent RDD, requiring a full recomputation. </li>
</ul>
</li>
<li>Checkpointing may never be worthwhile for RDDs with narrow dependencies on data in stable storage. <ul>
<li>If a node fails, lost partitions from these RDDs can be recomputed in parallel on other nodes at a fraction of the cost of replicating the whole RDD. </li>
</ul>
</li>
<li>The read-only nature of RDDs makes them simpler to checkpoint than general shared memory. <ul>
<li>Consistency is not a concern. RDDs can be written in the background without program pauses or distributed snapshot schemes. </li>
</ul>
</li>
</ol>
<h1 id="Experiment"><a href="#Experiment" class="headerlink" title="Experiment"></a>Experiment</h1><ol>
<li><p>The main contribution of this paper is improving the performance of iterative applications; hence, the author measured the speedup of Spark against Hadoop. </p>
<ul>
<li><p>One scene of iterative applications is machine learning applications. The author chose k-means and logistic regression to measure performance. </p>
<ul>
<li>The iteration time of k-means is dominated by computation. </li>
<li>Logistic regression is less compute-intensive and thus more sensitive to time spent in deserialization and I/O. </li>
<li>The time consumed should be reported for the first iteration and subsequent iterations separately as follows: </li>
</ul>
<p><img src="/imgs/Distributed/Spark/ml-base.png" width="50%"></p>
</li>
<li><p>Another scene is the PageRank algorithm. </p>
</li>
</ul>
</li>
<li><p>Hadoop ran slower due to several factors.</p>
<ul>
<li>Minimum overhead of the Hadoop software stack<ul>
<li>It can be measured by running no-op Hadoop jobs. </li>
</ul>
</li>
<li>The overhead of HDFS while serving data<ul>
<li>HDFS performed multiple memory copies and a checksum to serve each block. </li>
<li>This can be seen by comparing the time it takes to access in-memory HDFS and local files. </li>
</ul>
</li>
<li>Deserialization cost to convert binary records to usable in-memory Java objects.<ul>
<li>This can be seen by comparing the time of access to text and binary input. </li>
</ul>
</li>
</ul>
<p><img src="/imgs/Distributed/Spark/hadoop.png" width=50%></p>
</li>
<li><p>Scalability is another metric. The result of a machine learning algorithm is as shown below:</p>
<p><img src="/imgs/Distributed/Spark/ml-scale.png" width="50%"></p>
</li>
<li><p>Another important metric of the systems is failure fault recovery. </p>
<ul>
<li>The author measured the time consumed in each iteration while a node failed at the start of 6th iteration. </li>
</ul>
<p><img src="/imgs/Distributed/Spark/fault-recovery.png" width="50%"></p>
</li>
<li><p>Given that Spark assumes that most RDDs will be stored in memory, the author also measured the performance when memory is limited. </p>
<ul>
<li>The performance degrades gracefully with less space.</li>
</ul>
<p><img src="/imgs/Distributed/Spark/mem-lim.png" width=50%></p>
</li>
<li><p>Given that Spark provides an interactive interpreter, the author also measured the response time thes of those queries. </p>
</li>
<li><p>To prove that RDD can support a broad class of applications, the author showed how to use RDDs to express existing programming models (e.g., MapReduce, SQL, Pregel)</p>
</li>
</ol>

    </div>

    
    
    

    <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/Distributed-System/" rel="tag"><i class="fa fa-tag"></i> Distributed System</a>
              <a href="/tags/Distributed-Computation/" rel="tag"><i class="fa fa-tag"></i> Distributed Computation</a>
          </div>

        

          <div class="post-nav">
            <div class="post-nav-item">
                <a href="/2023/09/26/Paper/Distributed/Spanner/" rel="prev" title="Spanner">
                  <i class="fa fa-chevron-left"></i> Spanner
                </a>
            </div>
            <div class="post-nav-item">
                <a href="/2023/09/26/Paper/Distributed/Memcache/" rel="next" title="Memcache">
                  Memcache <i class="fa fa-chevron-right"></i>
                </a>
            </div>
          </div>
    </footer>
  </article>
</div>






</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">


<div class="copyright">
  &copy; 
  <span itemprop="copyrightYear">2024</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">LiyunZhang</span>
</div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.js.org/mist/" rel="noopener" target="_blank">NexT.Mist</a>
  </div>

    </div>
  </footer>

  
  <div class="toggle sidebar-toggle" role="button">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>
  <div class="sidebar-dimmer"></div>
  <div class="back-to-top" role="button" aria-label="Back to top">
    <i class="fa fa-arrow-up fa-lg"></i>
    <span>0%</span>
  </div>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


  
  <script src="https://cdnjs.cloudflare.com/ajax/libs/animejs/3.2.1/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script>
<script src="/js/comments.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/schemes/muse.js"></script><script src="/js/next-boot.js"></script>

  <script src="https://cdnjs.cloudflare.com/ajax/libs/hexo-generator-searchdb/1.4.1/search.js" integrity="sha256-1kfA5uHPf65M5cphT2dvymhkuyHPQp5A53EGZOnOLmc=" crossorigin="anonymous"></script>
<script src="/js/third-party/search/local-search.js"></script>







  




  

  <script class="next-config" data-name="enableMath" type="application/json">true</script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.7/katex.min.css" integrity="sha256-hLTCMFlKxdNgPXyWlSSxYN0ykJmxxq9Yt3MNfdRGWeA=" crossorigin="anonymous">



</body>
</html>

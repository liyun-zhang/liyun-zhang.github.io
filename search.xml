<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>Version Control</title>
      <link href="/2024/03/24/Version-Control/"/>
      <url>/2024/03/24/Version-Control/</url>
      
        <content type="html"><![CDATA[<p><ul class="markdownIt-TOC"><li><a href="#file">File</a><ul><li><a href="#how-to-organize-logs">How to organize logs?</a></li><li><a href="#how-do-we-know-the-information-of-files">How do we know the information of files?</a></li></ul></li></ul></p><h1 id="file"><a class="markdownIt-Anchor" href="#file"></a> File</h1><h2 id="how-to-organize-logs"><a class="markdownIt-Anchor" href="#how-to-organize-logs"></a> How to organize logs?</h2><ol><li>There are <code>mem_</code>, <code>imm_</code>, and persisted logs. They are all Memtables.</li><li>Both <code>mem_</code> and <code>imm_</code> are in volatile storages.<ul><li>The <code>mem_</code> is the latest Memtable to which we can append logs.</li><li>When <code>mem_</code> is full, it will be frozen into <code>imm_</code> to be an immutable Memtable.</li></ul></li><li>The <code>imm_</code> will be written into disks as persisted logs.<ul><li>The persisted logs are separated into several levels, starting from <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>0</mn></mrow><annotation encoding="application/x-tex">0</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">0</span></span></span></span>. The lower level contains newer logs.</li><li>The SSTables at lower levels can be compacted into higher-level SSTables.</li></ul></li></ol><h2 id="how-do-we-know-the-information-of-files"><a class="markdownIt-Anchor" href="#how-do-we-know-the-information-of-files"></a> How do we know the information of files?</h2><ol><li>Each <code>FileMetaData</code> corresponds to a file on the disk. It contained basic metadata of a file, including ID (<code>number</code>), size (<code>file_size</code>), and its key range (<code>smallest</code> and <code>largest</code>).</li><li>The <code>Version</code> contains all the metadata of files.<ul><li>List of files of different levels are stored in <code>std::vector&lt;FileMetaData*&gt; files_[config::kNumLevels]</code>.</li><li>Both <code>Version</code> and <code>FileMetaData</code> uses <code>ref</code> to track pointers that point to them. They are destroyed when <code>ref</code> goes to <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>0</mn></mrow><annotation encoding="application/x-tex">0</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">0</span></span></span></span>.</li></ul></li><li>The <code>VersionSet</code> contains all the <code>Version</code>s of the database. They are formed into a list.<ul><li>The most recent version is in <code>current_</code>. There is a <code>dummy_versions_</code> as the head of the list.</li><li>The <code>prev_</code> pointer in <code>Version</code> is the previous version while <code>next_</code> is the newer version.</li><li>The <code>current_</code> is considered the previous of <code>dummy_versions_</code>.</li></ul></li><li>From <code>VersionSet::AppendVersion</code>, we can see that this list is a cycle.<ul><li>The <code>next_</code> of <code>dummy_versions_</code> points to the oldest version since it will only be set when add the first version into the list.</li><li>The <code>prev_</code> of the oldest version points to the <code>dummy_versions_</code>.</li></ul></li></ol>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>2. Cache</title>
      <link href="/2024/03/22/OpenSource/LevelDB/Cache/"/>
      <url>/2024/03/22/OpenSource/LevelDB/Cache/</url>
      
        <content type="html"><![CDATA[<p><ul class="markdownIt-TOC"><li><a href="#how-to-prevent-reading-from-the-disk-too-often">How to prevent reading from the disk too often?</a></li><li><a href="#lrucache">LRUCache</a><ul><li><a href="#how-does-handletable-insert-evict-and-lookup-items-in-table_">How does HandleTable insert, evict, and lookup items in table_?</a></li><li><a href="#how-to-insert-evict-and-lookup-items">How to insert, evict, and lookup items?</a></li></ul></li><li><a href="#tablecache">TableCache</a><ul><li><a href="#what-is-stored-in-each-cache-slot">What is stored in each cache slot?</a></li><li><a href="#how-does-tablecache-read-a-key">How does TableCache read a key?</a></li><li><a href="#how-does-tablecache-iterate-over-a-file">How does TableCache iterate over a file?</a></li></ul></li></ul></p><h1 id="how-to-prevent-reading-from-the-disk-too-often"><a class="markdownIt-Anchor" href="#how-to-prevent-reading-from-the-disk-too-often"></a> How to prevent reading from the disk too often?</h1><ol><li>There are only two Memtables, <code>mem_</code> and <code>imm_</code>, in the memory. We may need to read from disk often, especially for level <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>0</mn></mrow><annotation encoding="application/x-tex">0</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">0</span></span></span></span> files. The solution is to cache</li><li>The <code>TableCache</code> provides interfaces for <code>VersionSet</code> to use cache strategies.<ul><li>It has a <code>Cache*</code> that points to a specific cache strategy. The <code>Cache</code> is a base class implemented by <code>ShardedLRUCache</code> in <a href="https://github.com/google/leveldb/blob/068d5ee1a3ac40dabd00d211d5013af44be55bea/util/cache.cc#L339">cache.cc</a>.</li></ul></li><li>The <code>ShardedLRUCache</code> hashes keys into several <code>LRUCache</code>s.</li><li>Each <code>LRUCache</code> uses <code>LRUHandle</code> to store the list of cached contents.<ul><li>There are two lists: one <code>in-use_</code> list contains the items currently referenced by clients, and another <code>lru_</code> list includes the items not currently referenced by clients in LRU order.</li><li>Another <code>HandleTable</code> is used to fetch the items according to their hash value.</li></ul></li></ol><h1 id="lrucache"><a class="markdownIt-Anchor" href="#lrucache"></a> LRUCache</h1><h2 id="how-does-handletable-insert-evict-and-lookup-items-in-table_"><a class="markdownIt-Anchor" href="#how-does-handletable-insert-evict-and-lookup-items-in-table_"></a> How does HandleTable insert, evict, and lookup items in table_?</h2><ol><li>In <code>HandleTable</code>, <code>length_</code> is the total number of items in the cache. Here, we need to take the modulo operation on <code>hash</code> again.<ul><li>Since <code>length_</code> is set to be a power of <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>2</mn></mrow><annotation encoding="application/x-tex">2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">2</span></span></span></span>, <code>hash &amp; length_-1</code> is the modulo operation of <code>hash</code> concerning <code>length_</code>.</li></ul></li><li>The items in <code>HandleTable</code> are contained in a variable-length array <code>LRUHandle** list_</code>.<ul><li>Normally, each slot only has one item. However, when the size is growing, rehashing may cause a hash collision. Those collide items are connected into a list by <code>next_hash</code>.</li></ul></li><li>The <code>HandleTable::FindPointer</code> returns a pointer that points to the slot instead of the item.<ul><li>The target item is identified by having the same <code>hash</code> or the same key.</li><li>When the target item does not exist, it should return a position indicating the slot to insert the item instead of a <code>nullptr</code>.</li><li>When inserting an item, the new item will be replaced if the pointer points to another item or increases the number of elements. If the number of elements exceeds the <code>length_</code>, the table needs to resize.</li><li>When evicting an item, store the <code>next_hash</code> pointer in the found slot.</li></ul></li></ol><h2 id="how-to-insert-evict-and-lookup-items"><a class="markdownIt-Anchor" href="#how-to-insert-evict-and-lookup-items"></a> How to insert, evict, and lookup items?</h2><ol><li>The <code>next</code> and <code>prev</code> in <code>LRUHandler</code> point to their neighbors in the <code>in_use_</code> or <code>lru_</code> list. The <code>next_hash</code> points to its neighbor in <code>table_</code>.</li><li>To lookup a key, the <code>HandleTable::Lookup</code> is invoked. If the key exists, its <code>refs</code> is increased and moved to the <code>in_use_</code> list if it is in the <code>lru_</code>.</li><li>To insert a key, it must be appended to the <code>in_use_</code> list and the <code>table_</code>. We also need to remove what it replaced.<ul><li>If the <code>capacity_</code> is <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>0</mn></mrow><annotation encoding="application/x-tex">0</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">0</span></span></span></span> indicating the cache is turned off, these operations can be skipped.</li><li>If the cache usage after inserting exceeds the capacity, we need to evict items in the <code>lru_</code> in order.</li></ul></li><li>Both lookup and insert return a <code>Handle*</code> that can be reinterpreted as an <code>LRUHandle*</code>.</li><li>When the clients release an item, its <code>refs</code> is decreased.<ul><li>When the <code>refs</code> is <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1</mn></mrow><annotation encoding="application/x-tex">1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">1</span></span></span></span>, which means that only the LRUCache is holding it and can be moved from <code>in_use_</code> to <code>lru_</code>. The <code>prev</code> of <code>lru_</code> is the newest item while the <code>next</code> of <code>lru_</code> is the oldest. Therefore, <code>lru_.next</code> is the first item to be evicted.</li><li>When the <code>refs</code> is <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>0</mn></mrow><annotation encoding="application/x-tex">0</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">0</span></span></span></span>, which means no one is holding it, and it will be deleted.</li></ul></li></ol><h1 id="tablecache"><a class="markdownIt-Anchor" href="#tablecache"></a> TableCache</h1><h2 id="what-is-stored-in-each-cache-slot"><a class="markdownIt-Anchor" href="#what-is-stored-in-each-cache-slot"></a> What is stored in each cache slot?</h2><ol><li>The first kind of cached content is a specific file’s index block.<ul><li>The table cache uses the file number as the key. The value is a void pointer that can be interpreted as <code>TableAndFile*</code>.</li><li>The <code>TableAndFile</code> is the <code>RandomAccessFile*</code> and <code>Table*</code> to access the file. So, a cache slot stores the access to a file and the index of its keys.</li><li>The <code>RandomAccessFile*</code> provides a <code>Read</code> to read content for a given destination. The cache operations are executed through <code>Table*</code>.</li><li>The core of a <code>Table</code> is <code>Table::Rep</code>, which contains the contents of the index block in <code>Block* index_block</code>, the contents of the Bloom filter in <code>FilterBlockReader* filter</code>, and its  <code>cache_id</code>, which is a globally unique, monotonously increasing ID.</li><li>The <code>rep_-&gt;options.block_cache</code> points to the <code>SharedLRUCache</code> where the <code>Table</code> is.</li></ul></li><li>The second kind of content cached is a data block of a <code>TableAndFile*</code>.<ul><li>The key is the <code>cache_id</code> of the <code>TableAndFile*</code> and its offset in that file. The value is a <code>Block</code> containing its contents.</li></ul></li></ol><h2 id="how-does-tablecache-read-a-key"><a class="markdownIt-Anchor" href="#how-does-tablecache-read-a-key"></a> How does TableCache read a key?</h2><ol><li>To read a key from a specific file with <code>TableCache</code>, <code>TableCache::Get</code> first tries to find the index block of that file by <code>FindTable</code>.<ul><li>If the target key is found, it will be processed by <code>void (*handle_result)(void*, const Slice&amp;, const Slice&amp;)</code>.</li><li>If the file is not currently in the cache, it will create an entry and be inserted.</li></ul></li><li>Then, use the <code>Table::InternalGet</code> to seek the target key from the index of the file.<ul><li>Check the Bloom filter. If the key is not in this file, do nothing and return.</li><li>Otherwise, use the <code>Table::BlockReader</code> to generate a block iterator to seek the key in the block designated by the information from the index iterator.</li><li>It would try to find whether the target block is read into the cache. If not, read the block from the disk and insert it into the cache.</li><li>If the key is found in that block, <code>handle_result</code> will process the key-value pair.</li></ul></li><li>The table can be released immediately after the <code>InternalGet</code> is returned.</li></ol><h2 id="how-does-tablecache-iterate-over-a-file"><a class="markdownIt-Anchor" href="#how-does-tablecache-iterate-over-a-file"></a> How does TableCache iterate over a file?</h2><ol><li>Like reading a value, the <code>FindTable</code> will load the index block into the cache.</li><li>Then, a <code>TwoLevelIterator</code> is created to iterate the <code>Table</code> using <code>Table::NewIterator</code>.<ul><li>It is initialized with a <code>Block::Iter</code> to iterate over the index block and a <code>BlockFunction</code> to generate another iterator to read data according to the information from the index iterator from its <code>value()</code>.<ul><li>The <code>BlockFunction</code> is defined as <code>Iterator* (*BlockFunction)(void*, const ReadOptions&amp;, const Slice&amp;)</code>.</li></ul></li><li>In <code>TableCache</code>, <code>Table::BlockReader</code> is passed to be the <code>BlockFunction</code>.</li></ul></li><li>To iterate over the file, iterate over the index block and fetch the corresponding data block of valid index entries.<ul><li>We can initiate the <code>TwoLevelIterator</code> with <code>Seek</code>, <code>SeekToFirst</code>, or <code>SeekToLast</code>.<ul><li>They will set the index iterator to a valid position that satisfies the requests.</li><li>Then, <code>TwoLevelIterator::InitDataBlock</code> is invoked to load the iterator of the data block with <code>block_function_</code>.</li></ul></li><li>It can advance with <code>TwoLevelIterator::Next</code> and move backward with <code>TwoLevelIterator::Prev</code>.<ul><li>They will move the data iterator before skipping those empty or invalid entries.</li><li>Skipping moves the index iterator and tries to initiate the data iterator until it is valid.</li><li>When constructing the data iterator, a <code>data_block_handle_</code> is stored to identify the current file so we can skip the entries in the same block when moving the index iterator.</li></ul></li></ul></li></ol>]]></content>
      
      
      <categories>
          
          <category> Open Source Code </category>
          
          <category> LevelDB </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Database System </tag>
            
            <tag> Cache </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>3. LSM-Tree</title>
      <link href="/2024/03/20/OpenSource/LevelDB/LSM-Tree/"/>
      <url>/2024/03/20/OpenSource/LevelDB/LSM-Tree/</url>
      
        <content type="html"><![CDATA[<p><ul class="markdownIt-TOC"><li><a href="#get">Get</a><ul><li><a href="#how-to-get-a-key-from-the-database">How to get a key from the database?</a></li><li><a href="#how-to-prevent-too-many-misses-in-a-file">How to prevent too many misses in a file?</a></li></ul></li><li><a href="#write">Write</a><ul><li><a href="#how-to-write-a-log">How to write a log?</a></li><li><a href="#how-are-writebatches-encoded">How are WriteBatches encoded?</a></li><li><a href="#how-to-make-room-for-the-writes">How to make room for the writes?</a></li><li><a href="#how-to-pick-the-tables-to-compact">How to pick the tables to compact?</a></li><li><a href="#how-to-perform-compact">How to perform compact?</a></li></ul></li></ul></p><h1 id="get"><a class="markdownIt-Anchor" href="#get"></a> Get</h1><h2 id="how-to-get-a-key-from-the-database"><a class="markdownIt-Anchor" href="#how-to-get-a-key-from-the-database"></a> How to get a key from the database?</h2><ol><li><p>The <code>DBImpl::Get</code> uses the user key and a sequence number to search for the correct version of the requested key.</p><ul><li>LevelDB supports snapshots to provide consistent read-only views over the entire state of the key-value store, ignoring future modifications. Snapshots are enabled by <code>DBImpl::GetSnapshot</code> when creating the <code>ReadOptions</code>.</li><li>A snapshot is a sequential number. When using a snapshot, the sequential number in the searching key will be the number in the snapshot. Otherwise, it is the latest sequential number.<ul><li>When searching the key, it returns the first key that is not smaller than the searching key, i.e., a larger user key or a smaller sequential number.</li><li>Providing a stale sequential number will skip those later records.</li></ul></li><li>The <code>DBImpl</code> uses a <code>SnapshotList snapshots_</code> to maintain all the alive snapshots. When the snapshot is no longer needed, it should be released by <code>DBImpl::ReleaseSnapshot</code>.</li></ul></li><li><p>It searches the key from the latest records to the oldest records. First, search on the <code>mem_</code>. If missed, try using the <code>imm_</code>.</p></li><li><p>If it is not found in memory, read from the files on disk by <code>Version::Get</code> of the current version.</p><ul><li><p>The level <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>0</mn></mrow><annotation encoding="application/x-tex">0</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">0</span></span></span></span> files may have overlapping ranges. Search level-<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>0</mn></mrow><annotation encoding="application/x-tex">0</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">0</span></span></span></span> in order from newest to oldest. Check every file that may contain the target key through <code>TableCache::Get</code>.</p></li><li><p>The <code>handle_result</code> function saves the matched value to a <code>Save*</code>.</p></li><li><p>Other levels can use binary search to file the possible file.</p></li><li><p>During the search, if we cannot find the target in some possible files, the</p></li></ul></li></ol><h2 id="how-to-prevent-too-many-misses-in-a-file"><a class="markdownIt-Anchor" href="#how-to-prevent-too-many-misses-in-a-file"></a> How to prevent too many misses in a file?</h2><ol><li>Each file has an <code>allowed_seeks</code> that limits the number of missing seeks.<ul><li>It is set to allow one to seek for every <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>16</mn><mtext> </mtext><mi>K</mi><mi>B</mi></mrow><annotation encoding="application/x-tex">16\ KB</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord">1</span><span class="mord">6</span><span class="mspace"> </span><span class="mord mathnormal" style="margin-right:0.07153em;">K</span><span class="mord mathnormal" style="margin-right:0.05017em;">B</span></span></span></span> of data before triggering a compaction.</li></ul></li><li>When a search reads a file to find the target key is not in it, its <code>allowed_seeks</code> will decrease. The file will be designated to seek compaction when its <code>allowed_seeks</code> is <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>0</mn></mrow><annotation encoding="application/x-tex">0</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">0</span></span></span></span>.<ul><li>During a search process, multiple files may miss the target. Only the first missed file is decreased.</li></ul></li><li>This can prevent too many misses during a search by pushing those frequently missed files to higher levels to lower its priority for a search.</li></ol><h1 id="write"><a class="markdownIt-Anchor" href="#write"></a> Write</h1><p>The codes are in <a href="https://github.com/google/leveldb/blob/068d5ee1a3ac40dabd00d211d5013af44be55bea/db/db_impl.h">db_impl.h</a> and <a href="https://github.com/google/leveldb/blob/068d5ee1a3ac40dabd00d211d5013af44be55bea/db/db_impl.cc">db_impl.cc</a>.</p><h2 id="how-to-write-a-log"><a class="markdownIt-Anchor" href="#how-to-write-a-log"></a> How to write a log?</h2><ol><li><p>The <code>db_impl</code> provided <code>Put</code> and <code>Delete</code>.</p><ul><li><p>They encode requested writes into a <code>WriteBatch</code> and invoke <code>db_impl::Write</code> to finish the write.</p></li><li><p>The orders of concurrent writes are determined by their orders in <code>db_impl::writers_</code>.</p></li></ul></li><li><p>To execute a write, the first step is to invoke <code>MakeRoomForWrite</code> to reserve enough space in <code>mem_</code>, which is the only structure that can be modified.</p></li><li><p>Each entry in the <code>WriteBatch</code> is assigned a unique, monotonously increasing sequential number.</p></li><li><p>Before calling the <code>MemTableInserter</code> to apply each write to <code>mem_</code>, the write records must be put into the write-ahead log <code>log_</code>.</p></li></ol><h2 id="how-are-writebatches-encoded"><a class="markdownIt-Anchor" href="#how-are-writebatches-encoded"></a> How are WriteBatches encoded?</h2><ol><li><p>In <code>WriteBatch</code>, a <code>req_</code> contains all requests in the following format, where <code>key_size</code> and <code>value_size</code> are encoded by <code>EncodeVarint32</code>, the same as <code>Memtable</code>.</p><figure class="highlight txt"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">req_: </span><br><span class="line">+----------+-------+-----------+</span><br><span class="line">|  SeqNum  |  cnt  |  records  |</span><br><span class="line">+----------+-------+-----------+</span><br><span class="line">records:</span><br><span class="line">+--------+------------+-------+-------------+---------+</span><br><span class="line">|  type  |  key_size  |  key  |  value_size |  value  |</span><br><span class="line">+--------+------------+-------+-------------+---------+</span><br></pre></td></tr></table></figure></li><li><p>A <code>Put</code> request has type <code>kTypeValue</code>. A <code>Delete</code> request has type <code>kTypeDeletion</code> and without the value part.</p></li><li><p>When creating a new <code>WriteBatch</code>, the <code>req_</code> reserves <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>12</mn></mrow><annotation encoding="application/x-tex">12</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">1</span><span class="mord">2</span></span></span></span> bytes, <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>8</mn></mrow><annotation encoding="application/x-tex">8</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">8</span></span></span></span> bytes for <code>SeqNum</code> and <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>4</mn></mrow><annotation encoding="application/x-tex">4</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">4</span></span></span></span> bytes for <code>cnt</code>.</p><ul><li>The <code>SeqNum</code> and <code>cnt</code> are initially <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>0</mn></mrow><annotation encoding="application/x-tex">0</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">0</span></span></span></span>.</li><li>When a new request is added to a <code>WriteBatch</code>, a <code>SetCount</code> is invoked to modify the <code>cnt</code>.</li><li>The <code>SeqNum</code> is set when the write is being executed instead of when collecting.</li></ul></li></ol><h2 id="how-to-make-room-for-the-writes"><a class="markdownIt-Anchor" href="#how-to-make-room-for-the-writes"></a> How to make room for the writes?</h2><ol><li>If the <code>WriteBatch</code> is <code>nullptr</code>, the compaction is forced.</li><li>If <code>mem_</code> is not full, no more efforts need to be made. Otherwise, we must set the current <code>mem_</code> as immutable, i.e., <code>imm_</code>, and switch to a new one.</li><li>If <code>imm_</code> is not empty or there are too many level-<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>0</mn></mrow><annotation encoding="application/x-tex">0</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">0</span></span></span></span> files, we need to wait for the background thread to compact the current files.</li><li>If <code>mem_</code> is full, <code>imm_</code> is empty, and there is enough space for level <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>0</mn></mrow><annotation encoding="application/x-tex">0</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">0</span></span></span></span> we can schedule a compaction and switch to a new <code>mem_</code>.<ul><li>The write-ahead log file <code>logfile_</code> is bound with a <code>mem_</code>. Switching to a new <code>mem__</code> also needs to create a new <code>logfile_</code>.</li><li>Then, <code>imm_</code> points to the current <code>mem_</code> before creating a new Memtable for <code>mem_</code>.</li></ul></li></ol><h2 id="how-to-pick-the-tables-to-compact"><a class="markdownIt-Anchor" href="#how-to-pick-the-tables-to-compact"></a> How to pick the tables to compact?</h2><p>The codes are in <a href="https://github.com/google/leveldb/blob/068d5ee1a3ac40dabd00d211d5013af44be55bea/db/db_impl.cc#L702">DBImpl::BackgroundCompaction</a>.</p><ol><li>The compaction with the highest priority is called a minor compact. It happens when <code>imm_</code> is not empty; it must be written on disks.<ul><li>It will be written to the highest level with no overlapping files, and its overlapping files in the next level are limited.</li></ul></li><li>The second priority is the manual compaction when <code>manual_compaction_</code> is not <code>nullptr</code>.<ul><li>A <code>ManualCompaction</code> indicates the level and the range of the compact. All files at the given level that overlap with the specific range will be compact.</li></ul></li><li>In <code>VersionSet::PickCompaction</code>, there are two kinds of compactions: size compaction and seek compaction.</li><li>The size compaction designates a <code>compaction_level_</code> with the highest <code>compaction_score_</code> to compact.<ul><li>It is calculated for each level when editing a new version in the database.</li><li>For level-<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>0</mn></mrow><annotation encoding="application/x-tex">0</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">0</span></span></span></span> files, the score is the ratio of the number of files and the <code>kL0_CompactionTrigger</code>. For other levels, it is the ratio of the total file size in that level against the maximum size for each level.</li><li>The size compaction is triggered when the <code>compaction_score_ &gt;= 1</code>, i.e., the number or size of files in a certain level exceeds the maximum line.</li><li>The first file that comes after <code>compact_pointer_[level]</code> is picked to compact.</li></ul></li><li>The seek compaction designates a <code>file_to_compact_</code> as the candidate.</li><li>The files in level-<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>0</mn></mrow><annotation encoding="application/x-tex">0</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">0</span></span></span></span> may overlap. We must make sure that no remaining files overlap with those files to compact.<ul><li>A file in the level-<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>0</mn></mrow><annotation encoding="application/x-tex">0</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">0</span></span></span></span> may extend the search range and require restarting the search in manual compaction.</li><li>The size compaction and seek compaction would pick multiple files to compact when overlap exists.</li></ul></li><li>After the above procedures, the size compaction and the seek compaction selected some files at the lower level to compact, which is in <code>Compaction.input[0]</code>.<ul><li>Those files will be compacted with others at the next level that overlaps them in <code>Compaction.input[1]</code>.</li><li>The boundaries of files are encoded by the user key and sequential number.<ul><li>The records are sorted in the order of increasing by user key and decreasing by sequential number.</li><li>There is a case in which the upper bound of a file and the lower bound of another file share the same user key with different sequence numbers.</li><li>If we only compact the former file, we will get the older result at a lower level instead of the correct value at a higher level during reading.</li></ul></li></ul></li><li>To compact more thoroughly, we expand the current inputs by including all files at the compact level that overlap with them.<ul><li>The files overlap with those at the compact level, which is already included. This time is mainly for the files at the compact level that overlap with files at the next level. Also, we need to include those boundary files.</li><li>This is merely a trial. It only happens when the total size of <code>Compaction.inputs[1]</code> and expanded files is less than the <code>ExpandedCompactionByteSizeLimit</code>.</li><li>Another condition for this expansion is that we cannot increase the number of files selected from the next level. Namely, the range of the new expanded files is already included in the <code>Compaction.inputs[1]</code>.</li></ul></li><li>The grandparent files in the next two levels that overlap with those in both lower levels are required.</li><li>Finally, update the next compaction for this level in <code>compact_pointer_[level]</code>.<ul><li>We will update this immediately instead of waiting for the VersionEdit to be applied so that if the compaction fails, we can try a different key range next time.</li></ul></li></ol><h2 id="how-to-perform-compact"><a class="markdownIt-Anchor" href="#how-to-perform-compact"></a> How to perform compact?</h2><ol><li>If this is not a manual compaction and there is only one file in <code>Compaction.inputs[0]</code> and no next-level file to merge, we only need to move the file to the next level trivially.<ul><li>In the <code>VersionEdit</code>, remove the <code>Compaction.inputs[0]</code> file from its level and add it to the next level.</li></ul></li><li>We create a <code>MergingIterator</code> to complete the merge process.<ul><li>Given that level-<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>0</mn></mrow><annotation encoding="application/x-tex">0</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">0</span></span></span></span> files might overlap, there is a <code>TwoLevelIterator</code> for each file. For other levels, one iterator is enough to traverse them in order.<ul><li>What a <code>TwoLevelIterator</code> reads is determined by the index iterator passed to it.</li><li>For the level-<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>0</mn></mrow><annotation encoding="application/x-tex">0</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">0</span></span></span></span> files, we use the index iterator of its index block.</li><li>For other levels, the <code>Version::LevelFileNumIterator</code> is passed to be the index iterator. It has an <code>index_</code> pointing to the current reading file and iterates them in order.</li><li>The passed <code>handler_result</code> is <code>GetFileIterator</code>, which will create another file iterator of the current reading file using <code>TableCache::NewIterator</code>.</li></ul></li><li>All the files that are involved are now pinned in the cache.</li></ul></li><li>The <code>MergingIterator</code> uses <code>children_</code> to store all iterators of involved files and a <code>current_</code> to point to the current entry.<ul><li>The <code>SeekToFirst</code> sets all iterators in <code>children_</code> to their first position and <code>current_</code> to the iterator with the smallest key. The <code>SeekToLast</code> is similar.</li><li>The <code>Seek</code> sets all iterators to their <code>Seek(target)</code> and <code>current_</code> to the smallest.</li><li>In the <code>Next</code>, all children are set to their seek of the current key and move to the next if they have the same key. Then, set the <code>current_</code> to the smallest among them. The <code>Prev</code> is similar.</li></ul></li><li>While iterating over files to compact, multiple records of the same user key could exist.<ul><li>We only want to reserve the latest records within the range of the smallest snapshot and other records after it.</li><li>The <code>last_sequence_for_key</code> is set to infinite to ensure that a key’s first occurrence will be stored.</li><li>During the later occurrences, if the <code>last_sequence_for_key</code> is smaller than the snapshot number, it means that the latest key is already stored within the range; there is no need to store the rest.</li><li>If the latest record for a key within the range of snapshot is a delete record, it can achieve its purpose by storing nothing and updating the <code>last_sequence_for_key</code>. So, later values will be discarded.</li></ul></li></ol>]]></content>
      
      
      <categories>
          
          <category> Open Source Code </category>
          
          <category> LevelDB </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Database System </tag>
            
            <tag> Storage </tag>
            
            <tag> Data Structure </tag>
            
            <tag> Index Structure </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>1. Memtable</title>
      <link href="/2024/03/19/OpenSource/LevelDB/Memtable/"/>
      <url>/2024/03/19/OpenSource/LevelDB/Memtable/</url>
      
        <content type="html"><![CDATA[<p><ul class="markdownIt-TOC"><li><a href="#skiplist">Skiplist</a><ul><li><a href="#what-is-the-structure-of-the-skip-list">What is the structure of the skip list?</a></li><li><a href="#what-does-the-list-node-look-like">What does the list node look like?</a></li><li><a href="#how-to-search-for-a-key">How to search for a key?</a></li><li><a href="#how-to-insert-a-key">How to insert a key?</a></li></ul></li><li><a href="#memtable">Memtable</a><ul><li><a href="#how-does-memtable-encode-data">How does Memtable encode data?</a></li><li><a href="#how-does-memtable-decode-data">How does Memtable decode data?</a></li></ul></li></ul></p><h1 id="skiplist"><a class="markdownIt-Anchor" href="#skiplist"></a> Skiplist</h1><p>The codes are in <a href="https://github.com/liyun-zhang/leveldb/blob/main/db/skiplist.h">skiplist.h</a></p><h2 id="what-is-the-structure-of-the-skip-list"><a class="markdownIt-Anchor" href="#what-is-the-structure-of-the-skip-list"></a> What is the structure of the skip list?</h2><ol><li>The skip list is a list with extended next pointers.</li><li>The next pointers in a node have different heights. The maximum height of each node is different. A next pointer at a specific height points to the next node that is not shorter than the height.</li><li>The “skip” refers to the higher pointers that point to distant nodes. Therefore, through the skip links, we can quickly locate the possible range of the target in search and inserting, similar to the doubling method in continuous arrays.</li></ol><h2 id="what-does-the-list-node-look-like"><a class="markdownIt-Anchor" href="#what-does-the-list-node-look-like"></a> What does the list node look like?</h2><ol><li>A node should contain a key and a series of pointers to the next node.</li><li>In the skip list, the next pointers are at different heights. The higher pointers point to further nodes.</li><li>To allocate an array of next node pointers, declare an array with one element at the end of the structure. Then, assign a large space to the object of that structure.<ul><li>The array of next pointers is declared as <code>std::atomic&lt;Node*&gt; next_[1];</code>.</li><li>In the <code>NewNode(const Key&amp; key, int height)</code>, use <code>Arena</code> to allocate size <code>sizeof(Node) + sizeof(std::atomic&lt;Node*&gt;) * (height - 1)</code>.</li><li>In <code>sizeof(Node)</code>, an array with one element is allocated. Then, the space of additional <code>height-1</code> elements is extended. Therefore, a <code>Node</code> has total <code>height</code> next pointers.</li></ul></li></ol><h2 id="how-to-search-for-a-key"><a class="markdownIt-Anchor" href="#how-to-search-for-a-key"></a> How to search for a key?</h2><ol><li><code>Skiplist</code> provided <code>FindGreaterOrEqual</code> and <code>FindLessThan</code> as basic functions to search for a key.</li><li>Each function starts from the <code>head_</code> and compares it with the next key, from higher to lower.</li><li>In <code>FindGreaterOrEqual</code>, we should keep lowering the height until the key is larger than the next. If it reaches the lowest height, <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>0</mn></mrow><annotation encoding="application/x-tex">0</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">0</span></span></span></span>, directly return the current node.</li><li><code>FindLessThan</code> is similar, searching until the key is less than the next or reaches the lowest height.</li><li>The search process is fast because the higher next pointers can skip many unnecessary nodes.</li></ol><h2 id="how-to-insert-a-key"><a class="markdownIt-Anchor" href="#how-to-insert-a-key"></a> How to insert a key?</h2><ol><li>To find a suitable position on the list for the new key, we can get all the previous nodes through <code>FindGreaterOrEqual</code>.<ul><li><code>FindGreaterOrEqual</code> only returns when it reaches the <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>0</mn></mrow><annotation encoding="application/x-tex">0</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">0</span></span></span></span> height. Whenever the next key of the current node in a certain height is less than the target key, we record the current node to the <code>prev</code> of the corresponding height.</li><li>When it returns, each element in <code>prev</code> is the previous node of the new node.</li></ul></li><li>The maximum height of the new node is random. If it is higher than the highest node, set extra pointers to <code>head_</code>.<ul><li>In <code>RandomHeight</code>, <code>while (height &lt; kMaxHeight &amp;&amp; rnd_.OneIn(kBranching))</code> shows that height is geometric distribution with probability of <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mn>1</mn><mrow><mi>k</mi><mi>B</mi><mi>r</mi><mi>a</mi><mi>n</mi><mi>c</mi><mi>h</mi><mi>i</mi><mi>n</mi><mi>g</mi></mrow></mfrac></mrow><annotation encoding="application/x-tex">\frac{1}{kBranching}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.326216em;vertical-align:-0.481108em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.845108em;"><span style="top:-2.6550000000000002em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span><span class="mord mathnormal mtight" style="margin-right:0.05017em;">B</span><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span><span class="mord mathnormal mtight">a</span><span class="mord mathnormal mtight">n</span><span class="mord mathnormal mtight">c</span><span class="mord mathnormal mtight">h</span><span class="mord mathnormal mtight">i</span><span class="mord mathnormal mtight">n</span><span class="mord mathnormal mtight" style="margin-right:0.03588em;">g</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.481108em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span> to keep increasing the height.</li></ul></li><li>Finally, we set the next pointers in the new node to the next pointers in <code>prev</code> and set the next pointers in <code>prev</code> to the new node.</li></ol><h1 id="memtable"><a class="markdownIt-Anchor" href="#memtable"></a> Memtable</h1><p>The codes are in <a href="https://github.com/liyun-zhang/leveldb/blob/main/db/memtable.h">memtable.h</a> and <a href="https://github.com/liyun-zhang/leveldb/blob/main/db/memtable.cc">memtable.cc</a></p><h2 id="how-does-memtable-encode-data"><a class="markdownIt-Anchor" href="#how-does-memtable-encode-data"></a> How does Memtable encode data?</h2><ol><li>In Memtable, the bottom storage uses <code>Table</code> defined as <code>SkipList&lt;const char*, KeyComparator&gt;</code>.<ul><li>From the skip list, we can see that it only stores keys instead of key-value pairs.</li><li>Memtable encodes values into keys and stores the whole bytes.</li></ul></li><li>There are three parts: <code>key, sequence number and type, value</code>.<ul><li>The structure of the encoded buffer is as follows:</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">+----------------+-------+----------------+--------------+---------+</span><br><span class="line">|  key_size + 8  |  key  |  SeqNum, type  |  value_size  |  value  |</span><br><span class="line">+----------------+-------+----------------+--------------+---------+</span><br></pre></td></tr></table></figure></li><li>Both the <code>key_size</code> and <code>value_size</code> are encoded by <code>EncodeVarint32</code>.<ul><li>Only content containing the most significant byte is saved. They are in a little-endian way with variant length.</li><li>Each byte only stores <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>7</mn></mrow><annotation encoding="application/x-tex">7</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">7</span></span></span></span> bits of the <code>uint32_t</code>. The highest bit in a byte is <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>0</mn></mrow><annotation encoding="application/x-tex">0</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">0</span></span></span></span> when this is the last byte for the variant-length int.</li></ul></li><li><code>SeqNum</code> and <code>type</code> are 8 bytes in total, where <code>SeqNum</code> is in higher bits and <code>type</code> is in lower bits. They are encoded in fixed size.</li></ol><h2 id="how-does-memtable-decode-data"><a class="markdownIt-Anchor" href="#how-does-memtable-decode-data"></a> How does Memtable decode data?</h2><ol><li>The target key is encoded without <code>value_size</code> and <code>value</code> to search the target with <code>FindGreaterOrEqual</code>.</li><li>To decode the variant length int, read byte-by-byte until a byte with the highest bit of <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>0</mn></mrow><annotation encoding="application/x-tex">0</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">0</span></span></span></span>.</li><li>If the key does not match or the type is <code>kTypeDeletion</code>, return <code>Status::NotFound</code>.</li></ol>]]></content>
      
      
      <categories>
          
          <category> Open Source Code </category>
          
          <category> LevelDB </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Database System </tag>
            
            <tag> Storage </tag>
            
            <tag> Data Structure </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Placement Driver and Multi-Raft</title>
      <link href="/2024/03/13/OpenSource/TinyKV/Multi-Raft/"/>
      <url>/2024/03/13/OpenSource/TinyKV/Multi-Raft/</url>
      
        <content type="html"><![CDATA[<p><ul class="markdownIt-TOC"><li><a href="#placement-driver">Placement Driver</a><ul><li><a href="#how-does-pd-know-the-information-of-regions">How does PD know the information of regions?</a></li><li><a href="#how-does-pd-schedule-placement">How does PD schedule placement?</a></li><li><a href="#what-are-the-schedulers">What are the schedulers?</a></li></ul></li><li><a href="#multi-raft">Multi-Raft</a><ul><li><a href="#how-to-split-regions">How to split regions?</a></li><li><a href="#how-to-move-regions">How to move regions?</a></li></ul></li></ul></p><h1 id="placement-driver"><a class="markdownIt-Anchor" href="#placement-driver"></a> Placement Driver</h1><h2 id="how-does-pd-know-the-information-of-regions"><a class="markdownIt-Anchor" href="#how-does-pd-know-the-information-of-regions"></a> How does PD know the information of regions?</h2><ol><li>The PD needs the necessary information to decide on placement and split. This information is sent to the PD by the heartbeat from the region or the store to the PD.</li><li>The store will send a heartbeat to the PD periodically when the onSchedulerStoreHeartbeatTick is triggered by the ticker.<ul><li>This heartbeat mainly tells the PD about the space information, e.g., disk capacity, used size, and available space.</li><li>The PD will update its knowledge about the given store according to the heartbeat.</li></ul></li><li>The region will send a heartbeat to the PD when something about the region is changed, e.g., peer joined or left, split.<ul><li>This heartbeat mainly tells the PD about the region information, e.g., region metadata, peer identity, lagged peers, and the approximate size of this region.</li><li>The PD will justify the validation of this heartbeat by the RegionEpoch of it. The region information will updated if it is valid.</li></ul></li></ol><h2 id="how-does-pd-schedule-placement"><a class="markdownIt-Anchor" href="#how-does-pd-schedule-placement"></a> How does PD schedule placement?</h2><ol><li>The schedule decisions are made periodically. However, they are not sent to region leaders immediately. The operators are returned when the PD receives a heartbeat from the region leader.</li><li>Every PD server has a <code>RaftCluster</code> that stores the information of the entire cluster. It handles the heartbeats sent to PD.</li><li>Each <code>RaftCluster</code> has a <code>coordinator</code> to run schedulers in parallel and store generated operators in its <code>schedule.OperatorController</code>.</li><li>When a region heartbeat is processed, the <code>RaftCluster</code> would ask for the <code>schedule.OperatorController</code> to <code>Dispatch</code> operators to the region.</li><li>These operators are sent to leaders as Raft commands. Similar to commands from clients, they may not be committed.</li></ol><h2 id="what-are-the-schedulers"><a class="markdownIt-Anchor" href="#what-are-the-schedulers"></a> What are the schedulers?</h2><ol><li>They all implemented the <code>Scheduler</code> control that provides the <code>Schedule(opt.Cluster) *operator.Operator</code> interface to generate operators.</li><li>A new goroutine is created to perform the schedule when a new scheduler is added to the <code>coordinator</code>. If new operators are created, they will be appended to the <code>schedule.OperatorController</code> waiting for the next heartbeat from the target region.</li><li>One kind of scheduler is to transfer a leader when the current leader is no longer considered available.</li><li>Another scheduler is to move regions between stores to balance the storage usage of each store.</li></ol><h1 id="multi-raft"><a class="markdownIt-Anchor" href="#multi-raft"></a> Multi-Raft</h1><h2 id="how-to-split-regions"><a class="markdownIt-Anchor" href="#how-to-split-regions"></a> How to split regions?</h2><ol><li>Every peer periodically checks whether their region needs to be split by sending a <code>SplitCheckTask</code> to the <code>splitCheckHandler</code> of its store.<ul><li>The checker will calculate the total size of the key-value pairs in this region. A split is initiated if the size is larger than <code>splitSize</code>.</li><li>The checker does not read through Raft. Instead, it directly reads from the DB engine file.</li><li>The checker will also notify the peer of the current size of its region it just calculated for the peer to update its information and tell the PD later.</li></ul></li><li>When a split key is generated, the checker will notify the peer to be prepared for splitting.<ul><li>The peer would ask the PD to assign globally unique IDs to identify the new region and peers.</li><li>The PD will send the leader an <code>AdminRequest</code> that contains the <code>NewRegionId</code> and <code>NewPeerIds</code> to suggest a split.</li></ul></li><li>If the <code>AdminRequest</code> is committed, all peers of the split region will create a new peer of the new region in their store.<ul><li>Notably, all data in the different regions of the same store are written into the same DB engine file.</li><li>There is no need to copy or move files when creating new peers. The only thing need to do is to set the new peers in the correct state.</li><li>The information on new peers must be updated in both the store and the PD.</li></ul></li></ol><h2 id="how-to-move-regions"><a class="markdownIt-Anchor" href="#how-to-move-regions"></a> How to move regions?</h2><ol><li>When we split the regions, no data is deleted from the store, which seems useless. However, splitting regions allows us to have finer-grained control. We can move regions to new stores later.</li><li>A move consists of adding a new peer and removing an existing peer.<ul><li>When adding a new peer, it is in a lagged state. The leader will send a snapshot to bring it up to date.</li><li>When removing an existing peer, the data of its region will be removed from the store engine file.</li></ul></li><li>Similar to split, peer changing needs to sync with the store and the PD.</li></ol>]]></content>
      
      
      <categories>
          
          <category> Open Source Code </category>
          
          <category> TiKV/TinyKV </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Storage </tag>
            
            <tag> TinyKV </tag>
            
            <tag> Raft </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>MVCC Transaction</title>
      <link href="/2024/03/12/OpenSource/TinyKV/MVCC-Transaction/"/>
      <url>/2024/03/12/OpenSource/TinyKV/MVCC-Transaction/</url>
      
        <content type="html"><![CDATA[<p><ul class="markdownIt-TOC"><li><a href="#how-does-the-mvcc-layer-record-operations">How does the MVCC layer record operations?</a></li><li><a href="#how-do-clients-manage-transactions">How do clients manage transactions?</a></li><li><a href="#how-to-perform-get-prewrite-and-scan">How to perform Get, Prewrite, and Scan?</a></li><li><a href="#how-to-perform-commit-and-rollback">How to perform commit and rollback?</a></li></ul></p><img src="/imgs/TiKV/mvcc.png"><h1 id="how-does-the-mvcc-layer-record-operations"><a class="markdownIt-Anchor" href="#how-does-the-mvcc-layer-record-operations"></a> How does the MVCC layer record operations?</h1><ol><li>There are three column families: <code>default</code> to hold user values, <code>lock</code> to store locks and <code>write</code> to record changes.<ul><li>The <code>lock</code> CF is accessed using the user key; it stores a serialized <code>Lock</code> data structure.</li><li>The <code>default</code> CF is accessed using the user key and the start timestamp of the transaction in which it was written; it stores the user value only.</li><li>The <code>write</code> CF is accessed using the user key and the commit timestamp of the transaction where it was written; it stores a <code>write</code> data structure.</li></ul></li><li>The key idea is that <code>default</code> CF stores all the written key-value pairs, including those uncommitted ones.</li><li>Whether a key-value pair is committed is determined by whether a record in the <code>write</code> CF contains the <code>StartTS</code> of the <code>default</code> CF.<ul><li>All readings are done by first iterating over the <code>write</code> CF to find the visible entry according to the commit timestamps integrated into the key of <code>write</code> CF.</li><li>We want the <code>write</code> CF to be sorted by the time from the most recent to the earliest and grouped by keys. Hence, keys are encoded so that the ascending order of encoded keys is ordered first by user key (ascending), then by timestamp (descending).</li></ul></li></ol><h1 id="how-do-clients-manage-transactions"><a class="markdownIt-Anchor" href="#how-do-clients-manage-transactions"></a> How do clients manage transactions?</h1><ol><li>Each transaction is represented by a unique start timestamp provided by clients. All APIs provided to clients are executed through a <code>MvccTxn</code> structure to perform the MVCC operations.</li><li>Clients can issue as much <code>KvGet</code>, <code>KvPreWrite</code>, or <code>KvScan</code> as they want during a transaction.</li><li>After the operations they want have been executed, the transaction can be committed by <code>KvCommit</code>. If the commit fails, it is rollbacked by <code>KvBatchRollback</code>.</li><li>Clients can also use <code>KvCheckTxnStatus</code> to check the status of their transactions. If the time-to-live of any lock is expired, the transaction must be rollbacked.</li></ol><h1 id="how-to-perform-get-prewrite-and-scan"><a class="markdownIt-Anchor" href="#how-to-perform-get-prewrite-and-scan"></a> How to perform Get, Prewrite, and Scan?</h1><ol><li>In a <code>Get(key)</code>,<ul><li>If the <code>key</code> is locked by an older transaction, we should not read it now because the modification of the older transaction may be visible in this current transaction.</li><li>If the <code>key</code> is locked by a younger transaction, it does not matter because the modification is not visible to us.</li><li>The MVCC layer gets values by checking the <code>write</code> CF to find the most recently committed write. Then, access the value of the key with the <code>StartTS</code> information provided by the write record from the <code>default</code> CF.</li></ul></li><li>In a <code>PreWrite(key, value)</code>,<ul><li>This transaction must hold an exclusive lock, i.e., it must wait if either an older or a younger transaction held the lock.</li><li>Also, the most recent committed write must be before the start time of this transaction, i.e., there is no write committed to this key after this transaction is initiated.</li><li>During the <code>PreWrite</code>, value modifications are written into the <code>default</code> CF in the MVCC layer. However, due to missing records in the <code>write</code> CF, they are not visible in the <code>Get</code> operations.</li></ul></li><li>The <code>Scan</code> is similar to <code>Get</code>. It is done through a <code>Scanner</code> that uses an <code>engine_util.DBIterator</code> to iterator over the <code>write</code> CF.</li></ol><h1 id="how-to-perform-commit-and-rollback"><a class="markdownIt-Anchor" href="#how-to-perform-commit-and-rollback"></a> How to perform commit and rollback?</h1><ol><li>In a <code>KvCommit</code>,<ul><li>Each modification must be assured that this transaction holds the exclusive lock.</li><li>Notably, this transaction may have already been committed or rollbacked due to the unreliable network.</li><li>During the commit, the modification records of <code>WriteKindPut</code> are written into the <code>write</code> CF so that the latter transactions can see the results.</li><li>Finally, all locks held by this transaction will be released when the commit succeeds.</li></ul></li><li>If the commit fails or the clients detect that the transaction is out of TTL for the lock of the primary key, <code>KvBatchRollback</code> will be issued.<ul><li>The records of the kind <code>WriteKindRollback</code> of the modified keys are written into the <code>write</code> CF and the value of the <code>default</code> CF is required to be deleted.</li><li>Similar to <code>KvCommit</code>, there is a possibility that this transaction is already committed or rollbacked.</li></ul></li><li>When the client encounters a lock failure, it will issue a <code>KvResolveLock</code> to commit or rollback.<ul><li><code>Lock</code> CF is iterated to find all keys locked by this transaction. Those are all keys to be resolved and will either be committed or rollbacked.</li></ul></li></ol>]]></content>
      
      
      <categories>
          
          <category> Open Source Code </category>
          
          <category> TiKV/TinyKV </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Transaction </tag>
            
            <tag> TinyKV </tag>
            
            <tag> MVCC </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>00. Trade-offs summary</title>
      <link href="/2024/02/22/Courses/15445/00-Trade-offs-summary/"/>
      <url>/2024/02/22/Courses/15445/00-Trade-offs-summary/</url>
      
        <content type="html"><![CDATA[<p></p><ol><li><strong>Database</strong> v.s. <strong>CSV files</strong>:<ul><li>Database provided a better encapsulation representation that provides ensurence of data integrety, necessary operations and durability. Only SQL is exposed to the users.</li><li>CSV files requires used to write all operations, e.g. searching and writing, by themselves. It is enough for small amount of data.</li><li>Database can be easily used to manage complex or enormously large data which can be difficult for CSV files.</li></ul></li><li><strong>Disk-oriented DBMS</strong> v.s. <strong>OS memory mapping</strong>:<ul><li>The basic idea is that DBMS always knows better than OS.</li><li>Transaction safety: OS can flush dirty pages at any time causing dirty data corrupt database.</li><li>Error handling: DBMS may isolate the error and handle it only in the storage layer.</li></ul></li><li></li></ol>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>TinyKV v.s. Spanner</title>
      <link href="/2023/12/09/OpenSource/TinyKV/TinyKV-vs-Spanner/"/>
      <url>/2023/12/09/OpenSource/TinyKV/TinyKV-vs-Spanner/</url>
      
        <content type="html"><![CDATA[<p><ul class="markdownIt-TOC"><li><a href="#organization">Organization</a><ul><li><a href="#what-is-the-structure-of-tinykv">What is the structure of TinyKV?</a></li><li><a href="#how-to-execute-a-command-from-a-client">How to execute a command from a client?</a></li></ul></li><li><a href="#time-representation">Time Representation</a><ul><li><a href="#how-does-raft-represent-time">How does Raft represent time?</a></li><li><a href="#what-events-are-scheduled-in-peers">What events are scheduled in peers?</a></li><li><a href="#how-do-transactions-represent-timestamps">How do transactions represent timestamps?</a></li></ul></li></ul></p><h1 id="organization"><a class="markdownIt-Anchor" href="#organization"></a> Organization</h1><h2 id="what-is-the-structure-of-tinykv"><a class="markdownIt-Anchor" href="#what-is-the-structure-of-tinykv"></a> What is the structure of TinyKV?</h2><ol><li>Each machine has a <code>Server</code> with a certain object that implements a <code>Storage</code> interface to store Key/Value pairs.<ul><li>The <code>Storage</code> interface only requires the provision of <code>Read</code> and <code>Write</code> APIs. The way they implement these methods decided this <code>Server</code> can provide the service.</li><li>Suppose that <code>Storage</code> is simply using <code>badger.DB</code> that directly writes data, the <code>Server</code> only provides a standalone database service.</li><li>If that <code>Storage</code> is <code>RaftStorage</code> that completes these methods by interacting with Raft groups, it can provide a distributed fault-tolerance database.</li></ul></li><li>Inside <code>RaftStorage</code>, there is a <code>RaftStore</code> that controls all <code>peer</code>s. Each peer is a peer in a raft group.<ul><li>When multi-raft is enabled, several peers in the same <code>RaftStore</code> may manage different shards.</li></ul></li><li>Overall, a <code>RaftStorage</code> is responsible for an entire key space. All peers in the same key space, though may be in charge of incontinuous shards, must communicate with clients through this <code>RaftStorage</code>.<ul><li>If another key space exists, e.g., another database, a separate <code>RaftStorage</code> must be created.</li></ul></li></ol><h2 id="how-to-execute-a-command-from-a-client"><a class="markdownIt-Anchor" href="#how-to-execute-a-command-from-a-client"></a> How to execute a command from a client?</h2><ol><li>The following is a diagram of the execution flow.</li><li>Clients give commands through the APIs provided by the <code>Server</code>. Those APIs will execute <code>Read</code> or <code>Write</code> provided by <code>Storage</code>.</li><li><code>RaftStorage</code> will send a message of <code>raft_cmdpb.Request</code> to <code>RaftStore</code> through <code>RaftRouter</code>. The request contains <code>regionId</code> and <code>peerId</code> information for the router to locate the destination.</li><li>The <code>RaftRouter</code> will send the request to the <code>RaftWorker</code> of <code>RaftStore</code>. When the <code>RaftWorker</code> receives messages, it will initiate a <code>peerMsgHandler</code> for each message individually.<ul><li><code>RaftWorker</code> will start the next <code>peerMsgHandler</code> until the last one is finished instead of creating goroutines to process them in parallel.</li><li>Raft peers will only receive commands and messages from <code>RaftWorker</code>. Hence, only one Raft thread in the entire <code>RaftStore</code> processes messages rather than handling them in parallel.</li></ul></li><li><code>peerMsgHandle</code> will ask <code>RaftGroup</code> to handle the message by <code>Step</code>.</li><li>After all read messages are handled, all peers that have received messages are asked to handle <code>raft.Ready</code> one be one. Applied commands will be executed; persisted states will be written into <code>PeerStorage</code>.</li></ol><img src="/imgs/TiKV/exec.png"><h1 id="time-representation"><a class="markdownIt-Anchor" href="#time-representation"></a> Time Representation</h1><h2 id="how-does-raft-represent-time"><a class="markdownIt-Anchor" href="#how-does-raft-represent-time"></a> How does Raft represent time?</h2><ol><li>Instead of using a TrueTime API to represent time like Spanner, TinyKV uses a logical time to control workflows.</li><li></li><li>All peers in the same store should register on <code>tickDriver</code> so that it will know which peers it needs to send messages to when events are triggered.</li><li>Each store has a store ticker, while each peer has a peer ticker. The store ticker is the driver of the entire store; it represents the logical time of this machine. The peer tickers are simply for scheduling peer events.</li><li>When the store ticker received from <code>time.Tick(baseTickInterval)</code>,<ul><li>A <code>MsgTypeTick</code> will be sent to all known peers. Each peer will check whether their schedule is up.</li><li>Then, the <code>tick</code> is increased by <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1</mn></mrow><annotation encoding="application/x-tex">1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">1</span></span></span></span> and <code>tickDriver</code> checks the store’s schedule. If a schedule is up, the driver will send a message of <code>MsgTypeStoreTick</code> to the store.</li></ul></li></ol><h2 id="what-events-are-scheduled-in-peers"><a class="markdownIt-Anchor" href="#what-events-are-scheduled-in-peers"></a> What events are scheduled in peers?</h2><ol><li>When the <code>tickDrive</code> of <code>RaftStore</code> sends a <code>MsgTypeTick</code> to <code>RaftWorker</code>, the <code>peerMsgHandler</code> will check several schedules.</li><li>When <code>PeerTickRaft</code> is up, the Raft node ticker is moved forward.</li><li>When <code>PeerTickRaftLogGC</code> is up, and existing applied entries are more than the limit, it will propose a Raft command with an administrator request to compact the Raft log to the applied index when this request is made.<ul><li>The compaction is only executed when this request is committed.</li><li>The Raft node and peer storage modify their state according to the compact index and term. Then, a garbage collection task is sent to the <code>raftLogGCWorker</code>, which will remove compacted entries from <code>RaftDB</code>.</li></ul></li><li>When <code>PeerTickSchedulerHeartbeat</code> is up, a <code>SchedulerRegionHeartbeatTask</code> is sent to <code>schedulerWorker</code>.</li></ol><h2 id="how-do-transactions-represent-timestamps"><a class="markdownIt-Anchor" href="#how-do-transactions-represent-timestamps"></a> How do transactions represent timestamps?</h2><ol><li>The placement driver is also responsible for assigning client timestamps for transaction events.<ul><li>The placement driver is another Raft group powered by etcd. Only the leader can assign timestamps. When the physical timestamp is changed, the leader will save a timestamp seconds later than the new one.</li><li>When a new leader is elected, it will read from the etcd files to sync its timestamp with the last saved timestamp. The new leader needs to wait until the time of the read timestamp comes before it can assign any new timestamp.</li><li>We can induct that the timestamp assigned by the PD group is unique and monotonously increasing. Therefore, the TiKV did not take the TrueTime API in Spanner.</li></ul></li><li>A transaction timestamp is an <code>uint64</code> that consists of two parts:<ul><li>The high bits are the physical time with units of milliseconds. The lower bits are the logical time to distinguish the events in the same millisecond.</li><li>It is reset to zero every time the physical time is updated to prevent logical time from becoming too large.</li></ul></li><li>The server will check whether need to update the physical timestamp every <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>50</mn><mtext> </mtext><mi>m</mi><mi>s</mi></mrow><annotation encoding="application/x-tex">50\ ms</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">5</span><span class="mord">0</span><span class="mspace"> </span><span class="mord mathnormal">m</span><span class="mord mathnormal">s</span></span></span></span>, instead of every millisecond.<ul><li>The physical timestamp will sync with the current time when it has not been updated for over <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>150</mn><mtext> </mtext><mi>m</mi><mi>s</mi></mrow><annotation encoding="application/x-tex">150\ ms</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">1</span><span class="mord">5</span><span class="mord">0</span><span class="mspace"> </span><span class="mord mathnormal">m</span><span class="mord mathnormal">s</span></span></span></span>.</li><li>When used over half of the logical timestamp, the physical timestamp will add <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1</mn><mtext> </mtext><mi>m</mi><mi>s</mi></mrow><annotation encoding="application/x-tex">1\ ms</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">1</span><span class="mspace"> </span><span class="mord mathnormal">m</span><span class="mord mathnormal">s</span></span></span></span> and reset the logical timestamp.</li></ul></li></ol>]]></content>
      
      
      <categories>
          
          <category> Open Source Code </category>
          
          <category> TiKV/TinyKV </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Storage </tag>
            
            <tag> TinyKV </tag>
            
            <tag> Raft </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Storage: Write and Read</title>
      <link href="/2023/11/24/OpenSource/TinyKV/Storage-Write-and-Read/"/>
      <url>/2023/11/24/OpenSource/TinyKV/Storage-Write-and-Read/</url>
      
        <content type="html"><![CDATA[<p><ul class="markdownIt-TOC"><li><a href="#key-value-storage-storagestorage">Key-Value Storage (storage.Storage)</a><ul><li><a href="#interface">Interface</a></li><li><a href="#simple-example-project1-standalonekv">Simple example: Project1 StandaloneKV</a></li><li><a href="#raftstorage">RaftStorage</a></li></ul></li><li><a href="#raft-storage-raftstorage">Raft storage (raft.Storage)</a><ul><li><a href="#interface-2">Interface</a></li><li><a href="#simple-example-memstorage">Simple example: MemStorage</a></li><li><a href="#project-2b-peerstorage">Project 2B: PeerStorage</a><ul><li><a href="#basic-duties">Basic duties</a></li><li><a href="#snapshot-generation-and-application">Snapshot generation and application</a></li></ul></li></ul></li></ul></p><h1 id="key-value-storage-storagestorage"><a class="markdownIt-Anchor" href="#key-value-storage-storagestorage"></a> Key-Value Storage (storage.Storage)</h1><ol><li>Each <code>Server</code> uses the KV storage interfaces <code>Write</code> and <code>Reader</code> to implement RPC interfaces like <code>RawGet</code>, <code>RawPut</code>, <code>RawDelete</code>, and <code>RawScan</code> (in <code>kv/storage/server/raw_api.go</code>) provided to clients for corresponding functions.</li><li>This higher-level abstract storage interface hides lower-level storage implementation from the servers and clients. How do we implement the interface changes in different scenarios?<ul><li>In <code>kv/storage/mem_storage.go</code>, it is implemented as an in-memory standalone storage.</li><li>In <code>kv/storage/standalone_storage/standalone_storage.go</code>, it is implemented as BadgerDB.</li><li>In <code>kv/storage/raft_storage/raft_server.go</code>, it is implemented as a distributed storage based on Raft.</li></ul></li></ol><h2 id="interface"><a class="markdownIt-Anchor" href="#interface"></a> Interface</h2><ol><li><p>The storage interface must implement <code>Write</code> and <code>Reader</code>.</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// kv/storage/storage.go</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">type</span> Storage <span class="keyword">interface</span> &#123;</span><br><span class="line">Write(ctx *kvrpcpb.Context, batch []Modify) <span class="type">error</span></span><br><span class="line">Reader(ctx *kvrpcpb.Context) (StorageReader, <span class="type">error</span>)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p><code>Write</code> receives a batch of modification requests. Each request can be a put request with a key-value pair or a delete request with only a key field.</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// kv/storage/modify.go</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">type</span> Modify <span class="keyword">struct</span> &#123;</span><br><span class="line">Data <span class="keyword">interface</span>&#123;&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">type</span> Put <span class="keyword">struct</span> &#123;</span><br><span class="line">Key   []<span class="type">byte</span></span><br><span class="line">Value []<span class="type">byte</span></span><br><span class="line">Cf    <span class="type">string</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">type</span> Delete <span class="keyword">struct</span> &#123;</span><br><span class="line">Key []<span class="type">byte</span></span><br><span class="line">Cf  <span class="type">string</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>The <code>Reader</code> returns an API to get the value of a certain key or iterate over a column family.</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// kv/storage/storage.go</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">type</span> StorageReader <span class="keyword">interface</span> &#123;</span><br><span class="line"><span class="comment">// When the key doesn&#x27;t exist, return nil for the value</span></span><br><span class="line">GetCF(cf <span class="type">string</span>, key []<span class="type">byte</span>) ([]<span class="type">byte</span>, <span class="type">error</span>)</span><br><span class="line">IterCF(cf <span class="type">string</span>) engine_util.DBIterator</span><br><span class="line">Close()</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>The <code>DBIterator</code> is another interface that provides APIs to iterate over the database.</p><ul><li><code>Item()</code> returns a pointer to the current key-value pair.</li><li><code>Valid()</code> returns false when iteration is done.</li><li><code>Next()</code> would advance the iterator by one.</li><li><code>Seek([]byte)</code> would seek the provided key if present. If absent, it would seek the next smallest key greater than provided.</li><li><code>Close()</code> would close the iterator.</li></ul><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// kv/util/engine_util/cf_iterator.go</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">type</span> DBIterator <span class="keyword">interface</span> &#123;</span><br><span class="line">Item() DBItem</span><br><span class="line">Valid() <span class="type">bool</span></span><br><span class="line">Next()</span><br><span class="line">Seek([]<span class="type">byte</span>)</span><br><span class="line">Close()</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>The access to <code>DBIterm</code> is an interface that provides methods to get or copy the keys and values.</p><ul><li><code>KeyCopy(dst []byte) byte</code> and <code>ValueCopy(dst []byte) ([byte, error])</code> returns a copy of the key or value of the item, writing it to the <code>dst</code> slice. If <code>nil</code> is passed, or the capacity of <code>dst</code> isn’t sufficient, a new slice would be allocated and returned.</li></ul><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">type</span> DBItem <span class="keyword">interface</span> &#123;</span><br><span class="line">Key() []<span class="type">byte</span></span><br><span class="line">KeyCopy(dst []<span class="type">byte</span>) []<span class="type">byte</span></span><br><span class="line">Value() ([]<span class="type">byte</span>, <span class="type">error</span>)</span><br><span class="line">ValueSize() <span class="type">int</span></span><br><span class="line">ValueCopy(dst []<span class="type">byte</span>) ([]<span class="type">byte</span>, <span class="type">error</span>)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>A <code>BadgerIterator</code> and <code>CFItem</code> is implemented that supports <code>DBIterator</code> and <code>DBItem</code>.</p><ul><li><code>func NewCFIterator(cf string, txn *badger.Txn) *BadgerIterator</code> can be used to create an iterator.</li><li>They are wrappers of <code>badger.Iterator</code> and <code>badger.Item</code> to support column family in <code>Valid</code> and <code>Seek</code> easier.</li><li>The column family prefix is stored inside and will be checked in <code>BadgerIterator.Valid</code> or removed in <code>CFItem.Key</code> and <code>CFItem.KeyCopy</code>.</li></ul></li></ol><h2 id="simple-example-project1-standalonekv"><a class="markdownIt-Anchor" href="#simple-example-project1-standalonekv"></a> Simple example: Project1 StandaloneKV</h2><ol><li>This project will help us learn how to write and read data with <code>BadgerDB</code> and how these interfaces are used.</li><li>Both writing and reading are handled through a badger transaction.<ul><li>The BadgerDB transaction can use <code>Set</code> and <code>Delete</code> to process write requests, and it will be committed after all write requests are finished.</li><li>The <code>BadgerIterator</code> uses the <code>NewIterator</code> method of the transaction to create a <code>badger.Iterator</code>.</li><li>When the iterator is no longer needed, <code>badger.Iterator</code> will be closed and the transaction discarded until the reader is finished.</li></ul></li></ol><h2 id="raftstorage"><a class="markdownIt-Anchor" href="#raftstorage"></a> RaftStorage</h2><p>The code is in <code>kv/storage/raft_storage/raft_server.go</code>.</p><ol><li>In a multi-Raft scenario, a <code>Store</code> stands for an instance of tinykv-server, a <code>Peer</code> stands for a Raft node running on a Store, while a <code>Region</code> is a collection of Peers, also called a Raft group.</li><li>When starting a <code>RaftStorage</code>, it first starts a <code>rs.resolveWorker</code> and a <code>rs.snapWorker</code>. Then, a <code>Node</code> is started.<ul><li>After a series of self-examinations, <code>Node</code> will start the core <code>Raftstore</code>.</li><li><code>Raftstore</code> first loads peers in this store. It scans the db engine, loads all regions and their peers from it, and registers them.</li><li>Then, it begins to start workers to get jobs done.<ul><li>A <code>raftWorker</code> is used to execute Raft commands. Messages for all peers are received here, and it needs to transmit them to their destination.</li><li>A <code>storeWorker</code> is used to handle store commands.<ul><li>One kind is <code>MsgTypeStoreStart</code>, which will be sent immediately after this worker is running.</li><li>Another kind is <code>MsgTypeStoreTick</code> to control the <code>tick()</code> on all peers in the same store. Another <code>tikerDriver</code> is used to generate this command.</li><li><code>MsgTypeStoreRaftMessage</code> can redirect a misplaced message.</li></ul></li><li>Other background threads, e.g., garbage collection or scheduler, are started as workers with different handlers.</li></ul></li></ul></li><li>A <code>RaftstoreRouter</code> is created together with <code>Raftstore</code>.<ul><li>It has a <code>peerSender chan message.Msg</code> that will be used to communicate with <code>raftWorker</code> and another <code>storeSender chan&lt;- message.Msg</code> that will be read by the <code>storeWorker</code>.</li><li>It provides <code>Send</code>, <code>SendRaftMessage</code>, and <code>SendRaftCommand</code> for communication inside this store.</li></ul></li><li><code>Write</code> and <code>Reader</code> will generate a corresponding request of type <code>raft_cmdpb.RaftCmdRequest</code>.<ul><li>The request is a proposal to the Raft group, and the result will only be returned when its request entry is applied.</li><li>It is sent through a <code>router</code>, i.e., ignoring <code>RawXXX</code>, <code>Write</code> and <code>Reader</code> receive commands from other servers or clients and forward them to peers.</li><li>Then, the command will be wrapped with a <code>Callback</code> that can be used to track the execution process of this command. When the <code>Callback</code> receives the done signal, it can return the response to the <code>Write</code> or <code>Reader</code>.</li></ul></li></ol><h1 id="raft-storage-raftstorage"><a class="markdownIt-Anchor" href="#raft-storage-raftstorage"></a> Raft storage (raft.Storage)</h1><p>This is the storage interface for Raft nodes to persist in their internal states. Unlike the KV storage interface above, this is only used when implementing a Raft node.</p><h2 id="interface-2"><a class="markdownIt-Anchor" href="#interface-2"></a> Interface</h2><ol><li><p>The interfaces required are all read-only functions. The writings are performed by upper applications.</p></li><li><p><code>InitialState()</code> returns the saved <code>HardState</code> and <code>ConfState</code> information.</p></li><li><p><code>Entries(lo, hi uint64)</code> returns a slice of log entries in the range <code>[lo,hi)</code>.</p><ul><li><code>MaxSize</code> limits the total size of the log entries returned, but it returns at least one entry, if any.</li></ul></li><li><p><code>Term(i uint64)</code> returns the term of entry <code>i</code>, which must be in the range <code>[FirstIndex()-1, LastIndex()]</code>.</p><ul><li>The term of the entry before <code>FirstIndex</code> is retained for matching purposes, even though the rest of that entry may not be available.</li></ul></li><li><p><code>LastIndex()</code> returns the index of the last entry in the log.</p></li><li><p><code>FirstIndex()</code> returns the index of the first log entry that is possibly available via <code>Entries</code> (older entries have been incorporated into the latest Snapshot; if storage only contains the dummy entry, the first log entry is unavailable).</p></li><li><p><code>Snapshot()</code> returns the most recent snapshot.</p><ul><li>If the snapshot is temporarily unavailable, it should return <code>ErrSnapshotTemporarilyUnavailable</code>, so the raft state machine knows Storage needs some time to prepare the snapshot and call Snapshot later.</li></ul><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">type</span> Storage <span class="keyword">interface</span> &#123;</span><br><span class="line">InitialState() (pb.HardState, pb.ConfState, <span class="type">error</span>)</span><br><span class="line">Entries(lo, hi <span class="type">uint64</span>) ([]pb.Entry, <span class="type">error</span>)</span><br><span class="line">Term(i <span class="type">uint64</span>) (<span class="type">uint64</span>, <span class="type">error</span>)</span><br><span class="line">LastIndex() (<span class="type">uint64</span>, <span class="type">error</span>)</span><br><span class="line">FirstIndex() (<span class="type">uint64</span>, <span class="type">error</span>)</span><br><span class="line">Snapshot() (pb.Snapshot, <span class="type">error</span>)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li></ol><h2 id="simple-example-memstorage"><a class="markdownIt-Anchor" href="#simple-example-memstorage"></a> Simple example: MemStorage</h2><ol><li>This is defined in <code>raft/storage.go</code>. Besides those read-only interfaces, <code>MemStorage</code> provides write methods for upper applications to change states.</li><li><code>SetHardState(st pb.HardState) error</code> changes the current <code>HardState</code> to the given one.</li><li><code>ApplySnapshot(snap pb.Snapshot) error</code> overwrites the contents of this Storage object with those of the given snapshot.<ul><li>In this case, it overwrites the current snapshot and truncates <code>ents</code> with only a dummy entry.</li></ul></li><li><code>CreateSnapshot(i uint64, cs *pb.ConfState, data []byte) (pb.Snapshot, error)</code> makes a snapshot which can be used to reconstruct the state.<ul><li>If any configuration changes have been made since the last compaction, the result of the last <code>ApplyConfChange</code> must be passed in.</li><li>The state machine’s data is acquired by the upper application, not this method.</li></ul></li><li><code>Compact(compactIndex uint64) error</code> discards all log entries prior to <code>compactIndex</code>.<ul><li>The application is responsible for not attempting to compact an index greater than <code>raftLog.applied</code>.</li></ul></li><li><code>Append(entries []pb.Entry) error</code> append the new entries to storage, i.e., persist Raft entries when this storage is writing to disk.</li></ol><h2 id="project-2b-peerstorage"><a class="markdownIt-Anchor" href="#project-2b-peerstorage"></a> Project 2B: PeerStorage</h2><h3 id="basic-duties"><a class="markdownIt-Anchor" href="#basic-duties"></a> Basic duties</h3><ol><li>A peer storage must maintain the persistence of both Key-Value pairs in this peer and its Raft logs.<ul><li>The entries of Raft logs are stored with the key <code>LocalPrefix_RegionRaftPrefix_regionID_RaftLogSuffix_entry index</code>.</li></ul></li><li>After acquiring a value from <code>*badger.DB</code>, it can be transferred to the correct type with the <code>Unmarshal</code> provided by the <code>struct</code> generated from protobuf.</li><li><code>SaveReadyState</code> will be used by <code>peerMsgHandler.HandleRaftReady</code> to persist according to <code>Ready</code>. It needs to install a snapshot and update persisted new Raft log entries, including deleting the entries the new leader removed.</li><li>The Raft commands that manipulate key-value storages are executed through the engines provided by <code>PeerStorage</code>.</li></ol><h3 id="snapshot-generation-and-application"><a class="markdownIt-Anchor" href="#snapshot-generation-and-application"></a> Snapshot generation and application</h3><ol><li><p>The snapshot generation is an asynchronous process.</p><ul><li><p>When the Raft node requests a snapshot, <code>PeerStorage</code> sends a message of <code>RegionTaskGen</code> to <code>regionWorker</code> and sets its <code>snapState</code> to <code>SnapState_Generating</code> and the channel to receive a snapshot.</p></li><li><p>The snapshots are sent by a <code>snapRunner</code>, different from the ordinary entries. The snapshot will be sliced into chunks of size <code>snapChunkLen</code> and sent to the same <code>grpc.ClientStream</code>.</p></li></ul></li><li><p>The receiver will collect all data from the <code>grpc.ClientStream</code> and write them into the same snapshot file.</p><ul><li>The snapshot is first sent to Raft to check its validation. If valid, <code>PeerStorage</code> will apply it in the <code>HandleRaftReady</code> of the <code>peerMsgHandler</code>.</li><li>The <code>PeerStorage</code> sends a <code>RegionTaskApply</code> to <code>regionWorker</code>. The worker will clean up the range of this region and directly ingest the content of the snapshot file into the DB with <code>IngestExternalFiles</code>.</li></ul></li></ol><img src="/imgs/TiKV/Snapshot.png">]]></content>
      
      
      <categories>
          
          <category> Open Source Code </category>
          
          <category> TiKV/TinyKV </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Storage </tag>
            
            <tag> TinyKV </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>BusTub Overview</title>
      <link href="/2023/10/30/OpenSource/BusTub/BusTub-Overview/"/>
      <url>/2023/10/30/OpenSource/BusTub/BusTub-Overview/</url>
      
        <content type="html"><![CDATA[<p><ul class="markdownIt-TOC"><li><a href="#shell-execution">Shell Execution</a></li></ul></p><h1 id="shell-execution"><a class="markdownIt-Anchor" href="#shell-execution"></a> Shell Execution</h1><ol><li>The shell (in the <a href="https://github.com/cmu-db/bustub/blob/master/tools/shell/shell.cpp">shell.cpp</a>) uses <code>linenoise</code> to read input lines until a line ending with <code>;</code> or beginning with <code>\</code>.<ul><li><code>;</code> means the end of a query while <code>\</code> leads an internal meta-command.</li><li>The backbone of the DBMS is <code>bustub::BustubInstance</code> (in <a href="https://github.com/cmu-db/bustub/blob/master/src/common/bustub_instance.cpp">bustub_instance.cpp</a>). It is initialized at the beginning of the shell.</li><li>After reading the complete query, execute it using <code>BustubInstance.ExecuteSql</code>. The result is writen in <code>bustub::FortTableWriter</code>.</li></ul></li><li>In <code>BustubInstance.ExecuteSqlTxn</code>:<ul><li>First, determine whether this is an internal meta-command. If so, only execute the corresponding command and exit.</li><li>If this is a query, use <strong><code>bustub::Binder</code></strong> (in <a href="https://github.com/cmu-db/bustub/blob/master/src/binder/binder.cpp#L45">binder.cpp</a>) to parse the query into an AST. Handle the output format according to the statement type using <code>HandlexxxStatement</code>.</li><li>Then <strong><code>bustub::Planner</code></strong> will plan the query execution according to the generated AST. And <strong><code>bustub::Optimizer</code></strong> will optimize the plan tree with certain rules.</li><li>Then, the plan will be executed by <strong><code>ExecutionEngine.Execute</code></strong> (in <a href="https://github.com/cmu-db/bustub/blob/master/src/include/execution/execution_engine.h#L54">execution_engine.h</a>).</li><li>Finally, the result will be written in the shell with a writer.</li></ul></li><li>To provide easier format control, the <code>bustub::ResultWriter</code> provides interfaces for standard output.<ul><li><code>BeginHeader</code>, <code>EndHeader</code>, <code>BeginRow</code>, <code>EndRow</code>, and <code>BeginTable</code>, <code>EndTable</code> to output pre-defined messages.</li><li><code>WriteCell</code> and <code>WriteHeaderCell</code> are used to output data and pre-defined separators.</li><li>Its sub-classes need to override these methods to perform as they want.<ul><li><code>NoopWriter</code> does nothing in all these methods.</li><li><code>SimpleStreamWriter</code> will output simple, plain text.</li><li><code>HtmlWriter</code> will output the results in HTML code that can be shown in the browser.</li><li><code>FortTableWriter</code> uses <code>fort</code> to output table.</li></ul></li></ul></li></ol>]]></content>
      
      
      <categories>
          
          <category> Open Source Code </category>
          
          <category> BusTub </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Database System </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Project #4: Concurrency Control</title>
      <link href="/2023/10/12/OpenSource/BusTub/Project-4-Concurrency-Control/"/>
      <url>/2023/10/12/OpenSource/BusTub/Project-4-Concurrency-Control/</url>
      
        <content type="html"><![CDATA[<p><ul class="markdownIt-TOC"><li><a href="#lockmanager">LockManager</a><ul><li><a href="#locks">Locks</a></li><li><a href="#lock">Lock</a><ul><li><a href="#before-granting-locks">Before granting locks</a></li><li><a href="#grant-locks">Grant locks</a></li></ul></li><li><a href="#unlocktable">UnlockTable</a></li></ul></li><li><a href="#concurrent-query-execution">Concurrent query execution</a><ul><li><a href="#seqscan-executor">SeqScan Executor</a></li><li><a href="#insert-delete-and-update-executors">Insert, Delete, and Update Executors</a></li><li><a href="#transaction-manager">Transaction manager</a></li></ul></li></ul></p><h1 id="lockmanager"><a class="markdownIt-Anchor" href="#lockmanager"></a> LockManager</h1><h2 id="locks"><a class="markdownIt-Anchor" href="#locks"></a> Locks</h2><ol><li><code>LockManager</code> is used to protect the data in the database. According to the lock granularities, the lock information is stored in <code>table_lock_map_</code> and <code>row_lock_map_</code>.</li><li>The interface of <code>LockManager</code> may be executed concurrently by each transaction. Hence <code>table_lock_map_latch_</code> and <code>row_lock_map_latch_</code> are necessary to protect the data of <code>LockManager</code>.</li><li>The information of each object is stored in <code>LockRequestQueue</code>, where all requests are stored, including both granted and waiting requests. Each queue has a <code>latch_</code> to protect its data and as the lock of the condition variable.</li><li>The <code>table_lock_map_latch_</code> or <code>row_lock_map_latch_</code> can be released once the <code>latch_</code> of the corresponding queue is acquired to support better throughput of processing lock requests.</li></ol><h2 id="lock"><a class="markdownIt-Anchor" href="#lock"></a> Lock</h2><h3 id="before-granting-locks"><a class="markdownIt-Anchor" href="#before-granting-locks"></a> Before granting locks</h3><ol><li>Check whether this transaction allows the acquisition of this lock based on its isolation level and current state.</li><li>Check whether this transaction is upgrading its lock.<ul><li>If so, check whether there is another transaction that is upgrading.</li><li>If not, check whether it can upgrade to this new lock mode.</li><li>If can, set the <code>upgrading_</code> of this queue, remove the recording of the currently holding lock from the transaction, update the lock_mode_ and granted_ of the request in the queue, and use this request as the request to be granted.</li></ul></li><li>If this is not an upgrade, create a new request and insert it into the queue.</li><li>When locking a row, we must also ensure that appropriate locks are held in the table.</li></ol><h3 id="grant-locks"><a class="markdownIt-Anchor" href="#grant-locks"></a> Grant locks</h3><ol><li>If the transaction is not aborted, try to grant the lock. If failed, sleep the process with the condition variable.</li><li>The rules for granting locks are as follows:<ul><li>If there are granted locks and they are compatible with all granted locks, grant the lock.</li><li>If there is no granted lock,<ul><li>If there is an upgrading request, when this is the upgrading request, or this is compatible with the upgrading request, grant the lock.</li><li>If there is no upgrading request, grant the lock when this is the first request on the waiting list or this is compatible with the first request.</li></ul></li></ul></li><li>If the loop of trying to grant the lock due to the transaction is aborted, its request needs to be deleted from the queue. Otherwise, add the record of the holding the lock to the transaction.</li></ol><h2 id="unlocktable"><a class="markdownIt-Anchor" href="#unlocktable"></a> UnlockTable</h2><ol><li>The transaction should not have any record of holding locks of rows of this table.</li><li>Find the request for this transaction, remove it from the queue, update the transaction state according to the isolation level, unlock the lock, and remove the recording from the transaction.</li><li>When unlocking a table, we need to ensure that no lock of rows in that table is held.</li></ol><h1 id="concurrent-query-execution"><a class="markdownIt-Anchor" href="#concurrent-query-execution"></a> Concurrent query execution</h1><h2 id="seqscan-executor"><a class="markdownIt-Anchor" href="#seqscan-executor"></a> SeqScan Executor</h2><ol><li>The concurrency control of deletion depends on the <code>SeqScan</code> executor. In <code>Init()</code>, we need to determine the lock type according to <code>exec_ctx_-&gt;IsDelete()</code>.<ul><li>If this scan is for future deletion, we must acquire an exclusive lock on rows and an intension-exclusive lock on the table.</li><li>Otherwise, we lock the table with an intension-shared lock if the isolation level is not <code>READ_UNCOMMITED</code>.</li></ul></li><li>In <code>Next</code>, if shared locks are on the previous row and the isolation level is <code>READ_COMMITTED</code>, we must first release the shared lock. Hence, we can only execute <code>++(*iter_)</code> at the beginning instead of right after fetching the row.<ul><li>Also, when reading tuples, we always acquire a lock first. If, after reading, the tuple does not match the predicate, we should force unlock the lock despite the lock mode.</li></ul></li><li>A corner case for this is that some transactions may execute a deletion before another sequential scan. Then, the later sequential scan should only acquire a shared lock while the first deletion has already acquired an exclusive lock.</li><li>When there is no more tuple to emit, we should unlock the shared lock this executor locks on the table.</li></ol><h2 id="insert-delete-and-update-executors"><a class="markdownIt-Anchor" href="#insert-delete-and-update-executors"></a> Insert, Delete, and Update Executors</h2><ol><li>As aforementioned, the concurrency control of deletion depends on <code>SeqScan</code>. Therefore, we do not need to do anything extra in the <code>Delete</code> executor.</li><li>For insert and update, we need to acquire an intension-exclusive lock on the table in the <code>Init</code>.</li><li>Insert needs to acquire an exclusive lock on the inserted row, but only after the row is generated.</li><li>The update can use an in-place update and needs an exclusive lock before that.</li></ol><h2 id="transaction-manager"><a class="markdownIt-Anchor" href="#transaction-manager"></a> Transaction manager</h2><ol><li>On abort, the transaction manager needs to restore the changes made by this transaction. The first is to restore the changes made to tables directly.<ul><li>The reversion must be performed in the opposite order as the modification.</li><li>If the transaction inserted or deleted some tuples, we must reverse the <code>is_deleted_</code> flag in metadata.</li><li>If the transaction updated some tuples without in-place update optimization, we need to insert a delete and an insert record.</li><li>If the transaction uses in-place update optimization, we must keep the old tuples and their meta in the record to restore when aborted.</li><li>Modification to indexes needs to be reverted similarly.</li></ul></li><li>After reverted modifications in abort or entered commit, all locks held by the transaction must be released. We only need to check the lock sets in a transaction.</li></ol>]]></content>
      
      
      <categories>
          
          <category> Open Source Code </category>
          
          <category> BusTub </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Database System </tag>
            
            <tag> Transaction </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Parameter Server</title>
      <link href="/2023/10/09/Paper/Sys4AI/Parameter-Server/"/>
      <url>/2023/10/09/Paper/Sys4AI/Parameter-Server/</url>
      
        <content type="html"><![CDATA[<p>Paper: <a href="https://www.usenix.org/system/files/conference/osdi14/osdi14-paper-li_mu.pdf">Scaling Distributed Machine Learning with the Parameter Server</a></p><p><ul class="markdownIt-TOC"><li><a href="#purpose">Purpose</a></li><li><a href="#model">Model</a><ul><li><a href="#what-is-a-conventional-distributed-ml-system">What is a conventional distributed ML system?</a></li><li><a href="#what-is-the-structure-of-this-new-parameter-server">What is the structure of this new parameter server?</a></li><li><a href="#how-to-optimize-the-cost-of-communication-of-pulling-parameters">How to optimize the cost of communication of pulling parameters?</a></li><li><a href="#how-to-support-flexible-consistency">How to support flexible consistency?</a></li><li><a href="#well-defined-behavior-background">Well-defined behavior (Background)</a><ul><li><a href="#how-to-provide-a-well-defined-behavior-after-failure">How to provide a well-defined behavior after failure?</a></li><li><a href="#what-is-the-problem-with-the-lamport-clock">What is the problem with the Lamport clock?</a></li></ul></li><li><a href="#what-is-the-problem-of-vector-clocks-in-the-parameter-server">What is the problem of vector clocks in the parameter server?</a></li><li><a href="#how-to-optimize-the-cost-of-communication">How to optimize the cost of communication?</a></li><li><a href="#what-is-the-difference-in-fault-tolerance-between-a-parameter-server-and-a-conventional-distributed-system">What is the difference in fault tolerance between a parameter server and a conventional distributed system?</a></li></ul></li><li><a href="#evaluation">Evaluation</a></li></ul></p><h1 id="purpose"><a class="markdownIt-Anchor" href="#purpose"></a> Purpose</h1><ol><li>Issues:<ul><li>Many research settings run jobs exclusively on a cluster without contention.</li></ul></li><li>Challenges:<ul><li>Sharing imposes three challenges:<ul><li>Accessing the parameters requires an enormous amount of network bandwidth.</li><li>Many machine learning algorithms are sequential.</li><li>At scale, fault tolerance is critical.</li></ul></li><li>When solving distributed data analysis problems, the issue of reading and updating parameters shared between different worker nodes is ubiquitous.<ul><li>Using key-value pair abstraction to update parameters naively is inefficient: values are typically small (floats or integers), and the overhead of sending each update as a key value operation is high.</li></ul></li><li>For efficient operation, fault tolerance must not require a full restart of a long-running computation.</li></ul></li><li>Contributions:<ul><li>Factoring out commonly required components of machine learning systems enables application-specific code to remain concise.</li><li>As a shared platform to target systems-level optimizations, it provides a robust, versatile, and high-performance implementation capable of handling a diverse array of algorithms, from sparse logistic regression to topic models and distributed sketching.</li><li>Five key features:<ul><li><strong>Efficient communication</strong> is achieved through an asynchronous communication model.</li><li><strong>Flexible consistency models</strong> to balance algorithmic convergence rate and system efficiency.</li><li><strong>Elastic scalability</strong>, where new nodes can be added without restarting the running framework.</li><li><strong>Fault tolerance and durability</strong> provide fast recovery and well-defined behavior.</li><li><strong>Ease of use</strong>.</li></ul></li><li>Achieved synergy by picking the right systems techniques, adapting them to the machine learning algorithms, and modifying the machine learning algorithms to be more systems-friendly.</li></ul></li></ol><h1 id="model"><a class="markdownIt-Anchor" href="#model"></a> Model</h1><h2 id="what-is-a-conventional-distributed-ml-system"><a class="markdownIt-Anchor" href="#what-is-a-conventional-distributed-ml-system"></a> What is a conventional distributed ML system?</h2><ol><li>Training typically consists of three components: feature extraction, the objective function, and learning.<ul><li>Feature extraction processes the raw training data to obtain feature vectors, where each feature captures an attribute of the training data.</li><li>Preprocessing can be executed efficiently by existing frameworks such as MapReduce.</li></ul></li><li>There are three components: task scheduler, worker, and server.<ul><li>The parameters are stored in servers while the training data is partitioned among the workers.</li><li>The task scheduler first notifies each worker to execute <code>LoadData</code>. Then, in each iteration, it issues each worker to execute <code>WorkerIterate</code>.</li><li>Each worker has two functions:<ul><li><code>LoadData</code> will load and cache a part of training data, which will not change in all iterations. It will also pull the initial working set of parameters from the server.</li><li><code>WorkIterate</code> will calculate the gradient based on the current parameter and send this gradient to the server before pulling new parameters.</li></ul></li><li>Servers only need to aggregate gradients from workers and update parameters in each iteration in <code>ServerIterate</code>.</li></ul></li><li>In each iteration, every worker independently uses its training data to determine what changes should be made to the weights to get closer to an optimal value.<ul><li>Because each worker’s updates reflect only its training data, the system needs a mechanism to allow these updates to mix. It does so by expressing the updates as a subgradient.</li></ul></li><li>The most expensive step in the algorithm is computing the subgradient to update <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>w</mi></mrow><annotation encoding="application/x-tex">w</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.02691em;">w</span></span></span></span>. This task is divided among all the workers, each executing <code>WorkerIterate</code>.</li><li>The total size of <code>w</code> may exceed the capacity of a single machine.<ul><li>A worker needs to know a coordinate of w if and only if some of its training data references that entry.</li><li>A particular worker’s working set of entries can be trivially cached locally.</li></ul></li></ol><img src="/imgs/Sys4ai/PS/subgradient.png" width="25%"><h2 id="what-is-the-structure-of-this-new-parameter-server"><a class="markdownIt-Anchor" href="#what-is-the-structure-of-this-new-parameter-server"></a> What is the structure of this new parameter server?</h2><ol><li>Parameter server nodes are grouped into a server group and several worker groups.<ul><li>A server node in the server group maintains a partition of the globally shared parameters.</li><li>Workers communicate only with the server nodes (not among themselves), updating and retrieving the shared parameters.</li></ul></li><li>There is a scheduler node for each worker group. It assigns tasks to workers and monitors their progress. If workers are added or removed, unfinished tasks are rescheduled.</li><li>The parameter server supports independent parameter namespaces.<ul><li>This allows a worker group to isolate its shared parameters from others.</li><li>Several worker groups may also share the same namespace: we may use more than one worker group to solve the same deep learning application to increase parallelization.</li></ul></li></ol><img src="/imgs/Sys4ai/PS/arch.png" width="25%"><h2 id="how-to-optimize-the-cost-of-communication-of-pulling-parameters"><a class="markdownIt-Anchor" href="#how-to-optimize-the-cost-of-communication-of-pulling-parameters"></a> How to optimize the cost of communication of pulling parameters?</h2><ol><li>Many learning algorithms represent parameters as structured mathematical objects.<ul><li>Workers usually send a segment of a vector or an entire row of the matrix.</li></ul></li><li>Batch both the communication of updates and their processing on the parameter server and allow the consistency tracking to be implemented efficiently.<ul><li>This lets us treat the parameters as (key, value) pairs while endowing them with vector and matrix semantics, where non-existing keys are associated with zeros.</li></ul></li><li>Data is sent between nodes using push and pull operations.<ul><li>If <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>R</mi></mrow><annotation encoding="application/x-tex">R</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.00773em;">R</span></span></span></span> is a key range, then <code>w.push(R, dest)</code> sends all existing entries of <code>w</code> in key range <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>R</mi></mrow><annotation encoding="application/x-tex">R</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.00773em;">R</span></span></span></span> to the destination, a particular node, or a node group such as the server group.</li><li>Similarly, <code>w.pull(R, dest)</code> reads all existing entries of <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>w</mi></mrow><annotation encoding="application/x-tex">w</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.02691em;">w</span></span></span></span> in key range <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>R</mi></mrow><annotation encoding="application/x-tex">R</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.00773em;">R</span></span></span></span> from the destination.</li><li>Gradients share the keys of the worker’s working set <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>w</mi></mrow><annotation encoding="application/x-tex">w</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.02691em;">w</span></span></span></span>. Hence, the programmer can use w.push(R, g, dest) to save memory for local gradients.</li></ul></li><li>The system also supports user-defined filters to selectively synchronize individual (key, value) pairs, allowing fine-grained data consistency control within a task.<ul><li>The optimization algorithm usually contains information on which parameters are most valuable for synchronization.</li><li>One example is the significantly modified filter, which only pushes entries that have changed by more than a threshold since their last synchronization.</li></ul></li></ol><h2 id="how-to-support-flexible-consistency"><a class="markdownIt-Anchor" href="#how-to-support-flexible-consistency"></a> How to support flexible consistency?</h2><ol><li>A remote procedure call issues tasks. It can be a push or a pull that a worker issues to servers. Tasks may include any number of subtasks.</li><li>Tasks are executed asynchronously.<ul><li>The caller can perform further computation immediately after issuing a task.</li><li>The caller marks a task as finished only after receiving the callee’s reply. The callee marks a task as finished only if the call of the task is returned and all subtasks issued by this call are finished.</li><li>A caller that wishes to serialize task execution can place an execute-after-finished dependency between tasks.</li></ul></li><li>We can implement different models by task dependency.<ul><li><strong>Sequential</strong>: All tasks are executed one by one.</li><li><strong>Eventual</strong>: All tasks may be started simultaneously. This is only recommendable if the underlying algorithms are robust with regard to delays.</li><li><strong>Bounded Delay</strong>: When a maximal delay time <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>τ</mi></mrow><annotation encoding="application/x-tex">\tau</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.1132em;">τ</span></span></span></span> is set, a new task will be blocked until all previous tasks <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>τ</mi></mrow><annotation encoding="application/x-tex">\tau</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.1132em;">τ</span></span></span></span> times ago have been finished.<ul><li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>τ</mi><mo>=</mo><mn>0</mn></mrow><annotation encoding="application/x-tex">\tau=0</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.1132em;">τ</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">0</span></span></span></span> is the sequential consistency model, and an infinite delay <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>τ</mi><mo>=</mo><mi mathvariant="normal">∞</mi></mrow><annotation encoding="application/x-tex">\tau = \infty</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.1132em;">τ</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord">∞</span></span></span></span> becomes the eventual consistency model.</li></ul></li></ul></li><li>The dependency graphs may be dynamic; the caller traverses the DAG.<ul><li>If the graph is static, the caller can send all tasks with the DAG to the callee to reduce synchronization costs.</li></ul></li><li>This inconsistency potentially slows down the convergence progress. Some algorithms may be less sensitive to this type of inconsistency.<ul><li>The best trade-off between system efficiency and algorithm convergence rate usually depends on various factors, including the algorithm’s sensitivity to data inconsistency, feature correlation in training data, and capacity difference of hardware components.</li></ul></li></ol><img src="/imgs/Sys4ai/PS/dag.png" width="50%"><h2 id="well-defined-behavior-background"><a class="markdownIt-Anchor" href="#well-defined-behavior-background"></a> Well-defined behavior (Background)</h2><h3 id="how-to-provide-a-well-defined-behavior-after-failure"><a class="markdownIt-Anchor" href="#how-to-provide-a-well-defined-behavior-after-failure"></a> How to provide a well-defined behavior after failure?</h3><ol><li>To provide a well-defined behavior, we only need to find a way to determine the logical order of concurrent operations.<ul><li>In a single-machine situation, suppose we perform a write to key <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi></mrow><annotation encoding="application/x-tex">k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.03148em;">k</span></span></span></span> with timestamp <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>t</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">t_1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.76508em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">t</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> and then perform another write to <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi></mrow><annotation encoding="application/x-tex">k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.03148em;">k</span></span></span></span> with timestamp <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>t</mi><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">t_2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.76508em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">t</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>.<ul><li>Since <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>t</mi><mn>2</mn></msub><mo>&gt;</mo><msub><mi>t</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">t_2 &gt; t_1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.76508em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">t</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">&gt;</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.76508em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">t</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>, the second write must be newer than the first so the database can safely overwrite the original value.</li></ul></li><li>In a distributed system, this assumption does not hold. The problem is <strong>clock skew</strong>, such as, different clocks tend to run at different rates, so we cannot assume that time <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>t</mi></mrow><annotation encoding="application/x-tex">t</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.61508em;vertical-align:0em;"></span><span class="mord mathnormal">t</span></span></span></span> on node <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>a</mi></mrow><annotation encoding="application/x-tex">a</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathnormal">a</span></span></span></span> happened before time <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>t</mi><mo>+</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">t + 1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69841em;vertical-align:-0.08333em;"></span><span class="mord mathnormal">t</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">1</span></span></span></span> on node <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>b</mi></mrow><annotation encoding="application/x-tex">b</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathnormal">b</span></span></span></span>.</li></ul></li><li>Lamport clock is a logical clock that provides a partial order of events. If an event <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>A</mi></mrow><annotation encoding="application/x-tex">A</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal">A</span></span></span></span> causally happens before another event <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>B</mi></mrow><annotation encoding="application/x-tex">B</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.05017em;">B</span></span></span></span>, i.e. <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>A</mi><mo>→</mo><mi>B</mi></mrow><annotation encoding="application/x-tex">A\rightarrow B</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal">A</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">→</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.05017em;">B</span></span></span></span>, then <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>t</mi><mi>i</mi><mi>m</mi><mi>e</mi><mi>s</mi><mi>t</mi><mi>a</mi><mi>m</mi><mi>p</mi><mo stretchy="false">(</mo><mi>A</mi><mo stretchy="false">)</mo><mo>&lt;</mo><mi>t</mi><mi>i</mi><mi>m</mi><mi>e</mi><mi>s</mi><mi>t</mi><mi>a</mi><mi>m</mi><mi>p</mi><mo stretchy="false">(</mo><mi>B</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">timestamp(A) &lt; timestamp(B)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">t</span><span class="mord mathnormal">i</span><span class="mord mathnormal">m</span><span class="mord mathnormal">e</span><span class="mord mathnormal">s</span><span class="mord mathnormal">t</span><span class="mord mathnormal">a</span><span class="mord mathnormal">m</span><span class="mord mathnormal">p</span><span class="mopen">(</span><span class="mord mathnormal">A</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">&lt;</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">t</span><span class="mord mathnormal">i</span><span class="mord mathnormal">m</span><span class="mord mathnormal">e</span><span class="mord mathnormal">s</span><span class="mord mathnormal">t</span><span class="mord mathnormal">a</span><span class="mord mathnormal">m</span><span class="mord mathnormal">p</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.05017em;">B</span><span class="mclose">)</span></span></span></span>.<ul><li>Causality means that if one event leads to another, then there is a path of events from the first event to the second event.</li><li>The algorithm provides only a partial order of events as we cannot relate all the events with the “happened before” relationship.</li></ul></li><li>In a distributed system, we can define mainly 3 types of events that each process can execute: a local event, a send event, and a receive event. Then the rules are defined as:<ul><li>For a local event, <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>a</mi><mo>→</mo><mi>b</mi></mrow><annotation encoding="application/x-tex">a \rightarrow b</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathnormal">a</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">→</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathnormal">b</span></span></span></span>, if <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>t</mi><mi>i</mi><mi>m</mi><mi>e</mi><mi>s</mi><mi>t</mi><mi>a</mi><mi>m</mi><mi>p</mi><mo stretchy="false">(</mo><mi>a</mi><mo stretchy="false">)</mo><mo>&lt;</mo><mi>t</mi><mi>i</mi><mi>m</mi><mi>e</mi><mi>s</mi><mi>t</mi><mi>a</mi><mi>m</mi><mi>p</mi><mo stretchy="false">(</mo><mi>b</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">timestamp(a) &lt; timestamp(b)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">t</span><span class="mord mathnormal">i</span><span class="mord mathnormal">m</span><span class="mord mathnormal">e</span><span class="mord mathnormal">s</span><span class="mord mathnormal">t</span><span class="mord mathnormal">a</span><span class="mord mathnormal">m</span><span class="mord mathnormal">p</span><span class="mopen">(</span><span class="mord mathnormal">a</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">&lt;</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">t</span><span class="mord mathnormal">i</span><span class="mord mathnormal">m</span><span class="mord mathnormal">e</span><span class="mord mathnormal">s</span><span class="mord mathnormal">t</span><span class="mord mathnormal">a</span><span class="mord mathnormal">m</span><span class="mord mathnormal">p</span><span class="mopen">(</span><span class="mord mathnormal">b</span><span class="mclose">)</span></span></span></span>.</li><li>If process <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>P</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">P_1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> sends a message to process <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>P</mi><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">P_2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>, then, <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>s</mi><mi>e</mi><mi>n</mi><mi>d</mi><mo stretchy="false">(</mo><mi>m</mi><mi>e</mi><mi>s</mi><mi>s</mi><mi>a</mi><mi>g</mi><mi>e</mi><mo stretchy="false">)</mo><mo>→</mo><mi>r</mi><mi>e</mi><mi>c</mi><mi>e</mi><mi>i</mi><mi>v</mi><mi>e</mi><mo stretchy="false">(</mo><mi>m</mi><mi>e</mi><mi>s</mi><mi>s</mi><mi>a</mi><mi>g</mi><mi>e</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">send(message) \rightarrow receive(message)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">s</span><span class="mord mathnormal">e</span><span class="mord mathnormal">n</span><span class="mord mathnormal">d</span><span class="mopen">(</span><span class="mord mathnormal">m</span><span class="mord mathnormal">e</span><span class="mord mathnormal">s</span><span class="mord mathnormal">s</span><span class="mord mathnormal">a</span><span class="mord mathnormal" style="margin-right:0.03588em;">g</span><span class="mord mathnormal">e</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">→</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mord mathnormal">e</span><span class="mord mathnormal">c</span><span class="mord mathnormal">e</span><span class="mord mathnormal">i</span><span class="mord mathnormal" style="margin-right:0.03588em;">v</span><span class="mord mathnormal">e</span><span class="mopen">(</span><span class="mord mathnormal">m</span><span class="mord mathnormal">e</span><span class="mord mathnormal">s</span><span class="mord mathnormal">s</span><span class="mord mathnormal">a</span><span class="mord mathnormal" style="margin-right:0.03588em;">g</span><span class="mord mathnormal">e</span><span class="mclose">)</span></span></span></span>.</li><li>If <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>a</mi><mo>→</mo><mi>b</mi></mrow><annotation encoding="application/x-tex">a \rightarrow b</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathnormal">a</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">→</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathnormal">b</span></span></span></span> and <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>b</mi><mo>→</mo><mi>c</mi></mrow><annotation encoding="application/x-tex">b\rightarrow c</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathnormal">b</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">→</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathnormal">c</span></span></span></span> then <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>a</mi><mo>→</mo><mi>c</mi></mrow><annotation encoding="application/x-tex">a \rightarrow c</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathnormal">a</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">→</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathnormal">c</span></span></span></span>.</li></ul></li><li>The time stamps of each node are updated as follows rules:<ul><li>Before executing an event, the process increments the logical timestamp by <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1</mn></mrow><annotation encoding="application/x-tex">1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">1</span></span></span></span>.</li><li>During a send event, the process increments the logical timestamp by <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1</mn></mrow><annotation encoding="application/x-tex">1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">1</span></span></span></span> and sends the time along with the message.</li><li>During a receive event, the recipient’s counter is updated to the max value of its time stamp and the timestamp in the received message. It then increments the timestamp by <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1</mn></mrow><annotation encoding="application/x-tex">1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">1</span></span></span></span>.</li></ul></li></ol><h3 id="what-is-the-problem-with-the-lamport-clock"><a class="markdownIt-Anchor" href="#what-is-the-problem-with-the-lamport-clock"></a> What is the problem with the Lamport clock?</h3><ol><li>One of the shortcomings of Lamport’s clock is that it cannot identify concurrent events that are causally related.</li></ol><ul><li>When two nodes concurrently modify the same object and send the result to a third node, the third node cannot determine which modification happens first.</li></ul><ol start="2"><li>Instead of using integer values for the timestamp, a vector clock uses a vector of integer values to represent the timestamp.<ul><li>If we have <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>N</mi></mrow><annotation encoding="application/x-tex">N</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">N</span></span></span></span> processes in the group, then each process will have a vector with <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>N</mi></mrow><annotation encoding="application/x-tex">N</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">N</span></span></span></span> elements.</li><li>Before executing an event, the process <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>i</mi></mrow><annotation encoding="application/x-tex">i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.65952em;vertical-align:0em;"></span><span class="mord mathnormal">i</span></span></span></span> increments the <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>i</mi></mrow><annotation encoding="application/x-tex">i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.65952em;vertical-align:0em;"></span><span class="mord mathnormal">i</span></span></span></span>-th element of its vector clock by <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1</mn></mrow><annotation encoding="application/x-tex">1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">1</span></span></span></span>.</li><li>During a send event, the process <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>i</mi></mrow><annotation encoding="application/x-tex">i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.65952em;vertical-align:0em;"></span><span class="mord mathnormal">i</span></span></span></span> increments the <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>i</mi></mrow><annotation encoding="application/x-tex">i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.65952em;vertical-align:0em;"></span><span class="mord mathnormal">i</span></span></span></span>-th element of its vector clock by <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1</mn></mrow><annotation encoding="application/x-tex">1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">1</span></span></span></span> and sends the vector along with the message.</li><li>During a receive event, the process <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>i</mi></mrow><annotation encoding="application/x-tex">i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.65952em;vertical-align:0em;"></span><span class="mord mathnormal">i</span></span></span></span> increments the <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>i</mi></mrow><annotation encoding="application/x-tex">i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.65952em;vertical-align:0em;"></span><span class="mord mathnormal">i</span></span></span></span>-th element of its vector clock by <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1</mn></mrow><annotation encoding="application/x-tex">1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">1</span></span></span></span>. For all other processes, it takes the maximum of the corresponding component of the incoming message and its local vector. It sets it as the corresponding element in the local clock itself.</li></ul></li><li>The vector clocks are compared as follows:<ul><li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>V</mi><mn>1</mn></msub><mo>=</mo><msub><mi>V</mi><mn>2</mn></msub><mtext>  </mtext><mo>⟺</mo><mtext>  </mtext><mi mathvariant="normal">∀</mi><mi>i</mi><mo>=</mo><mn>1</mn><mo>→</mo><mi>N</mi><mo separator="true">,</mo><msub><mi>V</mi><mn>1</mn></msub><mo stretchy="false">[</mo><mi>i</mi><mo stretchy="false">]</mo><mo>=</mo><msub><mi>V</mi><mn>2</mn></msub><mo stretchy="false">[</mo><mi>i</mi><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">V_1 = V_2\iff \forall i=1\to N,V_1[i]=V_2[i]</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.22222em;">V</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.22222em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.22222em;">V</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.22222em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">⟺</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord">∀</span><span class="mord mathnormal">i</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">1</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">→</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">N</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.22222em;">V</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.22222em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mopen">[</span><span class="mord mathnormal">i</span><span class="mclose">]</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.22222em;">V</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.22222em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mopen">[</span><span class="mord mathnormal">i</span><span class="mclose">]</span></span></span></span>.</li><li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>V</mi><mn>1</mn></msub><mo>≤</mo><msub><mi>V</mi><mn>2</mn></msub><mtext>  </mtext><mo>⟺</mo><mtext>  </mtext><mi mathvariant="normal">∀</mi><mi>i</mi><mo>=</mo><mn>1</mn><mo>→</mo><mi>N</mi><mo separator="true">,</mo><msub><mi>V</mi><mn>1</mn></msub><mo stretchy="false">[</mo><mi>i</mi><mo stretchy="false">]</mo><mo>≤</mo><msub><mi>V</mi><mn>2</mn></msub><mo stretchy="false">[</mo><mi>i</mi><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">V_1\le V_2\iff \forall i=1\to N,V_1[i]\le V_2[i]</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.22222em;">V</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.22222em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">≤</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.22222em;">V</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.22222em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">⟺</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord">∀</span><span class="mord mathnormal">i</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">1</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">→</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">N</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.22222em;">V</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.22222em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mopen">[</span><span class="mord mathnormal">i</span><span class="mclose">]</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">≤</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.22222em;">V</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.22222em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mopen">[</span><span class="mord mathnormal">i</span><span class="mclose">]</span></span></span></span>.</li><li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>V</mi><mn>1</mn></msub><mo>&lt;</mo><msub><mi>V</mi><mn>2</mn></msub><mtext>  </mtext><mo>⟺</mo><mtext>  </mtext><msub><mi>V</mi><mn>1</mn></msub><mo>≤</mo><msub><mi>V</mi><mn>2</mn></msub><mo>∧</mo><mi mathvariant="normal">∃</mi><mi>j</mi><mo separator="true">,</mo><msub><mi>V</mi><mn>1</mn></msub><mo stretchy="false">[</mo><mi>j</mi><mo stretchy="false">]</mo><mo>&lt;</mo><msub><mi>V</mi><mn>2</mn></msub><mo stretchy="false">[</mo><mi>j</mi><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">V_1&lt;V_2\iff V_1\le V_2\land\exist j, V_1[j]&lt;V_2[j]</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.22222em;">V</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.22222em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">&lt;</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.22222em;">V</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.22222em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">⟺</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.22222em;">V</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.22222em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">≤</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.22222em;">V</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.22222em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">∧</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord">∃</span><span class="mord mathnormal" style="margin-right:0.05724em;">j</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.22222em;">V</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.22222em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mopen">[</span><span class="mord mathnormal" style="margin-right:0.05724em;">j</span><span class="mclose">]</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">&lt;</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.22222em;">V</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.22222em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mopen">[</span><span class="mord mathnormal" style="margin-right:0.05724em;">j</span><span class="mclose">]</span></span></span></span>.</li></ul></li><li>We can identify the concurrent events when <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>N</mi><mi>O</mi><mi>T</mi><mo stretchy="false">(</mo><msub><mi>V</mi><mn>1</mn></msub><mo>≤</mo><msub><mi>V</mi><mn>2</mn></msub><mo stretchy="false">)</mo><mo>∧</mo><mi>N</mi><mi>O</mi><mi>T</mi><mo stretchy="false">(</mo><msub><mi>V</mi><mn>2</mn></msub><mo>≤</mo><msub><mi>V</mi><mn>1</mn></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">NOT(V_1\le V_2)\land NOT(V_2\le V_1)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">N</span><span class="mord mathnormal" style="margin-right:0.02778em;">O</span><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.22222em;">V</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.22222em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">≤</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.22222em;">V</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.22222em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">∧</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">N</span><span class="mord mathnormal" style="margin-right:0.02778em;">O</span><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.22222em;">V</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.22222em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">≤</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.22222em;">V</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.22222em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span>.<ul><li>When concurrent events are detected, the system must resolve the conflicts. Vector clock only provides a method to find concurrent events.</li><li>One way to resolve conflicts is to leave it to the client, who knows the semantics, to decide which version is correct.</li></ul></li></ol><h2 id="what-is-the-problem-of-vector-clocks-in-the-parameter-server"><a class="markdownIt-Anchor" href="#what-is-the-problem-of-vector-clocks-in-the-parameter-server"></a> What is the problem of vector clocks in the parameter server?</h2><ol><li>Each (key, value) pair is associated with a vector clock, which records the time of each node on this (key, value) pair. Hence, a naive vector clock implementation requires <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>O</mi><mo stretchy="false">(</mo><mi>n</mi><mi>m</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">O(nm)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">O</span><span class="mopen">(</span><span class="mord mathnormal">n</span><span class="mord mathnormal">m</span><span class="mclose">)</span></span></span></span> space to handle <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi></mrow><annotation encoding="application/x-tex">n</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathnormal">n</span></span></span></span> nodes and <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>m</mi></mrow><annotation encoding="application/x-tex">m</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathnormal">m</span></span></span></span> parameters.<ul><li>With thousands of nodes and billions of parameters, this is infeasible in terms of memory and bandwidth.</li></ul></li><li>Many parameters have the same timestamp due to the parameter server’s range-based communication pattern.<ul><li>If a node pushes the parameters in a range, then the timestamps of the parameters associated with the node are likely the same.</li><li>Assume that <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>V</mi><mi>i</mi></msub><mo stretchy="false">(</mo><mi>k</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">V_i(k)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.22222em;">V</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.22222em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.03148em;">k</span><span class="mclose">)</span></span></span></span> is the time of key <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi></mrow><annotation encoding="application/x-tex">k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.03148em;">k</span></span></span></span> for node <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>i</mi></mrow><annotation encoding="application/x-tex">i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.65952em;vertical-align:0em;"></span><span class="mord mathnormal">i</span></span></span></span>. Given a key range <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>R</mi></mrow><annotation encoding="application/x-tex">R</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.00773em;">R</span></span></span></span>, the ranged vector clock <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>V</mi><mi>i</mi></msub><mo stretchy="false">(</mo><mi>R</mi><mo stretchy="false">)</mo><mo>=</mo><mi>t</mi></mrow><annotation encoding="application/x-tex">V_i(R)=t</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.22222em;">V</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.22222em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.61508em;vertical-align:0em;"></span><span class="mord mathnormal">t</span></span></span></span> means <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal">∀</mi><mi>k</mi><mo>∈</mo><mi>R</mi><mo separator="true">,</mo><msub><mi>V</mi><mi>i</mi></msub><mo stretchy="false">(</mo><mi>k</mi><mo stretchy="false">)</mo><mo>=</mo><mi>t</mi></mrow><annotation encoding="application/x-tex">\forall k\in R, V_i(k)=t</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.73354em;vertical-align:-0.0391em;"></span><span class="mord">∀</span><span class="mord mathnormal" style="margin-right:0.03148em;">k</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.22222em;">V</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.22222em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.03148em;">k</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.61508em;vertical-align:0em;"></span><span class="mord mathnormal">t</span></span></span></span>.</li></ul></li><li>Initially, there is only one range vector clock for each node <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>i</mi></mrow><annotation encoding="application/x-tex">i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.65952em;vertical-align:0em;"></span><span class="mord mathnormal">i</span></span></span></span>. It covers the entire parameter key space as its range with <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>0</mn></mrow><annotation encoding="application/x-tex">0</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">0</span></span></span></span> as its initial timestamp. Each range set may split the range and create at most <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>3</mn></mrow><annotation encoding="application/x-tex">3</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">3</span></span></span></span> new vector clocks.</li></ol><h2 id="how-to-optimize-the-cost-of-communication"><a class="markdownIt-Anchor" href="#how-to-optimize-the-cost-of-communication"></a> How to optimize the cost of communication?</h2><ol><li>A worker might send the same key lists again. Hence, it is desirable for the receiving node to cache the key lists. Later, the sender only needs to send a hash of the list rather than the list itself.</li><li>Values may contain many zero entries. Hence, we only need to send nonzero (key, value) pairs. We use the fast Snappy compression library to compress messages, effectively removing the zeros.</li><li>Naive replication potentially increases network traffic by <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi></mrow><annotation encoding="application/x-tex">k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.03148em;">k</span></span></span></span> times, where <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi></mrow><annotation encoding="application/x-tex">k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.03148em;">k</span></span></span></span> is the number of replications.<ul><li>The parameter server framework permits replication after aggregation for many algorithms.</li><li>With n workers, replication uses only k/n bandwidth. Often, k is a small constant, while n is hundreds to thousands.</li><li>While aggregation increases the delay of the task reply, it can be hidden by relaxed consistency conditions.</li></ul></li></ol><h2 id="what-is-the-difference-in-fault-tolerance-between-a-parameter-server-and-a-conventional-distributed-system"><a class="markdownIt-Anchor" href="#what-is-the-difference-in-fault-tolerance-between-a-parameter-server-and-a-conventional-distributed-system"></a> What is the difference in fault tolerance between a parameter server and a conventional distributed system?</h2><ol><li>Servers replicate parameters with consistent hashing.</li><li>When a worker fails, the recovery depends on the algorithm designer.<ul><li>If the training data is huge, recovering a worker node may be more expensive than recovering a server node.</li><li>Losing a small amount of training data during optimization typically only affects the model.</li></ul></li></ol><h1 id="evaluation"><a class="markdownIt-Anchor" href="#evaluation"></a> Evaluation</h1><ol><li>The author evaluated the system on Sparse Logistic Regression and Latent Dirichlet Allocation.</li><li>They compare systems by running them to reach the same objective value. A better system achieves a lower objective in less time. They also compared the worker node utilization in different systems.</li><li>The reduction of network traffic by each system component is measured.</li></ol>]]></content>
      
      
      <categories>
          
          <category> Paper Notebook </category>
          
          <category> Sys4AI </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Distributed System </tag>
            
            <tag> Sys4AI </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>SparDA</title>
      <link href="/2023/10/06/Paper/Sys4AI/SparDA/"/>
      <url>/2023/10/06/Paper/Sys4AI/SparDA/</url>
      
        <content type="html"><![CDATA[<p>Paper: <a href="https://arxiv.org/abs/2301.10936">SparDA: Accelerating Dynamic Sparse Deep Neural Networks via Sparse-Dense Transformation</a></p><p><ul class="markdownIt-TOC"><li><a href="#purpose">Purpose</a></li><li><a href="#model">Model</a><ul><li><a href="#what-is-the-pipeline-of-sparda">What is the pipeline of SparDA?</a></li><li><a href="#what-is-permutation-invariant">What is permutation invariant?</a></li><li><a href="#what-are-the-rules-of-applying-permutation-invariant">What are the rules of applying permutation invariant?</a></li><li><a href="#what-is-stile">What is STile?</a></li><li><a href="#how-to-transform-input-and-eliminate-overhead">How to transform input and eliminate overhead?</a></li><li><a href="#how-to-choose-an-efficient-stile">How to choose an efficient STile?</a></li><li><a href="#how-to-represent-dynamic-sparsity">How to represent dynamic sparsity?</a></li><li><a href="#what-are-the-apis-of-sparda-what-is-its-working-pipeline">What are the APIs of SparDA? What is its working pipeline?</a></li></ul></li><li><a href="#evaluation">Evaluation</a></li></ul></p><h1 id="purpose"><a class="markdownIt-Anchor" href="#purpose"></a> Purpose</h1><ol><li>Sparsity has become the most important and efficient approach to accelerate neural networks by erasing a large portion of computation without unraveling model accuracy.</li><li>Issues:<ul><li>Most commodity accelerators (e.g., GPUs and TPUs) are mainly designed for efficient dense computations.</li><li>Previous research proposes sparsity optimizations to fit sparse computation, which only work for fixed granularities and perform poorly when the granularity mismatches.<ul><li>Fine-grained computation kernels cannot well saturate hardware due to the random memory access caused by fine-grained data.</li></ul></li><li>Existing solutions have to use time-consuming compiling to improve the efficiency of sparse kernels in an ahead-of-time manner and thus are limited to static sparsity.</li><li>An efficient general index construction mechanism for all data granularities is still missing.<ul><li>The performance of the previous sparse index construction methodology is also poor due to the constraint of sparse computation kernels.</li></ul></li></ul></li><li>Challenges:<ul><li>The dynamic sparsity pattern in different scenarios, even with the same scenario, is quite diverse and complex.</li><li>The key to optimizing such dynamic sparsity is simultaneously performing the calculations with an efficient kernel without computation waste.<ul><li>Therefore, optimizing such complex dynamic sparsity patterns requires breaking the binding between the data and computation granularity.</li></ul></li></ul></li><li>Contribution:<ul><li>Identified an important property called <em>permutation invariant</em>.<ul><li>It enables SparDA to extract dynamic sparsity patterns of tensors only known at runtime with negligible overhead.</li><li>It can transform dynamic sparse computation into equivalent dense computation that has been highly optimized on commodity accelerators.</li></ul></li><li>By combining permutation invariant with computation tiling, SparDA exploits the effect of permutation invariant to allow permutation on finer-grained granularity instead of the whole row or column of a tensor.<ul><li>It implies that the sparsity could be finer-grained and irregular if the non-zero values can be compacted into multiple dense computation tiles.</li><li>Define the sparsity pattern of the non-zero values and the compacted computation tile as a sparse tile, i.e., STile.</li></ul></li></ul></li></ol><h1 id="model"><a class="markdownIt-Anchor" href="#model"></a> Model</h1><h2 id="what-is-the-pipeline-of-sparda"><a class="markdownIt-Anchor" href="#what-is-the-pipeline-of-sparda"></a> What is the pipeline of SparDA?</h2><ol><li>The design of STile naturally splits sparse computation into two decoupled stages: data permutation and dense computation.<ul><li>Decoupling frees the computation stage from handling the intricate encoding and decoding of sparse tensors. Thus, the computation can more efficiently utilize the accelerators.</li><li>With the decoupled stages, SparDA can leverage a wide range of well-optimized implementations of dense computation, including hardware instructions, manually optimized kernels, and automatically tuned kernels.</li><li>The data permutation stage transforms sparse data into a dense format with a new primitive <code>SLoad</code>. After the computation, the produced dense data is transformed back to the required format (e.g., sparse format) with the other primitive <code>SWrite</code>.</li></ul></li><li>The first stage is to learn the sparsity distribution from only a few samples.<ul><li>The STile optimizer analyzes the sparsity of each operator. It selects the most suitable STile from a set of pre-constructed STiles, each connected to a well-optimized dense computation tile.</li><li>SparDA generates a sparse kernel for the operator based on the selected STile.</li><li>This stage can be executed during the initialization and periodically to deal with possible shifting of sparsity distribution.</li></ul></li><li>The second stage is applying the generated sparse kernel at runtime.<ul><li>To deal with the dynamically changed sparsity, SparDA detects the sparsity online and builds the index of the sparse data following the requirement of the STile.</li></ul></li><li>There are two components in the sparse kernel.<ul><li>The first one rearranges the sparse data into dense format when loading data across different memory hierarchies.</li><li>The second one applies dense computation to condensed data without knowing their indices.</li></ul></li></ol><h2 id="what-is-permutation-invariant"><a class="markdownIt-Anchor" href="#what-is-permutation-invariant"></a> What is permutation invariant?</h2><ol><li>Tensor Expression (TE) describes deep learning computation in existing deep learning compilers.<ul><li>ReduceSum: <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>C</mi><mo stretchy="false">[</mo><mi>p</mi><mo stretchy="false">]</mo><mo>+</mo><mo>=</mo><mi>A</mi><mo stretchy="false">[</mo><mi>p</mi><mo separator="true">,</mo><mi>l</mi><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">C[p]+=A[p,l]</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.07153em;">C</span><span class="mopen">[</span><span class="mord mathnormal">p</span><span class="mclose">]</span><span class="mord">+</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">A</span><span class="mopen">[</span><span class="mord mathnormal">p</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal" style="margin-right:0.01968em;">l</span><span class="mclose">]</span></span></span></span></li><li>Addition: <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>C</mi><mo stretchy="false">[</mo><mi>p</mi><mo stretchy="false">]</mo><mo>=</mo><mi>A</mi><mo stretchy="false">[</mo><mi>p</mi><mo stretchy="false">]</mo><mo>+</mo><mi>B</mi><mo stretchy="false">[</mo><mi>p</mi><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">C[p]=A[p]+B[p]</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.07153em;">C</span><span class="mopen">[</span><span class="mord mathnormal">p</span><span class="mclose">]</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">A</span><span class="mopen">[</span><span class="mord mathnormal">p</span><span class="mclose">]</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.05017em;">B</span><span class="mopen">[</span><span class="mord mathnormal">p</span><span class="mclose">]</span></span></span></span></li><li>MatMul: <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>C</mi><mo stretchy="false">[</mo><mi>m</mi><mo separator="true">,</mo><mi>n</mi><mo stretchy="false">]</mo><mo>+</mo><mo>=</mo><mi>A</mi><mo stretchy="false">[</mo><mi>m</mi><mo separator="true">,</mo><mi>k</mi><mo stretchy="false">]</mo><mo>×</mo><mi>B</mi><mo stretchy="false">[</mo><mi>k</mi><mo separator="true">,</mo><mi>n</mi><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">C[m,n]+=A[m,k]\times B[k,n]</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.07153em;">C</span><span class="mopen">[</span><span class="mord mathnormal">m</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal">n</span><span class="mclose">]</span><span class="mord">+</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">A</span><span class="mopen">[</span><span class="mord mathnormal">m</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal" style="margin-right:0.03148em;">k</span><span class="mclose">]</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.05017em;">B</span><span class="mopen">[</span><span class="mord mathnormal" style="margin-right:0.03148em;">k</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal">n</span><span class="mclose">]</span></span></span></span></li><li>BatchMatMul: <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>C</mi><mo stretchy="false">[</mo><mi>b</mi><mo separator="true">,</mo><mi>m</mi><mo separator="true">,</mo><mi>n</mi><mo stretchy="false">]</mo><mo>+</mo><mo>=</mo><mi>A</mi><mo stretchy="false">[</mo><mi>b</mi><mo separator="true">,</mo><mi>m</mi><mo separator="true">,</mo><mi>k</mi><mo stretchy="false">]</mo><mo>×</mo><mi>B</mi><mo stretchy="false">[</mo><mi>b</mi><mo separator="true">,</mo><mi>k</mi><mo separator="true">,</mo><mi>n</mi><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">C[b,m,n]+=A[b,m,k]\times B[b,k,n]</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.07153em;">C</span><span class="mopen">[</span><span class="mord mathnormal">b</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal">m</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal">n</span><span class="mclose">]</span><span class="mord">+</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">A</span><span class="mopen">[</span><span class="mord mathnormal">b</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal">m</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal" style="margin-right:0.03148em;">k</span><span class="mclose">]</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.05017em;">B</span><span class="mopen">[</span><span class="mord mathnormal">b</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal" style="margin-right:0.03148em;">k</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal">n</span><span class="mclose">]</span></span></span></span></li><li>Convolution: <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>C</mi><mo stretchy="false">[</mo><mi>n</mi><mo separator="true">,</mo><mi>f</mi><mo separator="true">,</mo><mi>x</mi><mo separator="true">,</mo><mi>y</mi><mo stretchy="false">]</mo><mo>+</mo><mo>=</mo><mi>A</mi><mo stretchy="false">[</mo><mi>n</mi><mo separator="true">,</mo><mi>m</mi><mo separator="true">,</mo><mi>x</mi><mo>+</mo><mi>i</mi><mo separator="true">,</mo><mi>y</mi><mo>+</mo><mi>j</mi><mo stretchy="false">]</mo><mo>×</mo><mi>B</mi><mo stretchy="false">[</mo><mi>f</mi><mo separator="true">,</mo><mi>m</mi><mo separator="true">,</mo><mi>i</mi><mo separator="true">,</mo><mi>j</mi><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">C[n,f,x,y]+=A[n,m,x+i,y+j]\times B[f,m,i,j]</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.07153em;">C</span><span class="mopen">[</span><span class="mord mathnormal">n</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal">x</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="mclose">]</span><span class="mord">+</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">A</span><span class="mopen">[</span><span class="mord mathnormal">n</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal">m</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal">x</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.85396em;vertical-align:-0.19444em;"></span><span class="mord mathnormal">i</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.05724em;">j</span><span class="mclose">]</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.05017em;">B</span><span class="mopen">[</span><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal">m</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal">i</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal" style="margin-right:0.05724em;">j</span><span class="mclose">]</span></span></span></span></li></ul></li><li>Definition of permutation invariant dimension:<ul><li>In a tensor expression <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>Y</mi><mo>←</mo><mi>f</mi><mo stretchy="false">(</mo><msub><mi>X</mi><mn>1</mn></msub><mo separator="true">,</mo><mo>…</mo><mo separator="true">,</mo><msub><mi>X</mi><mi>n</mi></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">Y \leftarrow f (X_1,\dots , X_n)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.22222em;">Y</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">←</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.07847em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="minner">…</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:-0.07847em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">n</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span>, where <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>f</mi></mrow><annotation encoding="application/x-tex">f</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord mathnormal" style="margin-right:0.10764em;">f</span></span></span></span> is an operator, <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>X</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">X_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.07847em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> and <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>Y</mi></mrow><annotation encoding="application/x-tex">Y</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.22222em;">Y</span></span></span></span> are its input and output tensors, respectively.</li><li>A dimension <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi></mrow><annotation encoding="application/x-tex">k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.03148em;">k</span></span></span></span> in the operator is <strong>permutation invariant</strong> if it satisfies: <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal">∀</mi><mi>P</mi><mo>∈</mo><msub><mi mathvariant="normal">Φ</mi><mi>k</mi></msub><mo separator="true">,</mo><mi mathvariant="normal">∃</mi><msup><mi>P</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msup><mo>∈</mo><msub><mi mathvariant="normal">Φ</mi><mi>k</mi></msub><mtext>s.t. </mtext><msup><mi>P</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msup><mo stretchy="false">(</mo><mi>f</mi><mo stretchy="false">(</mo><mi>P</mi><mo stretchy="false">(</mo><msub><mi>X</mi><mn>1</mn></msub><mo stretchy="false">)</mo><mo separator="true">,</mo><mo>…</mo><mo separator="true">,</mo><mi>P</mi><mo stretchy="false">(</mo><msub><mi>X</mi><mi>n</mi></msub><mo stretchy="false">)</mo><mo stretchy="false">)</mo><mo>=</mo><mi>Y</mi></mrow><annotation encoding="application/x-tex">\forall P \in \Phi_k, ∃ P&#x27; ∈ \Phi_k \text{s.t. }P&#x27;(f(P(X_1),\dots , P(X_n))=Y</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.73354em;vertical-align:-0.0391em;"></span><span class="mord">∀</span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.946332em;vertical-align:-0.19444em;"></span><span class="mord"><span class="mord">Φ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord">∃</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.751892em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.001892em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord">Φ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord text"><span class="mord">s.t. </span></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.751892em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.07847em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="minner">…</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:-0.07847em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">n</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.22222em;">Y</span></span></span></span></li><li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="normal">Φ</mi><mi>k</mi></msub></mrow><annotation encoding="application/x-tex">\Phi_k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord">Φ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> is the set of all permutation functions on <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi></mrow><annotation encoding="application/x-tex">k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.03148em;">k</span></span></span></span> dimension. <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>P</mi><mo stretchy="false">(</mo><mi>X</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">P (X)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class="mclose">)</span></span></span></span> means a permutation function <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>P</mi></mrow><annotation encoding="application/x-tex">P</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span></span></span></span> is applied to the <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi></mrow><annotation encoding="application/x-tex">k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.03148em;">k</span></span></span></span> dimension of the tensor <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>X</mi></mrow><annotation encoding="application/x-tex">X</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.07847em;">X</span></span></span></span>, to shuffle the elements on <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi></mrow><annotation encoding="application/x-tex">k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.03148em;">k</span></span></span></span> dimension to a new order. If <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi></mrow><annotation encoding="application/x-tex">k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.03148em;">k</span></span></span></span> dimension does not exist in <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>X</mi></mrow><annotation encoding="application/x-tex">X</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.07847em;">X</span></span></span></span>, <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>P</mi><mo stretchy="false">(</mo><mi>X</mi><mo stretchy="false">)</mo><mo>=</mo><mi>X</mi></mrow><annotation encoding="application/x-tex">P (X) = X</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.07847em;">X</span></span></span></span>.</li></ul></li><li>For a permutation invariant dimension, when permutation is applied to this dimension of the input tensors, a reverse permutation exists on the output tensor to make the result the same as the original computation.</li></ol><h2 id="what-are-the-rules-of-applying-permutation-invariant"><a class="markdownIt-Anchor" href="#what-are-the-rules-of-applying-permutation-invariant"></a> What are the rules of applying permutation invariant?</h2><ol><li>Permutation invariant of tensor dimensions can be classified into three categories:<ul><li><strong>Sporadic dimension</strong> exists in one or more tensors of a tensor expression but does not span all tensors. For example, <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>m</mi></mrow><annotation encoding="application/x-tex">m</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathnormal">m</span></span></span></span>, <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi></mrow><annotation encoding="application/x-tex">n</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathnormal">n</span></span></span></span>, <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi></mrow><annotation encoding="application/x-tex">k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.03148em;">k</span></span></span></span>, <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>f</mi></mrow><annotation encoding="application/x-tex">f</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord mathnormal" style="margin-right:0.10764em;">f</span></span></span></span>, <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>l</mi></mrow><annotation encoding="application/x-tex">l</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.01968em;">l</span></span></span></span> of the tensor expressions.</li><li><strong>Prevalent dimension</strong> is the dimension that exists in all the tensors (i.e., input and output tensors) of a tensor expression. Examples of prevalent dimensions are <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi></mrow><annotation encoding="application/x-tex">p</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord mathnormal">p</span></span></span></span> and <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>b</mi></mrow><annotation encoding="application/x-tex">b</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathnormal">b</span></span></span></span>.</li><li><strong>Compound dimension</strong> is the dimension that is involved in an arithmetic expression. E.g. <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>x</mi></mrow><annotation encoding="application/x-tex">x</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathnormal">x</span></span></span></span>, <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>y</mi></mrow><annotation encoding="application/x-tex">y</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span></span></span></span> and <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>i</mi></mrow><annotation encoding="application/x-tex">i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.65952em;vertical-align:0em;"></span><span class="mord mathnormal">i</span></span></span></span>, <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>j</mi></mrow><annotation encoding="application/x-tex">j</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.85396em;vertical-align:-0.19444em;"></span><span class="mord mathnormal" style="margin-right:0.05724em;">j</span></span></span></span> in Convolution.</li></ul></li><li>When permutation invariant is applied to only one dimension of a tensor expression, the dimension can be sporadic or prevalent but not a compound dimension.<ul><li>Because permuting a compound dimension violates its corresponding arithmetic expression.</li></ul></li><li>When permutation invariant is applied on multiple dimensions of a tensor expression:<ul><li>When the permuted dimensions are sporadic, each dimension can only have a single permutation function.</li><li>When the permuted dimensions include a prevalent dimension, the permutation function on each element of the prevalent dimension could be different.</li></ul></li></ol><h2 id="what-is-stile"><a class="markdownIt-Anchor" href="#what-is-stile"></a> What is STile?</h2><ol><li>A tile is a sliced piece of an operator’s computation.<ul><li>Computation tiling slices the computation into many small homogeneous pieces to parallelize the computation and increase data reuse.</li></ul></li><li>Permutation invariance can be applied to each tile independently; that is, the permutation functions on each tile can be different, leading to more diverse and fine-grained sparsity granularity.</li><li>An STile is a group of non-redundant elements following a specific type of layout associated with a dense computation tile.<ul><li>The non-redundant element is called the data tile, representing the sparsity granularity. The scattered data tiles can be condensed into dense tiles.</li><li>In reverse, a dense tile can correspond to different STiles with different permutation functions.</li></ul></li></ol><img src="/imgs/Sys4ai/SparDA/tile.png" width="50%"><h2 id="how-to-transform-input-and-eliminate-overhead"><a class="markdownIt-Anchor" href="#how-to-transform-input-and-eliminate-overhead"></a> How to transform input and eliminate overhead?</h2><ol><li><strong>Sparse-Dense Transform</strong>: With permutation invariant, we can construct a permutation function <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>P</mi></mrow><annotation encoding="application/x-tex">P</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span></span></span></span> to move all the redundant elements to the end while all the non-redundant elements to the front. The redundant elements can be safely removed to build a shorter <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi></mrow><annotation encoding="application/x-tex">k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.03148em;">k</span></span></span></span> dimension.</li><li><code>SLoad</code> maps sparse data tiles in input tensors to dense data blocks, while <code>SWrite</code> writes the output dense data block to the specified output data format, which could be sparse or dense.<ul><li><code>SLoad</code> and <code>SWrite</code> work on data rearrangement when the data moves from global memory to shared memory and in reverse.</li><li>As long as the data tile could saturate the read/write transaction of the memory (e.g., <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>32</mn></mrow><annotation encoding="application/x-tex">32</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">3</span><span class="mord">2</span></span></span></span> bytes in CUDA GPUs), the data rearrangement would introduce little overhead because loading sparse data tiles does not waste memory bandwidth.</li><li>This property further enables zero-copy of sparse data in online dynamic sparsity scenarios because the effective data tiles can be directly selected from their original data format and written to the higher-level memory with the desired format.</li></ul></li></ol><h2 id="how-to-choose-an-efficient-stile"><a class="markdownIt-Anchor" href="#how-to-choose-an-efficient-stile"></a> How to choose an efficient STile?</h2><ol><li>The most efficient STile for a sparse operator is determined mainly by two factors, i.e., the efficiency of its associated dense computation tile and the operator’s dynamic sparsity.</li><li>Though different-sized computation tiles are all dense for the first factor, they have different computation efficiency.<ul><li>Usually, the smaller the computation tile is, the less efficient it is. Because it is harder to saturate all the available cores.</li><li>Some carefully designed coordination of threads could significantly improve the computation efficiency of small computation tiles, leading to many efficient small computation tiles.</li><li>These well-optimized computation tiles are stored in a tile database of SparDA and serve as the base of STiles.</li></ul></li><li>All the STiles can be applied to a given sparsity for the second factor but lead to varied computation efficiency.<ul><li>If the data tile of an STile is larger than the granularity of the given sparsity, a proportion of the computation is wasted.</li><li>If the data tile is much smaller than the sparsity granularity, the computation tile is inefficient.</li></ul></li><li>In online dynamic sparsity, the most suitable STile is chosen based on several representative samples.<ul><li>It traverses all the STiles in the tile database to compute their cost on the given dynamically sparse operator and picks the best.</li><li><code>CoverAlgo</code> outputs the number of STiles needed to cover all the non-zero values of a given sparsity sample. The cost is the sum of the n sparsity samples.</li></ul></li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">@param  OP       : a dynamically sparse operator,</span></span><br><span class="line"><span class="string">        D_sparse : a list of n sparsity samples of Op</span></span><br><span class="line"><span class="string">@return Best_tile: the best STile for Op</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">ChooseStile</span>(<span class="params">D_sparse, Op</span>):</span><br><span class="line">  Best_stile, Cost_opt = null, inf</span><br><span class="line">  <span class="keyword">for</span> S <span class="keyword">in</span> GetStileFromTileDB(Op):</span><br><span class="line">    Cost = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> D <span class="keyword">in</span> D_sparse:</span><br><span class="line">      num_stiles = CoverAlgo(D, S.data_tile)</span><br><span class="line">      Cost += Num_stiles * S.tile_cost</span><br><span class="line">    <span class="keyword">if</span> Cost &lt; Cost_opt:</span><br><span class="line">      Best_stile = S</span><br><span class="line">      Cost_opt = Cost</span><br><span class="line">  <span class="keyword">return</span> Best_stile</span><br></pre></td></tr></table></figure><h2 id="how-to-represent-dynamic-sparsity"><a class="markdownIt-Anchor" href="#how-to-represent-dynamic-sparsity"></a> How to represent dynamic sparsity?</h2><ol><li>The representation is a sparsity attribute that can be efficiently constructed and parsed while consuming less memory.<ul><li>The sparsity attribute combines a <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>0</mn><mo>−</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">0-1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.72777em;vertical-align:-0.08333em;"></span><span class="mord">0</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">1</span></span></span></span> attribute matrix along with a sparsity granularity. Each value in the attribute matrix represents a data block’s existence, which is the sparsity granularity’s size.<ul><li>One type it can represent is that the location of sparse values keeps changing while the granularity is the same. Another type allows the granularity to change.</li></ul></li><li>The sparsity granularity is in the form of <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">(</mo><msub><mi>S</mi><mrow><mi>d</mi><mi>i</mi><mi>m</mi><mn>1</mn></mrow></msub><mo separator="true">,</mo><mo>…</mo><mo separator="true">,</mo><msub><mi>S</mi><mrow><mi>d</mi><mi>i</mi><mi>m</mi><mi>N</mi></mrow></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">(S_{dim1},\dots , S_{dimN} )</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05764em;">S</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:-0.05764em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">d</span><span class="mord mathnormal mtight">i</span><span class="mord mathnormal mtight">m</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="minner">…</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05764em;">S</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:-0.05764em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">d</span><span class="mord mathnormal mtight">i</span><span class="mord mathnormal mtight">m</span><span class="mord mathnormal mtight" style="margin-right:0.10903em;">N</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span>, where <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>S</mi><mrow><mi>d</mi><mi>i</mi><mi>m</mi></mrow></msub></mrow><annotation encoding="application/x-tex">S_{dim}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05764em;">S</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:-0.05764em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">d</span><span class="mord mathnormal mtight">i</span><span class="mord mathnormal mtight">m</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> is the size of the granularity on dimension dim.</li></ul></li><li>During online model execution, SparDA detects the annotated sparsity and builds the index of the non-zero blocks in every sparse tensor.<ul><li>The non-zero blocks are in the granularity of the data tile of the chosen STile. The blocks are translated into a bunch of STiles online.</li><li>SparDA constructs the sparsity index in an out-of-order manner because the permutation invariant property relaxes the order of the indices in a sparse data format.</li></ul></li><li>Unlike traditional sparse data format, which has data in it, SparDA only constructs an index while leaving the data as is. The index directly references the data blocks in their original tensor.<ul><li>STile uses the index to load the data blocks across memory hierarchies and rearranges the data blocks on-the-fly into the dense format.</li></ul></li></ol><h2 id="what-are-the-apis-of-sparda-what-is-its-working-pipeline"><a class="markdownIt-Anchor" href="#what-are-the-apis-of-sparda-what-is-its-working-pipeline"></a> What are the APIs of SparDA? What is its working pipeline?</h2><ol><li>Its working pipeline is as follows:<ul><li>To make PyTorch sparsity-aware, we first integrated the representation of dynamic sparsity into PyTorch with a class called <code>DSparsity</code>.</li><li>Users can annotate the arbitrary dynamic sparsity pattern with a unified interface called <code>SetDSparsity</code>.</li><li>After annotation, SparDA builds the sparse indexes through the fast index constructor with negligible overhead.</li><li>After index construction, the STile optimization policy will choose an appropriate STile from the STile database according to the offline profiled performance table.</li><li>The just-in-time code generator emits and compiles the corresponding STile for sparse computation.</li></ul></li><li>SparDA has already constructed around <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1500</mn></mrow><annotation encoding="application/x-tex">1500</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">1</span><span class="mord">5</span><span class="mord">0</span><span class="mord">0</span></span></span></span> STiles from the dense computation kernels and profiles the performance of these STiles under different sparsity ratios.</li><li>Users can easily customize the online STile optimization policy through the interface <code>RegisterOptPolicy</code> for different scenarios.<ul><li>Users can also easily expand more STiles by adding corresponding dense computation kernels and their tensor expressions into the database.</li></ul></li></ol><h1 id="evaluation"><a class="markdownIt-Anchor" href="#evaluation"></a> Evaluation</h1><ol><li>The authors evaluate SparDA on four representative dynamic sparse scenarios: MoE models, dynamic sparsity caused by different sequence lengths, dynamic sparse algorithms, and sparse training.</li><li>They compared SparDA with the state-of-art dense and sparse baselines: PyTorch (v1.11.0) and PyTorch with state-of-art sparse kernels (PyTorch-S).<ul><li>We integrate the state-of-the-art sparse libraries to construct PyTorch-S, including cuSPARSE (v11.6), Sputnik, and Triton. We select the best performance of all the sparse libraries as the final results of PyTorch-S.</li></ul></li></ol>]]></content>
      
      
      <categories>
          
          <category> Paper Notebook </category>
          
          <category> Sys4AI </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Sys4AI </tag>
            
            <tag> Sparsity </tag>
            
            <tag> Accelerator </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Elf</title>
      <link href="/2023/10/04/Paper/Sys4AI/ELF/"/>
      <url>/2023/10/04/Paper/Sys4AI/ELF/</url>
      
        <content type="html"><![CDATA[<p>Paper: <a href="https://dl.acm.org/doi/abs/10.1145/3447993.3448628">Elf: Accelerate High-resolution Mobile Deep Vision with Content-aware Parallel Offloading</a></p><p><ul class="markdownIt-TOC"><li><a href="#purpose">Purpose</a></li><li><a href="#model">Model</a><ul><li><a href="#what-is-the-pipeline-of-elf">What is the pipeline of Elf?</a></li><li><a href="#region-proposals">Region proposals</a><ul><li><a href="#how-to-predict-region-proposals">How to predict region proposals?</a></li><li><a href="#how-do-we-index-region-proposals">How do we index region proposals?</a></li></ul></li><li><a href="#offloading">Offloading</a><ul><li><a href="#how-to-optimize-elfs-schedule-problem">How to optimize Elf’s schedule problem?</a></li><li><a href="#why-send-rp-coordinates-and-the-original-image-instead-of-a-cropped-rp-task">Why send RP coordinates and the original image instead of a cropped RP task?</a></li><li><a href="#how-to-generate-rp-boxes">How to generate RP boxes?</a></li><li><a href="#how-do-we-estimate-server-capacity-and-rp-computation-cost">How do we estimate server capacity and RP computation cost?</a></li></ul></li></ul></li><li><a href="#evaluation">Evaluation</a></li></ul></p><h1 id="purpose"><a class="markdownIt-Anchor" href="#purpose"></a> Purpose</h1><ol><li>To support applications running deep neural networks on multimedia data in real-time, having mobile devices offload the computation, especially the neural network inference, to edge clouds has proved effective.</li><li>Issues:<ul><li>In reality, we may not be able to find a dedicated and powerful server but must make do with less powerful ones.</li><li>Various techniques to make DNN models smaller to reduce the computation load lead to compromised model accuracy due to the fundamental trade-off between model size and model accuracy.</li><li>The inference latency can be significantly reduced by offloading the intensive model inference to a powerful edge server and with the high bandwidth and low latency provided by the emerging 5G networks.<ul><li>Most existing solutions use low-resolution images throughout the entire pipeline.</li><li>Most existing methods only consider offloading tasks between a single pair of servers and clients, assuming that no competing clients or extra edge resources are available.</li><li>The heterogeneous resource demands of applications running on edge servers and highly dynamic workloads by mobile users lead to resource fragmentation.</li></ul></li></ul></li><li>Challenges:<ul><li>The client must effectively partition the inference job into multiple pieces while maintaining the inference accuracy.</li><li>The system needs to be aware of available computation resources on each server and dynamically develop the frame partitioning solution to ensure no server in the parallel offloading procedure becomes the bottleneck.</li><li>Such a system should have a general framework design independent of its host deep vision applications.</li></ul></li><li>Contribution:<ul><li>The idea is to partition the video frame and offload the partial inference tasks to multiple servers for parallel processing.</li><li>Elf is a framework to accelerate high-resolution mobile deep vision offloading in heterogeneous client and edge server environments, by adaptively distributing the computation to available edge servers.</li><li>It employs a recurrent region proposal prediction algorithm, a region proposal centric frame partitioning, and a resource-aware multi-offloading scheme.</li></ul></li></ol><h1 id="model"><a class="markdownIt-Anchor" href="#model"></a> Model</h1><h2 id="what-is-the-pipeline-of-elf"><a class="markdownIt-Anchor" href="#what-is-the-pipeline-of-elf"></a> What is the pipeline of Elf?</h2><ol><li>The first phase is recurrent region proposal prediction.<ul><li>On the mobile end, whenever a new video frame arrives, Elf predicts its region proposals (RPs) based on the ones detected in historical frames.</li><li>The algorithm must be lightweight, effectively learn the motion model of the objects/RPs from history frames, and pay more attention to recent frames.</li><li>Efficiently utilizing the historical RP inference results converts the computing-intensive image regression problem to a lightweight time series prediction problem.</li><li>An RP indexing algorithm keeps track of the motion across frames. A Low-Resolution Compensation scheme is proposed to handle new objects when they first appear.</li></ul></li><li>The second phase is frame partitioning and offloading.<ul><li>Ideally, a well-designed frame partitioning scheme should show a negligible overhead and have heterogeneous edge servers to finish parallel inference tasks at the same time.</li><li>The partitioning algorithm should be inclusive and aware of the number of and locations of RPs in a frame. Also, Elf discards background pixels that are unlikely to contain any RPs.</li><li>Partitions have different computation costs depending on the objects in each partition. The algorithm should consider this cost heterogeneity to achieve load balancing among the servers.</li><li>Unlike central clouds, edge cloud servers exhibit heterogeneous computing/storage/networking resources due to their distributed nature and high user mobility. Poor offloading may result in job stragglers completing tasks much slower than their peers, thus significantly increasing the overall latency.</li></ul></li><li>The last phase is partial inference and result integration.<ul><li>Taking the offloaded partitions as input, the edge servers run the application-specific CNN models to yield partial inference results.</li><li>These partial results are finally integrated on the mobile side to render the final result.</li></ul></li></ol><h2 id="region-proposals"><a class="markdownIt-Anchor" href="#region-proposals"></a> Region proposals</h2><h3 id="how-to-predict-region-proposals"><a class="markdownIt-Anchor" href="#how-to-predict-region-proposals"></a> How to predict region proposals?</h3><ol><li>An attention-based LSTM network is used to predict region proposals.<ul><li>It takes only the RPs of the past <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>N</mi></mrow><annotation encoding="application/x-tex">N</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">N</span></span></span></span> frames without the image of the current frame as its input and outputs the RPs of the current frame.</li><li>It can only handle the objects that already occurred in the previous frame.</li></ul></li><li>To handle new objects and reduce the computation overhead, Elf runs LRC once per n frames.<ul><li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi></mrow><annotation encoding="application/x-tex">n</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathnormal">n</span></span></span></span> is a hyperparameter, indicating the trade-off between computation cost and at most <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi></mrow><annotation encoding="application/x-tex">n</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathnormal">n</span></span></span></span>-frame delay to realize new objects.</li><li>First, LRC down-samples a high-resolution video frame using a max-pooling operation.</li><li>Then Elf offloads the resized video frame and the partitions from regular-sized partitions to edge servers to run application-specific models, which usually consist of an object detection component.</li><li>Based on the inference results, Elf can roughly locate the new objects in the frame.</li></ul></li><li>The predicted RP bounding box may not cover all the pixels of an object due to motion.<ul><li>The bounding box is expanded by <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi><mi mathvariant="normal">%</mi></mrow><annotation encoding="application/x-tex">p\%</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.94444em;vertical-align:-0.19444em;"></span><span class="mord mathnormal">p</span><span class="mord">%</span></span></span></span>. The downside of this scheme is the increased data transmission and computation.</li><li>It consults the corresponding RP position shift and the prediction confidence level as the indicators to assign different weights on <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi></mrow><annotation encoding="application/x-tex">p</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord mathnormal">p</span></span></span></span>.</li></ul></li></ol><h3 id="how-do-we-index-region-proposals"><a class="markdownIt-Anchor" href="#how-do-we-index-region-proposals"></a> How do we index region proposals?</h3><ol><li>Vision-based matching algorithms are not considered because they introduce significant overheads in hundreds of milliseconds.</li><li>From the first video frame, Elf assigns a unique index to each region proposal.<ul><li>Elf matches each RP with the corresponding index assigned earlier in each upcoming frame.</li><li>If an RP includes a new object not seen before, a new index will be automatically assigned.</li></ul></li><li>Match the RPs across frames with a combination of RP position shift and RP area shift.<ul><li>The RP position shift measures the change of the center point along the x-/y-axis between the current frame and the previous frame. A larger value indicates a bigger spatial shift and, thus, a lower matching probability.</li><li>The RP area shift measures the area change between the RPs in two adjacent frames. A lower value indicates a higher matching probability.</li><li>When the x and y RP position shift are both under <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>0.02</mn></mrow><annotation encoding="application/x-tex">0.02</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">0</span><span class="mord">.</span><span class="mord">0</span><span class="mord">2</span></span></span></span> and the area shift ratio is under <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>0.2</mn></mrow><annotation encoding="application/x-tex">0.2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">0</span><span class="mord">.</span><span class="mord">2</span></span></span></span>, we declare a match.</li></ul></li></ol><h2 id="offloading"><a class="markdownIt-Anchor" href="#offloading"></a> Offloading</h2><h3 id="how-to-optimize-elfs-schedule-problem"><a class="markdownIt-Anchor" href="#how-to-optimize-elfs-schedule-problem"></a> How to optimize Elf’s schedule problem?</h3><ol><li>Assuming <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>M</mi></mrow><annotation encoding="application/x-tex">M</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">M</span></span></span></span> is the total number of RPs, while <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>N</mi></mrow><annotation encoding="application/x-tex">N</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">N</span></span></span></span> is the total number of servers; Elf packs the <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>M</mi></mrow><annotation encoding="application/x-tex">M</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">M</span></span></span></span> RP processing tasks and one LRC task into <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>N</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msup></mrow><annotation encoding="application/x-tex">N&#x27;</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.751892em;vertical-align:0em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.10903em;">N</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.751892em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span></span></span></span></span></span></span></span> offloading tasks (<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>N</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msup><mo>≤</mo><mi>N</mi></mrow><annotation encoding="application/x-tex">N&#x27;≤N</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.887862em;vertical-align:-0.13597em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.10903em;">N</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.751892em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">≤</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">N</span></span></span></span> ), and offloads each task onto an edge server.</li><li>The overall objective of the partitioning and the offloading process is to minimize the completion time of the offloading tasks that are distributed across <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>N</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msup></mrow><annotation encoding="application/x-tex">N&#x27;</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.751892em;vertical-align:0em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.10903em;">N</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.751892em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span></span></span></span></span></span></span></span> edge servers, i.e., minimizing the task completion time, which has the longest execution time among all the tasks.</li><li>The optimization objective can be written as<ul><li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>min</mi><mo>⁡</mo><mi>max</mi><mo>⁡</mo><mo stretchy="false">(</mo><mo stretchy="false">{</mo><msubsup><mi>T</mi><mi>k</mi><mi>t</mi></msubsup><mo stretchy="false">}</mo><mo stretchy="false">)</mo><mo separator="true">,</mo><mi>k</mi><mo>∈</mo><mo stretchy="false">[</mo><mn>1</mn><mo separator="true">,</mo><mo>…</mo><mo separator="true">,</mo><msup><mi>N</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msup><mo stretchy="false">]</mo><mtext>,</mtext><mspace linebreak="newline"></mspace><mtext>s.t.  </mtext><msubsup><mi>T</mi><mi>k</mi><mi>t</mi></msubsup><mo>=</mo><msubsup><mi>T</mi><mrow><mi>r</mi><mi>e</mi><mi>s</mi><mo separator="true">,</mo><mi>k</mi></mrow><mi>t</mi></msubsup><mo>+</mo><msubsup><mi>T</mi><mrow><mi>l</mi><mi>r</mi><mi>c</mi><mo separator="true">,</mo><mi>k</mi></mrow><mi>t</mi></msubsup><mo>⋅</mo><mn>1</mn><mo stretchy="false">(</mo><mi>t</mi><mspace></mspace><mspace width="0.6666666666666666em"/><mrow><mi mathvariant="normal">m</mi><mi mathvariant="normal">o</mi><mi mathvariant="normal">d</mi></mrow><mtext> </mtext><mtext> </mtext><mi>n</mi><mo>=</mo><mn>0</mn><mo stretchy="false">)</mo><mo>⋅</mo><mn>1</mn><mo stretchy="false">(</mo><mi>arg</mi><mo>⁡</mo><mi>max</mi><mo>⁡</mo><mo stretchy="false">{</mo><msup><mi>p</mi><mi>t</mi></msup><mo stretchy="false">}</mo><mo>=</mo><mi>k</mi><mo stretchy="false">)</mo><mtext>, </mtext><msubsup><mi>T</mi><mrow><mi>r</mi><mi>p</mi><mi>s</mi><mo separator="true">,</mo><mi>k</mi></mrow><mi>t</mi></msubsup><mo>≈</mo><mfrac><msubsup><mi>C</mi><mrow><mi>r</mi><mi>p</mi><mi>s</mi><mo separator="true">,</mo><mi>k</mi></mrow><mi>t</mi></msubsup><msubsup><mi>p</mi><mi>k</mi><mi>t</mi></msubsup></mfrac><mtext>, </mtext><msubsup><mi>T</mi><mrow><mi>l</mi><mi>r</mi><mi>c</mi><mo separator="true">,</mo><mi>k</mi></mrow><mi>t</mi></msubsup><mo>≈</mo><mfrac><msubsup><mi>C</mi><mrow><mi>l</mi><mi>r</mi><mi>c</mi><mo separator="true">,</mo><mi>k</mi></mrow><mi>t</mi></msubsup><msubsup><mi>p</mi><mi>k</mi><mi>t</mi></msubsup></mfrac></mrow><annotation encoding="application/x-tex">\min\max(\{T^t_k\}), k\in[1,\dots,N&#x27;]\text{,}\\ \text{s.t. }\ T^t_k=T^t_{res,k}+T^t_{lrc,k}\cdot1(t\mod n=0)\cdot1(\arg\max\{p^t\}=k)\text{, }T^t_{rps,k}\approx\frac{C^t_{rps,k}}{p^t_k}\text{, }T^t_{lrc,k}\approx\frac{C^t_{lrc,k}}{p^t_k}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.0766639999999998em;vertical-align:-0.2831079999999999em;"></span><span class="mop">min</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mop">max</span><span class="mopen">(</span><span class="mopen">{</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.7935559999999999em;"><span style="top:-2.4168920000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2831079999999999em;"><span></span></span></span></span></span></span><span class="mclose">}</span><span class="mclose">)</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal" style="margin-right:0.03148em;">k</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.001892em;vertical-align:-0.25em;"></span><span class="mopen">[</span><span class="mord">1</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="minner">…</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.10903em;">N</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.751892em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span></span></span></span></span><span class="mclose">]</span><span class="mord text"><span class="mord">,</span></span></span><span class="mspace newline"></span><span class="base"><span class="strut" style="height:1.0766639999999998em;vertical-align:-0.2831079999999999em;"></span><span class="mord text"><span class="mord">s.t. </span></span><span class="mspace"> </span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.7935559999999999em;"><span style="top:-2.4168920000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2831079999999999em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.2127719999999997em;vertical-align:-0.4192159999999999em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.7935559999999999em;"><span style="top:-2.4168920000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span><span class="mord mathnormal mtight">e</span><span class="mord mathnormal mtight">s</span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.4192159999999999em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1.2127719999999997em;vertical-align:-0.4192159999999999em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.7935559999999999em;"><span style="top:-2.4168920000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.01968em;">l</span><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span><span class="mord mathnormal mtight">c</span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.4192159999999999em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord">1</span><span class="mopen">(</span><span class="mord mathnormal">t</span><span class="mspace allowbreak"></span><span class="mspace" style="margin-right:0.6666666666666666em;"></span></span><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord"><span class="mord"><span class="mord mathrm">m</span><span class="mord mathrm">o</span><span class="mord mathrm">d</span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal">n</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord">0</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1.043556em;vertical-align:-0.25em;"></span><span class="mord">1</span><span class="mopen">(</span><span class="mop">ar<span style="margin-right:0.01389em;">g</span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mop">max</span><span class="mopen">{</span><span class="mord"><span class="mord mathnormal">p</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.7935559999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span></span></span></span></span><span class="mclose">}</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.2127719999999997em;vertical-align:-0.4192159999999999em;"></span><span class="mord mathnormal" style="margin-right:0.03148em;">k</span><span class="mclose">)</span><span class="mord text"><span class="mord">, </span></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.7935559999999999em;"><span style="top:-2.4168920000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span><span class="mord mathnormal mtight">p</span><span class="mord mathnormal mtight">s</span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.4192159999999999em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">≈</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.81862em;vertical-align:-0.60196em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.2166599999999999em;"><span style="top:-2.6411em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight">p</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.7841428571428573em;"><span style="top:-2.1527714285714286em;margin-left:0em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span><span style="top:-2.8448em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.3472285714285714em;"><span></span></span></span></span></span></span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.60742em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.07153em;">C</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8703428571428571em;"><span style="top:-2.214em;margin-left:-0.07153em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span><span class="mord mathnormal mtight">p</span><span class="mord mathnormal mtight">s</span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span><span style="top:-2.931em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.42488571428571426em;"><span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.60196em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mord text"><span class="mord">, </span></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.7935559999999999em;"><span style="top:-2.4168920000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.01968em;">l</span><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span><span class="mord mathnormal mtight">c</span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.4192159999999999em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">≈</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.81862em;vertical-align:-0.60196em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.2166599999999999em;"><span style="top:-2.6411em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight">p</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.7841428571428573em;"><span style="top:-2.1527714285714286em;margin-left:0em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span><span style="top:-2.8448em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.3472285714285714em;"><span></span></span></span></span></span></span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.60742em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.07153em;">C</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8703428571428571em;"><span style="top:-2.214em;margin-left:-0.07153em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.01968em;">l</span><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span><span class="mord mathnormal mtight">c</span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span><span style="top:-2.931em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.42488571428571426em;"><span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.60196em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></li><li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msubsup><mi>T</mi><mi>k</mi><mi>t</mi></msubsup></mrow><annotation encoding="application/x-tex">T^t_k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.0766639999999998em;vertical-align:-0.2831079999999999em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.7935559999999999em;"><span style="top:-2.4168920000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2831079999999999em;"><span></span></span></span></span></span></span></span></span></span> is the completion time on the <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi></mrow><annotation encoding="application/x-tex">k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.03148em;">k</span></span></span></span>-th server at the time-<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>t</mi></mrow><annotation encoding="application/x-tex">t</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.61508em;vertical-align:0em;"></span><span class="mord mathnormal">t</span></span></span></span>, which consists of two completion-time terms, <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msubsup><mi>T</mi><mrow><mi>r</mi><mi>p</mi><mi>s</mi><mo separator="true">,</mo><mi>k</mi></mrow><mi>t</mi></msubsup></mrow><annotation encoding="application/x-tex">T^t_{rps,k}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.2127719999999997em;vertical-align:-0.4192159999999999em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.7935559999999999em;"><span style="top:-2.4168920000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span><span class="mord mathnormal mtight">p</span><span class="mord mathnormal mtight">s</span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.4192159999999999em;"><span></span></span></span></span></span></span></span></span></span> and <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msubsup><mi>T</mi><mrow><mi>l</mi><mi>r</mi><mi>c</mi><mo separator="true">,</mo><mi>k</mi></mrow><mi>t</mi></msubsup></mrow><annotation encoding="application/x-tex">T^t_{lrc,k}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.2127719999999997em;vertical-align:-0.4192159999999999em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.7935559999999999em;"><span style="top:-2.4168920000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.01968em;">l</span><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span><span class="mord mathnormal mtight">c</span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.4192159999999999em;"><span></span></span></span></span></span></span></span></span></span> for RPs and LRC, respectively.</li><li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msubsup><mi>C</mi><mrow><mi>r</mi><mi>p</mi><mi>s</mi><mo separator="true">,</mo><mi>k</mi></mrow><mi>t</mi></msubsup></mrow><annotation encoding="application/x-tex">C^t_{rps,k}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.2127719999999997em;vertical-align:-0.4192159999999999em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07153em;">C</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.7935559999999999em;"><span style="top:-2.4168920000000003em;margin-left:-0.07153em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span><span class="mord mathnormal mtight">p</span><span class="mord mathnormal mtight">s</span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.4192159999999999em;"><span></span></span></span></span></span></span></span></span></span> and <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msubsup><mi>C</mi><mrow><mi>l</mi><mi>r</mi><mi>c</mi><mo separator="true">,</mo><mi>k</mi></mrow><mi>t</mi></msubsup></mrow><annotation encoding="application/x-tex">C^t_{lrc,k}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.2127719999999997em;vertical-align:-0.4192159999999999em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07153em;">C</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.7935559999999999em;"><span style="top:-2.4168920000000003em;margin-left:-0.07153em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.01968em;">l</span><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span><span class="mord mathnormal mtight">c</span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.4192159999999999em;"><span></span></span></span></span></span></span></span></span></span> are the computing costs of the RP box and LRC offloading to the server <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi></mrow><annotation encoding="application/x-tex">k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.03148em;">k</span></span></span></span> while <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msubsup><mi>p</mi><mi>k</mi><mi>t</mi></msubsup></mrow><annotation encoding="application/x-tex">p^t_k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.0766639999999998em;vertical-align:-0.2831079999999999em;"></span><span class="mord"><span class="mord mathnormal">p</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.7935559999999999em;"><span style="top:-2.4168920000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2831079999999999em;"><span></span></span></span></span></span></span></span></span></span> is the available resource capacity of the <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi></mrow><annotation encoding="application/x-tex">k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.03148em;">k</span></span></span></span>-th server.</li></ul></li></ol><h3 id="why-send-rp-coordinates-and-the-original-image-instead-of-a-cropped-rp-task"><a class="markdownIt-Anchor" href="#why-send-rp-coordinates-and-the-original-image-instead-of-a-cropped-rp-task"></a> Why send RP coordinates and the original image instead of a cropped RP task?</h3><ol><li>The execution time of <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>r</mi></mrow><annotation encoding="application/x-tex">r</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span></span></span></span> (<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>r</mi></mrow><annotation encoding="application/x-tex">r</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span></span></span></span> is a small number, such as <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>2</mn></mrow><annotation encoding="application/x-tex">2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">2</span></span></span></span> and <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>3</mn></mrow><annotation encoding="application/x-tex">3</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">3</span></span></span></span>) small RP (e.g., <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>&lt;</mo><mn>5</mn><mi mathvariant="normal">%</mi></mrow><annotation encoding="application/x-tex">&lt;5\%</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5782em;vertical-align:-0.0391em;"></span><span class="mrel">&lt;</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.80556em;vertical-align:-0.05556em;"></span><span class="mord">5</span><span class="mord">%</span></span></span></span> size of the original image) tasks are not much less than <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>r</mi></mrow><annotation encoding="application/x-tex">r</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span></span></span></span> times of the execution time of running a single <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>r</mi></mrow><annotation encoding="application/x-tex">r</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span></span></span></span>-fold RP task.</li><li>It is hard to determine a good cropping strategy.<ul><li>The precise cut-out of individual RPs will lead to poor detection inference accuracy due to the lack of necessary background pixels.</li><li>If we leave large padding around the RPs, the total offloaded data will be too large to be efficient.</li></ul></li><li>Too many cropping operations generate high memory copy overheads, which may become problematic for mobile devices.</li></ol><h3 id="how-to-generate-rp-boxes"><a class="markdownIt-Anchor" href="#how-to-generate-rp-boxes"></a> How to generate RP boxes?</h3><ol><li>Compared to a single RP, an RP-box is larger and consists of one or more nearby RPs.<ul><li>Each offloading task consists of either an LRC task, or an RP-box processing task, or both.</li><li>By scheduling an RP box instead of individual RPs, we can avoid fragmentation problems.</li></ul></li><li>The number of available edge servers determines the number of offloading tasks.</li><li><strong>RP box initialization</strong>: Before partitioning a frame, Elf first crops the area with all the RPs and horizontally partitions it into <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>N</mi></mrow><annotation encoding="application/x-tex">N</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">N</span></span></span></span> segments (<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>N</mi></mrow><annotation encoding="application/x-tex">N</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">N</span></span></span></span> is the number of available servers), where each segment corresponds to an initial RP box.<ul><li>The size of each RP box is initialized to be proportional to the available resource of the corresponding server.</li><li>At the LRC round, we partition the cropped image into <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>N</mi><mtext>−</mtext><mn>1</mn></mrow><annotation encoding="application/x-tex">N − 1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.76666em;vertical-align:-0.08333em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">N</span><span class="mord">−</span><span class="mord">1</span></span></span></span> segments and have <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>N</mi><mtext>−</mtext><mn>1</mn></mrow><annotation encoding="application/x-tex">N − 1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.76666em;vertical-align:-0.08333em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">N</span><span class="mord">−</span><span class="mord">1</span></span></span></span> RP boxes accordingly. We reserve one server for the LRC task.</li></ul></li><li><strong>RP association</strong>: Elf evaluates its spatial relationship with all the RP boxes for each RP. Given a pair of RP <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>r</mi></mrow><annotation encoding="application/x-tex">r</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span></span></span></span> and box <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>b</mi></mrow><annotation encoding="application/x-tex">b</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathnormal">b</span></span></span></span>,<ul><li>If <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>r</mi></mrow><annotation encoding="application/x-tex">r</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span></span></span></span> is completely included in <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>b</mi></mrow><annotation encoding="application/x-tex">b</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathnormal">b</span></span></span></span> and we conveniently associate them.</li><li>If <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>r</mi></mrow><annotation encoding="application/x-tex">r</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span></span></span></span> and <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>b</mi></mrow><annotation encoding="application/x-tex">b</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathnormal">b</span></span></span></span> are not overlap, <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>r</mi></mrow><annotation encoding="application/x-tex">r</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span></span></span></span> is not associated with <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>b</mi></mrow><annotation encoding="application/x-tex">b</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathnormal">b</span></span></span></span>.</li><li>If <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>r</mi></mrow><annotation encoding="application/x-tex">r</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span></span></span></span> and <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>b</mi></mrow><annotation encoding="application/x-tex">b</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathnormal">b</span></span></span></span> are partially overlapped, it also overlaps with at least one other box. We choose to associate with the RP box that has the most overlap with the RP.<ul><li>If there is a tie, we choose the RP box with a larger gap between the server resource capacity and the computation costs of the RPs that are already associated.</li></ul></li></ul></li><li><strong>RP box adjustment</strong>: Elf resizes each RP box so that it can fully cover all the RPs that are associated with it.<ul><li>The computation cost of some RP boxes may drastically increase compared to the initialization stage and thus break the intended load balancing.</li><li>We examine those RP boxes whose cost increase exceeds a pre-defined threshold. For these boxes, we re-associate the RP with the lowest cost to the neighboring box, which has enough computation capacity to hold this RP.</li><li>After each re-association, the two boxes must adjust their sizes accordingly and estimate the new computation cost. We stop this process if the re-association results in a higher load imbalance.</li></ul></li><li>The <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msubsup><mi>C</mi><mrow><mi>r</mi><mi>p</mi><mi>s</mi><mo separator="true">,</mo><mi>k</mi></mrow><mi>t</mi></msubsup><mo>=</mo><msub><mo>∑</mo><mi>v</mi></msub><mo stretchy="false">{</mo><msubsup><mi>C</mi><mrow><mi>r</mi><mi>p</mi><mo separator="true">,</mo><mi>v</mi></mrow><mi>t</mi></msubsup><mo stretchy="false">}</mo></mrow><annotation encoding="application/x-tex">C^t_{rps,k}=\sum_v\{C^t_{rp,v}\}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.2127719999999997em;vertical-align:-0.4192159999999999em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07153em;">C</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.7935559999999999em;"><span style="top:-2.4168920000000003em;margin-left:-0.07153em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span><span class="mord mathnormal mtight">p</span><span class="mord mathnormal mtight">s</span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.4192159999999999em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.176664em;vertical-align:-0.383108em;"></span><span class="mop"><span class="mop op-symbol small-op" style="position:relative;top:-0.0000050000000000050004em;">∑</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.0016819999999999613em;"><span style="top:-2.40029em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03588em;">v</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.29971000000000003em;"><span></span></span></span></span></span></span><span class="mopen">{</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07153em;">C</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.7935559999999999em;"><span style="top:-2.4530000000000003em;margin-left:-0.07153em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span><span class="mord mathnormal mtight">p</span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight" style="margin-right:0.03588em;">v</span></span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.383108em;"><span></span></span></span></span></span></span><span class="mclose">}</span></span></span></span> and <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msubsup><mi>C</mi><mrow><mi>l</mi><mi>r</mi><mi>c</mi></mrow><mi>t</mi></msubsup><mo>=</mo><mi>α</mi><mo>⋅</mo><mo stretchy="false">(</mo><msubsup><mo>∑</mo><mrow><mi>k</mi><mo>=</mo><mn>1</mn></mrow><mi>M</mi></msubsup><msubsup><mi>C</mi><mrow><mi>r</mi><mi>p</mi><mi>s</mi><mo separator="true">,</mo><mi>k</mi></mrow><mi>t</mi></msubsup><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">C^t_{lrc}=\alpha\cdot(\sum^M_{k=1}C^t_{rps,k})</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.0766639999999998em;vertical-align:-0.2831079999999999em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07153em;">C</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.7935559999999999em;"><span style="top:-2.4168920000000003em;margin-left:-0.07153em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.01968em;">l</span><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span><span class="mord mathnormal mtight">c</span></span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2831079999999999em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.44445em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.0037em;">α</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1.4004469999999998em;vertical-align:-0.4192159999999999em;"></span><span class="mopen">(</span><span class="mop"><span class="mop op-symbol small-op" style="position:relative;top:-0.0000050000000000050004em;">∑</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.981231em;"><span style="top:-2.40029em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.2029em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em;">M</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.29971000000000003em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07153em;">C</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.7935559999999999em;"><span style="top:-2.4168920000000003em;margin-left:-0.07153em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span><span class="mord mathnormal mtight">p</span><span class="mord mathnormal mtight">s</span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.4192159999999999em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span>.<br /><img src="/imgs/Sys4ai/Elf/partition.png" width="50%"></li></ol><h3 id="how-do-we-estimate-server-capacity-and-rp-computation-cost"><a class="markdownIt-Anchor" href="#how-do-we-estimate-server-capacity-and-rp-computation-cost"></a> How do we estimate server capacity and RP computation cost?</h3><ol><li>There are two approaches to estimating server capacity.<ul><li>The first approach is through passive profiling.<ul><li>It calculates the server m’s average end-to-end latency <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>T</mi><mi>m</mi></msub></mrow><annotation encoding="application/x-tex">T_m</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">m</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> over the last <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi></mrow><annotation encoding="application/x-tex">n</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathnormal">n</span></span></span></span> (default value of <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>7</mn></mrow><annotation encoding="application/x-tex">7</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">7</span></span></span></span>) offloading requests that are served by <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>m</mi></mrow><annotation encoding="application/x-tex">m</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathnormal">m</span></span></span></span>. Then, the resource capacity is defined as <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1</mn><mi mathvariant="normal">/</mi><msub><mi>T</mi><mi>m</mi></msub></mrow><annotation encoding="application/x-tex">1/T_m</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord">1</span><span class="mord">/</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">m</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>.</li><li>This passive profiling can help evaluate the trade-off between computing and network resources.</li></ul></li><li>The second approach is through proactive profiling: Elf periodically queries the server for its GPU utilization.</li></ul></li><li>There are also two ways of estimating an RP’s computation cost.<ul><li>The first approach is based on the RP’s area, assuming the cost is linearly proportional to the RP’s area.</li><li>The second approach is through Spatially Adaptive Computation Time (SACT). Elf can accordingly estimate the cost of an RP at the pixel level.<ul><li>SACT is an optimization that early stops partial convolutional operations by evaluating the confidence of the outputs of intermediate layers.</li><li>SACT indicates how much computation has been applied with each pixel of a raw frame input.</li></ul></li></ul></li></ol><h1 id="evaluation"><a class="markdownIt-Anchor" href="#evaluation"></a> Evaluation</h1><ol><li>The author measured the latency of Elf using different numbers of servers.<ul><li>The latency with different server numbers highly depends on the size of the RP boxes shipped to each edge server.</li><li>The inference time shows distinct sensitivity among different deep vision models.<ul><li>The models with more, even fully, convolutional operations present a stronger correlation between frame resolution and inference latency.</li><li>Two-stage models usually generate the same number of Regions of Interest (ROI) independent of the input resolution and then ship each down the pipeline. The second stage thus costs the same time.</li><li>Two-stage models can dynamically adjust the number of ROI based on the frame resolution as a higher resolution input potentially involves more objects.<br /><img src="/imgs/Sys4ai/Elf/server_num.png" width="15%"></li></ul></li></ul></li><li>The cost of each processing part:<ul><li>At the server end, the GPU utilization v.s. GPU numbers are measured.<ul><li>On average, Elf-3 only consumes <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1.7</mn><mo>×</mo></mrow><annotation encoding="application/x-tex">1.7\times</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.72777em;vertical-align:-0.08333em;"></span><span class="mord">1</span><span class="mord">.</span><span class="mord">7</span><span class="mord">×</span></span></span></span> GPU utilization in total running with <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>3</mn></mrow><annotation encoding="application/x-tex">3</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">3</span></span></span></span> GPUs, then <em>SO</em> to finish a single request.</li><li>A lower per GPU utilization allows Elf to have more of a chance to efficiently utilize those resource fragmentations, thus improving the total GPU utilization of edge servers.<br /><img src="/imgs/Sys4ai/Elf/GPUutilization.png" width="15%"></li></ul></li><li>On the communication side, they measured the latency under different network conditions.<ul><li>Elf is less sensitive to the network bandwidth because it offloads much less data than SO.<br /><img src="/imgs/Sys4ai/Elf/network.png" width="15%"></li></ul></li><li>At the mobile end, they measured Elf’s overhead.<ul><li>RP prediction costs 70%+ of the total time as the attention LSTM model is implemented in Python and exported to C++ with TorchScript. It can be improved by rewriting the prediction model with TensorRT.<br /><img src="/imgs/Sys4ai/Elf/overhead.png" width="15%"></li></ul></li></ul></li><li>The inference accuracy and offload ratio of attention-based LSTM against vanilla LSTM, the fast tracker, showed the effectiveness of attention-based LSTM.</li><li>The impact of hyperparameters, e.g., the LRC parameter and RP expansion ratio, is measured.</li></ol>]]></content>
      
      
      <categories>
          
          <category> Paper Notebook </category>
          
          <category> Sys4AI </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Sys4AI </tag>
            
            <tag> Deployment </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>SiloD</title>
      <link href="/2023/09/27/Paper/Sys4AI/SiloD/"/>
      <url>/2023/09/27/Paper/Sys4AI/SiloD/</url>
      
        <content type="html"><![CDATA[<p>Paper: <a href="https://dl.acm.org/doi/abs/10.1145/3552326.3567499">SiloD: A Co-design of Caching and Scheduling for Deep Learning Clusters</a></p><p><ul class="markdownIt-TOC"><li><a href="#background">Background</a><ul><li><a href="#how-to-separate-storage-and-computing-in-dl-training">How to separate storage and computing in DL training?</a></li><li><a href="#how-to-leverage-the-cache-subsystem-for-dl-training">How to leverage the cache subsystem for DL training?</a></li><li><a href="#how-to-cache-data-for-dl-training">How to cache data for DL training?</a></li><li><a href="#what-is-the-problem-of-static-allocation">What is the problem of static allocation?</a></li></ul></li><li><a href="#purpose">Purpose</a></li><li><a href="#model">Model</a><ul><li><a href="#what-does-silod-do">What does SiloD do?</a></li><li><a href="#how-does-silod-estimate-performance">How does SiloD estimate performance?</a></li><li><a href="#how-to-integrate-silod-with-the-existing-scheduler">How to integrate SiloD with the existing scheduler?</a></li><li><a href="#how-to-use-silod-without-modifying-the-existing-scheduler">How to use SiloD without modifying the existing scheduler?</a></li><li><a href="#how-does-silod-allocate-resources">How does SiloD allocate resources?</a></li><li><a href="#how-to-handle-delayed-data-access-and-irregular-data-access">How to handle delayed data access and irregular data access?</a></li><li><a href="#how-does-silod-support-fault-tolerance">How does SiloD support fault tolerance?</a></li></ul></li><li><a href="#evaluation">Evaluation</a></li></ul></p><h1 id="background"><a class="markdownIt-Anchor" href="#background"></a> Background</h1><h2 id="how-to-separate-storage-and-computing-in-dl-training"><a class="markdownIt-Anchor" href="#how-to-separate-storage-and-computing-in-dl-training"></a> How to separate storage and computing in DL training?</h2><ol><li>Separate storage and computing. The training is executed on a compute cluster equipped with GPUs/TPUs while reading data from a separate cluster that hosts the storage service.</li><li>When submitting a DL job, users can specify the storage account and the location of the desired dataset, and the job can directly load the data through remote IO.</li><li>The remote IO between compute and storage services could become a bottleneck. The worst case is to read the entire training dataset remotely in each epoch.</li><li>Despite being highly diverse for different training jobs, the data access and the computation pattern are both highly stable and predictable within each individual job.</li></ol><h2 id="how-to-leverage-the-cache-subsystem-for-dl-training"><a class="markdownIt-Anchor" href="#how-to-leverage-the-cache-subsystem-for-dl-training"></a> How to leverage the cache subsystem for DL training?</h2><ol><li>Leverage local disks of GPU servers, instead of the small cache memory in traditional systems, to cache a subset of data to reduce the demands to remote IO.</li><li>The first type of cache subsystem is built into a data-loading library.<ul><li>The cache is built with the processes of a training job and is statically allocated.</li><li>DL training jobs have diverse demands on cache and remote IO. An isolated cache with a static allocation can neither satisfy nor exploit such diversity.</li></ul></li><li>The second type of cache subsystem is distributed cache, which consolidates the local storage of all cluster servers into a large storage pool shared by all jobs.<ul><li>Modern GPU cluster usually has a high-speed storage fabric (separate from the InfiniBand network used for distributed training) that supports accessing data from peer servers as fast as a local disk.</li><li>A distributed cache across the local cluster can generally satisfy the IO demands of training jobs.</li></ul></li></ol><h2 id="how-to-cache-data-for-dl-training"><a class="markdownIt-Anchor" href="#how-to-cache-data-for-dl-training"></a> How to cache data for DL training?</h2><ol><li><p>Due to the random-and-exactly-once data access pattern, uniform caching is optimal for a single training job.</p></li><li><p>In uniform caching, accessed data items are cached until the cache capacity is reached and will not be evicted after that. There is no eviction unless the cache capacity is reduced.</p><ul><li>Other cache eviction policies like LRU (Least-Recently-Used) may evict useful items, leading to the thrashing issue.</li><li>In uniform caching, part of the dataset stays on the local disk permanently and can be used in each epoch.</li><li>LRU will only reserve data used recently, and they won’t be used in the near future.</li></ul></li><li><p>Notably, the cached data are evenly distributed in each batch instead of caching some batches entirely.</p><ul><li>Each data item has a unique ID. The missed data items are fetched from the remote storage. Because each epoch shuffles the data loading order, the expected cache hit ratio is uniform for all items.</li><li>In this way, we can improve the performance of the data-loading pipeline.</li></ul></li><li><p>For deep learning training, uniform caching leads to a constant and predictable cache hit ratio w.r.t. the cache capacity regardless of which items are being cached.</p><img src="/imgs/Sys4ai/SiloD/cache.png" width="50%"></li></ol><h2 id="what-is-the-problem-of-static-allocation"><a class="markdownIt-Anchor" href="#what-is-the-problem-of-static-allocation"></a> What is the problem of static allocation?</h2><ol><li>When there are multiple jobs in a cluster, uniform caching transforms the cache management from a cache eviction problem to a cache space allocation problem.</li><li>The job’s cache efficiency is the amount of remote IO (in MB/s) saved per GB of cache allocated.</li><li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>𝑓</mi><mo>∗</mo></msup></mrow><annotation encoding="application/x-tex">𝑓^\ast</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.688696em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mbin mtight">∗</span></span></span></span></span></span></span></span></span></span></span> and <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>d</mi></mrow><annotation encoding="application/x-tex">d</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathnormal">d</span></span></span></span> are the IO demand to achieve the ideal training speed and the dataset size, respectively. A job’s cache efficiency is <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><msup><mi>𝑓</mi><mo>∗</mo></msup><mi>d</mi></mfrac></mrow><annotation encoding="application/x-tex">\frac{𝑓^\ast}{d}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.325448em;vertical-align:-0.345em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.980448em;"><span style="top:-2.6550000000000002em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">d</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.446108em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.10764em;">f</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.7633428571428571em;"><span style="top:-2.931em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mbin mtight">∗</span></span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.345em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span>.</li><li>The cache efficiency of different datasets can vary largely. A static cache allocation could not take advantage of the diverse cache-efficiency of DL jobs.</li></ol><h1 id="purpose"><a class="markdownIt-Anchor" href="#purpose"></a> Purpose</h1><ol><li>Issue:<ul><li>Existing deep learning schedulers do not manage storage resources and thus fail to consider the diverse caching effects across different training jobs.</li><li>State-of-the-art deep learning schedulers focus on arbitrating compute resources (e.g., GPUs and CPUs) with different optimization objectives like job completion time (JCT), fairness, or cluster utilization.</li></ul></li><li>Challenge:<ul><li>Deep learning schedulers have diverse scheduling objectives. An ad-hoc solution to every scheduling policy increases design complexity and is hard to scale.</li><li>Deep learning training exhibits highly diverse performance patterns: different jobs impose different cache and IO demands. This further complicates the system design.</li><li>Even deep learning-aware cache systems could exhibit poor performance because of caching policies that ignore scheduling impacts.</li></ul></li><li>Contribution:<ul><li>Co-design the cluster scheduler and the cache subsystems for deep learning training.</li><li>The job performance estimator is enhanced.<ul><li>To help different schedulers jointly consider the impact of storage and compute resource allocation while preserving their respective scheduling objectives.</li><li>SiloD derives a unified way of performance estimation by further leveraging the pipelined execution of data loading and computation.</li><li>SiloD can augment different state-of-the-art deep learning schedulers to jointly perform cache and remote IO allocation while preserving the original objectives of these scheduling policies.</li></ul></li></ul></li></ol><h1 id="model"><a class="markdownIt-Anchor" href="#model"></a> Model</h1><h2 id="what-does-silod-do"><a class="markdownIt-Anchor" href="#what-does-silod-do"></a> What does SiloD do?</h2><ol><li>SiloD allocates compute and cache-related resources jointly to training jobs. SiloD treats cache and remote IO as first-class citizens.<ul><li>Existing multi-resource schedulers can treat storage resources as yet another resource type whose impact has already been captured by the performance estimator.</li></ul></li><li>The scheduling problem can be generally abstracted as allocating cluster resources defined in <code>totalResource</code> to jobs with the help of a performance estimator <code>perf(j, R)</code>.</li><li>SiloD further enhances the estimator <code>perf</code> with <code>SiloDPerf</code> to estimate the joint impact of computing and storage resources.<ul><li>The SiloD-augmented performance estimator transforms a joint performance estimation into a two-step process.</li><li>It first estimates whether data loading will become the bottleneck of the entire training.</li><li>If so, SiloD will use <code>IOPerf</code>, a performance estimator we introduced, to analyze the impact of storage and estimate job performance under the IO bottleneck.</li></ul></li></ol><h2 id="how-does-silod-estimate-performance"><a class="markdownIt-Anchor" href="#how-does-silod-estimate-performance"></a> How does SiloD estimate performance?</h2><ol><li>The end-to-end throughput is then determined by the bottleneck stage, i.e., <code>SiloDPerf</code><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>=</mo><mi>m</mi><mi>i</mi><mi>n</mi><mo stretchy="false">{</mo><msup><mi>f</mi><mo>∗</mo></msup><mo separator="true">,</mo><mi>f</mi><mo stretchy="false">}</mo></mrow><annotation encoding="application/x-tex">=min\{f^\ast,f\}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.36687em;vertical-align:0em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">m</span><span class="mord mathnormal">i</span><span class="mord mathnormal">n</span><span class="mopen">{</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.688696em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mbin mtight">∗</span></span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="mclose">}</span></span></span></span>.<ul><li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>f</mi><mo>∗</mo></msup></mrow><annotation encoding="application/x-tex">f^\ast</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.688696em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mbin mtight">∗</span></span></span></span></span></span></span></span></span></span></span> is a job’s computation throughput when IO is not the bottleneck, i.e., <code>perf</code>, the original estimator used by an existing scheduler.</li><li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>f</mi></mrow><annotation encoding="application/x-tex">f</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord mathnormal" style="margin-right:0.10764em;">f</span></span></span></span> is the throughput of data loading, i.e., <code>IOPerf</code>, which is the estimator for IO given some cache allocation.</li></ul></li><li>A job’s remote IO demand can be calculated as <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>b</mi><mo>=</mo><mi>f</mi><mo>⋅</mo><mo stretchy="false">(</mo><mn>1</mn><mo>−</mo><mfrac><mi>c</mi><mi>d</mi></mfrac><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">b=f\cdot (1-\frac{c}{d})</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathnormal">b</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord">1</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1.095em;vertical-align:-0.345em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.695392em;"><span style="top:-2.6550000000000002em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">d</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">c</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.345em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mclose">)</span></span></span></span>.<ul><li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>𝑐</mi></mrow><annotation encoding="application/x-tex">𝑐</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathnormal">c</span></span></span></span> is the allocated cache space and <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>𝑑</mi></mrow><annotation encoding="application/x-tex">𝑑</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathnormal">d</span></span></span></span> the size of the training dataset. The expected cache hit ratio of a job is <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mi>c</mi><mi>d</mi></mfrac></mrow><annotation encoding="application/x-tex">\frac{c}{d}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.040392em;vertical-align:-0.345em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.695392em;"><span style="top:-2.6550000000000002em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">d</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">c</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.345em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span>.</li><li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>𝑏</mi></mrow><annotation encoding="application/x-tex">𝑏</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathnormal">b</span></span></span></span> is the remote IO demand of a job, which equals the data loading throughput multiplied by the cache miss ratio.</li></ul></li><li>A job’s IO throughput 𝑓 (i.e., <code>IOPerf</code>) can be estimated by <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>f</mi><mo>=</mo><mfrac><mi>b</mi><mrow><mn>1</mn><mo>−</mo><mi>c</mi><mi mathvariant="normal">/</mi><mi>d</mi></mrow></mfrac></mrow><annotation encoding="application/x-tex">f=\frac{b}{1-c/d}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.400108em;vertical-align:-0.52em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8801079999999999em;"><span style="top:-2.655em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span><span class="mbin mtight">−</span><span class="mord mathnormal mtight">c</span><span class="mord mtight">/</span><span class="mord mathnormal mtight">d</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">b</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.52em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span>.</li><li>When a job is fetching data at its ideal throughput (i.e., <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>f</mi><mo>=</mo><msup><mi>f</mi><mo>∗</mo></msup></mrow><annotation encoding="application/x-tex">f = f^\ast</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.688696em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mbin mtight">∗</span></span></span></span></span></span></span></span></span></span></span>), its cache efficiency is exactly the negative derivative of <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>b</mi></mrow><annotation encoding="application/x-tex">b</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathnormal">b</span></span></span></span>, i.e., cache Efficiency<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>=</mo><mo>−</mo><mfrac><mrow><mi mathvariant="normal">∂</mi><mi>b</mi></mrow><mrow><mi mathvariant="normal">∂</mi><mi>c</mi></mrow></mfrac><mo>=</mo><mfrac><msup><mi>f</mi><mo>∗</mo></msup><mi>d</mi></mfrac></mrow><annotation encoding="application/x-tex">=-\frac{\partial b}{\partial c}=\frac{f^\ast}{d}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.36687em;vertical-align:0em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.2251079999999999em;vertical-align:-0.345em;"></span><span class="mord">−</span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8801079999999999em;"><span style="top:-2.6550000000000002em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight" style="margin-right:0.05556em;">∂</span><span class="mord mathnormal mtight">c</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight" style="margin-right:0.05556em;">∂</span><span class="mord mathnormal mtight">b</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.345em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.325448em;vertical-align:-0.345em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.980448em;"><span style="top:-2.6550000000000002em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">d</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.446108em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.10764em;">f</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.7633428571428571em;"><span style="top:-2.931em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mbin mtight">∗</span></span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.345em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span>.<ul><li>The different computation throughput <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>f</mi><mo>∗</mo></msup></mrow><annotation encoding="application/x-tex">f^\ast</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.688696em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mbin mtight">∗</span></span></span></span></span></span></span></span></span></span></span> of different neural models and dataset size <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>d</mi></mrow><annotation encoding="application/x-tex">d</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathnormal">d</span></span></span></span> is the source of the heterogeneity.</li></ul></li><li>The policy assumes the ideal throughput of a job <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>𝑓</mi><mo>∗</mo></msup></mrow><annotation encoding="application/x-tex">𝑓^\ast</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.688696em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mbin mtight">∗</span></span></span></span></span></span></span></span></span></span></span> (when IO is not a bottleneck) can be profiled offline.</li></ol><h2 id="how-to-integrate-silod-with-the-existing-scheduler"><a class="markdownIt-Anchor" href="#how-to-integrate-silod-with-the-existing-scheduler"></a> How to integrate SiloD with the existing scheduler?</h2><ol><li>In Shortest Job First (SJF), each job will have a performance score defined as its weighted sum of resource demand of all resource types multiplied by its duration.<ul><li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>s</mi><mi>c</mi><mi>o</mi><mi>r</mi><mi>e</mi><mo>=</mo><mstyle scriptlevel="0" displaystyle="true"><munder><mo><mi>min</mi><mo>⁡</mo></mo><mi>R</mi></munder><munder><mo>∑</mo><mi>t</mi></munder><msub><mi>w</mi><mi>t</mi></msub><mo>⋅</mo><msub><mi>R</mi><mi>t</mi></msub><mo>⋅</mo><mo stretchy="false">(</mo><mfrac><mrow><mi>j</mi><mi mathvariant="normal">.</mi><mi>n</mi><mi>u</mi><mi>m</mi><mi>S</mi><mi>t</mi><mi>e</mi><mi>p</mi><mi>s</mi><mo>⋅</mo><mi>j</mi><mi mathvariant="normal">.</mi><mi>s</mi><mi>t</mi><mi>e</mi><mi>p</mi><mi>D</mi><mi>a</mi><mi>t</mi><mi>a</mi><mi>S</mi><mi>i</mi><mi>z</mi><mi>e</mi></mrow><mrow><mi>p</mi><mi>e</mi><mi>r</mi><mi>f</mi><mo stretchy="false">(</mo><mi>j</mi><mo separator="true">,</mo><mi mathvariant="bold">R</mi><mo stretchy="false">)</mo></mrow></mfrac><mo stretchy="false">)</mo></mstyle></mrow><annotation encoding="application/x-tex">score=\displaystyle\min_{R}\sum_{t}w_t\cdot R_t\cdot (\frac{j.numSteps\cdot j.stepDataSize}{perf(j,\bold{R})})</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathnormal">s</span><span class="mord mathnormal">c</span><span class="mord mathnormal">o</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mord mathnormal">e</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:2.3000100000000003em;vertical-align:-1.250005em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.66786em;"><span style="top:-2.355669em;margin-left:0em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.00773em;">R</span></span></span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span><span class="mop">min</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.744331em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.050005em;"><span style="top:-1.8999949999999999em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span style="top:-3.0500049999999996em;"><span class="pstrut" style="height:3.05em;"></span><span><span class="mop op-symbol large-op">∑</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.250005em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02691em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2805559999999999em;"><span style="top:-2.5500000000000003em;margin-left:-0.02691em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2805559999999999em;"><span style="top:-2.5500000000000003em;margin-left:-0.00773em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:2.2963299999999998em;vertical-align:-0.936em;"></span><span class="mopen">(</span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.3603299999999998em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathnormal">p</span><span class="mord mathnormal">e</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.05724em;">j</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathbf">R</span></span><span class="mclose">)</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05724em;">j</span><span class="mord">.</span><span class="mord mathnormal">n</span><span class="mord mathnormal">u</span><span class="mord mathnormal">m</span><span class="mord mathnormal" style="margin-right:0.05764em;">S</span><span class="mord mathnormal">t</span><span class="mord mathnormal">e</span><span class="mord mathnormal">p</span><span class="mord mathnormal">s</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mord mathnormal" style="margin-right:0.05724em;">j</span><span class="mord">.</span><span class="mord mathnormal">s</span><span class="mord mathnormal">t</span><span class="mord mathnormal">e</span><span class="mord mathnormal">p</span><span class="mord mathnormal" style="margin-right:0.02778em;">D</span><span class="mord mathnormal">a</span><span class="mord mathnormal">t</span><span class="mord mathnormal">a</span><span class="mord mathnormal" style="margin-right:0.05764em;">S</span><span class="mord mathnormal">i</span><span class="mord mathnormal" style="margin-right:0.04398em;">z</span><span class="mord mathnormal">e</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.936em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mclose">)</span></span></span></span></li><li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>w</mi><mi>t</mi></msub></mrow><annotation encoding="application/x-tex">w_t</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02691em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2805559999999999em;"><span style="top:-2.5500000000000003em;margin-left:-0.02691em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> is the weight of the <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>t</mi></mrow><annotation encoding="application/x-tex">t</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.61508em;vertical-align:0em;"></span><span class="mord mathnormal">t</span></span></span></span>-th resource type, <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="bold">R</mi></mrow><annotation encoding="application/x-tex">\bold{R}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68611em;vertical-align:0em;"></span><span class="mord"><span class="mord mathbf">R</span></span></span></span></span> is a vector of allocation of all resource types, and <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>R</mi><mi>t</mi></msub></mrow><annotation encoding="application/x-tex">R_{t}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2805559999999999em;"><span style="top:-2.5500000000000003em;margin-left:-0.00773em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> is the allocation of the <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>t</mi></mrow><annotation encoding="application/x-tex">t</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.61508em;vertical-align:0em;"></span><span class="mord mathnormal">t</span></span></span></span>-th resource type in <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="bold">R</mi></mrow><annotation encoding="application/x-tex">\bold{R}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68611em;vertical-align:0em;"></span><span class="mord"><span class="mord mathbf">R</span></span></span></span></span>, <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>𝑗</mi><mi mathvariant="normal">.</mi><mi>n</mi><mi>u</mi><mi>m</mi><mi>S</mi><mi>t</mi><mi>e</mi><mi>p</mi><mi>s</mi></mrow><annotation encoding="application/x-tex">𝑗.numSteps</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8777699999999999em;vertical-align:-0.19444em;"></span><span class="mord mathnormal" style="margin-right:0.05724em;">j</span><span class="mord">.</span><span class="mord mathnormal">n</span><span class="mord mathnormal">u</span><span class="mord mathnormal">m</span><span class="mord mathnormal" style="margin-right:0.05764em;">S</span><span class="mord mathnormal">t</span><span class="mord mathnormal">e</span><span class="mord mathnormal">p</span><span class="mord mathnormal">s</span></span></span></span> is the total number of steps and <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>𝑗</mi><mi mathvariant="normal">.</mi><mi>s</mi><mi>t</mi><mi>e</mi><mi>p</mi><mi>D</mi><mi>a</mi><mi>t</mi><mi>a</mi><mi>S</mi><mi>i</mi><mi>z</mi><mi>e</mi></mrow><annotation encoding="application/x-tex">𝑗.stepDataSize</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8777699999999999em;vertical-align:-0.19444em;"></span><span class="mord mathnormal" style="margin-right:0.05724em;">j</span><span class="mord">.</span><span class="mord mathnormal">s</span><span class="mord mathnormal">t</span><span class="mord mathnormal">e</span><span class="mord mathnormal">p</span><span class="mord mathnormal" style="margin-right:0.02778em;">D</span><span class="mord mathnormal">a</span><span class="mord mathnormal">t</span><span class="mord mathnormal">a</span><span class="mord mathnormal" style="margin-right:0.05764em;">S</span><span class="mord mathnormal">i</span><span class="mord mathnormal" style="margin-right:0.04398em;">z</span><span class="mord mathnormal">e</span></span></span></span> is the size of data consumed per step of the job <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>j</mi></mrow><annotation encoding="application/x-tex">j</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.85396em;vertical-align:-0.19444em;"></span><span class="mord mathnormal" style="margin-right:0.05724em;">j</span></span></span></span>.</li><li>The jobs with the least score will be scheduled first by the multi-resource SJF policy.</li></ul></li><li>The vanilla programming in Gavel’s max-min fairness is <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mstyle scriptlevel="0" displaystyle="true"><munder><mo><mi>max</mi><mo>⁡</mo></mo><mi>R</mi></munder><munder><mo><mi>min</mi><mo>⁡</mo></mo><mi>j</mi></munder><mfrac><mrow><mi>p</mi><mi>e</mi><mi>r</mi><mi>f</mi><mo stretchy="false">(</mo><mi>j</mi><mo separator="true">,</mo><mi>R</mi><mo stretchy="false">[</mo><mi>j</mi><mo stretchy="false">]</mo><mo stretchy="false">)</mo></mrow><mrow><mi>p</mi><mi>e</mi><mi>r</mi><mi>f</mi><mo stretchy="false">(</mo><mi>j</mi><mo separator="true">,</mo><msup><mi>R</mi><mrow><mi>e</mi><mi>q</mi><mi>u</mi><mi>a</mi><mi>l</mi></mrow></msup><mo stretchy="false">)</mo></mrow></mfrac><mo separator="true">,</mo><mi>s</mi><mi mathvariant="normal">.</mi><mi>t</mi><mi mathvariant="normal">.</mi><mi>S</mi><mi>u</mi><mi>m</mi><mo stretchy="false">(</mo><mi>R</mi><mo stretchy="false">)</mo><mo>≤</mo><mi>t</mi><mi>o</mi><mi>t</mi><mi>a</mi><mi>l</mi><mi>R</mi><mi>e</mi><mi>s</mi><mi>o</mi><mi>u</mi><mi>r</mi><mi>c</mi><mi>e</mi></mstyle></mrow><annotation encoding="application/x-tex">\displaystyle\max_{R}\min_{j}\frac{perf(j,R[j])}{perf(j,R^{equal})},s.t. Sum(R)≤totalResource</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:2.363em;vertical-align:-0.936em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.43055999999999983em;"><span style="top:-2.355669em;margin-left:0em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.00773em;">R</span></span></span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span><span class="mop">max</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.7443310000000001em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.66786em;"><span style="top:-2.3723360000000002em;margin-left:0em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span><span class="mop">min</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.863772em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.427em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathnormal">p</span><span class="mord mathnormal">e</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.05724em;">j</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.7751079999999999em;"><span style="top:-2.9890000000000003em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">e</span><span class="mord mathnormal mtight" style="margin-right:0.03588em;">q</span><span class="mord mathnormal mtight">u</span><span class="mord mathnormal mtight">a</span><span class="mord mathnormal mtight" style="margin-right:0.01968em;">l</span></span></span></span></span></span></span></span></span><span class="mclose">)</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathnormal">p</span><span class="mord mathnormal">e</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.05724em;">j</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="mopen">[</span><span class="mord mathnormal" style="margin-right:0.05724em;">j</span><span class="mclose">]</span><span class="mclose">)</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.936em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal">s</span><span class="mord">.</span><span class="mord mathnormal">t</span><span class="mord">.</span><span class="mord mathnormal" style="margin-right:0.05764em;">S</span><span class="mord mathnormal">u</span><span class="mord mathnormal">m</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">≤</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathnormal">t</span><span class="mord mathnormal">o</span><span class="mord mathnormal">t</span><span class="mord mathnormal">a</span><span class="mord mathnormal" style="margin-right:0.01968em;">l</span><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="mord mathnormal">e</span><span class="mord mathnormal">s</span><span class="mord mathnormal">o</span><span class="mord mathnormal">u</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mord mathnormal">c</span><span class="mord mathnormal">e</span></span></span></span>.<ul><li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>𝑅</mi><mo stretchy="false">[</mo><mi>𝑗</mi><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">𝑅[𝑗]</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="mopen">[</span><span class="mord mathnormal" style="margin-right:0.05724em;">j</span><span class="mclose">]</span></span></span></span> is the resource allocated to the job <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>j</mi></mrow><annotation encoding="application/x-tex">j</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.85396em;vertical-align:-0.19444em;"></span><span class="mord mathnormal" style="margin-right:0.05724em;">j</span></span></span></span> and <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>R</mi><mrow><mi>e</mi><mi>q</mi><mi>u</mi><mi>a</mi><mi>l</mi></mrow></msup></mrow><annotation encoding="application/x-tex">R^{equal}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8491079999999999em;vertical-align:0em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8491079999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">e</span><span class="mord mathnormal mtight" style="margin-right:0.03588em;">q</span><span class="mord mathnormal mtight">u</span><span class="mord mathnormal mtight">a</span><span class="mord mathnormal mtight" style="margin-right:0.01968em;">l</span></span></span></span></span></span></span></span></span></span></span></span> is the equal resource division among all jobs.</li><li>The max-min fairness objective maximizes the job with the least performance improvement over the equal resource division.</li></ul></li><li>When integrate SiloD, <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="bold">R</mi></mrow><annotation encoding="application/x-tex">\bold{R}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68611em;vertical-align:0em;"></span><span class="mord"><span class="mord mathbf">R</span></span></span></span></span> includes cache and remote IO as another two types of resources in addition to compute resources and the performance estimator function <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi><mi>e</mi><mi>r</mi><mi>f</mi><mo stretchy="false">(</mo><mi>j</mi><mo separator="true">,</mo><mi mathvariant="bold">R</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">perf(j,\bold{R})</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">p</span><span class="mord mathnormal">e</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.05724em;">j</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathbf">R</span></span><span class="mclose">)</span></span></span></span> is replaced by <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>S</mi><mi>i</mi><mi>l</mi><mi>o</mi><mi>D</mi><mi>P</mi><mi>e</mi><mi>r</mi><mi>f</mi><mo stretchy="false">(</mo><mi>j</mi><mo separator="true">,</mo><mi mathvariant="bold">R</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">SiloDPerf(j,\bold{R})</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.05764em;">S</span><span class="mord mathnormal">i</span><span class="mord mathnormal" style="margin-right:0.01968em;">l</span><span class="mord mathnormal">o</span><span class="mord mathnormal" style="margin-right:0.02778em;">D</span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="mord mathnormal">e</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.05724em;">j</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathbf">R</span></span><span class="mclose">)</span></span></span></span>.</li></ol><h2 id="how-to-use-silod-without-modifying-the-existing-scheduler"><a class="markdownIt-Anchor" href="#how-to-use-silod-without-modifying-the-existing-scheduler"></a> How to use SiloD without modifying the existing scheduler?</h2><ol><li>The greedy policy minimizes the remote IO consumption in a best-effort manner so that the impact of IO on original scheduling objectives can be minimized.</li><li>It can be done by allocating more cache to the most cache-efficient jobs.</li><li>Each job first calculates its cache efficiency. The datasets with the highest cache efficiency are first cached until the cache space is full.<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> job j <span class="keyword">in</span> <span class="keyword">all</span> jobs do</span><br><span class="line">  j.CacheEfficiency <span class="operator">=</span> j.fStar <span class="operator">/</span> j.datasetSize</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> job j <span class="keyword">in</span> descending <span class="keyword">order</span> <span class="keyword">of</span> j.CacheEfficiency do</span><br><span class="line">  alloc.Cache[j] <span class="operator">=</span> <span class="built_in">min</span>(j.datasetSize, totalCache)</span><br><span class="line">  totalCache <span class="operator">-</span><span class="operator">=</span> alloc.Cache[j]</span><br><span class="line"> </span><br><span class="line"><span class="keyword">return</span> alloc</span><br></pre></td></tr></table></figure></li></ol><h2 id="how-does-silod-allocate-resources"><a class="markdownIt-Anchor" href="#how-does-silod-allocate-resources"></a> How does SiloD allocate resources?</h2><ol><li>SiloD Data Manager serves in the storage layer to enforce the allocations made by the scheduler.<ul><li>A cluster scheduler uses the interface to allocate cache and remote IO to two types of entities: jobs and datasets.<ul><li>Remote IO is allocated to jobs directly, while cache is allocated to datasets and the associated jobs indirectly.</li><li>Multiple jobs can transparently share the same cache space for the same dataset. In contrast, since jobs using the same dataset still read data items in a different order, remote IO is exclusive to each job.</li><li>The cache consumption is charged once for each dataset instead of every job. The cache efficiency is defined at the dataset-level, which is the sum of all jobs’ cache efficiency using the same dataset.</li><li>The remote IO allocation is equally distributed to each job worker for distributed data-parallel training.</li></ul></li><li>The SiloD data manager sets up FUSE (Filesystem in USErspace) clients, which are co-located with training tasks to manage the cache, throttle remote IO, and maintain the metadata of datasets on each server.</li></ul></li><li>SiloD Scheduler extends the responsibility of the compute-only resource scheduler from job scheduling to compute-storage joint allocation.<br /><img src="/imgs/Sys4ai/SiloD/structure.png" width="50%"></li></ol><h2 id="how-to-handle-delayed-data-access-and-irregular-data-access"><a class="markdownIt-Anchor" href="#how-to-handle-delayed-data-access-and-irregular-data-access"></a> How to handle delayed data access and irregular data access?</h2><ol><li>Since DL training reads each data item exactly once per epoch, any newly cached data items will never be reaccessed until the next epoch.<ul><li>Even though the newly cached item consumes the cache space, it does not help to reduce the remote IO until the next epoch. Therefore, an accurate estimation of job performance should be made using an effective cache size.</li><li>However, since multiple jobs may use the same dataset, it is unknown beforehand if a newly cached item by one job is effective or not for other jobs.</li><li>The delayed effectiveness only has a limited impact, lasting for at most one epoch for newly cached items. A DL job usually trains a model for tens of epochs, thus most of the time, the cached data are effective.</li><li>SiloD also supports fine-grained management for policies to inspect the effective cache size and the instantaneous remote IO demand by maintaining a bitset for each job to track its accessed items.</li></ul></li><li>When a cluster is mixed with regular jobs satisfying SiloD’s assumptions and irregular jobs, we partition the cache and remote IO into two parts for all regular and irregular jobs, respectively.<ul><li>Allocate resources to the regular jobs in the first partition still using <code>SiloDPerf</code>.</li><li>The irregular jobs in the second partition fall back to the original scheduling policy and estimator and share the cache and remote IO within the partition.</li><li>In this way, the regular DL jobs can still benefit from exploiting the heterogeneous cache efficiency without being impacted by potential anomalies due to the mis-estimation of irregular jobs.</li></ul></li></ol><h2 id="how-does-silod-support-fault-tolerance"><a class="markdownIt-Anchor" href="#how-does-silod-support-fault-tolerance"></a> How does SiloD support fault tolerance?</h2><ol><li>The allocation of remote IO and cache is stored in “pod annotation” for the pods of each job, which is kept reliably by Kubernetes.</li><li>For the job with multiple pods, the remote IO allocation is proportionally divided into each pod, and the cache allocation is the same for all pods.</li><li>When SiloD Data Manager recovers from crashes, it reconstructs the status by collecting pod information.</li><li>The cache content on each server is stored on a local disk and thus can be reliably restored when the server restarts.</li><li>SiloD does not add stateful information to the cluster scheduler; thus, their fault tolerance is handled using their original approach.</li></ol><h1 id="evaluation"><a class="markdownIt-Anchor" href="#evaluation"></a> Evaluation</h1><ol><li>First, the author showed the evidence of the issues:<ul><li><p>They presented the increasing dataset size and the GPU performance as indirect evidence of remote IO bottleneck.<br /><img src="/imgs/Sys4ai/SiloD/indirect.png" width="50%"></p></li><li><p>Then, the required remote IO to reach the optimal speed for GPU is calculated, and the GPU cluster’s aggregate IO demand is profiled to prove that remote IO without cache is slowing down the training prosedure.<br /><img src="/imgs/Sys4ai/SiloD/optimal.png" width="25%"><br /><img src="/imgs/Sys4ai/SiloD/demand.png" width="25%"></p></li><li><p>When discussing the design for the cache subsystem, the author also provided the sub-optimal evidence of the current scheduler without knowing the cache subsystem.<br /><img src="/imgs/Sys4ai/SiloD/quiver.png" width="50%"></p></li></ul></li><li>When further exploring the cache efficiency, the author showed the variance between different datasets and effective cache size.<br /><img src="/imgs/Sys4ai/SiloD/variance.png" width="35%" /> <img src="/imgs/Sys4ai/SiloD/effective.png" width="35%" /></li><li>To evaluate SiloD in a large-scale cluster of fast V100 GPUs with a lower cost, the authors design an approach to accelerating the training on a K80 GPU cluster to investigate the data loading performance of running the same trace in a V100 GPU cluster.<ul><li>In the experiment, they first profile the training speed of selected models on real V100 GPUs.</li><li>Then, execute the same model on K80 GPUs by processing the same training pipeline of data loading, preprocessing, and model aggregation but replacing the model execution (forward pass and backward pass) with “<code>sleep()</code>” for the profiled duration from V100.</li><li>Since deep learning training usually has a very stable mini-batch duration, the IO behavior in accelerated K80 GPUs is almost the same as real training of V100 GPUs.</li></ul></li></ol>]]></content>
      
      
      <categories>
          
          <category> Paper Notebook </category>
          
          <category> Sys4AI </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Cache System </tag>
            
            <tag> Sys4AI </tag>
            
            <tag> Scheduler </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>COPS</title>
      <link href="/2023/09/26/Paper/Distributed/COPS/"/>
      <url>/2023/09/26/Paper/Distributed/COPS/</url>
      
        <content type="html"><![CDATA[<p>Paper: <a href="http://nil.csail.mit.edu/6.824/2020/papers/cops.pdf">Don’t Settle for Eventual: Scalable Causal Consistency for Wide-Area Storage with COPS</a></p><p><ul class="markdownIt-TOC"><li><a href="#purpose">Purpose</a></li><li><a href="#model">Model</a><ul><li><a href="#alps-systems">ALPS systems</a><ul><li><a href="#what-are-the-desirable-properties-of-alps-systems">What are the desirable properties of ALPS systems?</a></li><li><a href="#what-is-the-problem-of-linearizability">What is the problem of linearizability?</a></li></ul></li><li><a href="#causal-consistency">Causal+ consistency</a><ul><li><a href="#what-is-causal-consistency">What is causal consistency?</a></li><li><a href="#how-to-handle-conflicts">How to handle conflicts?</a></li><li><a href="#how-to-decide-which-write-is-the-last-write">How to decide which write is the last write?</a></li><li><a href="#what-are-other-consistency-models">What are other consistency models?</a></li><li><a href="#how-is-causal-ensured-in-cops">How is causal+ ensured in COPS?</a></li><li><a href="#why-previous-systems-cannot-provide-scalability">Why previous systems cannot provide scalability?</a></li></ul></li><li><a href="#cops-system">COPS system</a><ul><li><a href="#what-are-the-components-of-cops">What are the components of COPS?</a></li><li><a href="#what-consistency-is-achieved-in-cops">What consistency is achieved in COPS?</a></li><li><a href="#key-value-store">Key-value store</a><ul><li><a href="#what-is-stored-in-cops-storage">What is stored in COPS storage?</a></li><li><a href="#how-does-cops-support-scalability-in-kv-storage">How does COPS support scalability in KV-storage?</a></li></ul></li><li><a href="#client-library">Client library</a><ul><li><a href="#what-is-provided-in-the-client-api">What is provided in the client API?</a></li><li><a href="#what-is-the-context-in-the-library">What is the context in the library?</a></li><li><a href="#what-does-cops-gt-store-in-context">What does COPS-GT store in context?</a></li><li><a href="#what-are-the-concerns-of-the-cops-gt-context">What are the concerns of the COPS-GT context?</a></li><li><a href="#what-does-cops-store-in-context">What does COPS store in context?</a></li><li><a href="#how-does-cops-or-cops-gt-write-to-the-local-cluster">How does COPS (or COPS-GT) write to the local cluster?</a></li><li><a href="#how-to-replica-writes-between-clusters">How to replica writes between clusters?</a></li><li><a href="#how-to-read-values-in-cops">How to read values in COPS?</a></li><li><a href="#why-does-cops-gt-need-to-provide-get_trans-what-is-wrong-with-the-get-interface">Why does COPS-GT need to provide get_trans? What is wrong with the get interface?</a></li><li><a href="#how-does-get_trans-work">How does get_trans work?</a></li></ul></li><li><a href="#garbage-collection">Garbage collection</a><ul><li><a href="#how-does-cops-gt-collect-version-garbage">How does COPS-GT collect version garbage?</a></li><li><a href="#how-does-cops-gt-collect-dependency-garbage">How does COPS-GT collect dependency garbage?</a></li><li><a href="#how-does-cops-collect-client-metadata-garbage">How does COPS collect client metadata garbage?</a></li></ul></li><li><a href="#fault-tolerance">Fault tolerance</a><ul><li><a href="#how-does-cops-handle-client-failures">How does COPS handle client failures?</a></li><li><a href="#how-does-cops-handle-key-value-node-failures">How does COPS handle key-value node failures?</a></li><li><a href="#what-will-happen-when-the-datacenter-fails">What will happen when the datacenter fails?</a></li><li><a href="#how-does-cops-with-conflict-detection-cops-cd-detect-conflict">How does COPS with conflict detection (COPS-CD) detect conflict?</a></li></ul></li></ul></li></ul></li></ul></p><h1 id="purpose"><a class="markdownIt-Anchor" href="#purpose"></a> Purpose</h1><ol><li>Issues<ul><li>Systems often sacrifice strong consistency to achieve these goals, exposing inconsistencies to their clients and necessitating complex application logic.</li><li>The author referred to systems with these four properties—Availability, low Latency, partition tolerance, and high Scalability—as ALPS systems.</li><li>Eventual consistent systems may expose versions that are out of order.</li></ul></li><li>Contribution:<ul><li>The author identified and defined a consistency model—causal consistency with convergent conflict handling, or causal+ —the strongest achieved under ALPS systems.<ul><li>The convergent conflict handling component of causal+ consistency ensures that replicas never permanently diverge and that conflicting updates to the same key are dealt with identically at all sites.</li><li>When combined with causal consistency, this property ensures that clients see only progressively newer versions of keys.</li></ul></li><li>The scalability of the Clusters of Order-Preserving Servers (COPS) system can enforce causal dependencies between keys stored across an entire cluster rather than a single server like previous systems.</li><li>In COPS-GT, the author introduced get transactions to obtain a consistent view of multiple keys without locking or blocking.</li></ul></li></ol><h1 id="model"><a class="markdownIt-Anchor" href="#model"></a> Model</h1><h2 id="alps-systems"><a class="markdownIt-Anchor" href="#alps-systems"></a> ALPS systems</h2><h3 id="what-are-the-desirable-properties-of-alps-systems"><a class="markdownIt-Anchor" href="#what-are-the-desirable-properties-of-alps-systems"></a> What are the desirable properties of ALPS systems?</h3><ol><li><strong>Availability</strong>:<ul><li>All operations issued to the data store are completed successfully.</li><li>No operation can block indefinitely or return an error signifying that data is unavailable.</li></ul></li><li><strong>Low Latency</strong>: Client operations complete “quickly.”<ul><li>Commercial service-level objectives suggest an average performance of a few milliseconds and a worse-case performance (i.e., 99.9th percentile) of 10s or 100s milliseconds.</li></ul></li><li><strong>Partition Tolerance</strong>: The data store continues to operate under network partitions.</li><li><strong>High Scalability</strong>: The data store scales out linearly. Adding N resources to the system increases aggregate throughput and storage capacity by <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>O</mi><mo stretchy="false">(</mo><mi>N</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">O(N)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">O</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.10903em;">N</span><span class="mclose">)</span></span></span></span>.</li><li><strong>Stronger Consistency</strong>:<ul><li>Linearizability dictates that operations appear to take effect across the entire system at a single instance between the invocation and completion of the operation.</li><li>Eventual consistency models not only might subsequent reads not reflect the latest value, but reads across multiple objects might reflect an incoherent mix of old and new values.</li></ul></li></ol><h3 id="what-is-the-problem-of-linearizability"><a class="markdownIt-Anchor" href="#what-is-the-problem-of-linearizability"></a> What is the problem of linearizability?</h3><ol><li>The CAP Theorem proves that a shared-data system with availability and partition tolerance cannot achieve linearizability.</li><li>Low latency—defined as latency less than the maximum wide area delay between replicas—has also been proven incompatible with linearizability and sequential consistency.</li></ol><h2 id="causal-consistency"><a class="markdownIt-Anchor" href="#causal-consistency"></a> Causal+ consistency</h2><h3 id="what-is-causal-consistency"><a class="markdownIt-Anchor" href="#what-is-causal-consistency"></a> What is causal consistency?</h3><ol><li>Values are stored and retrieved from logical replicas, each hosting the entire key space.</li><li>The potential causality between operations denoted by <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>⇝</mo></mrow><annotation encoding="application/x-tex">\leadsto</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.37788em;vertical-align:0em;"></span><span class="mrel amsrm">⇝</span></span></span></span>:<ul><li><strong>Execution Thread</strong>: If <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>a</mi></mrow><annotation encoding="application/x-tex">a</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathnormal">a</span></span></span></span> and <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>b</mi></mrow><annotation encoding="application/x-tex">b</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathnormal">b</span></span></span></span> are two operations in a single thread of execution, then <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>a</mi><mo>⇝</mo><mi>b</mi></mrow><annotation encoding="application/x-tex">a \leadsto b</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathnormal">a</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel amsrm">⇝</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathnormal">b</span></span></span></span> if operation <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>a</mi></mrow><annotation encoding="application/x-tex">a</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathnormal">a</span></span></span></span> happens before operation <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>b</mi></mrow><annotation encoding="application/x-tex">b</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathnormal">b</span></span></span></span>.</li><li><strong>Gets From</strong>: If <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>a</mi></mrow><annotation encoding="application/x-tex">a</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathnormal">a</span></span></span></span> is a put operation and <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>b</mi></mrow><annotation encoding="application/x-tex">b</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathnormal">b</span></span></span></span> is a get operation that returns the value written by <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>a</mi></mrow><annotation encoding="application/x-tex">a</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathnormal">a</span></span></span></span>, then <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>a</mi><mo>⇝</mo><mi>b</mi></mrow><annotation encoding="application/x-tex">a \leadsto b</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathnormal">a</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel amsrm">⇝</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathnormal">b</span></span></span></span>.</li><li><strong>Transitivity</strong>: For operations <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>a</mi></mrow><annotation encoding="application/x-tex">a</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathnormal">a</span></span></span></span>, <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>b</mi></mrow><annotation encoding="application/x-tex">b</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathnormal">b</span></span></span></span>, and <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>c</mi></mrow><annotation encoding="application/x-tex">c</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathnormal">c</span></span></span></span>, if <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>a</mi><mo>⇝</mo><mi>b</mi></mrow><annotation encoding="application/x-tex">a \leadsto b</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathnormal">a</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel amsrm">⇝</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathnormal">b</span></span></span></span> and <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>b</mi><mo>⇝</mo><mi>c</mi></mrow><annotation encoding="application/x-tex">b \leadsto c</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathnormal">b</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel amsrm">⇝</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathnormal">c</span></span></span></span>, then <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>a</mi><mo>⇝</mo><mi>c</mi></mrow><annotation encoding="application/x-tex">a \leadsto c</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathnormal">a</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel amsrm">⇝</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathnormal">c</span></span></span></span>.</li></ul></li><li>Causal consistency requires that values returned from get operations at a replica are consistent with the order defined by <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>⇝</mo></mrow><annotation encoding="application/x-tex">\leadsto</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.37788em;vertical-align:0em;"></span><span class="mrel amsrm">⇝</span></span></span></span> (causality).<ul><li>The operation that writes a value must appear after all operations that causally precede it.</li><li>If <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>a</mi><mo>⇝̸</mo><mi>b</mi></mrow><annotation encoding="application/x-tex">a \not\leadsto b</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord mathnormal">a</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel"><span class="mord vbox"><span class="thinbox"><span class="rlap"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="inner"><span class="mrel"></span></span><span class="fix"></span></span></span></span></span></span><span class="base"><span class="strut" style="height:0.37788em;vertical-align:0em;"></span><span class="mrel amsrm">⇝</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathnormal">b</span></span></span></span> and <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>b</mi><mo>⇝̸</mo><mi>a</mi></mrow><annotation encoding="application/x-tex">b \not\leadsto a</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord mathnormal">b</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel"><span class="mord vbox"><span class="thinbox"><span class="rlap"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="inner"><span class="mrel"></span></span><span class="fix"></span></span></span></span></span></span><span class="base"><span class="strut" style="height:0.37788em;vertical-align:0em;"></span><span class="mrel amsrm">⇝</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathnormal">a</span></span></span></span>, then <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>a</mi></mrow><annotation encoding="application/x-tex">a</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathnormal">a</span></span></span></span> and <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>b</mi></mrow><annotation encoding="application/x-tex">b</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathnormal">b</span></span></span></span> are concurrent. Causal consistency does not order concurrent operations.</li></ul></li></ol><h3 id="how-to-handle-conflicts"><a class="markdownIt-Anchor" href="#how-to-handle-conflicts"></a> How to handle conflicts?</h3><ol><li>If <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>a</mi></mrow><annotation encoding="application/x-tex">a</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathnormal">a</span></span></span></span> and <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>b</mi></mrow><annotation encoding="application/x-tex">b</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathnormal">b</span></span></span></span> are both put to the same key, then they are in conflict.<ul><li>Conflicts are unordered by causal consistency and allow replicas to diverge forever.</li><li>Conflicts may represent an exceptional condition that requires special handling.</li></ul></li><li>Convergent conflict handling requires that all conflicting puts be handled in the same manner at all replicas, using a handler function <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>h</mi></mrow><annotation encoding="application/x-tex">h</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathnormal">h</span></span></span></span>.<ul><li>This handler function <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>h</mi></mrow><annotation encoding="application/x-tex">h</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathnormal">h</span></span></span></span> must be <strong>associative</strong> and <strong>commutative</strong> so that replicas can handle conflicting writes in the order they receive them and that the results of these handlings will converge.<ul><li>The last-writer-wins rule (Thomas’s write rule) is one of the conflicting writes that occurred later and was overwritten by the “earlier” write.</li><li>The default COPS system avoids conflict detection using a last-writer-wins strategy. The “last” write is determined by comparing version numbers.</li><li>Another way is to mark them as conflicting and require resolution through other means.</li></ul></li></ul></li><li>All potential forms of convergent conflict handling avoid the first issue by ensuring replicas reach the same result after exchanging operations.</li><li>The second conflict issue is only avoided using more explicit conflict resolution procedures.<ul><li>These explicit procedures provide greater application flexibility but require additional programmer complexity and performance overhead.</li></ul></li></ol><h3 id="how-to-decide-which-write-is-the-last-write"><a class="markdownIt-Anchor" href="#how-to-decide-which-write-is-the-last-write"></a> How to decide which write is the last write?</h3><ol><li>It uses a last-write-win strategy. So the problem is how to decide which write is the last.</li><li>The decision is made by attaching each put’s current wall-clock time as the version number.<ul><li>Local shard server assigns <code>version number (v#) = time</code> when it receives client <code>put()</code></li><li>Remote datacenter receives <code>put(k, -, v#)</code><ul><li>If <code>v#</code> is larger than the version of the currently stored value for k, it replaces the current value with a new value and updates <code>v#</code>.</li><li>Otherwise, it just ignores new values.</li></ul></li></ul></li><li>If two <code>put(k)</code> happen simultaneously at different datacenters, we can break the tie with a unique ID in the low bits of <code>v#</code>.</li><li>COPS uses Lamport clocks to assign <code>v#</code><ul><li>Each server implements a “Lamport clock” or “logical clock.”<ul><li><code>Tmax = highest v# seen</code> (from self and others)</li><li><code>T = max(Tmax + 1, wall-clock time)</code></li></ul></li></ul></li><li>In the naive strategy, if one datacenter’s (or server’s) clock is fast by an hour, it will cause that datacenter’s values to win. In the worst case, it prevents any other update for an hour.<ul><li>However, in  COPS, if some server has a fast clock, everyone who sees a version from that server will advance their Lamport clock.</li></ul></li></ol><h3 id="what-are-other-consistency-models"><a class="markdownIt-Anchor" href="#what-are-other-consistency-models"></a> What are other consistency models?</h3><ol><li><p>Linearizability (or strong consistency) maintains a global, real-time ordering.</p></li><li><p>Sequential consistency ensures at least a global ordering.</p></li><li><p>Causal consistency ensures partial orderings between dependent operations.</p></li><li><p>FIFO (PRAM) consistency only preserves the partial ordering of an execution thread, not between threads.</p></li><li><p>Per-key sequential consistency ensures that, for each key, all operations have a global order.</p></li><li><p>Eventual consistency is a “catch-all” term used today, suggesting eventual convergence with some agreement.</p></li><li><p>The strength of those models is as shown below:</p><img src="/imgs/Distributed/COPS/models.png" width="50%"></li></ol><h3 id="how-is-causal-ensured-in-cops"><a class="markdownIt-Anchor" href="#how-is-causal-ensured-in-cops"></a> How is causal+ ensured in COPS?</h3><ol><li><p><strong>Progressing property</strong></p><ul><li><p>Different values a key has are referred to as the versions of a key, which are denoted <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi><mi>e</mi><msub><mi>y</mi><mrow><mi>v</mi><mi>e</mi><mi>r</mi><mi>s</mi><mi>i</mi><mi>o</mi><mi>n</mi></mrow></msub></mrow><annotation encoding="application/x-tex">key_{version}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord mathnormal" style="margin-right:0.03148em;">k</span><span class="mord mathnormal">e</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.03588em;">v</span><span class="mord mathnormal mtight">e</span><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span><span class="mord mathnormal mtight">s</span><span class="mord mathnormal mtight">i</span><span class="mord mathnormal mtight">o</span><span class="mord mathnormal mtight">n</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>.</p></li><li><p>In COPS, versions are assigned in a manner that ensures that if <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>x</mi><mi>i</mi></msub><mo>⇝</mo><msub><mi>y</mi><mi>j</mi></msub></mrow><annotation encoding="application/x-tex">x_i \leadsto y_j</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel amsrm">⇝</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.716668em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.311664em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span></span></span></span> then <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>i</mi><mo>&lt;</mo><mi>j</mi></mrow><annotation encoding="application/x-tex">i &lt; j</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69862em;vertical-align:-0.0391em;"></span><span class="mord mathnormal">i</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">&lt;</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.85396em;vertical-align:-0.19444em;"></span><span class="mord mathnormal" style="margin-right:0.05724em;">j</span></span></span></span>.</p></li><li><p>Once a replica in COPS returns the version <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>i</mi></mrow><annotation encoding="application/x-tex">i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.65952em;vertical-align:0em;"></span><span class="mord mathnormal">i</span></span></span></span> of a key, <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>x</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">x_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>, causal+ consistency ensures it will then only return that version or a causally later version.</p></li><li><p>The handling of a conflict is causally later than the conflicting puts it resolves.</p><ul><li><p>Assume a replica first returns <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>x</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">x_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> and then <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>x</mi><mi>k</mi></msub></mrow><annotation encoding="application/x-tex">x_k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>, where <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>i</mi><mo mathvariant="normal">≠</mo><mi>k</mi></mrow><annotation encoding="application/x-tex">i \ne k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord mathnormal">i</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel"><span class="mrel"><span class="mord vbox"><span class="thinbox"><span class="rlap"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="inner"><span class="mrel"></span></span><span class="fix"></span></span></span></span></span><span class="mrel">=</span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.03148em;">k</span></span></span></span> and <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>x</mi><mi>i</mi></msub><mo>⇝̸</mo><msub><mi>x</mi><mi>k</mi></msub></mrow><annotation encoding="application/x-tex">x_i \not\leadsto x_k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel"><span class="mord vbox"><span class="thinbox"><span class="rlap"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="inner"><span class="mrel"></span></span><span class="fix"></span></span></span></span></span></span><span class="base"><span class="strut" style="height:0.37788em;vertical-align:0em;"></span><span class="mrel amsrm">⇝</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>.</p></li><li><p>Causal consistency ensures that if <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>x</mi><mi>k</mi></msub></mrow><annotation encoding="application/x-tex">x_k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> is returned after <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>x</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">x_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>, then <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>x</mi><mi>k</mi></msub><mo>⇝̸</mo><msub><mi>x</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">x_k \not\leadsto x_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel"><span class="mord vbox"><span class="thinbox"><span class="rlap"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="inner"><span class="mrel"></span></span><span class="fix"></span></span></span></span></span></span><span class="base"><span class="strut" style="height:0.37788em;vertical-align:0em;"></span><span class="mrel amsrm">⇝</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>, and so <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>x</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">x_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> and <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>x</mi><mi>k</mi></msub></mrow><annotation encoding="application/x-tex">x_k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> conflict.</p></li><li><p>But, if <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>x</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">x_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> and <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>x</mi><mi>k</mi></msub></mrow><annotation encoding="application/x-tex">x_k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> conflict, then convergent conflict handling ensures that as soon as both are present at a replica, their handling <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>h</mi><mo stretchy="false">(</mo><msub><mi>x</mi><mi>i</mi></msub><mo separator="true">,</mo><msub><mi>x</mi><mi>k</mi></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">h(x_i,x_k)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">h</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span>, which is causally after both will be returned instead of either <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>x</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">x_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> or <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>x</mi><mi>k</mi></msub></mrow><annotation encoding="application/x-tex">x_k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>, which contradicts our assumption.</p></li></ul></li><li><p>Thus, each replica in COPS always returns non-decreasing versions of a key.</p></li></ul></li><li><p><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>y</mi><mi>j</mi></msub></mrow><annotation encoding="application/x-tex">y_j</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.716668em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.311664em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span></span></span></span> depends on <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>x</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">x_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> if and only if <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi><mi>u</mi><mi>t</mi><mo stretchy="false">(</mo><msub><mi>x</mi><mi>i</mi></msub><mo stretchy="false">)</mo><mo>⇝</mo><mi>p</mi><mi>u</mi><mi>t</mi><mo stretchy="false">(</mo><msub><mi>y</mi><mi>j</mi></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">put(x_i) \leadsto put(y_j)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">p</span><span class="mord mathnormal">u</span><span class="mord mathnormal">t</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel amsrm">⇝</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.036108em;vertical-align:-0.286108em;"></span><span class="mord mathnormal">p</span><span class="mord mathnormal">u</span><span class="mord mathnormal">t</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.311664em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span>.</p><ul><li>These dependencies are, in essence, the reverse of the causal ordering of writes.</li><li>COPS provides causal+ consistency during replication by writing a version only after writing all of its dependencies.</li></ul></li></ol><h3 id="why-previous-systems-cannot-provide-scalability"><a class="markdownIt-Anchor" href="#why-previous-systems-cannot-provide-scalability"></a> Why previous systems cannot provide scalability?</h3><ol><li><p>They all use a form of log serialization and exchange.</p><ul><li><p>All operations at a logical replica are written to a single log in serialized order, commonly marked with a version vector.</p></li><li><p>Log-exchange-based serialization inhibits replica scalability, as it relies on a single serialization point in each replica to establish order.</p></li><li><p>Either causal dependencies between keys are limited to the set of keys stored on one node, or a single node (or replicated state machine) must provide a commit ordering and log for all operations across a cluster.</p></li></ul></li><li><p>In COPS, nodes in each datacenter are responsible for different partitions of the keyspace, but the system can track and enforce dependencies between keys stored on other nodes.</p><ul><li>COPS explicitly encodes dependencies in metadata associated with each key’s version.</li><li>When keys are replicated remotely, the receiving datacenter performs dependency checks before committing the incoming version.</li></ul></li></ol><h2 id="cops-system"><a class="markdownIt-Anchor" href="#cops-system"></a> COPS system</h2><h3 id="what-are-the-components-of-cops"><a class="markdownIt-Anchor" href="#what-are-the-components-of-cops"></a> What are the components of COPS?</h3><ol><li>Key-value store<ul><li>Each key-value pair has associated metadata.<ul><li>In COPS, this metadata is a version number.</li><li>In COPS-GT, it is both a version number and a list of dependencies (other keys and their respective versions).</li></ul></li><li>The key-value store exports three additional operations as part of its key-value interface: <code>get_by_version</code>, <code>put_after</code>, and <code>dep_check</code>.</li><li>For COPS-GT, the system keeps around old versions of key-value pairs, not just the most recent put, to ensure that it can provide get transactions.</li></ul></li><li>Client library<ul><li>The client library exports two main operations to applications: reads via <code>get</code> (in COPS) or <code>get_trans</code> (in COPS-GT) and writes via <code>put</code>.</li><li>The client library also maintains a state of a client’s current dependencies through a <code>context</code> parameter in the client library API.</li></ul></li><li>A client of COPS is an application that uses the COPS client library to call directly into the COPS key-value store.</li><li>Clients communicate only with their local COPS cluster running in the same datacenter.</li></ol><h3 id="what-consistency-is-achieved-in-cops"><a class="markdownIt-Anchor" href="#what-consistency-is-achieved-in-cops"></a> What consistency is achieved in COPS?</h3><ol><li>Each local COPS cluster is a linearizable (strongly consistent) key-value store.<ul><li>Linearizable systems can be implemented scalably by partitioning the keyspace into N linearizable partitions.</li><li>The composability of linearizability ensures that the resulting system remains linearizable.</li><li>Linearizability is acceptable locally because we expect very low latency and no partitions within a cluster.</li></ul></li><li>Replication between COPS clusters happens asynchronously to ensure low latency for client operations and availability in the face of external partitions.</li><li>The COPS design strives to provide causal+ consistency with resource and performance overhead similar to existing eventual consistent systems.<ul><li>COPS and COPS-GT need to minimize the overhead of consistency-preserving replication<ul><li>A naive implementation, however, would require checks on all of a value’s dependencies.</li></ul></li><li>COPS-GT needs to minimize space requirements</li><li>COPS-GT needs to ensure fast <code>get_trans</code> operations<ul><li>A naive algorithm could block and take an unbounded number of get rounds to complete.</li></ul></li></ul></li></ol><h3 id="key-value-store"><a class="markdownIt-Anchor" href="#key-value-store"></a> Key-value store</h3><h4 id="what-is-stored-in-cops-storage"><a class="markdownIt-Anchor" href="#what-is-stored-in-cops-storage"></a> What is stored in COPS storage?</h4><ol><li>COPS must track the versions of written values and their dependencies in the case of COPS-GT.</li><li>In COPS, the system stores each key’s most recent version number and value.</li><li>In COPS-GT, the system maps each key to a list of version entries consisting of <code>&lt;version, value, deps&gt;</code>.<ul><li>The <code>deps</code> field lists the version’s zero or more dependencies; each dependency is a <code>&lt;key, version&gt;</code> pair.</li></ul></li></ol><h4 id="how-does-cops-support-scalability-in-kv-storage"><a class="markdownIt-Anchor" href="#how-does-cops-support-scalability-in-kv-storage"></a> How does COPS support scalability in KV-storage?</h4><ol><li>It partitions the keyspace across a cluster’s nodes using consistent hashing.</li><li>Every key stored in COPS has one primary node in each cluster.<ul><li>The set of primary nodes for a key across all clusters is the <strong>equivalent nodes</strong> for that key.</li><li>After a write completes locally, the primary node places it in a replication queue, sending it asynchronously to remote equivalent nodes.</li><li>Those nodes, in turn, wait until the value’s dependencies are satisfied in their local cluster before locally committing the value.</li><li>This dependency-checking mechanism ensures that writes happen in a causally consistent order and reads never block.</li></ul></li><li>In practice, COPS’s consistent hashing assigns each node responsibility for a few different key ranges.<ul><li>Key ranges may have different sizes and node mappings in different datacenters.</li><li>The number of equivalent nodes with which a given node must communicate is proportional to the number of datacenters (i.e., communication is not all-to-all between nodes in different datacenters).</li></ul></li></ol><h3 id="client-library"><a class="markdownIt-Anchor" href="#client-library"></a> Client library</h3><h4 id="what-is-provided-in-the-client-api"><a class="markdownIt-Anchor" href="#what-is-provided-in-the-client-api"></a> What is provided in the client API?</h4><ol><li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>c</mi><mi>t</mi><mi>x</mi><mi mathvariant="normal">_</mi><mi>i</mi><mi>d</mi><mo>←</mo><mi>c</mi><mi>r</mi><mi>e</mi><mi>a</mi><mi>t</mi><mi>e</mi><mi>C</mi><mi>o</mi><mi>n</mi><mi>t</mi><mi>e</mi><mi>x</mi><mi>t</mi><mo stretchy="false">(</mo><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">ctx\_id\leftarrow createContext()</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.00444em;vertical-align:-0.31em;"></span><span class="mord mathnormal">c</span><span class="mord mathnormal">t</span><span class="mord mathnormal">x</span><span class="mord" style="margin-right:0.02778em;">_</span><span class="mord mathnormal">i</span><span class="mord mathnormal">d</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">←</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">c</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mord mathnormal">e</span><span class="mord mathnormal">a</span><span class="mord mathnormal">t</span><span class="mord mathnormal">e</span><span class="mord mathnormal" style="margin-right:0.07153em;">C</span><span class="mord mathnormal">o</span><span class="mord mathnormal">n</span><span class="mord mathnormal">t</span><span class="mord mathnormal">e</span><span class="mord mathnormal">x</span><span class="mord mathnormal">t</span><span class="mopen">(</span><span class="mclose">)</span></span></span></span></li><li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>b</mi><mi>o</mi><mi>o</mi><mi>l</mi><mo>←</mo><mi>d</mi><mi>e</mi><mi>l</mi><mi>e</mi><mi>t</mi><mi>e</mi><mi>C</mi><mi>o</mi><mi>n</mi><mi>t</mi><mi>e</mi><mi>x</mi><mi>t</mi><mo stretchy="false">(</mo><mi>c</mi><mi>t</mi><mi>x</mi><mi mathvariant="normal">_</mi><mi>i</mi><mi>d</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">bool\leftarrow deleteContext(ctx\_id)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathnormal">b</span><span class="mord mathnormal">o</span><span class="mord mathnormal">o</span><span class="mord mathnormal" style="margin-right:0.01968em;">l</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">←</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.06em;vertical-align:-0.31em;"></span><span class="mord mathnormal">d</span><span class="mord mathnormal">e</span><span class="mord mathnormal" style="margin-right:0.01968em;">l</span><span class="mord mathnormal">e</span><span class="mord mathnormal">t</span><span class="mord mathnormal">e</span><span class="mord mathnormal" style="margin-right:0.07153em;">C</span><span class="mord mathnormal">o</span><span class="mord mathnormal">n</span><span class="mord mathnormal">t</span><span class="mord mathnormal">e</span><span class="mord mathnormal">x</span><span class="mord mathnormal">t</span><span class="mopen">(</span><span class="mord mathnormal">c</span><span class="mord mathnormal">t</span><span class="mord mathnormal">x</span><span class="mord" style="margin-right:0.02778em;">_</span><span class="mord mathnormal">i</span><span class="mord mathnormal">d</span><span class="mclose">)</span></span></span></span></li><li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>b</mi><mi>o</mi><mi>o</mi><mi>l</mi><mo>←</mo><mi>p</mi><mi>u</mi><mi>t</mi><mo stretchy="false">(</mo><mi>k</mi><mi>e</mi><mi>y</mi><mo separator="true">,</mo><mi>v</mi><mi>a</mi><mi>l</mi><mi>u</mi><mi>e</mi><mo separator="true">,</mo><mi>c</mi><mi>t</mi><mi>x</mi><mi mathvariant="normal">_</mi><mi>i</mi><mi>d</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">bool\leftarrow put(key,value,ctx\_id)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathnormal">b</span><span class="mord mathnormal">o</span><span class="mord mathnormal">o</span><span class="mord mathnormal" style="margin-right:0.01968em;">l</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">←</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.06em;vertical-align:-0.31em;"></span><span class="mord mathnormal">p</span><span class="mord mathnormal">u</span><span class="mord mathnormal">t</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.03148em;">k</span><span class="mord mathnormal">e</span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">v</span><span class="mord mathnormal">a</span><span class="mord mathnormal" style="margin-right:0.01968em;">l</span><span class="mord mathnormal">u</span><span class="mord mathnormal">e</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal">c</span><span class="mord mathnormal">t</span><span class="mord mathnormal">x</span><span class="mord" style="margin-right:0.02778em;">_</span><span class="mord mathnormal">i</span><span class="mord mathnormal">d</span><span class="mclose">)</span></span></span></span></li><li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>v</mi><mi>a</mi><mi>l</mi><mi>u</mi><mi>e</mi><mo>←</mo><mi>g</mi><mi>e</mi><mi>t</mi><mo stretchy="false">(</mo><mi>k</mi><mi>e</mi><mi>y</mi><mo separator="true">,</mo><mi>c</mi><mi>t</mi><mi>x</mi><mi mathvariant="normal">_</mi><mi>i</mi><mi>d</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">value\leftarrow get(key,ctx\_id)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">v</span><span class="mord mathnormal">a</span><span class="mord mathnormal" style="margin-right:0.01968em;">l</span><span class="mord mathnormal">u</span><span class="mord mathnormal">e</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">←</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.06em;vertical-align:-0.31em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">g</span><span class="mord mathnormal">e</span><span class="mord mathnormal">t</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.03148em;">k</span><span class="mord mathnormal">e</span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal">c</span><span class="mord mathnormal">t</span><span class="mord mathnormal">x</span><span class="mord" style="margin-right:0.02778em;">_</span><span class="mord mathnormal">i</span><span class="mord mathnormal">d</span><span class="mclose">)</span></span></span></span> for COPS, or <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">⟨</mo><mi>v</mi><mi>a</mi><mi>l</mi><mi>u</mi><mi>e</mi><mi>s</mi><mo stretchy="false">⟩</mo><mo>←</mo><mi>g</mi><mi>e</mi><mi>t</mi><mi mathvariant="normal">_</mi><mi>t</mi><mi>r</mi><mi>a</mi><mi>n</mi><mi>s</mi><mo stretchy="false">(</mo><mo stretchy="false">⟨</mo><mi>k</mi><mi>e</mi><mi>y</mi><mi>s</mi><mo stretchy="false">⟩</mo><mo separator="true">,</mo><mi>c</mi><mi>t</mi><mi>x</mi><mi mathvariant="normal">_</mi><mi>i</mi><mi>d</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\langle values\rangle\leftarrow get\_trans(\langle keys\rangle,ctx\_id)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">⟨</span><span class="mord mathnormal" style="margin-right:0.03588em;">v</span><span class="mord mathnormal">a</span><span class="mord mathnormal" style="margin-right:0.01968em;">l</span><span class="mord mathnormal">u</span><span class="mord mathnormal">e</span><span class="mord mathnormal">s</span><span class="mclose">⟩</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">←</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.06em;vertical-align:-0.31em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">g</span><span class="mord mathnormal">e</span><span class="mord mathnormal">t</span><span class="mord" style="margin-right:0.02778em;">_</span><span class="mord mathnormal">t</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mord mathnormal">a</span><span class="mord mathnormal">n</span><span class="mord mathnormal">s</span><span class="mopen">(</span><span class="mopen">⟨</span><span class="mord mathnormal" style="margin-right:0.03148em;">k</span><span class="mord mathnormal">e</span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="mord mathnormal">s</span><span class="mclose">⟩</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal">c</span><span class="mord mathnormal">t</span><span class="mord mathnormal">x</span><span class="mord" style="margin-right:0.02778em;">_</span><span class="mord mathnormal">i</span><span class="mord mathnormal">d</span><span class="mclose">)</span></span></span></span> for COPS-GT<ul><li>COPS-GT provides <code>get_trans</code>, which returns a consistent view of multiple key-value pairs in a single call.</li></ul></li></ol><h4 id="what-is-the-context-in-the-library"><a class="markdownIt-Anchor" href="#what-is-the-context-in-the-library"></a> What is the context in the library?</h4><ol><li>All functions take a context argument, which the library uses internally to track causal dependencies across each client’s operations.</li><li>The context defines the causal+ “thread of execution.” A single process may contain many separate threads of execution.</li><li>By separating different threads of execution, COPS avoids false dependencies that would result from intermixing them.</li></ol><h4 id="what-does-cops-gt-store-in-context"><a class="markdownIt-Anchor" href="#what-does-cops-gt-store-in-context"></a> What does COPS-GT store in context?</h4><ol><li><p>The client library in COPS-GT stores the client’s context in a table of <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">⟨</mo><mi>k</mi><mi>e</mi><mi>y</mi><mo separator="true">,</mo><mi>v</mi><mi>e</mi><mi>r</mi><mi>s</mi><mi>i</mi><mi>o</mi><mi>n</mi><mo separator="true">,</mo><mi>d</mi><mi>e</mi><mi>p</mi><mi>s</mi><mo stretchy="false">⟩</mo></mrow><annotation encoding="application/x-tex">\langle key, version, deps\rangle</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">⟨</span><span class="mord mathnormal" style="margin-right:0.03148em;">k</span><span class="mord mathnormal">e</span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">v</span><span class="mord mathnormal">e</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mord mathnormal">s</span><span class="mord mathnormal">i</span><span class="mord mathnormal">o</span><span class="mord mathnormal">n</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal">d</span><span class="mord mathnormal">e</span><span class="mord mathnormal">p</span><span class="mord mathnormal">s</span><span class="mclose">⟩</span></span></span></span> entries.</p><ul><li>Clients reference their context using a context ID (<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>c</mi><mi>t</mi><mi>x</mi><mi mathvariant="normal">_</mi><mi>i</mi><mi>d</mi></mrow><annotation encoding="application/x-tex">ctx\_id</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.00444em;vertical-align:-0.31em;"></span><span class="mord mathnormal">c</span><span class="mord mathnormal">t</span><span class="mord mathnormal">x</span><span class="mord" style="margin-right:0.02778em;">_</span><span class="mord mathnormal">i</span><span class="mord mathnormal">d</span></span></span></span>) in the API.</li></ul></li><li><p>When a client gets a key from the data store, the library adds it and its causal dependencies to the context.</p></li><li><p>When a client puts a value, the library sets the put’s dependencies to the most recent version of each key in the current context.</p><ul><li>A successful put into the data store returns the version number v assigned to the written value.</li><li>The client library then adds this new entry, <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">⟨</mo><mi>k</mi><mi>e</mi><mi>y</mi><mo separator="true">,</mo><mi>v</mi><mo separator="true">,</mo><mi>D</mi><mo stretchy="false">⟩</mo></mrow><annotation encoding="application/x-tex">\langle key, v, D\rangle</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">⟨</span><span class="mord mathnormal" style="margin-right:0.03148em;">k</span><span class="mord mathnormal">e</span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">v</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">D</span><span class="mclose">⟩</span></span></span></span>, to the context.</li></ul></li></ol><h4 id="what-are-the-concerns-of-the-cops-gt-context"><a class="markdownIt-Anchor" href="#what-are-the-concerns-of-the-cops-gt-context"></a> What are the concerns of the COPS-GT context?</h4><ol><li>The context, therefore, includes all values previously read or written in the client’s session and all of those dependencies.</li><li>State requirements for storing these dependencies in the client library and the data store.<ul><li>COPS-GT provides garbage collection to mitigate the client and data-store state required to track dependencies.</li></ul></li><li>Several potential checks must be performed to ensure causal consistency when replicating writes between clusters.<ul><li>The dependencies that must be checked are termed the nearest dependencies.<ul><li>If the storage node commits a node, determining its direct dependencies are committed, it can infer that all former dependencies are also committed.</li><li>Hence, each dependency check only needs to check nodes within <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1</mn></mrow><annotation encoding="application/x-tex">1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">1</span></span></span></span> step in the graph of causal dependencies.</li></ul></li><li>The nearest dependencies are sufficient for the key-value store to provide causal+ consistency.</li><li>The full dependency list is only needed to provide <code>get_trans</code> operations in COPS-GT.</li></ul></li></ol><h4 id="what-does-cops-store-in-context"><a class="markdownIt-Anchor" href="#what-does-cops-store-in-context"></a> What does COPS store in context?</h4><ol><li>It does not store or even retrieve the dependencies of any value it gets<ul><li>The retrieved value is nearer than any of its dependencies, rendering them unnecessary.</li><li>The COPS client library stores only <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">⟨</mo><mi>k</mi><mi>e</mi><mi>y</mi><mo separator="true">,</mo><mi>v</mi><mi>e</mi><mi>r</mi><mi>s</mi><mi>i</mi><mi>o</mi><mi>n</mi><mo stretchy="false">⟩</mo></mrow><annotation encoding="application/x-tex">\langle key, version\rangle</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">⟨</span><span class="mord mathnormal" style="margin-right:0.03148em;">k</span><span class="mord mathnormal">e</span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">v</span><span class="mord mathnormal">e</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mord mathnormal">s</span><span class="mord mathnormal">i</span><span class="mord mathnormal">o</span><span class="mord mathnormal">n</span><span class="mclose">⟩</span></span></span></span> entries.</li></ul></li><li>For a get operation, the retrieved <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">⟨</mo><mi>k</mi><mi>e</mi><mi>y</mi><mo separator="true">,</mo><mi>v</mi><mi>e</mi><mi>r</mi><mi>s</mi><mi>i</mi><mi>o</mi><mi>n</mi><mo stretchy="false">⟩</mo></mrow><annotation encoding="application/x-tex">\langle key, version\rangle</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">⟨</span><span class="mord mathnormal" style="margin-right:0.03148em;">k</span><span class="mord mathnormal">e</span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">v</span><span class="mord mathnormal">e</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mord mathnormal">s</span><span class="mord mathnormal">i</span><span class="mord mathnormal">o</span><span class="mord mathnormal">n</span><span class="mclose">⟩</span></span></span></span> is added to the context.</li><li>For a put operation, the library uses the current context as the nearest dependencies, clears the context, and then repopulates it with only this put.<ul><li>This put depends on all previous key-version pairs and thus is nearer than them.</li></ul></li></ol><h4 id="how-does-cops-or-cops-gt-write-to-the-local-cluster"><a class="markdownIt-Anchor" href="#how-does-cops-or-cops-gt-write-to-the-local-cluster"></a> How does COPS (or COPS-GT) write to the local cluster?</h4><ol><li>All writes in COPS first go to the client’s local cluster and then propagate asynchronously to remote clusters.</li><li>The key-value store exports a single API call to provide both operations: <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">⟨</mo><mi>b</mi><mi>o</mi><mi>o</mi><mi>l</mi><mo separator="true">,</mo><mi>v</mi><mi>e</mi><mi>r</mi><mi>s</mi><mo stretchy="false">⟩</mo><mo>←</mo><mi>p</mi><mi>u</mi><mi>t</mi><mi mathvariant="normal">_</mi><mi>a</mi><mi>f</mi><mi>t</mi><mi>e</mi><mi>r</mi><mo stretchy="false">(</mo><mi>k</mi><mi>e</mi><mi>y</mi><mo separator="true">,</mo><mi>v</mi><mi>a</mi><mi>l</mi><mo separator="true">,</mo><mo stretchy="false">[</mo><mi>d</mi><mi>e</mi><mi>p</mi><mi>s</mi><mo stretchy="false">]</mo><mo separator="true">,</mo><mi>n</mi><mi>e</mi><mi>a</mi><mi>r</mi><mi>e</mi><mi>s</mi><mi>t</mi><mo separator="true">,</mo><mi>v</mi><mi>e</mi><mi>r</mi><mi>s</mi><mo>=</mo><mi mathvariant="normal">∅</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\langle bool,vers\rangle \leftarrow put\_after(key,val,[deps],nearest,vers=\empty)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">⟨</span><span class="mord mathnormal">b</span><span class="mord mathnormal">o</span><span class="mord mathnormal">o</span><span class="mord mathnormal" style="margin-right:0.01968em;">l</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">v</span><span class="mord mathnormal">e</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mord mathnormal">s</span><span class="mclose">⟩</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">←</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.06em;vertical-align:-0.31em;"></span><span class="mord mathnormal">p</span><span class="mord mathnormal">u</span><span class="mord mathnormal">t</span><span class="mord" style="margin-right:0.02778em;">_</span><span class="mord mathnormal">a</span><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="mord mathnormal">t</span><span class="mord mathnormal">e</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.03148em;">k</span><span class="mord mathnormal">e</span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">v</span><span class="mord mathnormal">a</span><span class="mord mathnormal" style="margin-right:0.01968em;">l</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mopen">[</span><span class="mord mathnormal">d</span><span class="mord mathnormal">e</span><span class="mord mathnormal">p</span><span class="mord mathnormal">s</span><span class="mclose">]</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal">n</span><span class="mord mathnormal">e</span><span class="mord mathnormal">a</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mord mathnormal">e</span><span class="mord mathnormal">s</span><span class="mord mathnormal">t</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">v</span><span class="mord mathnormal">e</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mord mathnormal">s</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord">∅</span><span class="mclose">)</span></span></span></span></li><li>When a client calls <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi><mi>u</mi><mi>t</mi><mo stretchy="false">(</mo><mi>k</mi><mi>e</mi><mi>y</mi><mo separator="true">,</mo><mi>v</mi><mi>a</mi><mi>l</mi><mo separator="true">,</mo><mi>c</mi><mi>t</mi><mi>x</mi><mi mathvariant="normal">_</mi><mi>i</mi><mi>d</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">put (key,val,ctx\_id)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.06em;vertical-align:-0.31em;"></span><span class="mord mathnormal">p</span><span class="mord mathnormal">u</span><span class="mord mathnormal">t</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.03148em;">k</span><span class="mord mathnormal">e</span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">v</span><span class="mord mathnormal">a</span><span class="mord mathnormal" style="margin-right:0.01968em;">l</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal">c</span><span class="mord mathnormal">t</span><span class="mord mathnormal">x</span><span class="mord" style="margin-right:0.02778em;">_</span><span class="mord mathnormal">i</span><span class="mord mathnormal">d</span><span class="mclose">)</span></span></span></span>,<ul><li>The library computes the complete set of dependencies <code>deps</code> and identifies some of those dependency tuples as the value’s nearest ones.</li><li>The library then calls put after without the version argument (i.e., it sets <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>v</mi><mi>e</mi><mi>r</mi><mi>s</mi><mi>i</mi><mi>o</mi><mi>n</mi><mo>=</mo><mi mathvariant="normal">∅</mi></mrow><annotation encoding="application/x-tex">version=\empty</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.65952em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">v</span><span class="mord mathnormal">e</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mord mathnormal">s</span><span class="mord mathnormal">i</span><span class="mord mathnormal">o</span><span class="mord mathnormal">n</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.80556em;vertical-align:-0.05556em;"></span><span class="mord">∅</span></span></span></span>).</li><li>The library includes <code>deps</code> in the put_after call in COPS-GT because dependencies must be stored with the value.</li><li>In COPS, the library only needs to include the nearest and does not include <code>deps</code>.</li></ul></li><li>The key’s primary storage node in the local cluster assigns the key a version number and returns it to the client library.</li><li>Each client is restricted to a single outstanding put; this is necessary because later puts must know the version numbers of earlier puts so that they may depend on them.</li><li>The put-after operation ensures that val is committed to each cluster only after all of the entries in its dependency list have been written.<ul><li>This property is automatically held in the client’s local cluster, as the local store provides linearizability.</li><li>If <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>y</mi></mrow><annotation encoding="application/x-tex">y</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span></span></span></span> depends on <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>x</mi></mrow><annotation encoding="application/x-tex">x</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathnormal">x</span></span></span></span>, then <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi><mi>u</mi><mi>t</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">put(x)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">p</span><span class="mord mathnormal">u</span><span class="mord mathnormal">t</span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mclose">)</span></span></span></span> must have been committed before <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi><mi>u</mi><mi>t</mi><mo stretchy="false">(</mo><mi>y</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">put(y)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">p</span><span class="mord mathnormal">u</span><span class="mord mathnormal">t</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="mclose">)</span></span></span></span> was issued.</li></ul></li></ol><h4 id="how-to-replica-writes-between-clusters"><a class="markdownIt-Anchor" href="#how-to-replica-writes-between-clusters"></a> How to replica writes between clusters?</h4><ol><li>After a write commits locally, the primary storage node asynchronously replicates that writes to its equivalent nodes in different clusters using a stream of <code>put_after</code> operations.<ul><li>The primary node includes the key’s version number in the put-after the call.</li><li>The <code>deps</code> argument is included in COPS-GT and not included in COPS.</li></ul></li><li>It requires the remote nodes receiving updates to commit an update only after its dependencies have been committed to the same cluster.<ul><li>A node that receives a put-after a request from another cluster must determine if the value’s nearest dependencies have already been satisfied locally.</li><li>It does so by issuing a check to the local nodes responsible for those dependencies: <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>b</mi><mi>o</mi><mi>o</mi><mi>l</mi><mo>←</mo><mi>d</mi><mi>e</mi><mi>p</mi><mi mathvariant="normal">_</mi><mi>c</mi><mi>h</mi><mi>e</mi><mi>c</mi><mi>k</mi><mo stretchy="false">(</mo><mi>k</mi><mi>e</mi><mi>y</mi><mo separator="true">,</mo><mi>v</mi><mi>e</mi><mi>r</mi><mi>s</mi><mi>i</mi><mi>o</mi><mi>n</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">bool\leftarrow dep\_check(key, version)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathnormal">b</span><span class="mord mathnormal">o</span><span class="mord mathnormal">o</span><span class="mord mathnormal" style="margin-right:0.01968em;">l</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">←</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.06em;vertical-align:-0.31em;"></span><span class="mord mathnormal">d</span><span class="mord mathnormal">e</span><span class="mord mathnormal">p</span><span class="mord" style="margin-right:0.02778em;">_</span><span class="mord mathnormal">c</span><span class="mord mathnormal">h</span><span class="mord mathnormal">e</span><span class="mord mathnormal">c</span><span class="mord mathnormal" style="margin-right:0.03148em;">k</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.03148em;">k</span><span class="mord mathnormal">e</span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">v</span><span class="mord mathnormal">e</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mord mathnormal">s</span><span class="mord mathnormal">i</span><span class="mord mathnormal">o</span><span class="mord mathnormal">n</span><span class="mclose">)</span></span></span></span></li><li>The way that nearest dependencies are computed ensures that all dependencies have been satisfied before the value is committed, ensuring causal consistency.</li></ul></li></ol><h4 id="how-to-read-values-in-cops"><a class="markdownIt-Anchor" href="#how-to-read-values-in-cops"></a> How to read values in COPS?</h4><ol><li>Reads are satisfied in the local cluster.</li><li>The library issues a read to the node responsible for the key in the local cluster: <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">⟨</mo><mi>v</mi><mi>a</mi><mi>l</mi><mi>u</mi><mi>e</mi><mo separator="true">,</mo><mi>v</mi><mi>e</mi><mi>r</mi><mi>s</mi><mi>i</mi><mi>o</mi><mi>n</mi><mo separator="true">,</mo><mi>d</mi><mi>e</mi><mi>p</mi><mi>s</mi><mo stretchy="false">⟩</mo><mo>←</mo><mi>g</mi><mi>e</mi><mi>t</mi><mi mathvariant="normal">_</mi><mi>b</mi><mi>y</mi><mi mathvariant="normal">_</mi><mi>v</mi><mi>e</mi><mi>r</mi><mi>s</mi><mi>i</mi><mi>o</mi><mi>n</mi><mo stretchy="false">(</mo><mi>k</mi><mi>e</mi><mi>y</mi><mo separator="true">,</mo><mi>v</mi><mi>e</mi><mi>r</mi><mi>s</mi><mi>i</mi><mi>o</mi><mi>n</mi><mo>=</mo><mi>L</mi><mi>A</mi><mi>T</mi><mi>E</mi><mi>S</mi><mi>T</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\langle value, version,deps\rangle\leftarrow get\_by\_version(key,version=LATEST)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">⟨</span><span class="mord mathnormal" style="margin-right:0.03588em;">v</span><span class="mord mathnormal">a</span><span class="mord mathnormal" style="margin-right:0.01968em;">l</span><span class="mord mathnormal">u</span><span class="mord mathnormal">e</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">v</span><span class="mord mathnormal">e</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mord mathnormal">s</span><span class="mord mathnormal">i</span><span class="mord mathnormal">o</span><span class="mord mathnormal">n</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal">d</span><span class="mord mathnormal">e</span><span class="mord mathnormal">p</span><span class="mord mathnormal">s</span><span class="mclose">⟩</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">←</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.06em;vertical-align:-0.31em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">g</span><span class="mord mathnormal">e</span><span class="mord mathnormal">t</span><span class="mord" style="margin-right:0.02778em;">_</span><span class="mord mathnormal">b</span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="mord" style="margin-right:0.02778em;">_</span><span class="mord mathnormal" style="margin-right:0.03588em;">v</span><span class="mord mathnormal">e</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mord mathnormal">s</span><span class="mord mathnormal">i</span><span class="mord mathnormal">o</span><span class="mord mathnormal">n</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.03148em;">k</span><span class="mord mathnormal">e</span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">v</span><span class="mord mathnormal">e</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mord mathnormal">s</span><span class="mord mathnormal">i</span><span class="mord mathnormal">o</span><span class="mord mathnormal">n</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">L</span><span class="mord mathnormal">A</span><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="mord mathnormal" style="margin-right:0.05764em;">E</span><span class="mord mathnormal" style="margin-right:0.05764em;">S</span><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="mclose">)</span></span></span></span></li><li>This read can request either the latest version of the key or a specific older one. Requesting a particular version is necessary to enable get transactions.</li><li>Upon receiving a response, the client library adds the <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">⟨</mo><mi>k</mi><mi>e</mi><mi>y</mi><mo separator="true">,</mo><mi>v</mi><mi>e</mi><mi>r</mi><mi>s</mi><mi>i</mi><mi>o</mi><mi>n</mi><mo separator="true">,</mo><mo stretchy="false">[</mo><mi>d</mi><mi>e</mi><mi>p</mi><mi>s</mi><mo stretchy="false">]</mo><mo stretchy="false">⟩</mo></mrow><annotation encoding="application/x-tex">\langle key,version,[deps]\rangle</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">⟨</span><span class="mord mathnormal" style="margin-right:0.03148em;">k</span><span class="mord mathnormal">e</span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">v</span><span class="mord mathnormal">e</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mord mathnormal">s</span><span class="mord mathnormal">i</span><span class="mord mathnormal">o</span><span class="mord mathnormal">n</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mopen">[</span><span class="mord mathnormal">d</span><span class="mord mathnormal">e</span><span class="mord mathnormal">p</span><span class="mord mathnormal">s</span><span class="mclose">]</span><span class="mclose">⟩</span></span></span></span> tuple to the client context and returns value to the calling code.</li><li>The <code>deps</code> are stored only in COPS-GT, not in COPS.</li></ol><h4 id="why-does-cops-gt-need-to-provide-get_trans-what-is-wrong-with-the-get-interface"><a class="markdownIt-Anchor" href="#why-does-cops-gt-need-to-provide-get_trans-what-is-wrong-with-the-get-interface"></a> Why does COPS-GT need to provide get_trans? What is wrong with the get interface?</h4><ol><li>Reading a set of dependent keys using a single-key get interface cannot ensure causal+ consistency, even though the data store itself is causal+ consistent.</li><li>It may have a “time-to-check-to-time-to-use” race condition, i.e., check operation and usage is not an atomic operation.</li><li>The standard way to achieve such a guarantee is to read and write all related keys in a transaction.<ul><li>This requires a single serialization point for all grouped keys, which COPS avoids for greater scalability and simplicity.</li></ul></li></ol><h4 id="how-does-get_trans-work"><a class="markdownIt-Anchor" href="#how-does-get_trans-work"></a> How does get_trans work?</h4><ol><li><p>To retrieve multiple values in a causal+ consistent manner, client calls get trans with the desired set of keys.</p></li><li><p>In the first round, the library issues <code>n</code> concurrent <code>get_by_version</code> operations to the local cluster, one for each key the client listed in <code>get_trans</code>.</p><ul><li><p>Because COPS-GT commits writes locally, the local data store guarantees that these explicitly listed keys’ dependencies are satisfied.</p></li><li><p>All listed keys have been written locally, and their reads will immediately be returned.</p></li><li><p>Each <code>get_by_version</code> operation returns a <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">⟨</mo><mi>v</mi><mi>a</mi><mi>l</mi><mi>u</mi><mi>e</mi><mo separator="true">,</mo><mi>v</mi><mi>e</mi><mi>r</mi><mi>s</mi><mi>i</mi><mi>o</mi><mi>n</mi><mo separator="true">,</mo><mi>d</mi><mi>e</mi><mi>p</mi><mi>s</mi><mo stretchy="false">⟩</mo></mrow><annotation encoding="application/x-tex">\langle value, version, deps\rangle</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">⟨</span><span class="mord mathnormal" style="margin-right:0.03588em;">v</span><span class="mord mathnormal">a</span><span class="mord mathnormal" style="margin-right:0.01968em;">l</span><span class="mord mathnormal">u</span><span class="mord mathnormal">e</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">v</span><span class="mord mathnormal">e</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mord mathnormal">s</span><span class="mord mathnormal">i</span><span class="mord mathnormal">o</span><span class="mord mathnormal">n</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal">d</span><span class="mord mathnormal">e</span><span class="mord mathnormal">p</span><span class="mord mathnormal">s</span><span class="mclose">⟩</span></span></span></span> tuple, where <code>deps</code> is a list of keys and versions.</p></li></ul></li><li><p>The client library then examines every dependency entry <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">⟨</mo><mi>k</mi><mi>e</mi><mi>y</mi><mo separator="true">,</mo><mi>v</mi><mi>e</mi><mi>r</mi><mi>s</mi><mi>i</mi><mi>o</mi><mi>n</mi><mo stretchy="false">⟩</mo></mrow><annotation encoding="application/x-tex">\langle key, version\rangle</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">⟨</span><span class="mord mathnormal" style="margin-right:0.03148em;">k</span><span class="mord mathnormal">e</span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">v</span><span class="mord mathnormal">e</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mord mathnormal">s</span><span class="mord mathnormal">i</span><span class="mord mathnormal">o</span><span class="mord mathnormal">n</span><span class="mclose">⟩</span></span></span></span>.</p><ul><li>The causal dependencies for that result are satisfied if either the client did not request the dependent key or it did, the version it retrieved was <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>≥</mo></mrow><annotation encoding="application/x-tex">≥</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7719400000000001em;vertical-align:-0.13597em;"></span><span class="mrel">≥</span></span></span></span> the version in the dependency list.</li></ul></li><li><p>For all keys that are not satisfied, the library issues a second round of concurrent get by version operations.</p><ul><li>The version requested will be the newest version seen in any dependency list from the first round.</li><li>These versions satisfy all causal dependencies from the first round because they are <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>≥</mo></mrow><annotation encoding="application/x-tex">≥</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7719400000000001em;vertical-align:-0.13597em;"></span><span class="mrel">≥</span></span></span></span> the needed versions.</li><li>Because dependencies are transitive and these second-round versions depend on versions retrieved in the first round, they do not introduce any new dependencies that must be satisfied.</li></ul></li><li><p>The second round happens only when the client must read newer versions than those retrieved in the first round.</p><ul><li>This case occurs only if keys involved in the get transaction are updated during the first round.</li></ul></li></ol><h3 id="garbage-collection"><a class="markdownIt-Anchor" href="#garbage-collection"></a> Garbage collection</h3><h4 id="how-does-cops-gt-collect-version-garbage"><a class="markdownIt-Anchor" href="#how-does-cops-gt-collect-version-garbage"></a> How does COPS-GT collect version garbage?</h4><ol><li>The <code>get_trans</code> algorithm limits the number of versions needed to complete a get transaction.<ul><li>COPS-GT limits the total running time of get trans through a configurable parameter, <code>trans_time</code>.</li><li>If the timeout fires, the client library will restart the get trans call and satisfy the transaction with newer versions of the keys.</li></ul></li><li>After a new version of a key is written, COPS-GT only needs to keep the old version around for <code>trans_time</code> plus a small delta for clock skew.</li><li>The space overhead is bounded by the number of old versions created within the <code>trans_time</code>.<ul><li>This number is determined by the maximum write throughput that the node can sustain.</li><li>This overhead is per-machine and does not grow with the cluster size or the number of datacenters.</li></ul></li></ol><h4 id="how-does-cops-gt-collect-dependency-garbage"><a class="markdownIt-Anchor" href="#how-does-cops-gt-collect-dependency-garbage"></a> How does COPS-GT collect dependency garbage?</h4><ol><li>COPS-GT can garbage collect these dependencies once the versions associated with old dependencies are no longer needed for correctness in get transaction operations.</li><li>After <code>trans_time</code> seconds after a value has been committed in all datacenters, COPS-GT can clean a value’s dependencies.<ul><li>To clean dependencies, each remote datacenter notifies the originating datacenter when the write has been committed and the timeout period has elapsed.</li><li>Once all datacenters have confirmed, the originating datacenter cleans its dependencies and informs the others to do likewise.</li></ul></li><li>To minimize bandwidth devoted to cleaning dependencies, a replica only notifies the originating datacenter if this version of a key is the newest after <code>trans_time</code> seconds<ul><li>If it is not, there is no need to collect the dependencies because the entire version will be collected.</li></ul></li><li>Under regular operation, dependencies are garbage collected after <code>trans_time</code> plus a round-trip time.</li><li>During a partition, dependencies on the most recent versions of keys cannot be collected.</li></ol><h4 id="how-does-cops-collect-client-metadata-garbage"><a class="markdownIt-Anchor" href="#how-does-cops-collect-client-metadata-garbage"></a> How does COPS collect client metadata garbage?</h4><ol><li>The COPS client library tracks all operations during a client session (single thread of execution) using the <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>c</mi><mi>t</mi><mi>x</mi><mi mathvariant="normal">_</mi><mi>i</mi><mi>d</mi></mrow><annotation encoding="application/x-tex">ctx\_id</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.00444em;vertical-align:-0.31em;"></span><span class="mord mathnormal">c</span><span class="mord mathnormal">t</span><span class="mord mathnormal">x</span><span class="mord" style="margin-right:0.02778em;">_</span><span class="mord mathnormal">i</span><span class="mord mathnormal">d</span></span></span></span> passed with all operations.<ul><li>In both systems, each get since the last put adds another nearest dependency.</li><li>Additionally, in COPS-GT, all new values and their dependencies are returned in get trans operations, and all put operations add normal dependencies.</li></ul></li><li>Clients need to track dependencies only until they are guaranteed to be satisfied everywhere.</li><li>Once a <code>put_after</code> commits successfully to all datacenters, COPS flags that key version as <em>never-depend</em> to indicate that clients need not express a dependence upon it.<ul><li>The client library will immediately remove a never-depend item from the list of dependencies in the client context.</li><li>Anything that a never-depend key depended on must have been flagged never-depend, so it too can be garbage collected from the context.</li></ul></li><li>The COPS storage nodes remove unnecessary dependencies from <code>put_after</code> operations.<ul><li>When a node receives a <code>put_after</code>, it checks each item in the dependency list and removes items with version numbers older than a global checkpoint time.</li></ul></li></ol><h3 id="fault-tolerance"><a class="markdownIt-Anchor" href="#fault-tolerance"></a> Fault tolerance</h3><h4 id="how-does-cops-handle-client-failures"><a class="markdownIt-Anchor" href="#how-does-cops-handle-client-failures"></a> How does COPS handle client failures?</h4><ol><li>From the storage system’s perspective, if a client fails, it simply stops issuing new requests; no recovery is necessary.</li><li>From a client’s perspective, COPS’s dependency tracking makes it easier to handle failures of other clients by ensuring properties such as referential integrity.</li></ol><h4 id="how-does-cops-handle-key-value-node-failures"><a class="markdownIt-Anchor" href="#how-does-cops-handle-key-value-node-failures"></a> How does COPS handle key-value node failures?</h4><ol><li><p>COPS can use any underlying fault-tolerant linearizable key-value store.</p><ul><li>The author uses chain replication within a cluster to mask node failures.</li></ul></li><li><p>Dependency garbage collection follows a similar pattern of interlocking chains.</p><p>Version garbage is collected locally on each node and can operate as in the single-node case.</p><p>The global checkpoint time calculation for client metadata garbage collection operates normally, with each tail updating its corresponding key range minimums.</p></li></ol><h4 id="what-will-happen-when-the-datacenter-fails"><a class="markdownIt-Anchor" href="#what-will-happen-when-the-datacenter-fails"></a> What will happen when the datacenter fails?</h4><ol><li>Any put-after operations that originated in the failed datacenter but were not yet copied out will be lost.</li><li>The storage required for replication queues in the active datacenters will grow.<ul><li>They will be unable to send put-after operations to the failed datacenter, and thus, COPS will be unable to garbage collect those dependencies.</li><li>Solutions: Allow the queues to grow if the partition is likely to heal soon, or reconfigure COPS to no longer use the failed datacenter.</li></ul></li></ol><h4 id="how-does-cops-with-conflict-detection-cops-cd-detect-conflict"><a class="markdownIt-Anchor" href="#how-does-cops-with-conflict-detection-cops-cd-detect-conflict"></a> How does COPS with conflict detection (COPS-CD) detect conflict?</h4><ol><li>All put operations carry with them previous version metadata.<ul><li>It indicates the most recent previous version of the key that was visible at the local cluster at the time of the write.</li></ul></li><li>All put operations now have an implicit dependency on the previous version.<ul><li>This ensures that a new version will only be written after its previous version.</li></ul></li><li>COPS-CD has an applicationspecified convergent conflict handler invoked when a conflict is detected.<ul><li>A put operation <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi><mi>e</mi><mi>w</mi></mrow><annotation encoding="application/x-tex">new</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathnormal">n</span><span class="mord mathnormal">e</span><span class="mord mathnormal" style="margin-right:0.02691em;">w</span></span></span></span> to a key (with the previous version <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi><mi>r</mi><mi>e</mi><mi>v</mi></mrow><annotation encoding="application/x-tex">prev</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord mathnormal">p</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mord mathnormal">e</span><span class="mord mathnormal" style="margin-right:0.03588em;">v</span></span></span></span>) conflicts with the key’s current visible version <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>c</mi><mi>u</mi><mi>r</mi><mi>r</mi></mrow><annotation encoding="application/x-tex">curr</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathnormal">c</span><span class="mord mathnormal">u</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span></span></span></span>: <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi><mi>r</mi><mi>e</mi><mi>v</mi><mo mathvariant="normal">≠</mo><mi>c</mi><mi>u</mi><mi>r</mi><mi>r</mi></mrow><annotation encoding="application/x-tex">prev \neq curr</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord mathnormal">p</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mord mathnormal">e</span><span class="mord mathnormal" style="margin-right:0.03588em;">v</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel"><span class="mrel"><span class="mord vbox"><span class="thinbox"><span class="rlap"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="inner"><span class="mrel"></span></span><span class="fix"></span></span></span></span></span><span class="mrel">=</span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathnormal">c</span><span class="mord mathnormal">u</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span></span></span></span> if and only if <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi><mi>e</mi><mi>w</mi></mrow><annotation encoding="application/x-tex">new</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathnormal">n</span><span class="mord mathnormal">e</span><span class="mord mathnormal" style="margin-right:0.02691em;">w</span></span></span></span> and <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>c</mi><mi>u</mi><mi>r</mi><mi>r</mi></mrow><annotation encoding="application/x-tex">curr</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathnormal">c</span><span class="mord mathnormal">u</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span></span></span></span> conflict.</li></ul></li></ol>]]></content>
      
      
      <categories>
          
          <category> Paper Notebook </category>
          
          <category> Distributed System </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Distributed System </tag>
            
            <tag> Consistency Level </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Memcache</title>
      <link href="/2023/09/26/Paper/Distributed/Memcache/"/>
      <url>/2023/09/26/Paper/Distributed/Memcache/</url>
      
        <content type="html"><![CDATA[<p>Paper: <a href="http://nil.csail.mit.edu/6.824/2020/papers/memcache-fb.pdf">Scaling Memcache at Facebook</a></p><p><ul class="markdownIt-TOC"><li><a href="#purpose">Purpose</a></li><li><a href="#model">Model</a><ul><li><a href="#overview">Overview</a><ul><li><a href="#how-are-queries-carried-out-with-memcache">How are queries carried out with memcache?</a></li><li><a href="#how-does-writing-carry-out-with-memcache">How does writing carry out with memcache?</a></li><li><a href="#what-are-the-stages-of-problems-when-users-increase">What are the stages of problems when users increase?</a></li><li><a href="#what-are-the-consistent-requirements">What are the consistent requirements?</a></li></ul></li><li><a href="#in-a-cluster-latency-and-load">In a cluster: latency and load</a><ul><li><a href="#how-do-clients-communicate-with-memcached-servers">How do clients communicate with memcached servers?</a></li><li><a href="#how-to-handle-incast-congestion">How to handle incast congestion?</a></li><li><a href="#how-to-prevent-stale-sets-problem">How to prevent stale sets problem?</a></li><li><a href="#how-to-prevent-thundering-herds">How to prevent thundering herds?</a></li><li><a href="#how-to-prevent-hit-rates-from-decreasing-caused-by-different-client-access-patterns">How to prevent hit rates from decreasing caused by different client access patterns?</a></li><li><a href="#how-to-handle-a-small-number-of-memcache-servers-inaccessible-due-to-network-or-server-failure">How to handle a small number of memcache servers inaccessible due to network or server failure?</a></li></ul></li><li><a href="#in-a-region-replication">In a region: replication</a><ul><li><a href="#what-is-the-problem-of-scaling-memcache">What is the problem of scaling memcache?</a></li><li><a href="#how-to-mitigate-the-poor-hit-rates-when-a-cold-cluster-starts-up">How to mitigate the poor hit rates when a cold cluster starts up?</a></li><li><a href="#how-to-solve-the-race-in-cold-cluster-warmup-caused-by-an-update-in-the-cold-cluster">How to solve the race in cold cluster warmup caused by an update in the cold cluster?</a></li></ul></li><li><a href="#across-regions-consistency">Across regions: consistency</a><ul><li><a href="#how-to-execute-a-write-operation">How to execute a write operation?</a></li></ul></li></ul></li></ul></p><h1 id="purpose"><a class="markdownIt-Anchor" href="#purpose"></a> Purpose</h1><ol><li><p>Issues:</p><ul><li>Users consume an order of magnitude more content than they create.<ul><li>This behavior results in a workload dominated by fetching data and suggests that caching can have significant advantages.</li></ul></li><li>Read operations fetch data from a variety of sources.<ul><li>This heterogeneity requires a flexible caching strategy to store data from disparate sources.</li></ul></li></ul></li><li><p>What is the requirement of a social network’s infrastructure?</p><ul><li><p>Allow near real-time communication.</p></li><li><p>Aggregate content on-the-fly from multiple sources</p></li><li><p>Be able to access and update very popular shared content.</p></li><li><p>Scale to process millions of user requests per second</p></li></ul></li><li><p>Memcached is an open-source implementation of an in-memory hash table, which provides low-latency access to a shared storage pool at a low cost.</p></li><li><p>Findings:</p><ul><li>While qualities like performance, efficiency, fault tolerance, and consistency are important at all scales and specific sizes, some qualities require more effort than others.</li><li>The importance of finding an optimal communication schedule increases as the number of servers increases and networking becomes the bottleneck.</li></ul></li></ol><h1 id="model"><a class="markdownIt-Anchor" href="#model"></a> Model</h1><h2 id="overview"><a class="markdownIt-Anchor" href="#overview"></a> Overview</h2><h3 id="how-are-queries-carried-out-with-memcache"><a class="markdownIt-Anchor" href="#how-are-queries-carried-out-with-memcache"></a> How are queries carried out with memcache?</h3><ol><li>When a web server needs data, it first requests the value from memcache by providing a string key.</li><li>If the item that the key addresses is not cached, the web server retrieves the data from the database or other backend service and populates the cache with the key-value pair.</li></ol><img src="/imgs/Distributed/Memcache/read.png" width="30%"><h3 id="how-does-writing-carry-out-with-memcache"><a class="markdownIt-Anchor" href="#how-does-writing-carry-out-with-memcache"></a> How does writing carry out with memcache?</h3><ol><li>The web server issues SQL statements to the database for write requests and then sends a delete request to memcache that invalidates stale data.</li><li>We delete cached data instead of updating it because deletes are idempotent.<ul><li>Considering two concurrent writes, there is no guarantee that the update operation will be in the same order as the database updates.</li><li>If database updates write A first, then write B while the Memcache set write B first then write A, the Memcache would be inconsistent with the database.</li></ul></li></ol><img src="/imgs/Distributed/Memcache/write.png" width="30%"><h3 id="what-are-the-stages-of-problems-when-users-increase"><a class="markdownIt-Anchor" href="#what-are-the-stages-of-problems-when-users-increase"></a> What are the stages of problems when users increase?</h3><ol><li>Initially, there were few users; the service could be provided with a single server running both scripts and the database.</li><li>As the number of users grows, the first problem is usually that the server runs out of CPU to execute scripts.<ul><li>Hence, the solution is to use multiple servers to run scripts and another server to run the database.</li></ul></li><li>If the number of users keeps growing, the next problem is that the database runs out of steam.<ul><li>The solution usually uses a distributed sharding database system. This is when all those consistent problems come.</li></ul></li><li>However, the MySQL cannot process reads and writes fast. And if some keys are the hot zone, no matter how delicate we shard, there is only one group for that key.<ul><li>Facebook uses Memcache to solve this situation when Memcache servers absorb most read requests; only a few are exposed to database servers.</li></ul></li></ol><h3 id="what-are-the-consistent-requirements"><a class="markdownIt-Anchor" href="#what-are-the-consistent-requirements"></a> What are the consistent requirements?</h3><ol><li>When users only read data, they can barely notice the stale data for a few seconds, but not too long, like data from yesterday.</li><li>When users change something, if they immediately try to read it, they should see the data they changed. There should not be any stale in this case.</li></ol><h2 id="in-a-cluster-latency-and-load"><a class="markdownIt-Anchor" href="#in-a-cluster-latency-and-load"></a> In a cluster: latency and load</h2><h3 id="how-do-clients-communicate-with-memcached-servers"><a class="markdownIt-Anchor" href="#how-do-clients-communicate-with-memcached-servers"></a> How do clients communicate with memcached servers?</h3><ol><li>Client logic is provided as two components: a library that can be embedded into applications or a standalone proxy named <em>mcrouter</em>.<ul><li>This proxy presents a Memcached server interface and routes the requests/replies to/from other servers.</li></ul></li><li><code>Get</code> requests relies on UDP to reduce latency and overhead.<ul><li>Each thread in the web server is allowed to communicate with <em>Memcached</em> servers directly, bypassing <em>mcrouter</em> without establishing and maintaining a connection, thereby reducing the overhead.</li><li>The UDP implementation detects packets that are dropped or received out of order (using sequence numbers) and treats them as errors on the client side. It does not provide any mechanism to try to recover from them.</li></ul></li><li>For reliability, clients perform <code>set</code> and <code>delete</code> operations over TCP through an instance of <em>mcrouter</em> running on the same machine as the web server.<ul><li>For operations where we need to confirm a state change (<code>update</code>s and <code>delete</code>s), TCP alleviates the need to add a retry mechanism to our UDP implementation.</li></ul></li></ol><h3 id="how-to-handle-incast-congestion"><a class="markdownIt-Anchor" href="#how-to-handle-incast-congestion"></a> How to handle incast congestion?</h3><ol><li>Web servers must routinely communicate with many memcached servers to satisfy user requests.<ul><li>As a result, all web servers communicate with every memcached server in a short period.</li><li>This all-to-all communication pattern can cause incast congestion or allow a single server to become the bottleneck for many web servers.</li></ul></li><li>Memcache clients implement flow control mechanisms to limit incast congestion.<ul><li>Clients use a sliding window mechanism to control the number of outstanding requests.</li><li>The size of this sliding window grows slowly upon a successful request and shrinks when a request goes unanswered.</li><li>With lower window sizes, the application will have to dispatch more groups of memcache requests serially, increasing the duration of the web request.</li><li>As the window size gets too large, the number of simultaneous memcache requests causes incast congestion.</li></ul></li></ol><h3 id="how-to-prevent-stale-sets-problem"><a class="markdownIt-Anchor" href="#how-to-prevent-stale-sets-problem"></a> How to prevent stale sets problem?</h3><ol><li>A stale set occurs when a web server sets a value in <em>memcache</em> that does not reflect the latest value that should be cached.<ul><li>For example, when server A tried to read an entry <code>get(k)</code> and missed, it read a value <code>v1</code> from the database. But before its <code>set(k, v1)</code> is executed, another server updated <code>k=v2</code> and executed <code>delete(k)</code>.</li><li>The problem is that after <code>delete(k)</code> is executed, there is no mechanism to prevent the stale <code>set(k, v1)</code> from being executed. Hence, a stale entry will be left in the <em>memcache</em> for an indefinite long time.</li></ul></li><li>A memcached instance gives a lease to a client to set data back into the cache when that client experiences a cache miss.<ul><li>The lease is a 64-bit token bound to the specific key the client originally requested.</li><li>The client provides the lease token when setting the value in the cache.</li><li>Verification can fail if Memcached has invalidated the lease token due to receiving a delete request for that item.</li></ul></li></ol><h3 id="how-to-prevent-thundering-herds"><a class="markdownIt-Anchor" href="#how-to-prevent-thundering-herds"></a> How to prevent thundering herds?</h3><ol><li>A thundering herd happens when a specific key undergoes heavy read and write activity.<ul><li>If one client updates the database and deletes a key, many clients get() but miss, causing them to try to fetch from the database and all <code>set()</code>.</li></ul></li><li>Each memcached server regulates the rate at which it returns lease tokens.<ul><li>Each memcached server only returns a lease token every period.</li><li>Other cache misses during that period will receive a special notification telling the client to wait a short time.</li><li>Return a lease every period instead of only returning to the first cache miss to prevent the first client from acquiring data from the database.</li></ul></li></ol><h3 id="how-to-prevent-hit-rates-from-decreasing-caused-by-different-client-access-patterns"><a class="markdownIt-Anchor" href="#how-to-prevent-hit-rates-from-decreasing-caused-by-different-client-access-patterns"></a> How to prevent hit rates from decreasing caused by different client access patterns?</h3><ol><li>A cluster’s memcached servers are partitioned into separate pools.<ul><li>One pool (named <em>wildcard</em>) is designated as the default.</li><li>Separate pools are provided for keys whose residence in wildcard is problematic.</li></ul></li><li>Within some pools, replication can be used to improve the latency and efficiency.<ul><li>Choose to replicate a category of keys within a pool when<ul><li>The application routinely fetches many keys simultaneously.</li><li>The entire data set fits in one or two Memcached servers.</li><li>The request rate is much higher than what a single server can manage.</li></ul></li><li>Favor replication in this instance over further dividing the key space due to the following reasons:<ul><li>The difference in memcached overhead for retrieving 100 keys per request instead of 1 key is small.</li><li>Replicating can reduce the requests that need to be processed by each server while dividing the key space can only reduce the keys retrieved from each server and increase the number of requests.</li></ul></li></ul></li></ol><h3 id="how-to-handle-a-small-number-of-memcache-servers-inaccessible-due-to-network-or-server-failure"><a class="markdownIt-Anchor" href="#how-to-handle-a-small-number-of-memcache-servers-inaccessible-due-to-network-or-server-failure"></a> How to handle a small number of memcache servers inaccessible due to network or server failure?</h3><ol><li><p>For small outages, it relies on an automated remediation system.</p><ul><li>These actions are not instant and can take up to a few minutes.</li><li>This duration is long enough to cause the aforementioned cascading failures.</li></ul></li><li><p>A small set of machines, named <em>Gutter</em>, takes over the responsibilities of a few failed servers.</p><ul><li><p>Gutter accounts for approximately 1% of the memcached servers in a cluster.</p></li><li><p>When a Memcached client receives no response to its get request, the client assumes the server has failed and issues the request again to a special Gutter pool.</p></li><li><p>If this second request misses, the client will insert the appropriate key-value pair into the Gutter machine after querying the database.</p></li><li><p>Entries in the Gutter expire quickly to obviate Gutter invalidations.</p></li><li><p>Gutter limits the load on backend services at the cost of slightly stale data.</p></li></ul></li><li><p>This design differs from an approach in which a client rehashes keys among the remaining memcached servers.</p><ul><li>The server that becomes responsible for this hot key might also become overloaded. By shunting load to idle servers, we limit that risk.</li></ul></li></ol><h2 id="in-a-region-replication"><a class="markdownIt-Anchor" href="#in-a-region-replication"></a> In a region: replication</h2><h3 id="what-is-the-problem-of-scaling-memcache"><a class="markdownIt-Anchor" href="#what-is-the-problem-of-scaling-memcache"></a> What is the problem of scaling memcache?</h3><ol><li><p>In communication traffic:</p><ul><li><p>Highly requested items will only become more popular as more web servers are added to cope with increased user traffic.</p></li><li><p>Incast congestion also worsens as the number of memcached servers increases.</p></li><li><p>Split web and Memcached servers into multiple <em>frontend</em> clusters.</p></li><li><p>These clusters, along with a storage cluster that contains the databases, define a region.</p></li></ul></li><li><p>The number of invalidations will increase.</p><ul><li>The storage cluster is responsible for invalidating cached data to keep frontend clusters consistent with the authoritative versions.</li><li>As an optimization, a web server that modifies data also sends invalidations to its cluster to provide read-after-write semantics for a single user request and reduce the time stale data is present in its local cache.</li><li>Also, batch invalidations can reduce packet rates.</li></ul></li><li><p>If users’ requests are randomly routed to all available frontend clusters, the cached data will be roughly the same across all the frontend clusters.</p><ul><li><p>Over-replicating the data can be memory inefficient, especially for large, rarely accessed items.</p></li><li><p>Reduce the number of replicas by having multiple frontend clusters share the same set of memcached servers called a regional pool.</p></li></ul></li></ol><h3 id="how-to-mitigate-the-poor-hit-rates-when-a-cold-cluster-starts-up"><a class="markdownIt-Anchor" href="#how-to-mitigate-the-poor-hit-rates-when-a-cold-cluster-starts-up"></a> How to mitigate the poor hit rates when a cold cluster starts up?</h3><ol><li>When we bring a new cluster online, an existing one fails, or perform scheduled maintenance; the caches will have very poor hit rates, diminishing the ability to insulate backend services.</li><li>A system called Cold Cluster Warmup mitigates this by allowing clients in the “cold cluster” (i.e., the frontend cluster that has an empty cache) to retrieve data from the “warm cluster” (i.e., a cluster that has caches with normal hit rates) rather than the persistent storage.</li><li>Cold clusters can be brought back to full capacity in a few hours instead of a few days with this system.</li><li>The cold cluster warmup is turned off once the cold cluster’s hit rate stabilizes and the benefits diminish.</li></ol><h3 id="how-to-solve-the-race-in-cold-cluster-warmup-caused-by-an-update-in-the-cold-cluster"><a class="markdownIt-Anchor" href="#how-to-solve-the-race-in-cold-cluster-warmup-caused-by-an-update-in-the-cold-cluster"></a> How to solve the race in cold cluster warmup caused by an update in the cold cluster?</h3><ol><li>If a client in the cold cluster does a database update, and a subsequent request from another client retrieves the stale value from the warm cluster before the warm cluster has received the invalidation, that item will be indefinitely inconsistent in the cold cluster.</li><li>Memcached deletes support nonzero hold-off times that reject add operations for the specified hold-off time.<ul><li>By default, all deletes to the cold cluster are issued with a two-second hold-off.</li><li>When a miss is detected in the cold cluster, the client re-requests the key from the warm cluster and adds it to the cold cluster.</li><li>The failure of the add indicates that newer data is available on the database, and thus, the client will refetch the value from the databases.</li></ul></li></ol><h2 id="across-regions-consistency"><a class="markdownIt-Anchor" href="#across-regions-consistency"></a> Across regions: consistency</h2><h3 id="how-to-execute-a-write-operation"><a class="markdownIt-Anchor" href="#how-to-execute-a-write-operation"></a> How to execute a write operation?</h3><ol><li><p>Of many regions, one region is designated to hold the master databases, and the other regions contain read-only replicas.</p></li><li><p>For writes from a master region:</p><ul><li><p>The storage cluster of each region will send invalidations after they have replicated data.</p></li><li><p>It avoids a race condition in which an invalidation arrives before the data has been replicated from the master region.</p></li></ul></li><li><p>For writes from a non-master region:</p><ul><li>The user’s next request could be confused about whether his recent change is missing.</li><li>Employ a remote marker mechanism to minimize the probability of reading stale data.<ul><li>The marker indicates that data in the local replica database are potentially stale, and the query should be redirected to the master region.</li></ul></li><li>When a web server wishes to update data that affects a key <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi></mrow><annotation encoding="application/x-tex">k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.03148em;">k</span></span></span></span>, that server<ul><li>sets a remote marker <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>r</mi><mi>k</mi></msub></mrow><annotation encoding="application/x-tex">r_k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> in the region</li><li>performs the write to the master embedding <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi></mrow><annotation encoding="application/x-tex">k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.03148em;">k</span></span></span></span> and <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>r</mi><mi>k</mi></msub></mrow><annotation encoding="application/x-tex">r_k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> to be invalidated in the SQL statement</li><li>deletes <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi></mrow><annotation encoding="application/x-tex">k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.03148em;">k</span></span></span></span> in the local cluster</li></ul></li><li>On a subsequent request for <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi></mrow><annotation encoding="application/x-tex">k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.03148em;">k</span></span></span></span>,<ul><li>A web server will be unable to find the cached data.</li><li>Check whether <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>r</mi><mi>k</mi></msub></mrow><annotation encoding="application/x-tex">r_k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> exists</li><li>Direct its query to the master or local region depending on the presence of <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>r</mi><mi>k</mi></msub></mrow><annotation encoding="application/x-tex">r_k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>.</li></ul></li><li>The remote markers are implemented by using a regional pool.</li><li>This mechanism may reveal stale information during concurrent modifications to the same key as one operation may delete a remote marker that should remain present for another in-flight operation.</li></ul></li></ol>]]></content>
      
      
      <categories>
          
          <category> Paper Notebook </category>
          
          <category> Distributed System </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Distributed System </tag>
            
            <tag> Cache System </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Spark</title>
      <link href="/2023/09/26/Paper/Distributed/Spark/"/>
      <url>/2023/09/26/Paper/Distributed/Spark/</url>
      
        <content type="html"><![CDATA[<p>Paper: <a href="http://nil.csail.mit.edu/6.824/2020/papers/zaharia-spark.pdf">Resilient Distributed Datasets: A Fault-Tolerant Abstraction for In-Memory Cluster Computing</a></p><p><ul class="markdownIt-TOC"><li><a href="#purpose">Purpose</a></li><li><a href="#model">Model</a><ul><li><a href="#rdds">RDDs</a><ul><li><a href="#what-is-rdd">What is RDD?</a></li><li><a href="#what-are-the-advantages-of-the-rdd-model-compared-with-distributed-shared-memory-dsm">What are the advantages of the RDD model compared with distributed shared memory (DSM)?</a></li><li><a href="#what-kind-of-applications-are-suited-for-rdds">What kind of applications are suited for RDDs?</a></li></ul></li><li><a href="#spark">Spark</a><ul><li><a href="#what-is-the-runtime-of-spark">What is the runtime of Spark?</a></li><li><a href="#what-is-the-spark-programming-interface-of-rdds">What is the Spark programming interface of RDDs?</a></li><li><a href="#what-rdd-operations-are-supported-in-spark">What RDD operations are supported in Spark?</a></li><li><a href="#what-is-the-common-interface-of-each-rdd">What is the common interface of each RDD?</a></li><li><a href="#what-is-the-interface-that-represents-dependencies-between-rdds">What is the interface that represents dependencies between RDDs?</a></li></ul></li><li><a href="#implementation">Implementation</a><ul><li><a href="#how-does-spark-schedule-computations">How does Spark schedule computations?</a></li><li><a href="#how-does-spark-handle-task-failures">How does Spark handle task failures?</a></li><li><a href="#how-does-spark-manage-the-storage-of-persistent-rdds">How does Spark manage the storage of persistent RDDs?</a></li><li><a href="#how-does-spark-evict-rdds-when-run-out-of-memory">How does Spark evict RDDs when run out of memory?</a></li><li><a href="#when-will-checkpointing-be-useful">When will checkpointing be useful?</a></li></ul></li></ul></li><li><a href="#experiment">Experiment</a></li></ul></p><h1 id="purpose"><a class="markdownIt-Anchor" href="#purpose"></a> Purpose</h1><ol><li><p>Contribution:</p><ul><li>Present Resilient Distributed Datasets (RDDs), a distributed memory abstraction, lets programmers perform in-memory computations on large clusters fault-tolerantly.</li><li>RDDs provide an interface based on coarse-grained transformations (e.g., map, filter, and join) that apply the same operation to many data items.</li></ul></li><li><p>Issues:</p><ul><li><p>Current computing frameworks handle two types of applications inefficiently: iterative algorithms and interactive data mining tools.</p></li><li><p>Current frameworks lack abstractions for leveraging distributed memory.</p><ul><li>In most current frameworks, the only way to reuse data between computations is to write it to an external stable storage system.</li><li>This makes them inefficient for those that reuse intermediate results across multiple computations.</li><li>This incurs substantial overheads due to data replication, disk I/O, and serialization.</li></ul></li><li><p>Some specialized frameworks have been developed for some applications that require data reuse. However, they do not provide abstractions for more general reuse.</p></li><li><p>Both replicating the data across machines and logging updates across machines are expensive for data-intensive workloads.</p></li></ul></li></ol><h1 id="model"><a class="markdownIt-Anchor" href="#model"></a> Model</h1><h2 id="rdds"><a class="markdownIt-Anchor" href="#rdds"></a> RDDs</h2><h3 id="what-is-rdd"><a class="markdownIt-Anchor" href="#what-is-rdd"></a> What is RDD?</h3><ol><li>An RDD is a read-only, partitioned collection of records.<ul><li>Although individual RDDs are immutable, it is possible to implement mutable states with multiple RDDs representing multiple dataset versions.</li></ul></li><li>RDDs can only be created through deterministic operations on either data in stable storage or other RDDs.<ul><li>These operations are called transformations to differentiate them from other operations on RDDs.</li></ul></li><li>An RDD has enough information about how it was derived from other datasets (its lineage) to compute its partitions from data in stable storage.<ul><li>A program cannot reference an RDD that it cannot reconstruct after a failure.</li><li>RDDs do not need to be materialized at all times.</li></ul></li><li>Users can control two other aspects of RDDs: persistence and partitioning.<ul><li>Users can indicate which RDDs they will reuse and choose a storage strategy.</li><li>They can also ask that an RDD’s elements be partitioned across machines based on a key in each record.</li></ul></li></ol><h3 id="what-are-the-advantages-of-the-rdd-model-compared-with-distributed-shared-memory-dsm"><a class="markdownIt-Anchor" href="#what-are-the-advantages-of-the-rdd-model-compared-with-distributed-shared-memory-dsm"></a> What are the advantages of the RDD model compared with distributed shared memory (DSM)?</h3><ol><li><p>The main difference between RDDs and DSM is that RDDs can only be created (“written”) through coarse-grained transformations, while DSM allows reads and writes to each memory location.</p><ul><li>This restricts RDDs to applications that perform bulk writes but allows for more efficient fault tolerance.</li><li>RDDs do not need to incur the overhead of checkpointing, as they can be recovered using lineage.</li><li>Only the lost partitions of an RDD need to be recomputed upon failure, and they can be recomputed in parallel on different nodes without having to roll back the whole program.</li></ul></li><li><p>RDDs’ immutable nature lets a system mitigate slow nodes (stragglers) by running backup copies of slow tasks, as in MapReduce.</p><ul><li>Backup tasks would be challenging to implement with DSM, as the two copies of a task would access the same memory locations and interfere with each other’s updates.</li></ul></li><li><p>In bulk operations on RDDs, a runtime can schedule tasks based on data locality to improve performance.</p></li><li><p>RDDs degrade gracefully when there is not enough memory to store them as long as they are only used in scan-based operations.</p><p>Partitions that do not fit in RAM can be stored on disk and provide performance similar to current data-parallel systems.</p></li></ol><h3 id="what-kind-of-applications-are-suited-for-rdds"><a class="markdownIt-Anchor" href="#what-kind-of-applications-are-suited-for-rdds"></a> What kind of applications are suited for RDDs?</h3><ol><li>RDDs are best suited for batch applications that apply the same operation to all dataset elements.<ul><li>RDDs can efficiently remember each transformation as one step in a lineage graph and recover lost partitions without logging large amounts of data.</li></ul></li><li>RDDs would be less suitable for applications that make asynchronous fine-grained updates to shared states.</li></ol><h2 id="spark"><a class="markdownIt-Anchor" href="#spark"></a> Spark</h2><h3 id="what-is-the-runtime-of-spark"><a class="markdownIt-Anchor" href="#what-is-the-runtime-of-spark"></a> What is the runtime of Spark?</h3><ol><li>Developers write a <strong>driver</strong> program that connects to a cluster of <strong>workers</strong>.<ul><li>The driver defines one or more RDDs and invokes actions on them.</li><li>Spark code on the driver also tracks the RDDs’ lineage.</li></ul></li><li>The workers are long-lived processes that can store RDD partitions in RAM across operations.</li></ol><img src="/imgs/Distributed/Spark/runtime.png" width="30%"><h3 id="what-is-the-spark-programming-interface-of-rdds"><a class="markdownIt-Anchor" href="#what-is-the-spark-programming-interface-of-rdds"></a> What is the Spark programming interface of RDDs?</h3><ol><li>Each dataset is represented as an object, and transformations are invoked using methods for these objects.</li><li>Programmers start by defining one or more RDDs through transformations on data in stable storage.<ul><li>They can then use these RDDs in actions, which are operations that return a value to the application or export data to a storage system.</li></ul></li><li>Programmers can call a <code>persist()</code> method to indicate which RDDs they want to reuse in future operations.<ul><li>Spark keeps persistent RDDs in memory by default but can spill them to disk without enough RAM.</li><li>Users can set a persistence priority on each RDD to specify which in-memory data should spill to disk first.</li><li>The user can call <code>persist</code> with a <code>RELIABLE</code> flag to reliably replicate some of the versions of RDDs to reduce fault recovery times.</li></ul></li></ol><h3 id="what-rdd-operations-are-supported-in-spark"><a class="markdownIt-Anchor" href="#what-rdd-operations-are-supported-in-spark"></a> What RDD operations are supported in Spark?</h3><ol><li>Users provide arguments to RDD operations by passing closures (function literals).</li><li>RDDs themselves are statically typed objects parametrized by an element type.</li><li>Transformations are <strong>lazy</strong> operations that define a new RDD.<ul><li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>m</mi><mi>a</mi><mi>p</mi><mo stretchy="false">(</mo><mi>f</mi><mo>:</mo><mi>T</mi><mo>⇒</mo><mi>U</mi><mo stretchy="false">)</mo><mo>:</mo><mi>R</mi><mi>D</mi><mi>D</mi><mo stretchy="false">[</mo><mi>T</mi><mo stretchy="false">]</mo><mo>⇒</mo><mi>R</mi><mi>D</mi><mi>D</mi><mo stretchy="false">[</mo><mi>U</mi><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">map(f: T\Rightarrow U): RDD[T]\Rightarrow RDD[U]</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">m</span><span class="mord mathnormal">a</span><span class="mord mathnormal">p</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">:</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">⇒</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">U</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">:</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="mord mathnormal" style="margin-right:0.02778em;">D</span><span class="mord mathnormal" style="margin-right:0.02778em;">D</span><span class="mopen">[</span><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="mclose">]</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">⇒</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="mord mathnormal" style="margin-right:0.02778em;">D</span><span class="mord mathnormal" style="margin-right:0.02778em;">D</span><span class="mopen">[</span><span class="mord mathnormal" style="margin-right:0.10903em;">U</span><span class="mclose">]</span></span></span></span></li><li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>f</mi><mi>i</mi><mi>l</mi><mi>t</mi><mi>e</mi><mi>r</mi><mo stretchy="false">(</mo><mi>f</mi><mo>:</mo><mi>T</mi><mo>⇒</mo><mi>B</mi><mi>o</mi><mi>o</mi><mi>l</mi><mo stretchy="false">)</mo><mo>:</mo><mi>R</mi><mi>D</mi><mi>D</mi><mo stretchy="false">[</mo><mi>T</mi><mo stretchy="false">]</mo><mo>⇒</mo><mi>R</mi><mi>D</mi><mi>D</mi><mo stretchy="false">[</mo><mi>T</mi><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">filter(f: T\Rightarrow Bool): RDD[T]\Rightarrow RDD[T]</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="mord mathnormal">i</span><span class="mord mathnormal" style="margin-right:0.01968em;">l</span><span class="mord mathnormal">t</span><span class="mord mathnormal">e</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">:</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">⇒</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.05017em;">B</span><span class="mord mathnormal">o</span><span class="mord mathnormal">o</span><span class="mord mathnormal" style="margin-right:0.01968em;">l</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">:</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="mord mathnormal" style="margin-right:0.02778em;">D</span><span class="mord mathnormal" style="margin-right:0.02778em;">D</span><span class="mopen">[</span><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="mclose">]</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">⇒</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="mord mathnormal" style="margin-right:0.02778em;">D</span><span class="mord mathnormal" style="margin-right:0.02778em;">D</span><span class="mopen">[</span><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="mclose">]</span></span></span></span></li><li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>f</mi><mi>l</mi><mi>a</mi><mi>t</mi><mi>M</mi><mi>a</mi><mi>p</mi><mo stretchy="false">(</mo><mi>f</mi><mo>:</mo><mi>T</mi><mo>⇒</mo><mi>S</mi><mi>e</mi><mi>q</mi><mo stretchy="false">[</mo><mi>U</mi><mo stretchy="false">]</mo><mo stretchy="false">)</mo><mo>:</mo><mi>R</mi><mi>D</mi><mi>D</mi><mo stretchy="false">[</mo><mi>T</mi><mo stretchy="false">]</mo><mo>⇒</mo><mi>R</mi><mi>D</mi><mi>D</mi><mo stretchy="false">[</mo><mi>U</mi><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">flatMap(f: T\Rightarrow Seq[U]): RDD[T]\Rightarrow RDD[U]</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="mord mathnormal" style="margin-right:0.01968em;">l</span><span class="mord mathnormal">a</span><span class="mord mathnormal">t</span><span class="mord mathnormal" style="margin-right:0.10903em;">M</span><span class="mord mathnormal">a</span><span class="mord mathnormal">p</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">:</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">⇒</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.05764em;">S</span><span class="mord mathnormal">e</span><span class="mord mathnormal" style="margin-right:0.03588em;">q</span><span class="mopen">[</span><span class="mord mathnormal" style="margin-right:0.10903em;">U</span><span class="mclose">]</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">:</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="mord mathnormal" style="margin-right:0.02778em;">D</span><span class="mord mathnormal" style="margin-right:0.02778em;">D</span><span class="mopen">[</span><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="mclose">]</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">⇒</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="mord mathnormal" style="margin-right:0.02778em;">D</span><span class="mord mathnormal" style="margin-right:0.02778em;">D</span><span class="mopen">[</span><span class="mord mathnormal" style="margin-right:0.10903em;">U</span><span class="mclose">]</span></span></span></span></li><li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>s</mi><mi>a</mi><mi>m</mi><mi>p</mi><mi>l</mi><mi>e</mi><mo stretchy="false">(</mo><mi>f</mi><mi>r</mi><mi>a</mi><mi>c</mi><mi>t</mi><mi>i</mi><mi>o</mi><mi>n</mi><mo>:</mo><mi>F</mi><mi>l</mi><mi>o</mi><mi>a</mi><mi>t</mi><mo stretchy="false">)</mo><mo>:</mo><mi>R</mi><mi>D</mi><mi>D</mi><mo stretchy="false">[</mo><mi>T</mi><mo stretchy="false">]</mo><mo>⇒</mo><mi>R</mi><mi>D</mi><mi>D</mi><mo stretchy="false">[</mo><mi>T</mi><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">sample(fraction: Float): RDD[T]\Rightarrow RDD[T]</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">s</span><span class="mord mathnormal">a</span><span class="mord mathnormal">m</span><span class="mord mathnormal">p</span><span class="mord mathnormal" style="margin-right:0.01968em;">l</span><span class="mord mathnormal">e</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mord mathnormal">a</span><span class="mord mathnormal">c</span><span class="mord mathnormal">t</span><span class="mord mathnormal">i</span><span class="mord mathnormal">o</span><span class="mord mathnormal">n</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">:</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">F</span><span class="mord mathnormal" style="margin-right:0.01968em;">l</span><span class="mord mathnormal">o</span><span class="mord mathnormal">a</span><span class="mord mathnormal">t</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">:</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="mord mathnormal" style="margin-right:0.02778em;">D</span><span class="mord mathnormal" style="margin-right:0.02778em;">D</span><span class="mopen">[</span><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="mclose">]</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">⇒</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="mord mathnormal" style="margin-right:0.02778em;">D</span><span class="mord mathnormal" style="margin-right:0.02778em;">D</span><span class="mopen">[</span><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="mclose">]</span></span></span></span> (Deterministic sampling)</li><li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>g</mi><mi>r</mi><mi>o</mi><mi>u</mi><mi>p</mi><mi>B</mi><mi>y</mi><mi>K</mi><mi>e</mi><mi>y</mi><mo stretchy="false">(</mo><mo stretchy="false">)</mo><mo>:</mo><mi>R</mi><mi>D</mi><mi>D</mi><mo stretchy="false">[</mo><mo stretchy="false">(</mo><mi>K</mi><mo separator="true">,</mo><mi>V</mi><mo stretchy="false">)</mo><mo stretchy="false">]</mo><mo>⇒</mo><mi>R</mi><mi>D</mi><mi>D</mi><mo stretchy="false">[</mo><mo stretchy="false">(</mo><mi>K</mi><mo separator="true">,</mo><mi>S</mi><mi>e</mi><mi>q</mi><mo stretchy="false">[</mo><mi>V</mi><mo stretchy="false">]</mo><mo stretchy="false">)</mo><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">groupByKey(): RDD[(K,V)]\Rightarrow RDD[(K,Seq[V])]</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">g</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mord mathnormal">o</span><span class="mord mathnormal">u</span><span class="mord mathnormal">p</span><span class="mord mathnormal" style="margin-right:0.05017em;">B</span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="mord mathnormal" style="margin-right:0.07153em;">K</span><span class="mord mathnormal">e</span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="mopen">(</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">:</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="mord mathnormal" style="margin-right:0.02778em;">D</span><span class="mord mathnormal" style="margin-right:0.02778em;">D</span><span class="mopen">[</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.07153em;">K</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal" style="margin-right:0.22222em;">V</span><span class="mclose">)</span><span class="mclose">]</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">⇒</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="mord mathnormal" style="margin-right:0.02778em;">D</span><span class="mord mathnormal" style="margin-right:0.02778em;">D</span><span class="mopen">[</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.07153em;">K</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal" style="margin-right:0.05764em;">S</span><span class="mord mathnormal">e</span><span class="mord mathnormal" style="margin-right:0.03588em;">q</span><span class="mopen">[</span><span class="mord mathnormal" style="margin-right:0.22222em;">V</span><span class="mclose">]</span><span class="mclose">)</span><span class="mclose">]</span></span></span></span></li><li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>r</mi><mi>e</mi><mi>d</mi><mi>u</mi><mi>c</mi><mi>e</mi><mi>B</mi><mi>y</mi><mi>K</mi><mi>e</mi><mi>y</mi><mo stretchy="false">(</mo><mi>f</mi><mo>:</mo><mo stretchy="false">(</mo><mi>V</mi><mo separator="true">,</mo><mi>V</mi><mo stretchy="false">)</mo><mo>⇒</mo><mi>V</mi><mo stretchy="false">)</mo><mo>:</mo><mi>R</mi><mi>D</mi><mi>D</mi><mo stretchy="false">[</mo><mo stretchy="false">(</mo><mi>K</mi><mo separator="true">,</mo><mi>V</mi><mo stretchy="false">)</mo><mo stretchy="false">]</mo><mo>⇒</mo><mi>R</mi><mi>D</mi><mi>D</mi><mo stretchy="false">[</mo><mo stretchy="false">(</mo><mi>K</mi><mo separator="true">,</mo><mi>V</mi><mo stretchy="false">)</mo><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">reduceByKey(f:(V,V)\Rightarrow V): RDD[(K,V)]\Rightarrow RDD[(K,V)]</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mord mathnormal">e</span><span class="mord mathnormal">d</span><span class="mord mathnormal">u</span><span class="mord mathnormal">c</span><span class="mord mathnormal">e</span><span class="mord mathnormal" style="margin-right:0.05017em;">B</span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="mord mathnormal" style="margin-right:0.07153em;">K</span><span class="mord mathnormal">e</span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">:</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.22222em;">V</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal" style="margin-right:0.22222em;">V</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">⇒</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.22222em;">V</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">:</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="mord mathnormal" style="margin-right:0.02778em;">D</span><span class="mord mathnormal" style="margin-right:0.02778em;">D</span><span class="mopen">[</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.07153em;">K</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal" style="margin-right:0.22222em;">V</span><span class="mclose">)</span><span class="mclose">]</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">⇒</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="mord mathnormal" style="margin-right:0.02778em;">D</span><span class="mord mathnormal" style="margin-right:0.02778em;">D</span><span class="mopen">[</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.07153em;">K</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal" style="margin-right:0.22222em;">V</span><span class="mclose">)</span><span class="mclose">]</span></span></span></span></li><li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>u</mi><mi>n</mi><mi>i</mi><mi>o</mi><mi>n</mi><mo stretchy="false">(</mo><mo stretchy="false">)</mo><mo>:</mo><mo stretchy="false">(</mo><mi>R</mi><mi>D</mi><mi>D</mi><mo stretchy="false">[</mo><mi>T</mi><mo stretchy="false">]</mo><mo separator="true">,</mo><mi>R</mi><mi>D</mi><mi>D</mi><mo stretchy="false">[</mo><mi>T</mi><mo stretchy="false">]</mo><mo stretchy="false">)</mo><mo>⇒</mo><mi>R</mi><mi>D</mi><mi>D</mi><mo stretchy="false">[</mo><mi>T</mi><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">union(): (RDD[T],RDD[T])\Rightarrow RDD[T]</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">u</span><span class="mord mathnormal">n</span><span class="mord mathnormal">i</span><span class="mord mathnormal">o</span><span class="mord mathnormal">n</span><span class="mopen">(</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">:</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="mord mathnormal" style="margin-right:0.02778em;">D</span><span class="mord mathnormal" style="margin-right:0.02778em;">D</span><span class="mopen">[</span><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="mclose">]</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="mord mathnormal" style="margin-right:0.02778em;">D</span><span class="mord mathnormal" style="margin-right:0.02778em;">D</span><span class="mopen">[</span><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="mclose">]</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">⇒</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="mord mathnormal" style="margin-right:0.02778em;">D</span><span class="mord mathnormal" style="margin-right:0.02778em;">D</span><span class="mopen">[</span><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="mclose">]</span></span></span></span></li><li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>j</mi><mi>o</mi><mi>i</mi><mi>n</mi><mo stretchy="false">(</mo><mo stretchy="false">)</mo><mo>:</mo><mo stretchy="false">(</mo><mi>R</mi><mi>D</mi><mi>D</mi><mo stretchy="false">[</mo><mo stretchy="false">(</mo><mi>K</mi><mo separator="true">,</mo><mi>V</mi><mo stretchy="false">)</mo><mo stretchy="false">]</mo><mo separator="true">,</mo><mi>R</mi><mi>D</mi><mi>D</mi><mo stretchy="false">[</mo><mo stretchy="false">(</mo><mi>K</mi><mo separator="true">,</mo><mi>W</mi><mo stretchy="false">)</mo><mo stretchy="false">]</mo><mo stretchy="false">)</mo><mo>⇒</mo><mi>R</mi><mi>D</mi><mi>D</mi><mo stretchy="false">[</mo><mo stretchy="false">(</mo><mi>K</mi><mo separator="true">,</mo><mo stretchy="false">(</mo><mi>V</mi><mo separator="true">,</mo><mi>W</mi><mo stretchy="false">)</mo><mo stretchy="false">)</mo><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">join():(RDD[(K,V)],RDD[(K,W)])\Rightarrow RDD[(K,(V,W))]</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.05724em;">j</span><span class="mord mathnormal">o</span><span class="mord mathnormal">i</span><span class="mord mathnormal">n</span><span class="mopen">(</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">:</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="mord mathnormal" style="margin-right:0.02778em;">D</span><span class="mord mathnormal" style="margin-right:0.02778em;">D</span><span class="mopen">[</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.07153em;">K</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal" style="margin-right:0.22222em;">V</span><span class="mclose">)</span><span class="mclose">]</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="mord mathnormal" style="margin-right:0.02778em;">D</span><span class="mord mathnormal" style="margin-right:0.02778em;">D</span><span class="mopen">[</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.07153em;">K</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="mclose">)</span><span class="mclose">]</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">⇒</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="mord mathnormal" style="margin-right:0.02778em;">D</span><span class="mord mathnormal" style="margin-right:0.02778em;">D</span><span class="mopen">[</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.07153em;">K</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.22222em;">V</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="mclose">)</span><span class="mclose">)</span><span class="mclose">]</span></span></span></span></li><li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>c</mi><mi>o</mi><mi>g</mi><mi>r</mi><mi>o</mi><mi>u</mi><mi>p</mi><mo stretchy="false">(</mo><mo stretchy="false">)</mo><mo>:</mo><mo stretchy="false">(</mo><mi>R</mi><mi>D</mi><mi>D</mi><mo stretchy="false">[</mo><mo stretchy="false">(</mo><mi>K</mi><mo separator="true">,</mo><mi>V</mi><mo stretchy="false">)</mo><mo stretchy="false">]</mo><mo separator="true">,</mo><mi>R</mi><mi>D</mi><mi>D</mi><mo stretchy="false">[</mo><mo stretchy="false">(</mo><mi>K</mi><mo separator="true">,</mo><mi>W</mi><mo stretchy="false">)</mo><mo stretchy="false">]</mo><mo stretchy="false">)</mo><mo>⇒</mo><mi>R</mi><mi>D</mi><mi>D</mi><mo stretchy="false">[</mo><mo stretchy="false">(</mo><mi>K</mi><mo separator="true">,</mo><mo stretchy="false">(</mo><mi>S</mi><mi>e</mi><mi>q</mi><mo stretchy="false">[</mo><mi>V</mi><mo stretchy="false">]</mo><mo separator="true">,</mo><mi>S</mi><mi>e</mi><mi>q</mi><mo stretchy="false">[</mo><mi>W</mi><mo stretchy="false">]</mo><mo stretchy="false">)</mo><mo stretchy="false">)</mo><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">cogroup():(RDD[(K,V)],RDD[(K,W)])\Rightarrow RDD[(K,(Seq[V],Seq[W]))]</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">c</span><span class="mord mathnormal">o</span><span class="mord mathnormal" style="margin-right:0.03588em;">g</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mord mathnormal">o</span><span class="mord mathnormal">u</span><span class="mord mathnormal">p</span><span class="mopen">(</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">:</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="mord mathnormal" style="margin-right:0.02778em;">D</span><span class="mord mathnormal" style="margin-right:0.02778em;">D</span><span class="mopen">[</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.07153em;">K</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal" style="margin-right:0.22222em;">V</span><span class="mclose">)</span><span class="mclose">]</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="mord mathnormal" style="margin-right:0.02778em;">D</span><span class="mord mathnormal" style="margin-right:0.02778em;">D</span><span class="mopen">[</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.07153em;">K</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="mclose">)</span><span class="mclose">]</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">⇒</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="mord mathnormal" style="margin-right:0.02778em;">D</span><span class="mord mathnormal" style="margin-right:0.02778em;">D</span><span class="mopen">[</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.07153em;">K</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.05764em;">S</span><span class="mord mathnormal">e</span><span class="mord mathnormal" style="margin-right:0.03588em;">q</span><span class="mopen">[</span><span class="mord mathnormal" style="margin-right:0.22222em;">V</span><span class="mclose">]</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal" style="margin-right:0.05764em;">S</span><span class="mord mathnormal">e</span><span class="mord mathnormal" style="margin-right:0.03588em;">q</span><span class="mopen">[</span><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="mclose">]</span><span class="mclose">)</span><span class="mclose">)</span><span class="mclose">]</span></span></span></span></li><li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>c</mi><mi>r</mi><mi>o</mi><mi>s</mi><mi>s</mi><mi>P</mi><mi>r</mi><mi>o</mi><mi>d</mi><mi>u</mi><mi>c</mi><mi>t</mi><mo stretchy="false">(</mo><mo stretchy="false">)</mo><mo>:</mo><mo stretchy="false">(</mo><mi>R</mi><mi>D</mi><mi>D</mi><mo stretchy="false">[</mo><mi>T</mi><mo stretchy="false">]</mo><mo separator="true">,</mo><mi>R</mi><mi>D</mi><mi>D</mi><mo stretchy="false">[</mo><mi>U</mi><mo stretchy="false">]</mo><mo stretchy="false">)</mo><mo>⇒</mo><mi>R</mi><mi>D</mi><mi>D</mi><mo stretchy="false">[</mo><mo stretchy="false">(</mo><mi>T</mi><mo separator="true">,</mo><mi>U</mi><mo stretchy="false">)</mo><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">crossProduct():(RDD[T],RDD[U])\Rightarrow RDD[(T,U)]</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">c</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mord mathnormal">o</span><span class="mord mathnormal">s</span><span class="mord mathnormal">s</span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mord mathnormal">o</span><span class="mord mathnormal">d</span><span class="mord mathnormal">u</span><span class="mord mathnormal">c</span><span class="mord mathnormal">t</span><span class="mopen">(</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">:</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="mord mathnormal" style="margin-right:0.02778em;">D</span><span class="mord mathnormal" style="margin-right:0.02778em;">D</span><span class="mopen">[</span><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="mclose">]</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="mord mathnormal" style="margin-right:0.02778em;">D</span><span class="mord mathnormal" style="margin-right:0.02778em;">D</span><span class="mopen">[</span><span class="mord mathnormal" style="margin-right:0.10903em;">U</span><span class="mclose">]</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">⇒</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="mord mathnormal" style="margin-right:0.02778em;">D</span><span class="mord mathnormal" style="margin-right:0.02778em;">D</span><span class="mopen">[</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">U</span><span class="mclose">)</span><span class="mclose">]</span></span></span></span></li><li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>m</mi><mi>a</mi><mi>p</mi><mi>V</mi><mi>a</mi><mi>l</mi><mi>u</mi><mi>e</mi><mi>s</mi><mo stretchy="false">(</mo><mi>f</mi><mo>:</mo><mi>V</mi><mo>⇒</mo><mi>W</mi><mo stretchy="false">)</mo><mo>:</mo><mi>R</mi><mi>D</mi><mi>D</mi><mo stretchy="false">[</mo><mo stretchy="false">(</mo><mi>K</mi><mo separator="true">,</mo><mi>V</mi><mo stretchy="false">)</mo><mo stretchy="false">]</mo><mo>⇒</mo><mi>R</mi><mi>D</mi><mi>D</mi><mo stretchy="false">[</mo><mo stretchy="false">(</mo><mi>K</mi><mo separator="true">,</mo><mi>W</mi><mo stretchy="false">)</mo><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">mapValues(f:V\Rightarrow W):RDD[(K,V)]\Rightarrow RDD[(K,W)]</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">m</span><span class="mord mathnormal">a</span><span class="mord mathnormal">p</span><span class="mord mathnormal" style="margin-right:0.22222em;">V</span><span class="mord mathnormal">a</span><span class="mord mathnormal" style="margin-right:0.01968em;">l</span><span class="mord mathnormal">u</span><span class="mord mathnormal">e</span><span class="mord mathnormal">s</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">:</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.22222em;">V</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">⇒</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">:</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="mord mathnormal" style="margin-right:0.02778em;">D</span><span class="mord mathnormal" style="margin-right:0.02778em;">D</span><span class="mopen">[</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.07153em;">K</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal" style="margin-right:0.22222em;">V</span><span class="mclose">)</span><span class="mclose">]</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">⇒</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="mord mathnormal" style="margin-right:0.02778em;">D</span><span class="mord mathnormal" style="margin-right:0.02778em;">D</span><span class="mopen">[</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.07153em;">K</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="mclose">)</span><span class="mclose">]</span></span></span></span> (Preserves partitioning)</li><li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>s</mi><mi>o</mi><mi>r</mi><mi>t</mi><mo stretchy="false">(</mo><mi>c</mi><mo>:</mo><mi>C</mi><mi>o</mi><mi>m</mi><mi>p</mi><mi>a</mi><mi>r</mi><mi>a</mi><mi>t</mi><mi>o</mi><mi>r</mi><mo stretchy="false">[</mo><mi>K</mi><mo stretchy="false">]</mo><mo stretchy="false">)</mo><mo>:</mo><mi>R</mi><mi>D</mi><mi>D</mi><mo stretchy="false">[</mo><mo stretchy="false">(</mo><mi>K</mi><mo separator="true">,</mo><mi>V</mi><mo stretchy="false">)</mo><mo stretchy="false">]</mo><mo>⇒</mo><mi>R</mi><mi>D</mi><mi>D</mi><mo stretchy="false">[</mo><mo stretchy="false">(</mo><mi>K</mi><mo separator="true">,</mo><mi>V</mi><mo stretchy="false">)</mo><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">sort(c:Comparator[K]):RDD[(K,V)]\Rightarrow RDD[(K,V)]</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">s</span><span class="mord mathnormal">o</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mord mathnormal">t</span><span class="mopen">(</span><span class="mord mathnormal">c</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">:</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.07153em;">C</span><span class="mord mathnormal">o</span><span class="mord mathnormal">m</span><span class="mord mathnormal">p</span><span class="mord mathnormal">a</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mord mathnormal">a</span><span class="mord mathnormal">t</span><span class="mord mathnormal">o</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mopen">[</span><span class="mord mathnormal" style="margin-right:0.07153em;">K</span><span class="mclose">]</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">:</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="mord mathnormal" style="margin-right:0.02778em;">D</span><span class="mord mathnormal" style="margin-right:0.02778em;">D</span><span class="mopen">[</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.07153em;">K</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal" style="margin-right:0.22222em;">V</span><span class="mclose">)</span><span class="mclose">]</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">⇒</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="mord mathnormal" style="margin-right:0.02778em;">D</span><span class="mord mathnormal" style="margin-right:0.02778em;">D</span><span class="mopen">[</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.07153em;">K</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal" style="margin-right:0.22222em;">V</span><span class="mclose">)</span><span class="mclose">]</span></span></span></span></li><li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi><mi>a</mi><mi>r</mi><mi>t</mi><mi>i</mi><mi>t</mi><mi>i</mi><mi>o</mi><mi>n</mi><mi>B</mi><mi>y</mi><mo stretchy="false">(</mo><mi>p</mi><mo>:</mo><mi>P</mi><mi>a</mi><mi>r</mi><mi>t</mi><mi>i</mi><mi>t</mi><mi>i</mi><mi>o</mi><mi>n</mi><mi>e</mi><mi>r</mi><mo stretchy="false">[</mo><mi>K</mi><mo stretchy="false">]</mo><mo stretchy="false">)</mo><mo>:</mo><mi>R</mi><mi>D</mi><mi>D</mi><mo stretchy="false">[</mo><mo stretchy="false">(</mo><mi>K</mi><mo separator="true">,</mo><mi>V</mi><mo stretchy="false">)</mo><mo stretchy="false">]</mo><mo>⇒</mo><mi>R</mi><mi>D</mi><mi>D</mi><mo stretchy="false">[</mo><mo stretchy="false">(</mo><mi>K</mi><mo separator="true">,</mo><mi>V</mi><mo stretchy="false">)</mo><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">partitionBy(p:Partitioner[K]):RDD[(K,V)]\Rightarrow RDD[(K,V)]</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">p</span><span class="mord mathnormal">a</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mord mathnormal">t</span><span class="mord mathnormal">i</span><span class="mord mathnormal">t</span><span class="mord mathnormal">i</span><span class="mord mathnormal">o</span><span class="mord mathnormal">n</span><span class="mord mathnormal" style="margin-right:0.05017em;">B</span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="mopen">(</span><span class="mord mathnormal">p</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">:</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="mord mathnormal">a</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mord mathnormal">t</span><span class="mord mathnormal">i</span><span class="mord mathnormal">t</span><span class="mord mathnormal">i</span><span class="mord mathnormal">o</span><span class="mord mathnormal">n</span><span class="mord mathnormal">e</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mopen">[</span><span class="mord mathnormal" style="margin-right:0.07153em;">K</span><span class="mclose">]</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">:</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="mord mathnormal" style="margin-right:0.02778em;">D</span><span class="mord mathnormal" style="margin-right:0.02778em;">D</span><span class="mopen">[</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.07153em;">K</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal" style="margin-right:0.22222em;">V</span><span class="mclose">)</span><span class="mclose">]</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">⇒</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="mord mathnormal" style="margin-right:0.02778em;">D</span><span class="mord mathnormal" style="margin-right:0.02778em;">D</span><span class="mopen">[</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.07153em;">K</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal" style="margin-right:0.22222em;">V</span><span class="mclose">)</span><span class="mclose">]</span></span></span></span></li></ul></li><li>Actions launch a computation to return a value to the program or write data to external storage.<ul><li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>c</mi><mi>o</mi><mi>u</mi><mi>n</mi><mi>t</mi><mo stretchy="false">(</mo><mo stretchy="false">)</mo><mo>:</mo><mi>R</mi><mi>D</mi><mi>D</mi><mo stretchy="false">[</mo><mi>T</mi><mo stretchy="false">]</mo><mo>⇒</mo><mi>L</mi><mi>o</mi><mi>n</mi><mi>g</mi><mo>:</mo></mrow><annotation encoding="application/x-tex">count(): RDD[T]\Rightarrow Long:</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">c</span><span class="mord mathnormal">o</span><span class="mord mathnormal">u</span><span class="mord mathnormal">n</span><span class="mord mathnormal">t</span><span class="mopen">(</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">:</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="mord mathnormal" style="margin-right:0.02778em;">D</span><span class="mord mathnormal" style="margin-right:0.02778em;">D</span><span class="mopen">[</span><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="mclose">]</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">⇒</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.8777699999999999em;vertical-align:-0.19444em;"></span><span class="mord mathnormal">L</span><span class="mord mathnormal">o</span><span class="mord mathnormal">n</span><span class="mord mathnormal" style="margin-right:0.03588em;">g</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">:</span></span></span></span> Returns the number of elements in the dataset</li><li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>c</mi><mi>o</mi><mi>l</mi><mi>l</mi><mi>e</mi><mi>c</mi><mi>t</mi><mo stretchy="false">(</mo><mo stretchy="false">)</mo><mo>:</mo><mi>R</mi><mi>D</mi><mi>D</mi><mo stretchy="false">[</mo><mi>T</mi><mo stretchy="false">]</mo><mo>⇒</mo><mi>S</mi><mi>e</mi><mi>q</mi><mo stretchy="false">[</mo><mi>T</mi><mo stretchy="false">]</mo><mo>:</mo></mrow><annotation encoding="application/x-tex">collect(): RDD[T]\Rightarrow Seq[T]:</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">c</span><span class="mord mathnormal">o</span><span class="mord mathnormal" style="margin-right:0.01968em;">l</span><span class="mord mathnormal" style="margin-right:0.01968em;">l</span><span class="mord mathnormal">e</span><span class="mord mathnormal">c</span><span class="mord mathnormal">t</span><span class="mopen">(</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">:</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="mord mathnormal" style="margin-right:0.02778em;">D</span><span class="mord mathnormal" style="margin-right:0.02778em;">D</span><span class="mopen">[</span><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="mclose">]</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">⇒</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.05764em;">S</span><span class="mord mathnormal">e</span><span class="mord mathnormal" style="margin-right:0.03588em;">q</span><span class="mopen">[</span><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="mclose">]</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">:</span></span></span></span> Returns the elements themselves</li><li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>r</mi><mi>e</mi><mi>d</mi><mi>u</mi><mi>c</mi><mi>e</mi><mo stretchy="false">(</mo><mi>f</mi><mo>:</mo><mo stretchy="false">(</mo><mi>T</mi><mo separator="true">,</mo><mi>T</mi><mo stretchy="false">)</mo><mo>⇒</mo><mi>T</mi><mo stretchy="false">)</mo><mo>:</mo><mi>R</mi><mi>D</mi><mi>D</mi><mo stretchy="false">[</mo><mi>T</mi><mo stretchy="false">]</mo><mo>⇒</mo><mi>T</mi></mrow><annotation encoding="application/x-tex">reduce(f:(T,T)\Rightarrow T): RDD[T]\Rightarrow T</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mord mathnormal">e</span><span class="mord mathnormal">d</span><span class="mord mathnormal">u</span><span class="mord mathnormal">c</span><span class="mord mathnormal">e</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">:</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">⇒</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">:</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="mord mathnormal" style="margin-right:0.02778em;">D</span><span class="mord mathnormal" style="margin-right:0.02778em;">D</span><span class="mopen">[</span><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="mclose">]</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">⇒</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">T</span></span></span></span></li><li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>l</mi><mi>o</mi><mi>o</mi><mi>k</mi><mi>u</mi><mi>p</mi><mo stretchy="false">(</mo><mi>k</mi><mo>:</mo><mi>K</mi><mo stretchy="false">)</mo><mo>:</mo><mi>R</mi><mi>D</mi><mi>D</mi><mo stretchy="false">[</mo><mo stretchy="false">(</mo><mi>K</mi><mo separator="true">,</mo><mi>V</mi><mo stretchy="false">)</mo><mo stretchy="false">]</mo><mo>⇒</mo><mi>S</mi><mi>e</mi><mi>q</mi><mo stretchy="false">[</mo><mi>V</mi><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">lookup(k:K):RDD[(K,V)]\Rightarrow Seq[V]</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.01968em;">l</span><span class="mord mathnormal">o</span><span class="mord mathnormal">o</span><span class="mord mathnormal" style="margin-right:0.03148em;">k</span><span class="mord mathnormal">u</span><span class="mord mathnormal">p</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.03148em;">k</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">:</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.07153em;">K</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">:</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="mord mathnormal" style="margin-right:0.02778em;">D</span><span class="mord mathnormal" style="margin-right:0.02778em;">D</span><span class="mopen">[</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.07153em;">K</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal" style="margin-right:0.22222em;">V</span><span class="mclose">)</span><span class="mclose">]</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">⇒</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.05764em;">S</span><span class="mord mathnormal">e</span><span class="mord mathnormal" style="margin-right:0.03588em;">q</span><span class="mopen">[</span><span class="mord mathnormal" style="margin-right:0.22222em;">V</span><span class="mclose">]</span></span></span></span> (On hash/range partitioned RDDs)</li><li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>s</mi><mi>a</mi><mi>v</mi><mi>e</mi><mo stretchy="false">(</mo><mi>p</mi><mi>a</mi><mi>t</mi><mi>h</mi><mo>:</mo><mi>S</mi><mi>t</mi><mi>r</mi><mi>i</mi><mi>n</mi><mi>g</mi><mo stretchy="false">)</mo><mo>:</mo></mrow><annotation encoding="application/x-tex">save(path:String):</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">s</span><span class="mord mathnormal">a</span><span class="mord mathnormal" style="margin-right:0.03588em;">v</span><span class="mord mathnormal">e</span><span class="mopen">(</span><span class="mord mathnormal">p</span><span class="mord mathnormal">a</span><span class="mord mathnormal">t</span><span class="mord mathnormal">h</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">:</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.05764em;">S</span><span class="mord mathnormal">t</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mord mathnormal">i</span><span class="mord mathnormal">n</span><span class="mord mathnormal" style="margin-right:0.03588em;">g</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">:</span></span></span></span> Outputs RDD to a storage system</li></ul></li></ol><h3 id="what-is-the-common-interface-of-each-rdd"><a class="markdownIt-Anchor" href="#what-is-the-common-interface-of-each-rdd"></a> What is the common interface of each RDD?</h3><ol><li>A set of partitions, which are atomic pieces of the dataset<ul><li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi><mi>a</mi><mi>r</mi><mi>t</mi><mi>i</mi><mi>t</mi><mi>i</mi><mi>o</mi><mi>n</mi><mi>e</mi><mi>r</mi><mo stretchy="false">(</mo><mo stretchy="false">)</mo><mo>:</mo></mrow><annotation encoding="application/x-tex">partitioner():</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">p</span><span class="mord mathnormal">a</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mord mathnormal">t</span><span class="mord mathnormal">i</span><span class="mord mathnormal">t</span><span class="mord mathnormal">i</span><span class="mord mathnormal">o</span><span class="mord mathnormal">n</span><span class="mord mathnormal">e</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mopen">(</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">:</span></span></span></span> Return metadata specifying whether the RDD is hash/range partitioned.</li></ul></li><li>A set of dependencies on parent RDDs<ul><li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>d</mi><mi>e</mi><mi>p</mi><mi>e</mi><mi>n</mi><mi>d</mi><mi>e</mi><mi>n</mi><mi>c</mi><mi>i</mi><mi>e</mi><mi>s</mi><mo stretchy="false">(</mo><mo stretchy="false">)</mo><mo>:</mo></mrow><annotation encoding="application/x-tex">dependencies():</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">d</span><span class="mord mathnormal">e</span><span class="mord mathnormal">p</span><span class="mord mathnormal">e</span><span class="mord mathnormal">n</span><span class="mord mathnormal">d</span><span class="mord mathnormal">e</span><span class="mord mathnormal">n</span><span class="mord mathnormal">c</span><span class="mord mathnormal">i</span><span class="mord mathnormal">e</span><span class="mord mathnormal">s</span><span class="mopen">(</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">:</span></span></span></span> Return a list of dependencies.</li></ul></li><li>A function for computing the dataset based on its parents<ul><li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>i</mi><mi>t</mi><mi>e</mi><mi>r</mi><mi>a</mi><mi>t</mi><mi>o</mi><mi>r</mi><mo stretchy="false">(</mo><mi>p</mi><mo separator="true">,</mo><mi>p</mi><mi>a</mi><mi>r</mi><mi>e</mi><mi>n</mi><mi>t</mi><mi>I</mi><mi>t</mi><mi>e</mi><mi>r</mi><mi>s</mi><mo stretchy="false">)</mo><mo>:</mo></mrow><annotation encoding="application/x-tex">iterator(p, parentIters):</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">i</span><span class="mord mathnormal">t</span><span class="mord mathnormal">e</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mord mathnormal">a</span><span class="mord mathnormal">t</span><span class="mord mathnormal">o</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mopen">(</span><span class="mord mathnormal">p</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal">p</span><span class="mord mathnormal">a</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mord mathnormal">e</span><span class="mord mathnormal">n</span><span class="mord mathnormal">t</span><span class="mord mathnormal" style="margin-right:0.07847em;">I</span><span class="mord mathnormal">t</span><span class="mord mathnormal">e</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mord mathnormal">s</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">:</span></span></span></span> Compute the elements of partition p given iterators for its parent partitions.</li></ul></li><li>Metadata about its partitioning scheme and data placement<ul><li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi><mi>a</mi><mi>r</mi><mi>t</mi><mi>i</mi><mi>t</mi><mi>i</mi><mi>o</mi><mi>n</mi><mi>s</mi><mo stretchy="false">(</mo><mo stretchy="false">)</mo><mo>:</mo></mrow><annotation encoding="application/x-tex">partitions():</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">p</span><span class="mord mathnormal">a</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mord mathnormal">t</span><span class="mord mathnormal">i</span><span class="mord mathnormal">t</span><span class="mord mathnormal">i</span><span class="mord mathnormal">o</span><span class="mord mathnormal">n</span><span class="mord mathnormal">s</span><span class="mopen">(</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">:</span></span></span></span> Return a list of Partition objects.</li><li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi><mi>r</mi><mi>e</mi><mi>f</mi><mi>e</mi><mi>r</mi><mi>r</mi><mi>e</mi><mi>d</mi><mi>L</mi><mi>o</mi><mi>c</mi><mi>a</mi><mi>t</mi><mi>i</mi><mi>o</mi><mi>n</mi><mi>s</mi><mo stretchy="false">(</mo><mi>p</mi><mo stretchy="false">)</mo><mo>:</mo></mrow><annotation encoding="application/x-tex">preferredLocations(p):</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">p</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mord mathnormal">e</span><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="mord mathnormal">e</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mord mathnormal">e</span><span class="mord mathnormal">d</span><span class="mord mathnormal">L</span><span class="mord mathnormal">o</span><span class="mord mathnormal">c</span><span class="mord mathnormal">a</span><span class="mord mathnormal">t</span><span class="mord mathnormal">i</span><span class="mord mathnormal">o</span><span class="mord mathnormal">n</span><span class="mord mathnormal">s</span><span class="mopen">(</span><span class="mord mathnormal">p</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">:</span></span></span></span> List nodes where the partition <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi></mrow><annotation encoding="application/x-tex">p</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord mathnormal">p</span></span></span></span> can be accessed faster due to data locality</li></ul></li></ol><h3 id="what-is-the-interface-that-represents-dependencies-between-rdds"><a class="markdownIt-Anchor" href="#what-is-the-interface-that-represents-dependencies-between-rdds"></a> What is the interface that represents dependencies between RDDs?</h3><ol><li><p>Classify dependencies into two types:</p><ul><li>Narrow dependencies: each partition of the parent RDD is used by at most one partition of the child RDD.</li><li>Wide dependencies: multiple child partitions may depend on it.</li></ul></li><li><p>Narrow dependencies allow pipelined execution on one cluster node, which can compute all the parent partitions.</p><p>Wide dependencies require data from all parent partitions to be available and shuffled across the nodes using a MapReduce-like operation.</p></li><li><p>Recovery after a node failure is more efficient with a narrow dependency, as only the lost parent partitions need to be recomputed, and they can be recomputed in parallel on different nodes.</p><p>In a lineage graph with wide dependencies, a single failed node might cause the loss of some partition from all the ancestors of an RDD, requiring a complete re-execution.</p></li></ol><h2 id="implementation"><a class="markdownIt-Anchor" href="#implementation"></a> Implementation</h2><h3 id="how-does-spark-schedule-computations"><a class="markdownIt-Anchor" href="#how-does-spark-schedule-computations"></a> How does Spark schedule computations?</h3><ol><li><p>Whenever a user runs an action on an RDD, the scheduler examines that RDD’s lineage graph to build a DAG of stages to execute.</p><ul><li><p>Each stage contains as many pipelined transformations with narrow dependencies as possible.</p></li><li><p>The boundaries of the stages are the shuffle operations required for wide dependencies or any already computed partitions that can short-circuit the computation of a parent RDD.</p></li></ul></li><li><p>The scheduler then launches tasks to compute missing partitions from each stage until the target RDD is computed.</p><ul><li>The scheduler assigns tasks to machines based on data locality using delay scheduling.</li><li>If a task needs to process a partition available in memory on a node, we send it to that node.</li><li>Otherwise, if a task processes a partition for which the containing RDD provides preferred locations (e.g., an HDFS file), we send it to those.</li></ul></li></ol><h3 id="how-does-spark-handle-task-failures"><a class="markdownIt-Anchor" href="#how-does-spark-handle-task-failures"></a> How does Spark handle task failures?</h3><ol><li><p>For wide dependencies, it is possible that those alive workers have long passed the wide-dependent points and already discard intermediate results, causing the stage to become unavailable. In that case, all the dependencies must be re-calculated, which is costly.</p></li><li><p>Hence, intermediate records are materialized on the nodes holding parent partitions to simplify fault recovery.</p><ul><li><p>If a task fails, it will be re-run on another node if its stage’s parents are still available.</p></li><li><p>If some stages have become unavailable, a limited number of tasks to compute the missing partitions are resubmitted in parallel.</p></li></ul></li></ol><h3 id="how-does-spark-manage-the-storage-of-persistent-rdds"><a class="markdownIt-Anchor" href="#how-does-spark-manage-the-storage-of-persistent-rdds"></a> How does Spark manage the storage of persistent RDDs?</h3><ol><li>In-memory storage as deserialized Java objects<ul><li>It provides the fastest performance because the Java VM can access each RDD element natively.</li></ul></li><li>In-memory storage as serialized data<ul><li>It lets users choose a more memory-efficient representation than Java object graphs when space is limited, at the cost of lower performance.</li></ul></li><li>On-disk storage<ul><li>It is useful for RDDs that are too large to keep in RAM but costly to recompute on each use.</li></ul></li></ol><h3 id="how-does-spark-evict-rdds-when-run-out-of-memory"><a class="markdownIt-Anchor" href="#how-does-spark-evict-rdds-when-run-out-of-memory"></a> How does Spark evict RDDs when run out of memory?</h3><ol><li>The LRU eviction policy is used at the RDD level.</li><li>Unless the LRU RDD is the same RDD as the one with the new partition.<ul><li>The old partition is kept in memory to prevent cycling partitions from the same RDD in and out.</li><li>This is important because most operations will run tasks over an entire RDD, so it is likely that the partition already in memory will be needed in the future.</li></ul></li></ol><h3 id="when-will-checkpointing-be-useful"><a class="markdownIt-Anchor" href="#when-will-checkpointing-be-useful"></a> When will checkpointing be useful?</h3><ol><li>Checkpointing is useful for RDDs with long lineage graphs containing wide dependencies.<ul><li>A node failure in the cluster may result in the loss of some slice of data from each parent RDD, requiring a full recomputation.</li></ul></li><li>Checkpointing may never be worthwhile for RDDs with narrow dependencies on data in stable storage.<ul><li>If a node fails, lost partitions from these RDDs can be recomputed in parallel on other nodes at a fraction of the cost of replicating the whole RDD.</li></ul></li><li>The read-only nature of RDDs makes them simpler to checkpoint than general shared memory.<ul><li>Consistency is not a concern. RDDs can be written in the background without program pauses or distributed snapshot schemes.</li></ul></li></ol><h1 id="experiment"><a class="markdownIt-Anchor" href="#experiment"></a> Experiment</h1><ol><li><p>The main contribution of this paper is improving the performance of iterative applications; hence, the author measured the speedup of Spark against Hadoop.</p><ul><li><p>One scene of iterative applications is machine learning applications. The author chose k-means and logistic regression to measure performance.</p><ul><li>The iteration time of k-means is dominated by computation.</li><li>Logistic regression is less compute-intensive and thus more sensitive to time spent in deserialization and I/O.</li><li>The time consumed should be reported for the first iteration and subsequent iterations separately as follows:</li></ul><img src="/imgs/Distributed/Spark/ml-base.png" width="50%"></li><li><p>Another scene is the PageRank algorithm.</p></li></ul></li><li><p>Hadoop ran slower due to several factors.</p><ul><li>Minimum overhead of the Hadoop software stack<ul><li>It can be measured by running no-op Hadoop jobs.</li></ul></li><li>The overhead of HDFS while serving data<ul><li>HDFS performed multiple memory copies and a checksum to serve each block.</li><li>This can be seen by comparing the time it takes to access in-memory HDFS and local files.</li></ul></li><li>Deserialization cost to convert binary records to usable in-memory Java objects.<ul><li>This can be seen by comparing the time of access to text and binary input.</li></ul></li></ul><img src="/imgs/Distributed/Spark/hadoop.png" width=50%></li><li><p>Scalability is another metric. The result of a machine learning algorithm is as shown below:</p><img src="/imgs/Distributed/Spark/ml-scale.png" width="50%"></li><li><p>Another important metric of the systems is failure fault recovery.</p><ul><li>The author measured the time consumed in each iteration while a node failed at the start of 6th iteration.</li></ul><img src="/imgs/Distributed/Spark/fault-recovery.png" width="50%"></li><li><p>Given that Spark assumes that most RDDs will be stored in memory, the author also measured the performance when memory is limited.</p><ul><li>The performance degrades gracefully with less space.</li></ul><img src="/imgs/Distributed/Spark/mem-lim.png" width=50%></li><li><p>Given that Spark provides an interactive interpreter, the author also measured the response time thes of those queries.</p></li><li><p>To prove that RDD can support a broad class of applications, the author showed how to use RDDs to express existing programming models (e.g., MapReduce, SQL, Pregel)</p></li></ol>]]></content>
      
      
      <categories>
          
          <category> Paper Notebook </category>
          
          <category> Distributed System </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Distributed System </tag>
            
            <tag> Distributed Computation </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Spanner</title>
      <link href="/2023/09/26/Paper/Distributed/Spanner/"/>
      <url>/2023/09/26/Paper/Distributed/Spanner/</url>
      
        <content type="html"><![CDATA[<p>Paper: <a href="http://nil.csail.mit.edu/6.824/2020/papers/spanner.pdf">Spanner: Google’s Globally-Distributed Database</a></p><p><ul class="markdownIt-TOC"><li><a href="#abstract">Abstract</a></li><li><a href="#purpose">Purpose</a></li><li><a href="#model">Model</a><ul><li><a href="#structure-of-implementation">Structure of implementation</a><ul><li><a href="#what-is-the-overview-of-the-spanner-server-organization">What is the overview of the Spanner server organization?</a></li><li><a href="#what-are-the-zones-in-spanner">What are the zones in Spanner?</a></li><li><a href="#software-stack">Software stack</a><ul><li><a href="#how-does-spanner-manage-key-value-pairs">How does Spanner manage key-value pairs?</a></li><li><a href="#how-does-spanner-support-replication">How does Spanner support replication?</a></li><li><a href="#how-does-spanner-manage-the-lock-table">How does Spanner manage the lock table?</a></li><li><a href="#how-does-spanner-manage-transactions">How does Spanner manage transactions?</a></li></ul></li><li><a href="#data-management">Data management</a><ul><li><a href="#how-does-spanner-manage-data-placement">How does Spanner manage data placement?</a></li><li><a href="#when-would-spanner-move-a-directory">When would Spanner move a directory?</a></li><li><a href="#how-does-spanner-move-a-directory">How does Spanner move a directory?</a></li><li><a href="#how-do-applications-specify-the-placement-of-data">How do applications specify the placement of data?</a></li><li><a href="#what-is-the-data-model-of-spanner">What is the data model of Spanner?</a></li></ul></li></ul></li><li><a href="#truetime-api">TrueTime API</a><ul><li><a href="#how-does-truetime-api-represent-time">How does TrueTime API represent time?</a></li><li><a href="#how-is-truetime-api-implemented">How is TrueTime API implemented?</a></li><li><a href="#what-do-time-masters-need-to-do">What do time masters need to do?</a></li><li><a href="#what-do-daemons-need-to-do">What do daemons need to do?</a></li></ul></li><li><a href="#concurrency-control">Concurrency control</a><ul><li><a href="#how-does-spanner-manage-paxos-leader-leases">How does Spanner manage Paxos leader leases?</a></li><li><a href="#read-write-transactions">Read-write transactions</a><ul><li><a href="#how-does-spanner-assign-timestamps-to-rw-transactions">How does Spanner assign timestamps to RW transactions?</a></li><li><a href="#how-does-spanner-enforce-external-consistency-invariant">How does Spanner enforce external-consistency invariant?</a></li><li><a href="#how-does-spanner-handle-reads-within-rw-transactions">How does Spanner handle reads within RW transactions?</a></li><li><a href="#how-does-the-client-drive-a-two-phase-commit">How does the client drive a two-phase commit?</a></li><li><a href="#how-to-perform-the-two-phase-commit">How to perform the two-phase commit?</a></li></ul></li><li><a href="#read-only-transactions">Read-only transactions</a><ul><li><a href="#what-kinds-of-ro-transactions-does-spanner-provide">What kinds of RO transactions does Spanner provide?</a></li><li><a href="#how-does-the-spanner-server-read-given-its-timestamp">How does the Spanner server read, given its timestamp?</a></li><li><a href="#how-to-optimize-for-the-safe-read-timestamp">How to optimize for the safe read timestamp?</a></li><li><a href="#how-to-perform-ro-transactions">How to perform RO transactions?</a></li><li><a href="#how-does-spanner-assign-timestamps-to-ro-transactions">How does Spanner assign timestamps to RO transactions?</a></li></ul></li></ul></li></ul></li><li><a href="#evaluation">Evaluation</a></li></ul></p><h1 id="abstract"><a class="markdownIt-Anchor" href="#abstract"></a> Abstract</h1><ol><li><strong>Main idea</strong>: Spanner is a semi-relational database that supports MVCC. The TrueTime API is designed to solve the problem of clock skew. All timestamps are represented as an interval, and events are ordered by definitely before or after.</li><li><strong>Key findings</strong>: The absolute time of invoking <code>time.Now()</code> is ensured to be contained in the <code>TTInterval</code>. Due to the bias introduced by the clock skew, we must wait until we are sure that a former event has been passed before processing the next event. This could cost transactions waiting for the order determination.</li><li><strong>The system</strong>: The database is built upon key-value storage powered by a consensus algorithm to provide strong linearizability. The transaction actions are based on the TrueTime API to solve the problem of clock skew when deployed globally.</li><li><strong>Evaluation</strong>: Latency and throughput are chosen as the performance metrics, while different replicas and scalability scenarios are measured.</li></ol><h1 id="purpose"><a class="markdownIt-Anchor" href="#purpose"></a> Purpose</h1><ol><li><p>Spanner’s primary focus is managing cross-datacenter replicated data.</p></li><li><p>Problems of Bigtable:</p><ul><li><p>Bigtable can be difficult for those with complex, evolving schemas or those who want strong consistency in the presence of wide-area replication.</p></li><li><p>Many applications at Google have chosen to use Megastore because of its semi-relational data model and support for synchronous replication despite its relatively poor write throughput.</p></li></ul></li><li><p>Spanner new features:</p><ul><li><p>Spanner has evolved from a Bigtable-like versioned key-value store into a temporal multi-version database.</p></li><li><p>Data is stored in schematized semi-relational tables.</p><ul><li>Data is versioned, and each version is automatically timestamped with its commit time.</li><li>Old versions of data are subject to configurable garbage-collection policies.</li><li>Applications can read data at old timestamps.</li></ul></li></ul></li><li><p>Spanner assigns globally meaningful commit timestamps to transactions.</p><ul><li>If a transaction <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>T</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">T_1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> commits before another transaction <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>T</mi><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">T_2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> starts, then <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>T</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">T_1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>’s commit timestamp is smaller than <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>T</mi><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">T_2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>’s.</li><li>Spanner provides externally consistent reads and writes and globally consistent reads across the database at a timestamp.</li></ul></li></ol><h1 id="model"><a class="markdownIt-Anchor" href="#model"></a> Model</h1><h2 id="structure-of-implementation"><a class="markdownIt-Anchor" href="#structure-of-implementation"></a> Structure of implementation</h2><h3 id="what-is-the-overview-of-the-spanner-server-organization"><a class="markdownIt-Anchor" href="#what-is-the-overview-of-the-spanner-server-organization"></a> What is the overview of the Spanner server organization?</h3><ol><li>A Spanner deployment is called a universe.</li><li>Spanner is organized as a set of zones.<ul><li>A zone has one zonemaster and between one hundred and several thousand spanservers.</li><li>The zonemaster assigns data to spanservers; the spanservers serve data to clients.</li><li>Clients use the per-zone location proxies to locate the spanservers assigned to serve their data.</li></ul></li><li>The universe master is primarily a console that displays status information about all the zones for interactive debugging.</li><li>The placement driver handles the automated movement of data across zones on the timescale of minutes.<ul><li>The placement driver periodically communicates with the spanservers to find data that needs to be moved to meet updated replication constraints or balance the load.</li></ul></li><li>The universe master and the placement driver are currently singletons.</li></ol><img src="/imgs/Distributed/Spanner/structure.png" width="50%"><h3 id="what-are-the-zones-in-spanner"><a class="markdownIt-Anchor" href="#what-are-the-zones-in-spanner"></a> What are the zones in Spanner?</h3><ol><li>Each zone is the rough analog of a deployment of Bigtable servers.</li><li>Zones are the unit of administrative deployment. The set of zones is also the set of locations across which data can be replicated.</li><li>Zones can be added to or removed from a running system as new datacenters are brought into service and old ones are turned off, respectively.</li><li>Zones are also the unit of physical isolation. There may be one or more zones in a datacenter.</li></ol><h3 id="software-stack"><a class="markdownIt-Anchor" href="#software-stack"></a> Software stack</h3><img src="/imgs/Distributed/Spanner/software.png" width=50%><h4 id="how-does-spanner-manage-key-value-pairs"><a class="markdownIt-Anchor" href="#how-does-spanner-manage-key-value-pairs"></a> How does Spanner manage key-value pairs?</h4><ol><li>At the bottom, each spanserver is responsible for between 100 and 1000 instances of a data structure called a tablet.</li><li>A tablet is similar to Bigtable’s tablet abstraction, which implements a bag of the following mappings: <code>(key: string, timestamp: int64) → string</code>.</li><li>Unlike Bigtable, Spanner assigns timestamps to data, which is more like a multi-version database than a key-value store.</li><li>A tablet’s state is stored in a set of B-tree-like files and a write-ahead log, all on a distributed file system called Colossus.</li></ol><h4 id="how-does-spanner-support-replication"><a class="markdownIt-Anchor" href="#how-does-spanner-support-replication"></a> How does Spanner support replication?</h4><ol><li>Each spanserver implements a single Paxos state machine on top of each tablet.<ul><li>Its Paxos implementation supports long-lived leaders with time-based leader leases, whose length defaults to 10 seconds.</li><li>The implementation logs every Paxos write twice: once in the tablet’s and once in the Paxos’ log. (made out of expediency, to be remedied eventually)</li><li>The implementation of Paxos is pipelined to improve Spanner’s throughput in the presence of WAN latencies, but Paxos applies the writes in order.</li></ul></li><li>The Paxos state machines implement a consistently replicated bag of mappings.<ul><li>Each state machine stores its metadata and logs in its corresponding tablet.</li><li>Writes must initiate the Paxos protocol at the leader; reads access state directly from the underlying tablet at any sufficiently up-to-date replica.</li></ul></li></ol><h4 id="how-does-spanner-manage-the-lock-table"><a class="markdownIt-Anchor" href="#how-does-spanner-manage-the-lock-table"></a> How does Spanner manage the lock table?</h4><ol><li>At every replica that is a leader, each spanserver implements a lock table to implement concurrency control.</li><li>The lock table contains the state for two-phase locking: it maps ranges of keys to lock states.</li><li>Having a long-lived Paxos leader is critical to efficiently managing the lock table.</li></ol><h4 id="how-does-spanner-manage-transactions"><a class="markdownIt-Anchor" href="#how-does-spanner-manage-transactions"></a> How does Spanner manage transactions?</h4><ol><li><p>At every replica that is a leader, each spanserver also implements a transaction manager to support distributed transactions.</p><ul><li>The transaction manager is used to implement a <strong>participant leader</strong>; the other replicas in the group will be referred to as <strong>participant slaves</strong>.</li></ul></li><li><p>A transaction involving only one Paxos group can bypass the transaction manager, since the lock table and Paxos together provide transactionality.</p></li><li><p>If a transaction involves more than one Paxos group, those groups’ leaders coordinate to perform a two-phase commit.</p><ul><li><p>One of the participant groups is chosen as the coordinator: the participant leader of that group will be referred to as the <strong>coordinator leader</strong>, and the slaves of that group as <strong>coordinator slaves</strong>.</p></li><li><p>The state of each transaction manager is stored in the underlying Paxos group.</p></li></ul></li></ol><h3 id="data-management"><a class="markdownIt-Anchor" href="#data-management"></a> Data management</h3><h4 id="how-does-spanner-manage-data-placement"><a class="markdownIt-Anchor" href="#how-does-spanner-manage-data-placement"></a> How does Spanner manage data placement?</h4><ol><li>A <strong>directory</strong> is a set of contiguous keys that share a common prefix.<ul><li>A directory is the unit of data placement. All data in a directory has the same replication configuration.</li><li>Directories can be moved while client operations are ongoing.</li><li>A Paxos group may contain multiple directories, i.e., a Spanner tablet is a container that may encapsulate multiple partitions of the row space.</li></ul></li><li>Spanner will shard a directory into multiple fragments if it grows too large.<ul><li>Fragments may be served from different Paxos groups.</li><li><code>Movedir</code> moves fragments, and not whole directories, between groups.</li></ul></li></ol><h4 id="when-would-spanner-move-a-directory"><a class="markdownIt-Anchor" href="#when-would-spanner-move-a-directory"></a> When would Spanner move a directory?</h4><ol><li>To shed load from a Paxos group.</li><li>To put directories that are frequently accessed together into the same group.</li><li>To move a directory into a group that is closer to its accessors.</li></ol><h4 id="how-does-spanner-move-a-directory"><a class="markdownIt-Anchor" href="#how-does-spanner-move-a-directory"></a> How does Spanner move a directory?</h4><ol><li>Movedir is not implemented as a single transaction to avoid blocking ongoing reads and writes on a bulky data move.</li><li>Instead, <code>movedir</code> registers that it is starting to move data and moves the data in the background.</li><li>When it has moved all but a nominal amount of the data, it uses a transaction to atomically move that nominal amount and update the metadata for the two Paxos groups.</li></ol><h4 id="how-do-applications-specify-the-placement-of-data"><a class="markdownIt-Anchor" href="#how-do-applications-specify-the-placement-of-data"></a> How do applications specify the placement of data?</h4><ol><li>A directory is also the smallest unit whose geographic replication properties can be specified by an application.</li><li>Administrators control two dimensions: the number and types of replicas, and the geographic placement of those replicas.<ul><li>They create a menu of named options in these two dimensions.</li></ul></li><li>An application controls how data is replicated by tagging each database and individual directories with a combination of those options.</li></ol><h4 id="what-is-the-data-model-of-spanner"><a class="markdownIt-Anchor" href="#what-is-the-data-model-of-spanner"></a> What is the data model of Spanner?</h4><ol><li><p>Spanner exposes the following set of data features to applications.</p><ul><li>A data model based on schematized semi-relational tables</li><li>A query language</li><li>General purpose transactions</li></ul></li><li><p>The application data model is layered on top of the directory-bucketed key-value mappings supported by the implementation.</p><ul><li><p>An application creates one or more databases in a universe.</p></li><li><p>Each database can contain an unlimited number of schematized tables.</p></li><li><p>Tables look like relational-database tables, with rows, columns, and versioned values.</p></li></ul></li><li><p>Every table must have an ordered set of one or more primary-key columns.</p><ul><li>The primary keys form the name of a row, and each table defines a mapping from the primary-key columns to the non-primary-key columns.</li><li>A row has existence only if some value (even if it is NULL) is defined for the row’s keys.</li></ul></li><li><p>Clients must partition every Spanner database into one or more tables in a hierarchical order.</p><ul><li>Each row in a directory table with key K and all of the rows in descendant tables that start with K in lexicographic order form a directory.</li></ul></li></ol><h2 id="truetime-api"><a class="markdownIt-Anchor" href="#truetime-api"></a> TrueTime API</h2><h3 id="how-does-truetime-api-represent-time"><a class="markdownIt-Anchor" href="#how-does-truetime-api-represent-time"></a> How does TrueTime API represent time?</h3><ol><li><p>TrueTime explicitly represents time as a <code>TTinterval</code>, an interval with bounded time uncertainty. The endpoints of a <code>TTinterval</code> are of type <code>TTstamp</code>.</p></li><li><p>The <code>TT.now()</code> method returns a <code>TTinterval</code>: <code>[earliest, latest]</code> that is guaranteed to contain the absolute time during which <code>TT.now()</code> was invoked.</p><ul><li>Denote the absolute time of an event e by the function <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>t</mi><mrow><mi>a</mi><mi>b</mi><mi>s</mi></mrow></msub><mo stretchy="false">(</mo><mi>e</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">t_{abs}(e)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathnormal">t</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">a</span><span class="mord mathnormal mtight">b</span><span class="mord mathnormal mtight">s</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathnormal">e</span><span class="mclose">)</span></span></span></span>.</li><li>TrueTime guarantees that for an invocation <code>tt = TT.now()</code>, <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>t</mi><mi>t</mi><mi mathvariant="normal">.</mi><mi>e</mi><mi>a</mi><mi>r</mi><mi>l</mi><mi>i</mi><mi>e</mi><mi>s</mi><mi>t</mi><mo>≤</mo><msub><mi>t</mi><mrow><mi>a</mi><mi>b</mi><mi>s</mi></mrow></msub><mo stretchy="false">(</mo><msub><mi>e</mi><mrow><mi>n</mi><mi>o</mi><mi>w</mi></mrow></msub><mo stretchy="false">)</mo><mo>≤</mo><mi>t</mi><mi>t</mi><mi mathvariant="normal">.</mi><mi>l</mi><mi>a</mi><mi>t</mi><mi>e</mi><mi>s</mi><mi>t</mi></mrow><annotation encoding="application/x-tex">tt.earliest ≤ t_{abs}(e_{now}) ≤ tt.latest</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83041em;vertical-align:-0.13597em;"></span><span class="mord mathnormal">t</span><span class="mord mathnormal">t</span><span class="mord">.</span><span class="mord mathnormal">e</span><span class="mord mathnormal">a</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mord mathnormal" style="margin-right:0.01968em;">l</span><span class="mord mathnormal">i</span><span class="mord mathnormal">e</span><span class="mord mathnormal">s</span><span class="mord mathnormal">t</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">≤</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathnormal">t</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">a</span><span class="mord mathnormal mtight">b</span><span class="mord mathnormal mtight">s</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">e</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">n</span><span class="mord mathnormal mtight">o</span><span class="mord mathnormal mtight" style="margin-right:0.02691em;">w</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">≤</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathnormal">t</span><span class="mord mathnormal">t</span><span class="mord">.</span><span class="mord mathnormal" style="margin-right:0.01968em;">l</span><span class="mord mathnormal">a</span><span class="mord mathnormal">t</span><span class="mord mathnormal">e</span><span class="mord mathnormal">s</span><span class="mord mathnormal">t</span></span></span></span>, where <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>e</mi><mrow><mi>n</mi><mi>o</mi><mi>w</mi></mrow></msub></mrow><annotation encoding="application/x-tex">e_{now}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">e</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">n</span><span class="mord mathnormal mtight">o</span><span class="mord mathnormal mtight" style="margin-right:0.02691em;">w</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> is the invocation event.</li></ul></li><li><p><code>TT.after(t)</code> returns <code>true</code> if t has definitely passed.</p><p><code>TT.before(t)</code> returns <code>true</code> if t has definitely not arrived.</p></li></ol><h3 id="how-is-truetime-api-implemented"><a class="markdownIt-Anchor" href="#how-is-truetime-api-implemented"></a> How is TrueTime API implemented?</h3><ol><li>TrueTime is implemented by a set of <strong>time master</strong> machines per datacenter and a <strong>timeslave daemon</strong> per machine.</li><li>The majority of masters have GPS receivers with dedicated antennas.<ul><li>These masters are separated physically to reduce the effects of antenna failures, radio interference, and spoofing.</li></ul></li><li>The remaining masters (which we refer to as <strong>Armageddon masters</strong>) are equipped with atomic clocks.</li></ol><h3 id="what-do-time-masters-need-to-do"><a class="markdownIt-Anchor" href="#what-do-time-masters-need-to-do"></a> What do time masters need to do?</h3><ol><li><p>All masters’ time references are regularly compared against each other.</p></li><li><p>Each master also cross-checks the rate at which its reference advances time against its local clock and evicts itself if there is substantial divergence.</p></li><li><p>Between synchronizations,</p><ul><li><p>Armageddon masters advertise a slowly increasing time uncertainty derived from conservatively applied worst-case clock drift.</p></li><li><p>GPS masters advertise uncertainty that is typically close to zero.</p></li></ul></li></ol><h3 id="what-do-daemons-need-to-do"><a class="markdownIt-Anchor" href="#what-do-daemons-need-to-do"></a> What do daemons need to do?</h3><ol><li>Every daemon polls a variety of masters to reduce vulnerability to errors from any one master.<ul><li>Some are GPS masters chosen from nearby datacenters.</li><li>The rest are GPS masters from farther datacenters and some Armageddon masters.</li></ul></li><li>Daemons apply a variant of Marzullo’s algorithm to detect and reject liars, and synchronize the local machine clocks to the non-liars.</li><li>To protect against broken local clocks, machines that exhibit frequency excursions larger than the worst-case bound derived from component specifications and operating environment are evicted.</li><li>Between synchronizations,<ul><li>A daemon advertises a slowly increasing time uncertainty. <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>ϵ</mi></mrow><annotation encoding="application/x-tex">\epsilon</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathnormal">ϵ</span></span></span></span> is derived from conservatively applied worst-case local clock drift.</li><li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>ϵ</mi></mrow><annotation encoding="application/x-tex">\epsilon</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathnormal">ϵ</span></span></span></span> also depends on time-master uncertainty and communication delays to the time masters.</li></ul></li></ol><h2 id="concurrency-control"><a class="markdownIt-Anchor" href="#concurrency-control"></a> Concurrency control</h2><h3 id="how-does-spanner-manage-paxos-leader-leases"><a class="markdownIt-Anchor" href="#how-does-spanner-manage-paxos-leader-leases"></a> How does Spanner manage Paxos leader leases?</h3><ol><li>Spanner depends on the <strong>disjointness invariant</strong>: for each Paxos group, each Paxos leader’s lease interval is disjoint from every other leader’s.</li><li>The Spanner implementation permits a Paxos leader to abdicate by releasing its slaves from their lease votes.<ul><li>To preserve the disjointness invariant, Spanner constrains when abdication is permissible.</li><li>Define <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>s</mi><mrow><mi>m</mi><mi>a</mi><mi>x</mi></mrow></msub></mrow><annotation encoding="application/x-tex">s_{max}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">m</span><span class="mord mathnormal mtight">a</span><span class="mord mathnormal mtight">x</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> to be the maximum timestamp used by a leader. Before abdicating, a leader must wait until <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>T</mi><mi>T</mi><mi mathvariant="normal">.</mi><mi>a</mi><mi>f</mi><mi>t</mi><mi>e</mi><mi>r</mi><mo stretchy="false">(</mo><msub><mi>s</mi><mrow><mi>m</mi><mi>a</mi><mi>x</mi></mrow></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">TT.after(s_{max})</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="mord">.</span><span class="mord mathnormal">a</span><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="mord mathnormal">t</span><span class="mord mathnormal">e</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">m</span><span class="mord mathnormal mtight">a</span><span class="mord mathnormal mtight">x</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span> is true.</li></ul></li></ol><h3 id="read-write-transactions"><a class="markdownIt-Anchor" href="#read-write-transactions"></a> Read-write transactions</h3><h4 id="how-does-spanner-assign-timestamps-to-rw-transactions"><a class="markdownIt-Anchor" href="#how-does-spanner-assign-timestamps-to-rw-transactions"></a> How does Spanner assign timestamps to RW transactions?</h4><ol><li>For a given transaction, Spanner assigns the timestamp Paxos assigns to the Paxos write representing the transaction commit.</li><li><strong>Monotonicity invariant</strong>: within each Paxos group, Spanner assigns timestamps to Paxos writes in monotonically increasing order, even across leaders.<ul><li>This invariance is enforced across leaders by using the disjointness invariant: a leader must only assign timestamps within the interval of its leader lease.</li><li>Whenever a timestamp <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>s</mi></mrow><annotation encoding="application/x-tex">s</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathnormal">s</span></span></span></span> is assigned, <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>s</mi><mrow><mi>m</mi><mi>a</mi><mi>x</mi></mrow></msub></mrow><annotation encoding="application/x-tex">s_{max}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">m</span><span class="mord mathnormal mtight">a</span><span class="mord mathnormal mtight">x</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> is advanced to s to preserve disjointness.</li></ul></li></ol><h4 id="how-does-spanner-enforce-external-consistency-invariant"><a class="markdownIt-Anchor" href="#how-does-spanner-enforce-external-consistency-invariant"></a> How does Spanner enforce external-consistency invariant?</h4><ol><li><p><strong>External-consistency invariant</strong>: if the start of a transaction <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>T</mi><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">T_2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> occurs after the commit of a transaction <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>T</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">T_1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>, then the commit timestamp of <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>T</mi><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">T_2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> must be greater than the commit timestamp of <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>T</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">T_1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>.</p></li><li><p>Define the start and commit events for a transaction <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>T</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">T_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> by <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msubsup><mi>e</mi><mi>i</mi><mrow><mi>s</mi><mi>t</mi><mi>a</mi><mi>r</mi><mi>t</mi></mrow></msubsup></mrow><annotation encoding="application/x-tex">e^{start}_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.05222em;vertical-align:-0.258664em;"></span><span class="mord"><span class="mord mathnormal">e</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.7935559999999999em;"><span style="top:-2.441336em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">s</span><span class="mord mathnormal mtight">t</span><span class="mord mathnormal mtight">a</span><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span><span class="mord mathnormal mtight">t</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.258664em;"><span></span></span></span></span></span></span></span></span></span> and <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msubsup><mi>e</mi><mi>i</mi><mrow><mi>c</mi><mi>o</mi><mi>m</mi><mi>m</mi><mi>i</mi><mi>t</mi></mrow></msubsup></mrow><annotation encoding="application/x-tex">e^{commit}_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.0833279999999998em;vertical-align:-0.258664em;"></span><span class="mord"><span class="mord mathnormal">e</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.824664em;"><span style="top:-2.441336em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">c</span><span class="mord mathnormal mtight">o</span><span class="mord mathnormal mtight">m</span><span class="mord mathnormal mtight">m</span><span class="mord mathnormal mtight">i</span><span class="mord mathnormal mtight">t</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.258664em;"><span></span></span></span></span></span></span></span></span></span> ; and the commit timestamp of a transaction <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>T</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">T_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> by <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>s</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">s_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>. The invariant becomes <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>t</mi><mrow><mi>a</mi><mi>b</mi><mi>s</mi></mrow></msub><mo stretchy="false">(</mo><msubsup><mi>e</mi><mn>1</mn><mrow><mi>c</mi><mi>o</mi><mi>m</mi><mi>m</mi><mi>i</mi><mi>t</mi></mrow></msubsup><mo stretchy="false">)</mo><mo>&lt;</mo><msub><mi>t</mi><mrow><mi>a</mi><mi>b</mi><mi>s</mi></mrow></msub><mo stretchy="false">(</mo><msubsup><mi>e</mi><mn>2</mn><mrow><mi>s</mi><mi>t</mi><mi>a</mi><mi>r</mi><mi>t</mi></mrow></msubsup><mo stretchy="false">)</mo><mo>⇒</mo><msub><mi>s</mi><mn>1</mn></msub><mo>&lt;</mo><msub><mi>s</mi><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">t_{abs}(e^{commit}_1 ) &lt; t_{abs}(e^{start}_2 ) \Rightarrow s_1 &lt; s_2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.0746639999999998em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathnormal">t</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">a</span><span class="mord mathnormal mtight">b</span><span class="mord mathnormal mtight">s</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">e</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.824664em;"><span style="top:-2.4518920000000004em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">c</span><span class="mord mathnormal mtight">o</span><span class="mord mathnormal mtight">m</span><span class="mord mathnormal mtight">m</span><span class="mord mathnormal mtight">i</span><span class="mord mathnormal mtight">t</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.24810799999999997em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">&lt;</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.043556em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathnormal">t</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">a</span><span class="mord mathnormal mtight">b</span><span class="mord mathnormal mtight">s</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">e</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.7935559999999999em;"><span style="top:-2.4518920000000004em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">s</span><span class="mord mathnormal mtight">t</span><span class="mord mathnormal mtight">a</span><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span><span class="mord mathnormal mtight">t</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.24810799999999997em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">⇒</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.6891em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">&lt;</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>.</p></li><li><p>Define the arrival event of the commit request at the coordinator leader for a write <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>T</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">T_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> to be <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msubsup><mi>e</mi><mi>i</mi><mrow><mi>s</mi><mi>e</mi><mi>r</mi><mi>v</mi><mi>e</mi><mi>r</mi></mrow></msubsup></mrow><annotation encoding="application/x-tex">e^{server}_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.923056em;vertical-align:-0.258664em;"></span><span class="mord"><span class="mord mathnormal">e</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.664392em;"><span style="top:-2.441336em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">s</span><span class="mord mathnormal mtight">e</span><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span><span class="mord mathnormal mtight" style="margin-right:0.03588em;">v</span><span class="mord mathnormal mtight">e</span><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.258664em;"><span></span></span></span></span></span></span></span></span></span>.</p></li><li><p>The protocol for executing transactions and assigning timestamps obeys two rules.</p><ul><li><strong>Start</strong>: The coordinator leader for a write <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>T</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">T_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> assigns a commit timestamp <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>s</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">s_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> no less than the value of <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>T</mi><mi>T</mi><mi mathvariant="normal">.</mi><mi>n</mi><mi>o</mi><mi>w</mi><mo stretchy="false">(</mo><mo stretchy="false">)</mo><mi mathvariant="normal">.</mi><mi>l</mi><mi>a</mi><mi>t</mi><mi>e</mi><mi>s</mi><mi>t</mi></mrow><annotation encoding="application/x-tex">TT.now().latest</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="mord">.</span><span class="mord mathnormal">n</span><span class="mord mathnormal">o</span><span class="mord mathnormal" style="margin-right:0.02691em;">w</span><span class="mopen">(</span><span class="mclose">)</span><span class="mord">.</span><span class="mord mathnormal" style="margin-right:0.01968em;">l</span><span class="mord mathnormal">a</span><span class="mord mathnormal">t</span><span class="mord mathnormal">e</span><span class="mord mathnormal">s</span><span class="mord mathnormal">t</span></span></span></span>, computed after <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msubsup><mi>e</mi><mi>i</mi><mrow><mi>s</mi><mi>e</mi><mi>r</mi><mi>v</mi><mi>e</mi><mi>r</mi></mrow></msubsup></mrow><annotation encoding="application/x-tex">e^{server}_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.923056em;vertical-align:-0.258664em;"></span><span class="mord"><span class="mord mathnormal">e</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.664392em;"><span style="top:-2.441336em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">s</span><span class="mord mathnormal mtight">e</span><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span><span class="mord mathnormal mtight" style="margin-right:0.03588em;">v</span><span class="mord mathnormal mtight">e</span><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.258664em;"><span></span></span></span></span></span></span></span></span></span> .</li><li><strong>Commit Wait</strong>: The coordinator leader ensures that clients cannot see any data committed by <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>T</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">T_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> until <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>T</mi><mi>T</mi><mi mathvariant="normal">.</mi><mi>a</mi><mi>f</mi><mi>t</mi><mi>e</mi><mi>r</mi><mo stretchy="false">(</mo><msub><mi>s</mi><mi>i</mi></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">TT.after(s_i)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="mord">.</span><span class="mord mathnormal">a</span><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="mord mathnormal">t</span><span class="mord mathnormal">e</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span> is true.<ul><li>Commit wait ensures that <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>s</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">s_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> is less than the absolute commit time of <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>T</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">T_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>, or <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>s</mi><mi>i</mi></msub><mo>&lt;</mo><msub><mi>t</mi><mrow><mi>a</mi><mi>b</mi><mi>s</mi></mrow></msub><mo stretchy="false">(</mo><msubsup><mi>e</mi><mi>i</mi><mrow><mi>c</mi><mi>o</mi><mi>m</mi><mi>m</mi><mi>i</mi><mi>t</mi></mrow></msubsup><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">s_i &lt; t_{abs}(e^{commit}_i )</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6891em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">&lt;</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.0833279999999998em;vertical-align:-0.258664em;"></span><span class="mord"><span class="mord mathnormal">t</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">a</span><span class="mord mathnormal mtight">b</span><span class="mord mathnormal mtight">s</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">e</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.824664em;"><span style="top:-2.441336em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">c</span><span class="mord mathnormal mtight">o</span><span class="mord mathnormal mtight">m</span><span class="mord mathnormal mtight">m</span><span class="mord mathnormal mtight">i</span><span class="mord mathnormal mtight">t</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.258664em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span>.</li></ul></li></ul></li><li><p>Proof:</p><img src="/imgs/Distributed/Spanner/ec_invariant.png" width="50%"></li></ol><h4 id="how-does-spanner-handle-reads-within-rw-transactions"><a class="markdownIt-Anchor" href="#how-does-spanner-handle-reads-within-rw-transactions"></a> How does Spanner handle reads within RW transactions?</h4><ol><li>Reads in a transaction do not see the effects of the transaction’s writes.<ul><li>Writes that occur in a transaction are buffered at the client until committed.</li><li>A read returns the timestamps of any data read, and uncommitted writes still need to be assigned timestamps.</li></ul></li><li>Reads within read-write transactions use wound-wait to avoid deadlocks.<ul><li>If an older transaction requests for a resource held by a younger transaction, then an older transaction forces a younger transaction to kill the transaction and release the resource.<ul><li>The younger transaction is restarted with a minute delay but with the same timestamp.</li></ul></li><li>If the younger transaction requests a resource that an older one holds, the younger transaction is asked to wait until the older one releases it.</li></ul></li></ol><h4 id="how-does-the-client-drive-a-two-phase-commit"><a class="markdownIt-Anchor" href="#how-does-the-client-drive-a-two-phase-commit"></a> How does the client drive a two-phase commit?</h4><ol><li>The client issues reads to the leader replica of the appropriate group, which acquires read locks and then reads the most recent data.</li><li>While a client transaction remains open, it sends keepalive messages to prevent participant leaders from timing out its transaction.</li><li>A two-phase commit begins when a client has completed all reads and buffered all writes.<ul><li>The client chooses a coordinator group.</li><li>Then it sends a commit message to each participant’s leader with the identity of the coordinator and any buffered writes.</li></ul></li><li>Having the client drive a two-phase commit avoids sending data twice across wide-area links.</li></ol><h4 id="how-to-perform-the-two-phase-commit"><a class="markdownIt-Anchor" href="#how-to-perform-the-two-phase-commit"></a> How to perform the two-phase commit?</h4><ol><li>A non-coordinator-participant leader,<ul><li>It first acquires write locks.</li><li>It then chooses a prepared timestamp that must be larger than any timestamps assigned to previous transactions and logs a prepared record through Paxos.</li><li>Each participant then notifies the coordinator of the prepared timestamp.</li></ul></li><li>The coordinator leader,<ul><li>It also first acquires write locks but skips the preparation phase.</li><li>After hearing from other participant leaders, a timestamp for the entire transaction is chosen.</li><li>The commit timestamp <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>s</mi></mrow><annotation encoding="application/x-tex">s</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathnormal">s</span></span></span></span> must be<ul><li>Greater or equal to all prepare timestamps,</li><li>Greater than <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>T</mi><mi>T</mi><mi mathvariant="normal">.</mi><mi>n</mi><mi>o</mi><mi>w</mi><mo stretchy="false">(</mo><mo stretchy="false">)</mo><mi mathvariant="normal">.</mi><mi>l</mi><mi>a</mi><mi>t</mi><mi>e</mi><mi>s</mi><mi>t</mi></mrow><annotation encoding="application/x-tex">TT.now().latest</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="mord">.</span><span class="mord mathnormal">n</span><span class="mord mathnormal">o</span><span class="mord mathnormal" style="margin-right:0.02691em;">w</span><span class="mopen">(</span><span class="mclose">)</span><span class="mord">.</span><span class="mord mathnormal" style="margin-right:0.01968em;">l</span><span class="mord mathnormal">a</span><span class="mord mathnormal">t</span><span class="mord mathnormal">e</span><span class="mord mathnormal">s</span><span class="mord mathnormal">t</span></span></span></span> at the time the coordinator received its commit message,</li><li>Greater than any timestamps the leader has assigned to previous transactions.</li><li>The coordinator leader logs a commit record through Paxos, or an abort if it timed out while waiting on the other participants.</li></ul></li></ul></li><li>Before allowing any coordinator replica to apply the commit record, the coordinator leader waits until <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>T</mi><mi>T</mi><mi mathvariant="normal">.</mi><mi>a</mi><mi>f</mi><mi>t</mi><mi>e</mi><mi>r</mi><mo stretchy="false">(</mo><mi>s</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">TT.after(s)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="mord">.</span><span class="mord mathnormal">a</span><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="mord mathnormal">t</span><span class="mord mathnormal">e</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mopen">(</span><span class="mord mathnormal">s</span><span class="mclose">)</span></span></span></span>.<ul><li>This wait is typically overlapped with Paxos communication.</li></ul></li><li>After the commit wait, the coordinator sends the commit timestamp to the client and all other participant leaders.</li><li>Each participant leader logs the transaction’s outcome through Paxos. All participants apply at the same timestamp and then release locks.</li></ol><h3 id="read-only-transactions"><a class="markdownIt-Anchor" href="#read-only-transactions"></a> Read-only transactions</h3><h4 id="what-kinds-of-ro-transactions-does-spanner-provide"><a class="markdownIt-Anchor" href="#what-kinds-of-ro-transactions-does-spanner-provide"></a> What kinds of RO transactions does Spanner provide?</h4><ol><li>A read-only transaction is a transaction that has the performance benefits of snapshot isolation.<ul><li>Reads in a read-only transaction execute at a system-chosen timestamp without locking, so incoming writes are not blocked.</li></ul></li><li>A snapshot read is a read in the past that executes without locking.<ul><li>A client can specify a timestamp for a snapshot read.</li><li>Or they can provide an upper bound on the desired timestamp’s staleness and let Spanner choose a timestamp.</li></ul></li><li>For both read-only transactions and snapshot reads<ul><li>The execution of the reads in a read-only transaction can proceed on any sufficiently up-to-date replica.</li><li>Commit is inevitable once a timestamp has been chosen unless the data has been garbage collected.<ul><li>Clients can avoid buffering results inside a retry loop.</li><li>When a server fails, clients can internally continue the query on a different server by repeating the timestamp and the current read position.</li></ul></li></ul></li></ol><h4 id="how-does-the-spanner-server-read-given-its-timestamp"><a class="markdownIt-Anchor" href="#how-does-the-spanner-server-read-given-its-timestamp"></a> How does the Spanner server read, given its timestamp?</h4><ol><li>Every replica tracks a value called safe time <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>t</mi><mrow><mi>s</mi><mi>a</mi><mi>f</mi><mi>e</mi></mrow></msub></mrow><annotation encoding="application/x-tex">t_{safe}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.9011879999999999em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord mathnormal">t</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361079999999999em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">s</span><span class="mord mathnormal mtight">a</span><span class="mord mathnormal mtight" style="margin-right:0.10764em;">f</span><span class="mord mathnormal mtight">e</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span></span></span></span> which is the maximum timestamp at which a replica is up-to-date.</li><li>Each Paxos state machine has a safe time <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msubsup><mi>t</mi><mrow><mi>s</mi><mi>a</mi><mi>f</mi><mi>e</mi></mrow><mrow><mi>P</mi><mi>a</mi><mi>x</mi><mi>o</mi><mi>s</mi></mrow></msubsup></mrow><annotation encoding="application/x-tex">t^{Paxos}_{safe}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.2605469999999999em;vertical-align:-0.4192159999999999em;"></span><span class="mord"><span class="mord mathnormal">t</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8413309999999999em;"><span style="top:-2.4168920000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">s</span><span class="mord mathnormal mtight">a</span><span class="mord mathnormal mtight" style="margin-right:0.10764em;">f</span><span class="mord mathnormal mtight">e</span></span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em;">P</span><span class="mord mathnormal mtight">a</span><span class="mord mathnormal mtight">x</span><span class="mord mathnormal mtight">o</span><span class="mord mathnormal mtight">s</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.4192159999999999em;"><span></span></span></span></span></span></span></span></span></span>.<ul><li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msubsup><mi>t</mi><mrow><mi>s</mi><mi>a</mi><mi>f</mi><mi>e</mi></mrow><mrow><mi>P</mi><mi>a</mi><mi>x</mi><mi>o</mi><mi>s</mi></mrow></msubsup></mrow><annotation encoding="application/x-tex">t^{Paxos}_{safe}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.2605469999999999em;vertical-align:-0.4192159999999999em;"></span><span class="mord"><span class="mord mathnormal">t</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8413309999999999em;"><span style="top:-2.4168920000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">s</span><span class="mord mathnormal mtight">a</span><span class="mord mathnormal mtight" style="margin-right:0.10764em;">f</span><span class="mord mathnormal mtight">e</span></span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em;">P</span><span class="mord mathnormal mtight">a</span><span class="mord mathnormal mtight">x</span><span class="mord mathnormal mtight">o</span><span class="mord mathnormal mtight">s</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.4192159999999999em;"><span></span></span></span></span></span></span></span></span></span> is the timestamp of the highest-applied Paxos write.</li><li>Because timestamps increase monotonically and writes are applied in order, writes will no longer occur at or below <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msubsup><mi>t</mi><mrow><mi>s</mi><mi>a</mi><mi>f</mi><mi>e</mi></mrow><mrow><mi>P</mi><mi>a</mi><mi>x</mi><mi>o</mi><mi>s</mi></mrow></msubsup></mrow><annotation encoding="application/x-tex">t^{Paxos}_{safe}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.2605469999999999em;vertical-align:-0.4192159999999999em;"></span><span class="mord"><span class="mord mathnormal">t</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8413309999999999em;"><span style="top:-2.4168920000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">s</span><span class="mord mathnormal mtight">a</span><span class="mord mathnormal mtight" style="margin-right:0.10764em;">f</span><span class="mord mathnormal mtight">e</span></span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em;">P</span><span class="mord mathnormal mtight">a</span><span class="mord mathnormal mtight">x</span><span class="mord mathnormal mtight">o</span><span class="mord mathnormal mtight">s</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.4192159999999999em;"><span></span></span></span></span></span></span></span></span></span> concerning Paxos.</li></ul></li><li>Each transaction manager has a safe time <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msubsup><mi>t</mi><mrow><mi>s</mi><mi>a</mi><mi>f</mi><mi>e</mi></mrow><mrow><mi>T</mi><mi>M</mi></mrow></msubsup></mrow><annotation encoding="application/x-tex">t^{TM}_{safe}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.2605469999999999em;vertical-align:-0.4192159999999999em;"></span><span class="mord"><span class="mord mathnormal">t</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8413309999999999em;"><span style="top:-2.4168920000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">s</span><span class="mord mathnormal mtight">a</span><span class="mord mathnormal mtight" style="margin-right:0.10764em;">f</span><span class="mord mathnormal mtight">e</span></span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em;">T</span><span class="mord mathnormal mtight" style="margin-right:0.10903em;">M</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.4192159999999999em;"><span></span></span></span></span></span></span></span></span></span>.<ul><li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msubsup><mi>t</mi><mrow><mi>s</mi><mi>a</mi><mi>f</mi><mi>e</mi></mrow><mrow><mi>T</mi><mi>M</mi></mrow></msubsup></mrow><annotation encoding="application/x-tex">t^{TM}_{safe}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.2605469999999999em;vertical-align:-0.4192159999999999em;"></span><span class="mord"><span class="mord mathnormal">t</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8413309999999999em;"><span style="top:-2.4168920000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">s</span><span class="mord mathnormal mtight">a</span><span class="mord mathnormal mtight" style="margin-right:0.10764em;">f</span><span class="mord mathnormal mtight">e</span></span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em;">T</span><span class="mord mathnormal mtight" style="margin-right:0.10903em;">M</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.4192159999999999em;"><span></span></span></span></span></span></span></span></span></span> is <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal">∞</mi></mrow><annotation encoding="application/x-tex">\infty</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord">∞</span></span></span></span> at a replica if there are zero prepared (but not committed) transactions, i.e., transactions between the two phases of a two-phase commit.</li><li>If there are any such transactions, then the state affected by those transactions is indeterminate.<ul><li>A participant replica has yet to determine whether such transactions will be committed.</li><li>The commit protocol ensures that every participant knows a lower bound on a prepared transaction’s timestamp.</li><li>Every participant leader (for a group <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>g</mi></mrow><annotation encoding="application/x-tex">g</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">g</span></span></span></span>) for a transaction <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>T</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">T_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> assigns a prepared timestamp <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msubsup><mi>s</mi><mrow><mi>i</mi><mo separator="true">,</mo><mi>g</mi></mrow><mrow><mi>p</mi><mi>r</mi><mi>e</mi><mi>p</mi><mi>a</mi><mi>r</mi><mi>e</mi></mrow></msubsup></mrow><annotation encoding="application/x-tex">s^{prepare}_{i,g}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.1952720000000001em;vertical-align:-0.412972em;"></span><span class="mord"><span class="mord mathnormal">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.7823em;"><span style="top:-2.4231360000000004em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight" style="margin-right:0.03588em;">g</span></span></span></span><span style="top:-3.1809080000000005em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">p</span><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span><span class="mord mathnormal mtight">e</span><span class="mord mathnormal mtight">p</span><span class="mord mathnormal mtight">a</span><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span><span class="mord mathnormal mtight">e</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.412972em;"><span></span></span></span></span></span></span></span></span></span> to its prepared record.</li><li>The coordinator leader ensures that the transaction’s commit timestamp <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>s</mi><mi>i</mi></msub><mo>≥</mo><msubsup><mi>s</mi><mrow><mi>i</mi><mo separator="true">,</mo><mi>g</mi></mrow><mrow><mi>p</mi><mi>r</mi><mi>e</mi><mi>p</mi><mi>a</mi><mi>r</mi><mi>e</mi></mrow></msubsup></mrow><annotation encoding="application/x-tex">s_i ≥ s^{prepare}_{i,g}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7859700000000001em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">≥</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.1952720000000001em;vertical-align:-0.412972em;"></span><span class="mord"><span class="mord mathnormal">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.7823em;"><span style="top:-2.4231360000000004em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight" style="margin-right:0.03588em;">g</span></span></span></span><span style="top:-3.1809080000000005em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">p</span><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span><span class="mord mathnormal mtight">e</span><span class="mord mathnormal mtight">p</span><span class="mord mathnormal mtight">a</span><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span><span class="mord mathnormal mtight">e</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.412972em;"><span></span></span></span></span></span></span></span></span></span> over participant groups <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>g</mi></mrow><annotation encoding="application/x-tex">g</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">g</span></span></span></span>.</li><li>For every replica in a group <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>g</mi></mrow><annotation encoding="application/x-tex">g</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">g</span></span></span></span>, overall transactions <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>T</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">T_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> prepared at <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>g</mi></mrow><annotation encoding="application/x-tex">g</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">g</span></span></span></span>, <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msubsup><mi>t</mi><mrow><mi>s</mi><mi>a</mi><mi>f</mi><mi>e</mi></mrow><mrow><mi>T</mi><mi>M</mi></mrow></msubsup><mo>=</mo><mi>m</mi><mi>i</mi><msub><mi>n</mi><mi>i</mi></msub><mo stretchy="false">(</mo><msubsup><mi>s</mi><mrow><mi>i</mi><mo separator="true">,</mo><mi>g</mi></mrow><mrow><mi>p</mi><mi>r</mi><mi>e</mi><mi>p</mi><mi>a</mi><mi>r</mi><mi>e</mi></mrow></msubsup><mo stretchy="false">)</mo><mtext>−</mtext><mn>1</mn></mrow><annotation encoding="application/x-tex">t^{TM}_{safe} = min_i(s^{prepare}_{i,g}) − 1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.2605469999999999em;vertical-align:-0.4192159999999999em;"></span><span class="mord"><span class="mord mathnormal">t</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8413309999999999em;"><span style="top:-2.4168920000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">s</span><span class="mord mathnormal mtight">a</span><span class="mord mathnormal mtight" style="margin-right:0.10764em;">f</span><span class="mord mathnormal mtight">e</span></span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em;">T</span><span class="mord mathnormal mtight" style="margin-right:0.10903em;">M</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.4192159999999999em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.1952720000000001em;vertical-align:-0.412972em;"></span><span class="mord mathnormal">m</span><span class="mord mathnormal">i</span><span class="mord"><span class="mord mathnormal">n</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.7823em;"><span style="top:-2.4231360000000004em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight" style="margin-right:0.03588em;">g</span></span></span></span><span style="top:-3.1809080000000005em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">p</span><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span><span class="mord mathnormal mtight">e</span><span class="mord mathnormal mtight">p</span><span class="mord mathnormal mtight">a</span><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span><span class="mord mathnormal mtight">e</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.412972em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mord">−</span><span class="mord">1</span></span></span></span> overall transactions prepared at <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>g</mi></mrow><annotation encoding="application/x-tex">g</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">g</span></span></span></span>.</li></ul></li></ul></li><li>Define <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>t</mi><mrow><mi>s</mi><mi>a</mi><mi>f</mi><mi>e</mi></mrow></msub><mo>=</mo><mi>m</mi><mi>i</mi><mi>n</mi><mo stretchy="false">(</mo><msubsup><mi>t</mi><mrow><mi>s</mi><mi>a</mi><mi>f</mi><mi>e</mi></mrow><mrow><mi>P</mi><mi>a</mi><mi>x</mi><mi>o</mi><mi>s</mi></mrow></msubsup><mo separator="true">,</mo><msubsup><mi>t</mi><mrow><mi>s</mi><mi>a</mi><mi>f</mi><mi>e</mi></mrow><mrow><mi>T</mi><mi>M</mi></mrow></msubsup><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">t_{safe} = min(t^{Paxos}_{safe} , t^{TM}_{safe})</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.9011879999999999em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord mathnormal">t</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361079999999999em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">s</span><span class="mord mathnormal mtight">a</span><span class="mord mathnormal mtight" style="margin-right:0.10764em;">f</span><span class="mord mathnormal mtight">e</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.2605469999999999em;vertical-align:-0.4192159999999999em;"></span><span class="mord mathnormal">m</span><span class="mord mathnormal">i</span><span class="mord mathnormal">n</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">t</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8413309999999999em;"><span style="top:-2.4168920000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">s</span><span class="mord mathnormal mtight">a</span><span class="mord mathnormal mtight" style="margin-right:0.10764em;">f</span><span class="mord mathnormal mtight">e</span></span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em;">P</span><span class="mord mathnormal mtight">a</span><span class="mord mathnormal mtight">x</span><span class="mord mathnormal mtight">o</span><span class="mord mathnormal mtight">s</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.4192159999999999em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathnormal">t</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8413309999999999em;"><span style="top:-2.4168920000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">s</span><span class="mord mathnormal mtight">a</span><span class="mord mathnormal mtight" style="margin-right:0.10764em;">f</span><span class="mord mathnormal mtight">e</span></span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em;">T</span><span class="mord mathnormal mtight" style="margin-right:0.10903em;">M</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.4192159999999999em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span>. A replica can satisfy a read at a timestamp <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>t</mi></mrow><annotation encoding="application/x-tex">t</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.61508em;vertical-align:0em;"></span><span class="mord mathnormal">t</span></span></span></span> if <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>t</mi><mo>≤</mo><msub><mi>t</mi><mrow><mi>s</mi><mi>a</mi><mi>f</mi><mi>e</mi></mrow></msub></mrow><annotation encoding="application/x-tex">t ≤ t_{safe}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7719400000000001em;vertical-align:-0.13597em;"></span><span class="mord mathnormal">t</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">≤</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.9011879999999999em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord mathnormal">t</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361079999999999em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">s</span><span class="mord mathnormal mtight">a</span><span class="mord mathnormal mtight" style="margin-right:0.10764em;">f</span><span class="mord mathnormal mtight">e</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span></span></span></span>.</li></ol><h4 id="how-to-optimize-for-the-safe-read-timestamp"><a class="markdownIt-Anchor" href="#how-to-optimize-for-the-safe-read-timestamp"></a> How to optimize for the safe read timestamp?</h4><ol><li><p>No reads can occur at timestamps later than <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msubsup><mi>t</mi><mrow><mi>s</mi><mi>a</mi><mi>f</mi><mi>e</mi></mrow><mrow><mi>T</mi><mi>M</mi></mrow></msubsup></mrow><annotation encoding="application/x-tex">t^{TM}_{safe}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.2605469999999999em;vertical-align:-0.4192159999999999em;"></span><span class="mord"><span class="mord mathnormal">t</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8413309999999999em;"><span style="top:-2.4168920000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">s</span><span class="mord mathnormal mtight">a</span><span class="mord mathnormal mtight" style="margin-right:0.10764em;">f</span><span class="mord mathnormal mtight">e</span></span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em;">T</span><span class="mord mathnormal mtight" style="margin-right:0.10903em;">M</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.4192159999999999em;"><span></span></span></span></span></span></span></span></span></span>, even if the reads do not conflict with the transaction.</p><ul><li><p>This can be removed by augmenting <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msubsup><mi>t</mi><mrow><mi>s</mi><mi>a</mi><mi>f</mi><mi>e</mi></mrow><mrow><mi>T</mi><mi>M</mi></mrow></msubsup></mrow><annotation encoding="application/x-tex">t^{TM}_{safe}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.2605469999999999em;vertical-align:-0.4192159999999999em;"></span><span class="mord"><span class="mord mathnormal">t</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8413309999999999em;"><span style="top:-2.4168920000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">s</span><span class="mord mathnormal mtight">a</span><span class="mord mathnormal mtight" style="margin-right:0.10764em;">f</span><span class="mord mathnormal mtight">e</span></span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em;">T</span><span class="mord mathnormal mtight" style="margin-right:0.10903em;">M</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.4192159999999999em;"><span></span></span></span></span></span></span></span></span></span> with a fine-grained mapping from key ranges to prepared transaction timestamps.</p></li><li><p>This information can be stored in the lock table, which maps key ranges to lock metadata.</p></li><li><p>When a read arrives, it only needs to be checked against the fine-grained safe time for key ranges with which the read conflicts.</p></li></ul></li><li><p><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msubsup><mi>t</mi><mrow><mi>s</mi><mi>a</mi><mi>f</mi><mi>e</mi></mrow><mrow><mi>P</mi><mi>a</mi><mi>x</mi><mi>o</mi><mi>s</mi></mrow></msubsup></mrow><annotation encoding="application/x-tex">t^{Paxos}_{safe}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.2605469999999999em;vertical-align:-0.4192159999999999em;"></span><span class="mord"><span class="mord mathnormal">t</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8413309999999999em;"><span style="top:-2.4168920000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">s</span><span class="mord mathnormal mtight">a</span><span class="mord mathnormal mtight" style="margin-right:0.10764em;">f</span><span class="mord mathnormal mtight">e</span></span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em;">P</span><span class="mord mathnormal mtight">a</span><span class="mord mathnormal mtight">x</span><span class="mord mathnormal mtight">o</span><span class="mord mathnormal mtight">s</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.4192159999999999em;"><span></span></span></span></span></span></span></span></span></span> cannot advance in the absence of Paxos writes. A snapshot read at <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>t</mi></mrow><annotation encoding="application/x-tex">t</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.61508em;vertical-align:0em;"></span><span class="mord mathnormal">t</span></span></span></span> cannot execute at Paxos groups whose last write happened before <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>t</mi></mrow><annotation encoding="application/x-tex">t</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.61508em;vertical-align:0em;"></span><span class="mord mathnormal">t</span></span></span></span>.</p><ul><li>Spanner addresses this problem by taking advantage of the disjointness of leader-lease intervals.</li><li>Each Paxos leader advances <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msubsup><mi>t</mi><mrow><mi>s</mi><mi>a</mi><mi>f</mi><mi>e</mi></mrow><mrow><mi>P</mi><mi>a</mi><mi>x</mi><mi>o</mi><mi>s</mi></mrow></msubsup></mrow><annotation encoding="application/x-tex">t^{Paxos}_{safe}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.2605469999999999em;vertical-align:-0.4192159999999999em;"></span><span class="mord"><span class="mord mathnormal">t</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8413309999999999em;"><span style="top:-2.4168920000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">s</span><span class="mord mathnormal mtight">a</span><span class="mord mathnormal mtight" style="margin-right:0.10764em;">f</span><span class="mord mathnormal mtight">e</span></span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em;">P</span><span class="mord mathnormal mtight">a</span><span class="mord mathnormal mtight">x</span><span class="mord mathnormal mtight">o</span><span class="mord mathnormal mtight">s</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.4192159999999999em;"><span></span></span></span></span></span></span></span></span></span> by keeping a threshold above which future writes’ timestamps will occur.<ul><li>It maintains a mapping <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>M</mi><mi>i</mi><mi>n</mi><mi>N</mi><mi>e</mi><mi>x</mi><mi>t</mi><mi>T</mi><mi>S</mi><mo stretchy="false">(</mo><mi>n</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">MinNextTS(n)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">M</span><span class="mord mathnormal">i</span><span class="mord mathnormal">n</span><span class="mord mathnormal" style="margin-right:0.10903em;">N</span><span class="mord mathnormal">e</span><span class="mord mathnormal">x</span><span class="mord mathnormal">t</span><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="mord mathnormal" style="margin-right:0.05764em;">S</span><span class="mopen">(</span><span class="mord mathnormal">n</span><span class="mclose">)</span></span></span></span> from Paxos sequence number <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi></mrow><annotation encoding="application/x-tex">n</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathnormal">n</span></span></span></span> to the minimum timestamp that may be assigned to the Paxos sequence number <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi><mo>+</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">n + 1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.66666em;vertical-align:-0.08333em;"></span><span class="mord mathnormal">n</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">1</span></span></span></span>.</li><li>A replica can advance <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msubsup><mi>t</mi><mrow><mi>s</mi><mi>a</mi><mi>f</mi><mi>e</mi></mrow><mrow><mi>P</mi><mi>a</mi><mi>x</mi><mi>o</mi><mi>s</mi></mrow></msubsup></mrow><annotation encoding="application/x-tex">t^{Paxos}_{safe}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.2605469999999999em;vertical-align:-0.4192159999999999em;"></span><span class="mord"><span class="mord mathnormal">t</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8413309999999999em;"><span style="top:-2.4168920000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">s</span><span class="mord mathnormal mtight">a</span><span class="mord mathnormal mtight" style="margin-right:0.10764em;">f</span><span class="mord mathnormal mtight">e</span></span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em;">P</span><span class="mord mathnormal mtight">a</span><span class="mord mathnormal mtight">x</span><span class="mord mathnormal mtight">o</span><span class="mord mathnormal mtight">s</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.4192159999999999em;"><span></span></span></span></span></span></span></span></span></span> to <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>M</mi><mi>i</mi><mi>n</mi><mi>N</mi><mi>e</mi><mi>x</mi><mi>t</mi><mi>T</mi><mi>S</mi><mo stretchy="false">(</mo><mi>n</mi><mo stretchy="false">)</mo><mtext>−</mtext><mn>1</mn></mrow><annotation encoding="application/x-tex">MinNextTS(n) − 1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">M</span><span class="mord mathnormal">i</span><span class="mord mathnormal">n</span><span class="mord mathnormal" style="margin-right:0.10903em;">N</span><span class="mord mathnormal">e</span><span class="mord mathnormal">x</span><span class="mord mathnormal">t</span><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="mord mathnormal" style="margin-right:0.05764em;">S</span><span class="mopen">(</span><span class="mord mathnormal">n</span><span class="mclose">)</span><span class="mord">−</span><span class="mord">1</span></span></span></span> when it has been applied through <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi></mrow><annotation encoding="application/x-tex">n</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathnormal">n</span></span></span></span>.</li></ul></li><li>A single leader can enforce its <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>M</mi><mi>i</mi><mi>n</mi><mi>N</mi><mi>e</mi><mi>x</mi><mi>t</mi><mi>T</mi><mi>S</mi><mo stretchy="false">(</mo><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">MinNextTS()</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">M</span><span class="mord mathnormal">i</span><span class="mord mathnormal">n</span><span class="mord mathnormal" style="margin-right:0.10903em;">N</span><span class="mord mathnormal">e</span><span class="mord mathnormal">x</span><span class="mord mathnormal">t</span><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="mord mathnormal" style="margin-right:0.05764em;">S</span><span class="mopen">(</span><span class="mclose">)</span></span></span></span> promises easily.<ul><li>The timestamps promised by <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>M</mi><mi>i</mi><mi>n</mi><mi>N</mi><mi>e</mi><mi>x</mi><mi>t</mi><mi>T</mi><mi>S</mi><mo stretchy="false">(</mo><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">MinNextTS()</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">M</span><span class="mord mathnormal">i</span><span class="mord mathnormal">n</span><span class="mord mathnormal" style="margin-right:0.10903em;">N</span><span class="mord mathnormal">e</span><span class="mord mathnormal">x</span><span class="mord mathnormal">t</span><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="mord mathnormal" style="margin-right:0.05764em;">S</span><span class="mopen">(</span><span class="mclose">)</span></span></span></span> lie within a leader’s lease, the disjointness invariant enforces <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>M</mi><mi>i</mi><mi>n</mi><mi>N</mi><mi>e</mi><mi>x</mi><mi>t</mi><mi>T</mi><mi>S</mi><mo stretchy="false">(</mo><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">MinNextTS()</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">M</span><span class="mord mathnormal">i</span><span class="mord mathnormal">n</span><span class="mord mathnormal" style="margin-right:0.10903em;">N</span><span class="mord mathnormal">e</span><span class="mord mathnormal">x</span><span class="mord mathnormal">t</span><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="mord mathnormal" style="margin-right:0.05764em;">S</span><span class="mopen">(</span><span class="mclose">)</span></span></span></span> promises across leaders.</li><li>If a leader wishes to advance MinNextTS() beyond the end of its leader lease, it must first extend its lease.</li></ul></li><li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>s</mi><mrow><mi>m</mi><mi>a</mi><mi>x</mi></mrow></msub></mrow><annotation encoding="application/x-tex">s_{max}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">m</span><span class="mord mathnormal mtight">a</span><span class="mord mathnormal mtight">x</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> is always advanced to the highest value in <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>M</mi><mi>i</mi><mi>n</mi><mi>N</mi><mi>e</mi><mi>x</mi><mi>t</mi><mi>T</mi><mi>S</mi><mo stretchy="false">(</mo><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">MinNextTS()</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">M</span><span class="mord mathnormal">i</span><span class="mord mathnormal">n</span><span class="mord mathnormal" style="margin-right:0.10903em;">N</span><span class="mord mathnormal">e</span><span class="mord mathnormal">x</span><span class="mord mathnormal">t</span><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="mord mathnormal" style="margin-right:0.05764em;">S</span><span class="mopen">(</span><span class="mclose">)</span></span></span></span> to preserve disjointness.</li></ul></li></ol><h4 id="how-to-perform-ro-transactions"><a class="markdownIt-Anchor" href="#how-to-perform-ro-transactions"></a> How to perform RO transactions?</h4><ol><li>A read-only transaction executes in two phases.<ul><li>Assign a timestamp <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>s</mi><mrow><mi>r</mi><mi>e</mi><mi>a</mi><mi>d</mi></mrow></msub></mrow><annotation encoding="application/x-tex">s_{read}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span><span class="mord mathnormal mtight">e</span><span class="mord mathnormal mtight">a</span><span class="mord mathnormal mtight">d</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span></li><li>Then execute the transaction’s reads as snapshot reads at <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>s</mi><mrow><mi>r</mi><mi>e</mi><mi>a</mi><mi>d</mi></mrow></msub></mrow><annotation encoding="application/x-tex">s_{read}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span><span class="mord mathnormal mtight">e</span><span class="mord mathnormal mtight">a</span><span class="mord mathnormal mtight">d</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>.</li><li>The snapshot reads can execute at any sufficiently up-to-date replicas.</li></ul></li><li>The simple assignment of <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>s</mi><mrow><mi>r</mi><mi>e</mi><mi>a</mi><mi>d</mi></mrow></msub><mo>=</mo><mi>T</mi><mi>T</mi><mi mathvariant="normal">.</mi><mi>n</mi><mi>o</mi><mi>w</mi><mo stretchy="false">(</mo><mo stretchy="false">)</mo><mi mathvariant="normal">.</mi><mi>l</mi><mi>a</mi><mi>t</mi><mi>e</mi><mi>s</mi><mi>t</mi></mrow><annotation encoding="application/x-tex">s_{read} = TT.now().latest</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span><span class="mord mathnormal mtight">e</span><span class="mord mathnormal mtight">a</span><span class="mord mathnormal mtight">d</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="mord">.</span><span class="mord mathnormal">n</span><span class="mord mathnormal">o</span><span class="mord mathnormal" style="margin-right:0.02691em;">w</span><span class="mopen">(</span><span class="mclose">)</span><span class="mord">.</span><span class="mord mathnormal" style="margin-right:0.01968em;">l</span><span class="mord mathnormal">a</span><span class="mord mathnormal">t</span><span class="mord mathnormal">e</span><span class="mord mathnormal">s</span><span class="mord mathnormal">t</span></span></span></span><ul><li>At any time after a transaction starts, it preserves external consistency by an argument analogous to that presented for writes.</li><li>Such a timestamp may require the execution of the data reads at <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>s</mi><mrow><mi>r</mi><mi>e</mi><mi>a</mi><mi>d</mi></mrow></msub></mrow><annotation encoding="application/x-tex">s_{read}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span><span class="mord mathnormal mtight">e</span><span class="mord mathnormal mtight">a</span><span class="mord mathnormal mtight">d</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> to block if <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>t</mi><mrow><mi>s</mi><mi>a</mi><mi>f</mi><mi>e</mi></mrow></msub></mrow><annotation encoding="application/x-tex">t_{safe}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.9011879999999999em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord mathnormal">t</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361079999999999em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">s</span><span class="mord mathnormal mtight">a</span><span class="mord mathnormal mtight" style="margin-right:0.10764em;">f</span><span class="mord mathnormal mtight">e</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span></span></span></span> has not advanced sufficiently.</li></ul></li><li>To reduce the chances of blocking, Spanner should assign the oldest timestamp that preserves external consistency.</li></ol><h4 id="how-does-spanner-assign-timestamps-to-ro-transactions"><a class="markdownIt-Anchor" href="#how-does-spanner-assign-timestamps-to-ro-transactions"></a> How does Spanner assign timestamps to RO transactions?</h4><ol><li>Assigning a timestamp requires a negotiation phase between all Paxos groups involved in the reads.</li><li>Spanner requires a scope expression for every read-only transaction, which summarizes the keys the entire transaction will read.</li><li>If a single Paxos group serves the scope’s values<ul><li>The client issues the read-only transaction to that group’s leader. That leader assigns <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>s</mi><mrow><mi>r</mi><mi>e</mi><mi>a</mi><mi>d</mi></mrow></msub></mrow><annotation encoding="application/x-tex">s_{read}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span><span class="mord mathnormal mtight">e</span><span class="mord mathnormal mtight">a</span><span class="mord mathnormal mtight">d</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> and executes the read.</li><li>Define <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>L</mi><mi>a</mi><mi>s</mi><mi>t</mi><mi>T</mi><mi>S</mi><mo stretchy="false">(</mo><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">LastTS()</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">L</span><span class="mord mathnormal">a</span><span class="mord mathnormal">s</span><span class="mord mathnormal">t</span><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="mord mathnormal" style="margin-right:0.05764em;">S</span><span class="mopen">(</span><span class="mclose">)</span></span></span></span> to be the timestamp of the last committed to write at a Paxos group.</li><li>If there are no prepared transactions, the assignment <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>s</mi><mrow><mi>r</mi><mi>e</mi><mi>a</mi><mi>d</mi></mrow></msub><mo>=</mo><mi>L</mi><mi>a</mi><mi>s</mi><mi>t</mi><mi>T</mi><mi>S</mi><mo stretchy="false">(</mo><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">s_{read} = LastTS()</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span><span class="mord mathnormal mtight">e</span><span class="mord mathnormal mtight">a</span><span class="mord mathnormal mtight">d</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">L</span><span class="mord mathnormal">a</span><span class="mord mathnormal">s</span><span class="mord mathnormal">t</span><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="mord mathnormal" style="margin-right:0.05764em;">S</span><span class="mopen">(</span><span class="mclose">)</span></span></span></span> trivially satisfies external consistency: the transaction will see the result of the last write and be ordered after it.</li></ul></li><li>If multiple Paxos groups serve the scope’s values<ul><li>The most complicated option is to do a round of communication with all of the groups’s leaders to negotiate <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>s</mi><mrow><mi>r</mi><mi>e</mi><mi>a</mi><mi>d</mi></mrow></msub></mrow><annotation encoding="application/x-tex">s_{read}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span><span class="mord mathnormal mtight">e</span><span class="mord mathnormal mtight">a</span><span class="mord mathnormal mtight">d</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> based on <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>L</mi><mi>a</mi><mi>s</mi><mi>t</mi><mi>T</mi><mi>S</mi><mo stretchy="false">(</mo><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">LastTS()</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">L</span><span class="mord mathnormal">a</span><span class="mord mathnormal">s</span><span class="mord mathnormal">t</span><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="mord mathnormal" style="margin-right:0.05764em;">S</span><span class="mopen">(</span><span class="mclose">)</span></span></span></span>.</li><li>A more straightforward choice is that the client avoids a negotiation round and has its reads executed at <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>s</mi><mrow><mi>r</mi><mi>e</mi><mi>a</mi><mi>d</mi></mrow></msub><mo>=</mo><mi>T</mi><mi>T</mi><mi mathvariant="normal">.</mi><mi>n</mi><mi>o</mi><mi>w</mi><mo stretchy="false">(</mo><mo stretchy="false">)</mo><mi mathvariant="normal">.</mi><mi>l</mi><mi>a</mi><mi>t</mi><mi>e</mi><mi>s</mi><mi>t</mi></mrow><annotation encoding="application/x-tex">s_{read} = TT.now().latest</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span><span class="mord mathnormal mtight">e</span><span class="mord mathnormal mtight">a</span><span class="mord mathnormal mtight">d</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="mord">.</span><span class="mord mathnormal">n</span><span class="mord mathnormal">o</span><span class="mord mathnormal" style="margin-right:0.02691em;">w</span><span class="mopen">(</span><span class="mclose">)</span><span class="mord">.</span><span class="mord mathnormal" style="margin-right:0.01968em;">l</span><span class="mord mathnormal">a</span><span class="mord mathnormal">t</span><span class="mord mathnormal">e</span><span class="mord mathnormal">s</span><span class="mord mathnormal">t</span></span></span></span>.</li></ul></li><li>If a transaction has just been committed, a non-conflicting read-only transaction must still be assigned <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>s</mi><mrow><mi>r</mi><mi>e</mi><mi>a</mi><mi>d</mi></mrow></msub></mrow><annotation encoding="application/x-tex">s_{read}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span><span class="mord mathnormal mtight">e</span><span class="mord mathnormal mtight">a</span><span class="mord mathnormal mtight">d</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> to follow that transaction.<ul><li>This weakness can be remedied by augmenting <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>L</mi><mi>a</mi><mi>s</mi><mi>t</mi><mi>T</mi><mi>S</mi><mo stretchy="false">(</mo><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">LastTS()</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">L</span><span class="mord mathnormal">a</span><span class="mord mathnormal">s</span><span class="mord mathnormal">t</span><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="mord mathnormal" style="margin-right:0.05764em;">S</span><span class="mopen">(</span><span class="mclose">)</span></span></span></span> with a fine-grained mapping from key ranges to commit timestamps in the lock table.</li><li>When a read-only transaction arrives, its timestamp can be assigned by taking the maximum value of <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>L</mi><mi>a</mi><mi>s</mi><mi>t</mi><mi>T</mi><mi>S</mi><mo stretchy="false">(</mo><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">LastTS()</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">L</span><span class="mord mathnormal">a</span><span class="mord mathnormal">s</span><span class="mord mathnormal">t</span><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="mord mathnormal" style="margin-right:0.05764em;">S</span><span class="mopen">(</span><span class="mclose">)</span></span></span></span> for the key ranges with which the transaction conflicts unless there is a conflicting prepared transaction.</li></ul></li></ol><h1 id="evaluation"><a class="markdownIt-Anchor" href="#evaluation"></a> Evaluation</h1><ol><li><p>For the performance experiment, the author tested for the two common benchmarks: latency and throughput.</p><ul><li><p>For the latency experiments, clients issued sufficiently few operations to avoid queuing at the servers.</p></li><li><p>For the throughput experiments, clients issued enough operations to saturate the servers’ CPUs.</p></li><li><p>The result is as shown below. 1D means one replica with commit wait disabled.</p></li><li><p>As the number of replicas increases,</p><ul><li>The latency stays roughly constant with less standard deviation because Paxos executes in parallel at a group’s replicas. Hence, the latency to achieve a quorum becomes less sensitive to slowness at one slave replica.</li></ul><img src="/imgs/Distributed/Spanner/performance.png" width="75%"></li></ul></li><li><p>The author also tested the scalability of the two-phase commit.</p><img src="/imgs/Distributed/Spanner/2pc.png" width=50%></li><li><p>The availability after server failure is another important metric.</p><ul><li><p>Non-leader killing does not affect read throughput.</p></li><li><p>Killing leaders while giving time to handoff leadership to a different zone has a minor effect around <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>3</mn><mo>−</mo><mn>4</mn><mi mathvariant="normal">%</mi></mrow><annotation encoding="application/x-tex">3-4\%</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.72777em;vertical-align:-0.08333em;"></span><span class="mord">3</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.80556em;vertical-align:-0.05556em;"></span><span class="mord">4</span><span class="mord">%</span></span></span></span>.</p></li><li><p>Killing leaders with no warning has a severe effect: the rate of completion drops almost to <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>0</mn></mrow><annotation encoding="application/x-tex">0</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">0</span></span></span></span>.</p><img src="/imgs/Distributed/Spanner/availability.png" width="50%"></li></ul></li><li><p>The uncertainty of TrueTime would affect Spanner’s reliability.</p></li></ol>]]></content>
      
      
      <categories>
          
          <category> Paper Notebook </category>
          
          <category> Distributed System </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Distributed System </tag>
            
            <tag> Database System </tag>
            
            <tag> Distributed Database </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>2-Phase Commit</title>
      <link href="/2023/09/26/Paper/Distributed/2-Phase-Commit/"/>
      <url>/2023/09/26/Paper/Distributed/2-Phase-Commit/</url>
      
        <content type="html"><![CDATA[<p><ul class="markdownIt-TOC"><li><a href="#before-or-after-atomicity">Before-or-After Atomicity</a><ul><li><a href="#what-is-before-or-after-atomicity">What is before-or-after atomicity?</a></li><li><a href="#what-is-the-problem-of-before-or-after-atomicity">What is the problem of before-or-after atomicity?</a></li><li><a href="#what-kind-of-coordination-is-correct">What kind of coordination is correct?</a></li></ul></li><li><a href="#locking-disciplines">Locking disciplines</a><ul><li><a href="#simple-locking">Simple locking</a><ul><li><a href="#what-are-the-rules-of-simple-locking">What are the rules of simple locking?</a></li><li><a href="#what-is-the-lock-point-and-lock-set-of-a-transaction">What is the lock point and lock set of a transaction?</a></li><li><a href="#how-can-we-implement-a-lock-manager">How can we implement a lock manager?</a></li><li><a href="#how-to-argue-the-correctness-of-simple-locking">How to argue the correctness of simple locking?</a></li></ul></li><li><a href="#two-phase-locking">Two-phase locking</a><ul><li><a href="#what-are-the-rules-of-two-phase-locking">What are the rules of two-phase locking?</a></li><li><a href="#how-can-we-implement-the-lock-manager">How can we implement the lock manager?</a></li><li><a href="#how-do-locks-interact-with-log-based-recovery">How do locks interact with log-based recovery?</a></li></ul></li><li><a href="#distributed-two-phase-commit">Distributed two-phase commit</a><ul><li><a href="#what-is-correct-in-multi-site-transactions">What is correct in multi-site transactions?</a></li><li><a href="#what-is-the-problem-of-multi-site-transactions">What is the problem of multi-site transactions?</a></li><li><a href="#what-are-the-steps-of-the-distributed-two-phase-commit-protocol">What are the steps of the distributed two-phase commit protocol?</a></li><li><a href="#how-to-handle-the-lost-delayed-or-duplicated-message-problem">How to handle the lost, delayed, or duplicated message problem?</a></li><li><a href="#how-does-a-worker-site-recover-from-crashes">How does a worker site recover from crashes?</a></li><li><a href="#how-can-we-optimize-the-protocol">How can we optimize the protocol?</a></li></ul></li></ul></li></ul></p><h1 id="before-or-after-atomicity"><a class="markdownIt-Anchor" href="#before-or-after-atomicity"></a> Before-or-After Atomicity</h1><h2 id="what-is-before-or-after-atomicity"><a class="markdownIt-Anchor" href="#what-is-before-or-after-atomicity"></a> What is before-or-after atomicity?</h2><ol><li><p>The before-or-after property states that several actions that concurrently operate on the same data should not interfere with one another.</p></li><li><p>Concurrent actions have the before-or-after property if their effect from the point of view of their invokers is the same as if the actions occurred either completely before or completely after one another.</p></li></ol><h2 id="what-is-the-problem-of-before-or-after-atomicity"><a class="markdownIt-Anchor" href="#what-is-the-problem-of-before-or-after-atomicity"></a> What is the problem of before-or-after atomicity?</h2><ol><li>The programmer does not necessarily know the identities of all the other actions that might touch the shared vari­able.</li><li>This lack of knowledge can make coordinating actions by explicit program steps problematic.</li><li>Instead, the programmer needs an automatic, implicit mechanism that ensures proper handling of every shared variable.</li></ol><h2 id="what-kind-of-coordination-is-correct"><a class="markdownIt-Anchor" href="#what-kind-of-coordination-is-correct"></a> What kind of coordination is correct?</h2><ol><li>Coordination among concurrent actions can be considered correct if every result is guaranteed to be one that could have been obtained by some purely serial application of those same actions.</li><li>As long as the intermediate states are not visible above the implementing layer, and the system is guaranteed to end up in one of the acceptable final states, we can declare the coordination correct.</li></ol><h1 id="locking-disciplines"><a class="markdownIt-Anchor" href="#locking-disciplines"></a> Locking disciplines</h1><h2 id="simple-locking"><a class="markdownIt-Anchor" href="#simple-locking"></a> Simple locking</h2><h3 id="what-are-the-rules-of-simple-locking"><a class="markdownIt-Anchor" href="#what-are-the-rules-of-simple-locking"></a> What are the rules of simple locking?</h3><ol><li>Each transaction must acquire a lock for every shared data object it intends to read or write before doing any actual reading and writing.</li><li>It may release its locks only after the transaction installs its last update and commits or completely restores the data and aborts.</li><li>Applications that discover which objects need to be read by reading other shared data objects have no alter­ native but to lock every object that they might need to read.</li></ol><h3 id="what-is-the-lock-point-and-lock-set-of-a-transaction"><a class="markdownIt-Anchor" href="#what-is-the-lock-point-and-lock-set-of-a-transaction"></a> What is the lock point and lock set of a transaction?</h3><ol><li><em>Lock point</em>: the first instant at which it acquired all its locks.</li><li><em>Lock set</em>: The collection of locks it has acquired when it reaches its lock point.</li></ol><h3 id="how-can-we-implement-a-lock-manager"><a class="markdownIt-Anchor" href="#how-can-we-implement-a-lock-manager"></a> How can we implement a lock manager?</h3><ol><li><p>Acquire locks</p><ul><li><p>Each transaction supplies its intended lock set as an argu­ment to the <strong>begin_transaction</strong> operation, which acquires all locks of the lock set, if necessary, waiting for them to become available.</p><ul><li>Interpose itself on all calls to read data and log changes, and verify that they refer to variables in the lock set.</li></ul></li></ul></li><li><p>Release locks</p><ul><li>Intercept the call to <em>commit</em> or <em>abort</em> (or, if the application uses roll-forward recovery, to log an <em>END</em> record), at which time it auto­matically releases all of the locks of the lock set.</li></ul></li></ol><h3 id="how-to-argue-the-correctness-of-simple-locking"><a class="markdownIt-Anchor" href="#how-to-argue-the-correctness-of-simple-locking"></a> How to argue the correctness of simple locking?</h3><ol><li>Imagine that an all-seeing outside observer maintains an ordered list to which it adds each transaction identifier as soon as the transaction reaches its lock point and removes it from the list when it begins to release its locks.</li><li>Each transaction has agreed not to read or write anything until that transaction has been added to the observer’s list.</li><li>Since no data object can appear in the lock sets of two transactions, no data object in any transaction’s lock set appears in the lock set of the transaction preceding it in the list and by induction to any transaction earlier in the list.</li><li>Thus, all of this transaction’s input values are the same as they will be when the preceding transaction in the list commits or aborts.</li><li>The same argument applies to the transaction before the preceding one, so all inputs to any trans­ action are identical to the inputs that would be available if all the transactions ahead of it in the list ran serially, in the order of the list.</li><li>Thus, the simple locking discipline ensures that this transaction runs completely after the preceding one and completely before the next.</li><li>Concurrent transactions will produce results as if they had been serialized in the order that they reached their lock points.</li></ol><h2 id="two-phase-locking"><a class="markdownIt-Anchor" href="#two-phase-locking"></a> Two-phase locking</h2><h3 id="what-are-the-rules-of-two-phase-locking"><a class="markdownIt-Anchor" href="#what-are-the-rules-of-two-phase-locking"></a> What are the rules of two-phase locking?</h3><ol><li>It avoids the requirement that a transaction must know which locks to acquire in advance.</li><li>The two-phase locking discipline allows a transaction to acquire locks as it proceeds, and the trans­ action may read or write a data object as soon as it acquires a lock on that object.</li><li>The primary constraint is that the transaction may not release any locks until it passes its lock point.</li><li>The transaction can release a lock on an object that it only reads after it reaches its lock point if it will never need to read that object again, even to abort.</li></ol><h3 id="how-can-we-implement-the-lock-manager"><a class="markdownIt-Anchor" href="#how-can-we-implement-the-lock-manager"></a> How can we implement the lock manager?</h3><ol><li>Intercept all calls to read and write data; it acquires a lock (perhaps having to wait) on the first use of each shared variable.</li><li>As with simple locking, it then holds the locks until it intercepts the call to <em>commit</em>, <em>abort</em>, or log the <em>END</em> record of the transaction, at which time it releases them all at once.</li></ol><h3 id="how-do-locks-interact-with-log-based-recovery"><a class="markdownIt-Anchor" href="#how-do-locks-interact-with-log-based-recovery"></a> How do locks interact with log-based recovery?</h3><ol><li><p>Whether locks themselves are data objects for which changes should be logged?</p><ul><li><p>After crash recovery, there should be no pending transactions because the recovery procedure should have rolled back any pending transactions at the time of the crash, and recov­ery does not allow any new transactions to begin until it completes.</p></li><li><p>Since locks exist only to coordinate pending transactions, it would be an error if locks were still set when crash recovery is complete.</p></li><li><p>Locks belong in vol­atile storage, where they will automatically disappear on a crash, rather than in non­-volatile storage, where the recovery procedure would have to hunt them down to release them.</p></li></ul></li><li><p>Will the log-based recovery algorithm construct a correct system state?</p><ul><li>The incomplete transactions at the instant of the crash had nonoverlapping lock sets when the lock values vanished.</li><li>Those actions can safely be redone or undone without con­ cern for before-or-after atomicity during recovery.</li><li>The locks created a particular transaction serialization, and the log captured that serialization.</li><li>Since <em>RECOVER</em> performs <em>UNDO</em> actions in reverse order as specified in the log, and it per­ forms <em>REDO</em> actions in forward order, again as specified in the log, <em>RECOVER</em> reconstructs exactly that same serialization.</li></ul></li></ol><h2 id="distributed-two-phase-commit"><a class="markdownIt-Anchor" href="#distributed-two-phase-commit"></a> Distributed two-phase commit</h2><h3 id="what-is-correct-in-multi-site-transactions"><a class="markdownIt-Anchor" href="#what-is-correct-in-multi-site-transactions"></a> What is correct in multi-site transactions?</h3><ol><li>Correctness of the multiple-site ato­micity protocol will be achieved if all the sites commit or if all the sites abort.</li><li>It fails if some sites commit their part of a multiple-site transaction while others abort their part of that same transaction.</li></ol><h3 id="what-is-the-problem-of-multi-site-transactions"><a class="markdownIt-Anchor" href="#what-is-the-problem-of-multi-site-transactions"></a> What is the problem of multi-site transactions?</h3><ol><li>The coordinator has created a higher-layer transaction, and each worker is to perform a transaction nested in the higher-layer transaction.</li><li>The complication is that the coordinator and workers cannot reliably communicate.</li><li>The problem thus reduces to constructing a reliable distributed version of the two-phase commit protocol. We can do that by applying persistent senders and duplicate suppression.</li></ol><h3 id="what-are-the-steps-of-the-distributed-two-phase-commit-protocol"><a class="markdownIt-Anchor" href="#what-are-the-steps-of-the-distributed-two-phase-commit-protocol"></a> What are the steps of the distributed two-phase commit protocol?</h3><ol><li><p>Beginning</p><ul><li><p>The coordinator creates a top-layer outcome record for the overall transaction.</p></li><li><p>It persistently sends the content of sub-transactions to each site, referring to the same transaction, respectively.</p></li><li><p>Upon receiving a request, a worker site checks for duplicates and then creates a transaction of its own. Still, it makes the transaction nested, with its superior being the coordinator’s original transaction.</p></li><li><p>Then, the worker site does the pre-commit part of the requested action, reporting back to the coordinator that this has gone well.</p></li></ul></li><li><p>Two-phase commit</p><ul><li>Phase one:<ul><li>Upon collecting a complete set of such responses, the coordinator then moves to the two-phase commit part of the transaction by sending <code>PREPARE</code> messages to each worker site.</li><li>Upon receiving this message, each worker site commits—but only tentatively—or aborts.</li><li>Having created durable tentative versions (or logged to journal storage its planned updates) and having recorded an outcome record saying that it is <code>PREPARED</code> either to commit or abort, worker sites persistently send a response to the coordinator of commit or abort.</li><li>If all workers send PREPARED messages, phase one of the two-phase commit is complete.</li><li>Suppose any worker responds with an abort message or doesn’t respond at all. In that case, the coordinator can abort the entire transaction or try a different worker site to carry out that component transaction.</li></ul></li><li>Phase two:<ul><li>The coordinator commits the entire transaction by marking its outcome record as <code>COMMITTED</code>.</li><li>It sends a completion message back to each worker site.</li><li>Upon receiving such a message, each worker site changes its state from <code>PREPARED</code> to <code>COM­MITTED</code>, performs any needed post-commit actions, and exits.</li></ul></li></ul></li></ol><h3 id="how-to-handle-the-lost-delayed-or-duplicated-message-problem"><a class="markdownIt-Anchor" href="#how-to-handle-the-lost-delayed-or-duplicated-message-problem"></a> How to handle the lost, delayed, or duplicated message problem?</h3><ol><li>Suppose the coordinator doesn’t receive a response to a ready message of some sub-transaction request from one or more of the workers in a reasonable time. In that case, she resends the message to the non-responding workers as often as necessary to elicit a response.</li><li>If a worker site receives a duplicate request of <code>PREPARE</code> from the coordinator, its persistent sender sends back a duplicate of the <code>PREPARED</code> or <code>ABORTED</code> response.</li><li>If the coordinator goes down before the coordinator sends the final COMMITTED message in phase two, all of the workers must wait until it recovers; in this protocol, the coordinator is a single point of failure.</li><li>The coordinator must remem­ ber, reliably and for an indefinite time, the outcome of this transaction.<ul><li>If a completion message does not arrive in a reasonable period, the persistent sender at the worker site will resend its <code>PREPARED</code> message.</li><li>Whenever the coordinator receives a duplicate <code>PREPARED</code> message, it simply sends back the current state of the outcome record for the named transaction.</li></ul></li></ol><h3 id="how-does-a-worker-site-recover-from-crashes"><a class="markdownIt-Anchor" href="#how-does-a-worker-site-recover-from-crashes"></a> How does a worker site recover from crashes?</h3><ol><li>It must classify any <code>PREPARED</code> transaction as a tentative win­ner that it should restore to the <code>PREPARED</code> state.</li><li>If the worker uses locks for before-or-after atomicity, the recovery procedure must reacquire any locks the PREPARED transaction held at the time of the failure.</li><li>The recovery procedure must restart the persistent sender to learn the current status of the higher-layer transaction.</li><li>If the worker site uses version histories, only the last step, restarting the persistent sender, is required.</li><li>Other servers will commit if the worker site crashes after sending PREPARED before receiving COMMIT. So we want server recovery as <code>PREPARED</code>. So before sending <code>PREPARED</code>, servers need to make their log durable.</li></ol><h3 id="how-can-we-optimize-the-protocol"><a class="markdownIt-Anchor" href="#how-can-we-optimize-the-protocol"></a> How can we optimize the protocol?</h3><ol><li>The initial RPC request and response could also carry the PREPARE and PREPARED messages.<ul><li>Once a worker sends a <code>PREPARED</code> message, it loses the ability to abort unilaterally, and it must remain on the knife edge, awaiting instructions from the coordinator.</li><li>To minimize this wait, delaying the PREPARE/PREPARED message pair is usually preferable until the coordinator knows that the other workers seem to be in a position to do their parts.</li></ul></li><li>Have a fourth acknowl­edgment message from the worker sites to the coordinator.<ul><li>Once all acknowledgments are in, the coordinator can then safely discard its outcome record since every worker site is known to have gotten the word.</li></ul></li><li>Presumed commit: The coordi­nator answers any inquiry about a non-existent outcome record by sending a <code>COMMITTED</code> response.<ul><li>The coordinator commits by destroying the out­come record, so a fourth acknowledgment message from every worker is unnecessary.</li><li>The coor­dinator can persistently ask for acknowledgment of aborted transactions and discard the outcome record after all these acknowledgments are in.</li></ul></li></ol>]]></content>
      
      
      <categories>
          
          <category> Paper Notebook </category>
          
          <category> Distributed System </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Distributed System </tag>
            
            <tag> Concurrency Control </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Aurora</title>
      <link href="/2023/09/26/Paper/Distributed/Aurora/"/>
      <url>/2023/09/26/Paper/Distributed/Aurora/</url>
      
        <content type="html"><![CDATA[<p>Paper: <a href="http://nil.csail.mit.edu/6.824/2020/papers/aurora.pdf">Amazon Aurora: Design Considerations for High Throughput Cloud-Native Relational Databases</a></p><p><ul class="markdownIt-TOC"><li><a href="#purpose">Purpose</a></li><li><a href="#model">Model</a><ul><li><a href="#background-conceptions-of-aws">Background conceptions of AWS</a></li><li><a href="#durability-at-scale">Durability at scale</a><ul><li><a href="#how-does-aurora-tolerate-failures">How does Aurora tolerate failures?</a></li><li><a href="#how-does-aurora-shrink-the-window-of-vulnerability">How does Aurora shrink the window of vulnerability?</a></li><li><a href="#what-are-the-problems-of-the-io-volume-of-mirrored-mysql">What are the problems of the I/O volume of mirrored MySQL?</a></li><li><a href="#how-does-aurora-reduce-network-traffic">How does Aurora reduce network traffic?</a></li><li><a href="#logs">Logs</a></li><li><a href="#how-does-aurora-decide-what-is-completed-and-what-is-durable">How does Aurora decide what is completed and what is durable?</a></li><li><a href="#how-does-the-database-and-storage-interact">How does the database and storage interact?</a></li><li><a href="#how-does-the-database-write-data">How does the database write data?</a></li><li><a href="#how-does-the-database-commit-transactions">How does the database commit transactions?</a></li><li><a href="#where-does-the-database-read">Where does the database read?</a></li><li><a href="#how-does-the-database-read">How does the database read?</a></li><li><a href="#how-does-the-database-replicate">How does the database replicate?</a></li><li><a href="#how-does-the-database-perform-undo-and-redo">How does the database perform undo and redo?</a></li><li><a href="#how-does-the-database-reestablish-the-runtime-state">How does the database reestablish the runtime state?</a></li></ul></li></ul></li></ul></p><h1 id="purpose"><a class="markdownIt-Anchor" href="#purpose"></a> Purpose</h1><ol><li>Aurora is a relational database service for OLTP workloads.</li><li>Issue:<ul><li>In modern distributed cloud services, resilience and scalability are increasingly achieved by decoupling computing from storage and replicating storage across multiple nodes.</li><li>The central constraint in high throughput data processing has moved from computing and storage to the network.</li></ul></li><li>Contribution:<ul><li>Build storage as an independent fault-tolerant and self-healing service across multiple datacenters.<ul><li>Protect the database from performance variance and transient or permanent failures at either the networking or storage tiers.</li></ul></li><li>Only write redo log records to storage.<ul><li>Reduce network IOPS by an order of magnitude.</li><li>When the bottleneck is removed, the system’s scalability is greatly improved. And they can aggressively optimize numerous other points of contention.</li></ul></li><li>Move some of the most complex and critical functions (backup and redo recovery) from one-time expensive operations in the database engine to continuous asynchronous operations amortized across a large distributed fleet.<ul><li>This yields near-instant crash recovery without checkpointing and inexpensive backups that do not interfere with foreground processing.</li></ul></li><li>Also, it achieves consensus on a durable state across numerous storage nodes using an efficient asynchronous scheme, avoiding expensive and chatty recovery protocols.</li></ul></li></ol><h1 id="model"><a class="markdownIt-Anchor" href="#model"></a> Model</h1><h2 id="background-conceptions-of-aws"><a class="markdownIt-Anchor" href="#background-conceptions-of-aws"></a> Background conceptions of AWS</h2><h2 id="durability-at-scale"><a class="markdownIt-Anchor" href="#durability-at-scale"></a> Durability at scale</h2><h3 id="how-does-aurora-tolerate-failures"><a class="markdownIt-Anchor" href="#how-does-aurora-tolerate-failures"></a> How does Aurora tolerate failures?</h3><ol><li>It uses a quorum-based voting protocol. The ordinary quorum voting protocol is as follows:<ul><li>If each of the <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>V</mi></mrow><annotation encoding="application/x-tex">V</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.22222em;">V</span></span></span></span> copies of a replicated data item are assigned a vote; a read must obtain a quorum of <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>V</mi><mi>r</mi></msub></mrow><annotation encoding="application/x-tex">V_r</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.22222em;">V</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:-0.22222em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> votes, while a writer must obtain a quorum of <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>V</mi><mi>w</mi></msub></mrow><annotation encoding="application/x-tex">V_w</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.22222em;">V</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:-0.22222em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.02691em;">w</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> votes.</li><li>Each read must be aware of the most recent write, formulated as <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>V</mi><mi>r</mi></msub><mo>+</mo><msub><mi>V</mi><mi>w</mi></msub><mo>&gt;</mo><mi>V</mi></mrow><annotation encoding="application/x-tex">V_r + V_w &gt; V</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.22222em;">V</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:-0.22222em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.22222em;">V</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:-0.22222em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.02691em;">w</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">&gt;</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.22222em;">V</span></span></span></span>.</li><li>Each write must be aware of the most recent write to avoid conflicting writes, formulated as <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>V</mi><mi>w</mi></msub><mo>&gt;</mo><mi>V</mi><mi mathvariant="normal">/</mi><mn>2</mn></mrow><annotation encoding="application/x-tex">V_w &gt; V/2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.22222em;">V</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:-0.22222em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.02691em;">w</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">&gt;</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.22222em;">V</span><span class="mord">/</span><span class="mord">2</span></span></span></span>.</li></ul></li><li>The failure of each Availability Zone (AZ) is independent.<ul><li>For a common setting <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>V</mi><mo>=</mo><mn>3</mn></mrow><annotation encoding="application/x-tex">V=3</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.22222em;">V</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">3</span></span></span></span>, <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>V</mi><mi>r</mi></msub><mo>=</mo><mn>2</mn></mrow><annotation encoding="application/x-tex">V_r=2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.22222em;">V</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:-0.22222em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">2</span></span></span></span>, <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>V</mi><mi>w</mi></msub><mo>=</mo><mn>2</mn></mrow><annotation encoding="application/x-tex">V_w=2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.22222em;">V</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:-0.22222em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.02691em;">w</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">2</span></span></span></span>, we can set <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>3</mn></mrow><annotation encoding="application/x-tex">3</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">3</span></span></span></span> replicas in different AZs to be tolerant to large-scale events in addition to the smaller individual failures.</li><li>However, the failure of an AZ will break the quorum for any of the replicas that concurrently have failures in another AZ.</li><li>While the individual failures of replicas in each of the AZs are uncorrelated, the failure of an AZ is a correlated failure of all disks and nodes in that AZ.</li></ul></li><li>Quorum protocol of Aurora:<ul><li>Replicate each data item <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>6</mn></mrow><annotation encoding="application/x-tex">6</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">6</span></span></span></span> ways across <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>3</mn></mrow><annotation encoding="application/x-tex">3</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">3</span></span></span></span> AZs with <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>2</mn></mrow><annotation encoding="application/x-tex">2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">2</span></span></span></span> copies of each item in each AZ.</li><li>Use a quorum model with <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>6</mn></mrow><annotation encoding="application/x-tex">6</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">6</span></span></span></span> votes (<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>V</mi><mo>=</mo><mn>6</mn></mrow><annotation encoding="application/x-tex">V = 6</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.22222em;">V</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">6</span></span></span></span>), a write quorum of <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>4</mn><mi mathvariant="normal">/</mi><mn>6</mn></mrow><annotation encoding="application/x-tex">4/6</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord">4</span><span class="mord">/</span><span class="mord">6</span></span></span></span> (<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>V</mi><mi>w</mi></msub><mo>=</mo><mn>4</mn></mrow><annotation encoding="application/x-tex">V_w = 4</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.22222em;">V</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:-0.22222em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.02691em;">w</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">4</span></span></span></span>), and a read quorum of <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>3</mn><mi mathvariant="normal">/</mi><mn>6</mn></mrow><annotation encoding="application/x-tex">3/6</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord">3</span><span class="mord">/</span><span class="mord">6</span></span></span></span> (<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>V</mi><mi>r</mi></msub><mo>=</mo><mn>3</mn></mrow><annotation encoding="application/x-tex">V_r = 3</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.22222em;">V</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:-0.22222em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">3</span></span></span></span>).</li><li>It can lose a single AZ and one additional node (<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>A</mi><mi>Z</mi><mo>+</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">AZ+1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.76666em;vertical-align:-0.08333em;"></span><span class="mord mathnormal">A</span><span class="mord mathnormal" style="margin-right:0.07153em;">Z</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">1</span></span></span></span>) without losing read availability, and lose any two nodes, including a single AZ failure, and maintain write availability.</li></ul></li></ol><h3 id="how-does-aurora-shrink-the-window-of-vulnerability"><a class="markdownIt-Anchor" href="#how-does-aurora-shrink-the-window-of-vulnerability"></a> How does Aurora shrink the window of vulnerability?</h3><ol><li>To provide sufficient durability in this model, one must ensure the probability of a double fault on uncorrelated failures, represented by Mean Time to Failure (MTTF), is sufficiently low over the time it takes to repair one of these failures, Mean Time to Repair (MTTR).</li><li>It is difficult, past a point, to reduce the probability of MTTF on independent failures.</li><li>Focus on reducing MTTR.<ul><li>Partition the database volume into small fixed-size segments, currently <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>10</mn></mrow><annotation encoding="application/x-tex">10</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">1</span><span class="mord">0</span></span></span></span>GB in size.<ul><li>These are each replicated <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>6</mn></mrow><annotation encoding="application/x-tex">6</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">6</span></span></span></span> ways into Protection Groups (PGs) so that each PG consists of six  segments organized across <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>3</mn></mrow><annotation encoding="application/x-tex">3</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">3</span></span></span></span> AZs, with two segments in each AZ.</li><li>A storage volume is a concatenated set of PGs, physically implemented using a large fleet of storage nodes that are provisioned as virtual hosts with attached SSDs using Amazon Elastic Compute Cloud (EC2).</li><li>The PGs that constitute a volume are allocated as the volume grows.</li></ul></li><li>Segments are now units of independent background noise failure and repair. The system monitors and automatically repairs faults as part of service.</li></ul></li></ol><h3 id="what-are-the-problems-of-the-io-volume-of-mirrored-mysql"><a class="markdownIt-Anchor" href="#what-are-the-problems-of-the-io-volume-of-mirrored-mysql"></a> What are the problems of the I/O volume of mirrored MySQL?</h3><img src="/imgs/Distributed/Aurora/MySQL.png" width="50%"><ol><li>The engine needs to write various types of data:<ul><li>The redo log, the binary (statement) log that is archived to Amazon Simple Storage Service (S3) to support point-in-time restores</li><li>The modified data pages, a second temporary write of the data page (double-write) to prevent torn pages, and finally, the metadata (FRM) files.</li></ul></li><li>Steps 1, 3, and 5 are sequential and synchronous.<ul><li>Latency is additive because many writes are sequential.</li><li>Even on asynchronous writes, one must wait for the slowest operation, leaving the system at the mercy of outliers.</li><li>From a distributed system perspective, this model has a 4/4 write quorum and is vulnerable to failures and outlier performance.</li></ul></li><li>User operations resulting from OLTP applications cause many different types of writes often representing the same information in multiple ways.</li></ol><h3 id="how-does-aurora-reduce-network-traffic"><a class="markdownIt-Anchor" href="#how-does-aurora-reduce-network-traffic"></a> How does Aurora reduce network traffic?</h3><ol><li><p>The only writes that cross the network are redo log records. The log applicator is pushed to the storage tier, where it can generate database pages in the background or on demand.</p></li><li><p>Generating each page from the complete chain of its modifications from the beginning of time is prohibitively expensive.</p><ul><li>Continually materialize database pages in the background to avoid regenerating them from scratch on demand every time.</li><li>As far as the engine is concerned, the log is the database, and any pages that the storage system materializes are simply a cache of log applications.</li></ul></li><li><p>The primary only writes log records to the storage service and streams those log records and metadata updates to the replica instances.</p><img src="/imgs/Distributed/Aurora/NetworkIO.png" width=50%></li><li><p>The storage node involves the following steps:</p><ul><li>(1) receive the log record and add it to an in-memory queue</li><li>(2) persist record on disk and acknowledge</li><li>(3) organize records and identify gaps in the log since some batches may be lost</li><li>(4) gossip with peers to fill in gaps</li><li>(5) coalesce log records into new data pages</li><li>(6) periodically stage log and new pages to S3</li><li>(7) periodically garbage collect old versions</li><li>(8) periodically validate CRC codes on pages</li><li>Each step above is asynchronous; only steps (1) and (2) are in the foreground path, potentially impacting latency.</li></ul><img src="/imgs/Distributed/Aurora/StorageNode.png" width="50%"></li></ol><h3 id="logs"><a class="markdownIt-Anchor" href="#logs"></a> Logs</h3><h3 id="how-does-aurora-decide-what-is-completed-and-what-is-durable"><a class="markdownIt-Anchor" href="#how-does-aurora-decide-what-is-completed-and-what-is-durable"></a> How does Aurora decide what is completed and what is durable?</h3><ol><li>At a high level, The system maintains points of consistency and durability and continually advances them as it receives acknowledgments for outstanding storage requests.</li><li>The logic for tracking and undoing partially completed transactions is kept in the database engine, just as if written on simple disks.<br />Upon restart, before the database can access the storage volume, the storage service makes its recovery, focusing not on user-level transactions but on ensuring that the database sees a uniform view of storage despite its distributed nature.</li><li>Completeness:<ul><li><em>Log Sequence Number (LSN)</em>: Each log record has an associated LSN, a monotonically increasing value generated by the database.</li><li><em>Volume Complete LSN (VCL)</em>: The storage service determines the highest LSN to guarantee the availability of all prior log records.</li><li>Every log record with an LSN larger than the VCL during storage recovery must be truncated.</li></ul></li><li>Durability:<ul><li><em>Consistency Point LSNs (CPL)</em>: The database can further constrain a subset of points that are allowable for truncation by tagging log records</li><li><em>Volume Durable LSN (VDL)</em>: the highest CPL smaller than or equal to VCL and truncate all log records with LSN greater than the VDL.</li><li>A CPL delineates some limited storage system transactions that must be accepted in order.</li></ul></li></ol><h3 id="how-does-the-database-and-storage-interact"><a class="markdownIt-Anchor" href="#how-does-the-database-and-storage-interact"></a> How does the database and storage interact?</h3><ol><li>Each database-level transaction is broken up into multiple mini-transactions (MTRs) ordered and must be performed atomically.</li><li>Each mini-transaction comprises multiple contiguous log records (as many as needed).</li><li>The final log record in a mini-transaction is a CPL.</li><li>On recovery, the database talks to the storage service to establish the durable point of each PG and uses that to establish the VDL. Then, commands are issued to truncate the log records above VDL.</li></ol><h3 id="how-does-the-database-write-data"><a class="markdownIt-Anchor" href="#how-does-the-database-write-data"></a> How does the database write data?</h3><ol><li>Database view:<ul><li>As the database receives acknowledgments to establish the write quorum for each batch of log records, it advances the current VDL.</li><li>The database allocates a unique ordered LSN for each redo log record of each transaction that is no greater than the sum of the current VDL and the LSN Allocation Limit (LAL).</li><li>This limit ensures the database does not get too far ahead of the storage system and introduces back pressure that can throttle the incoming writes if the storage or network cannot keep up.</li></ul></li><li>PG view:<ul><li>Each segment of each PG only sees a subset of log records in the volume that affects the pages residing on that segment.</li><li>Each log record contains a backlink that identifies the previous log record for that PG to track the point of completeness of the log records that have reached each segment.</li><li><em>Segment Complete LSN (SCL)</em>: Identifies the greatest LSN below which all log records of the PG have been received and established through backlinks.</li><li>The SCL is used by the storage nodes when they gossip with each other to find and exchange log records that they are missing.</li></ul></li></ol><h3 id="how-does-the-database-commit-transactions"><a class="markdownIt-Anchor" href="#how-does-the-database-commit-transactions"></a> How does the database commit transactions?</h3><ol><li>When a client commits a transaction, the thread handling the commit request sets the transaction aside by recording its “commit LSN” as part of a separate list of transactions waiting on commit and moves on to perform other work.</li><li>Completing a commit only if the latest VDL is greater than or equal to the transaction’s commit LSN.</li><li>As the VDL advances, the database identifies qualifying transactions waiting to be committed and uses a dedicated thread to send commit acknowledgments to wait clients.</li></ol><h3 id="where-does-the-database-read"><a class="markdownIt-Anchor" href="#where-does-the-database-read"></a> Where does the database read?</h3><ol><li>Pages are served from the buffer cache, resulting in a storage IO request if the page is not in the cache.</li><li>While the Aurora database does not write out pages on cache eviction (or anywhere else), it enforces a similar guarantee: a page in the buffer cache must always be of the latest version.<ul><li><em>Page LSN</em>: identify the log record associated with the latest change to the page</li><li>Evict a page from the cache only if its page LSN is greater than or equal to the VDL.</li><li>Hence, all changes in the page have been hardened in the log, and on a cache miss, it is sufficient to request a version of the page as of the current VDL to get its latest durable version.</li></ul></li></ol><h3 id="how-does-the-database-read"><a class="markdownIt-Anchor" href="#how-does-the-database-read"></a> How does the database read?</h3><ol><li>When reading a page from a disk, the database establishes a read-point, representing the VDL when the request was issued.</li><li>The database can then select a completed storage node with respect to the read point, knowing that it will, therefore, receive an up-to-date version.</li><li>Protection Group Min Read Point LSN (PGMRPL): represents that all the log records of the PG below it are unnecessary.<ul><li>If there are read replicas, the writer gossips with them to establish the per-PG Minimum Read Point LSN across all nodes.</li><li>A storage node segment guarantees that there will be no read page requests with a read point lower than the PGMRPL.</li><li>Each storage node is aware of the PGMRPL from the database and can, therefore, advance the materialized pages on disk by coalescing the older log records and then safely garbage collecting them.</li></ul></li></ol><h3 id="how-does-the-database-replicate"><a class="markdownIt-Anchor" href="#how-does-the-database-replicate"></a> How does the database replicate?</h3><ol><li>A single writer and up to 15 read replicas can all mount a shared storage volume.</li><li>To minimize lag, the log stream generated by the writer and sent to the storage nodes is also sent to all read replicas.</li><li>The database consumes this log stream in the reader by considering each log record in turn.<ul><li>If the log record refers to a page in the reader’s buffer cache, it uses the log applicator to apply the specified redo operation to the page in the cache.</li><li>Otherwise, it simply discards the log record.</li><li>The replicas consume log records asynchronously from the writer’s perspective, which acknowledges user commits independent of the replica.</li><li>The only log records that will be applied are those whose LSN is less than or equal to the VDL.<br />The log records that are part of a single mini-transaction are applied atomically in the replica’s cache to ensure that the replica sees a consistent view of all database objects.</li></ul></li></ol><h3 id="how-does-the-database-perform-undo-and-redo"><a class="markdownIt-Anchor" href="#how-does-the-database-perform-undo-and-redo"></a> How does the database perform undo and redo?</h3><ol><li>The same redo log applicator is used in the forward processing path and on recovery, where it operates synchronously and in the foreground while the database is offline.</li><li>The redo log applicator is decoupled from the database and operates on storage nodes, in parallel, and all the time in the background. Once the database starts up, it performs volume recovery in collaboration with the storage service.</li><li>Undo recovery can happen when the database is online after the system builds the list of these in-flight transactions from the undo segments.</li></ol><h3 id="how-does-the-database-reestablish-the-runtime-state"><a class="markdownIt-Anchor" href="#how-does-the-database-reestablish-the-runtime-state"></a> How does the database reestablish the runtime state?</h3><ol><li>It contacts, for each PG, a read quorum of segments, which is sufficient to guarantee the discovery of any data that could have reached a write quorum.</li><li>Once the database has established a read quorum for every PG, it can recalculate the VDL above which data is truncated by generating a truncation range that annuls every log record after the new VDL, up to and including an end LSN, which the database can prove is at least as high as the highest possible outstanding log record that could ever have been seen.</li><li>The database infers this upper bound because it allocates LSNs and limits how far allocation can occur above VDL (the 10 million limit described earlier).</li><li>The truncation ranges are versioned with epoch numbers and written durably to the storage service so that there is no confusion over the durability of truncations in case recovery is interrupted and restarted.</li></ol>]]></content>
      
      
      <categories>
          
          <category> Paper Notebook </category>
          
          <category> Distributed System </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Distributed System </tag>
            
            <tag> Communication </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>CRAQ</title>
      <link href="/2023/09/26/Paper/Distributed/CRAQ/"/>
      <url>/2023/09/26/Paper/Distributed/CRAQ/</url>
      
        <content type="html"><![CDATA[<p>Paper: <a href="http://nil.csail.mit.edu/6.824/2020/papers/craq.pdf">Object Storage on CRAQ High-throughput chain replication for read-mostly workloads</a></p><p><ul class="markdownIt-TOC"><li><a href="#purpose">Purpose</a></li><li><a href="#model">Model</a><ul><li><a href="#related">Related</a><ul><li><a href="#what-is-object-based-storage">What is object-based storage?</a></li><li><a href="#what-are-strong-consistency-and-eventual-consistency">What are strong consistency and eventual consistency?</a></li><li><a href="#chain-replication">Chain replication</a><ul><li><a href="#what-is-chain-replication">What is chain replication?</a></li><li><a href="#what-is-the-problem-of-basic-chain-replication">What is the problem of basic chain replication?</a></li><li><a href="#how-does-cr-handle-client-requests">How does CR handle client requests?</a></li><li><a href="#why-can-cr-not-provide-a-read-from-intermediate-nodes">Why can CR not provide a read from intermediate nodes?</a></li></ul></li></ul></li><li><a href="#craq-system-model">CRAQ System Model</a><ul><li><a href="#how-does-craq-handle-write-requests">How does CRAQ handle write requests?</a></li><li><a href="#how-does-craq-handle-read-requests-to-guarantee-strong-consistency">How does CRAQ handle read requests to guarantee strong consistency?</a></li><li><a href="#in-what-scenarios-does-craq-outperform-basic-cr">In what scenarios does CRAQ outperform basic CR?</a></li><li><a href="#how-does-craq-support-eventual-consistency">How does CRAQ support eventual consistency?</a></li><li><a href="#how-does-craq-recover-from-failure">How does CRAQ recover from failure?</a></li><li><a href="#how-does-craq-manage-configuration">How does CRAQ manage configuration?</a></li><li><a href="#how-does-craq-handle-transient-failure-eg-partition-failure">How does CRAQ handle transient failure (e.g., partition failure)?</a></li><li><a href="#how-should-craq-choose-nodes-within-a-datacenter">How should CRAQ choose nodes within a Datacenter?</a></li><li><a href="#how-does-craq-support-the-mini-transaction-of-single-key-operations">How does CRAQ support the mini-transaction of single-key operations?</a></li><li><a href="#how-does-craq-lower-write-latency-with-multicast">How does CRAQ lower write latency with multicast?</a></li><li><a href="#how-does-craq-use-zookeeper-to-manage-configuration">How does CRAQ use ZooKeeper to manage configuration?</a></li><li><a href="#how-do-nodes-communicate-with-each-other">How do nodes communicate with each other?</a></li></ul></li></ul></li><li><a href="#evaluation">Evaluation</a></li></ul></p><h1 id="purpose"><a class="markdownIt-Anchor" href="#purpose"></a> Purpose</h1><ol><li>Issue: many commercially deployed systems sacrifice stronger consistency properties in the desire for greater availability and higher throughput.</li><li>Contribution:<ul><li>This system is an improvement on Chain Replication and maintains strong consistency while significantly improving read throughput by enabling any chain node to handle read operations.<ul><li>By distributing the load across all object replicas, CRAQ scales linearly with chain size without increasing consistency coordination.</li></ul></li><li>CRAQ’s design naturally supports eventual consistency among read operations for lower-latency reads during write contention and degradation to read-only behavior during transient partitions.<ul><li>CRAQ allows applications to specify the maximum staleness acceptable for read operations.</li></ul></li><li>Leveraging these load-balancing properties, we describe a wide-area system design for building CRAQ chains across geographically diverse clusters that preserve strong locality properties.</li></ul></li></ol><h1 id="model"><a class="markdownIt-Anchor" href="#model"></a> Model</h1><h2 id="related"><a class="markdownIt-Anchor" href="#related"></a> Related</h2><h3 id="what-is-object-based-storage"><a class="markdownIt-Anchor" href="#what-is-object-based-storage"></a> What is object-based storage?</h3><ol><li>Object-based storage: Supported by key-value databases, data is presented to applications as entire units.</li><li>Object stores support two basic primitives: read (or query) operations return the data block stored under an object name, and write (or update) operations change the state of a single object.</li><li>Object stores are better suited for flat namespaces, such as in key-value databases, than hierarchical directory structures, where file systems are better.</li><li>Object stores simplify the process of supporting whole-object modifications.<br />Typically only need to reason about ordering modifications to a specific object, as opposed to the entire storage system.<br />Significantly cheaper to provide consistency guarantees per object instead of across all operations and objects.</li></ol><h3 id="what-are-strong-consistency-and-eventual-consistency"><a class="markdownIt-Anchor" href="#what-are-strong-consistency-and-eventual-consistency"></a> What are strong consistency and eventual consistency?</h3><ol><li><p>Strong consistency guarantees that all read and write operations to an object are executed sequentially and that a read to an object always sees the latest written value.</p></li><li><p>Eventual consistency implies that</p><ul><li><p>Writes to an object are still applied in sequential order on all nodes, but eventual consistent reads to different nodes can return stale data for some period of inconsistency.</p></li><li><p>However, read operations will never return an older version than the latest committed write.</p></li><li><p>A client will also see monotonic read consistency if it maintains a session with a particular node.</p></li></ul></li><li><p>The Eventual consistency is still different from the guarantees from ZooKeeper or Raft. In ZooKeeper or Raft, clients only see monotonic read consistency even if they cross sessions with other servers.</p></li></ol><h3 id="chain-replication"><a class="markdownIt-Anchor" href="#chain-replication"></a> Chain replication</h3><h4 id="what-is-chain-replication"><a class="markdownIt-Anchor" href="#what-is-chain-replication"></a> What is chain replication?</h4><ol><li>It organizes all nodes storing an object in a chain, where the chain tail handles all read requests, and the chain head handles all write requests,  as shown below:<br /><img src="/imgs/Distributed/CRAQ/basicCR.png" alt="" /></li><li>Writes propagate down the chain before the client is acknowledged, thus providing a simple ordering of all object operations and strong consistency at the tail.</li><li>The lack of complex or multi-round protocols yields simplicity, good throughput, and easy recovery.</li></ol><h4 id="what-is-the-problem-of-basic-chain-replication"><a class="markdownIt-Anchor" href="#what-is-the-problem-of-basic-chain-replication"></a> What is the problem of basic chain replication?</h4><ol><li>All reads for an object must go to the same node, leading to potential hotspots.</li><li>Multiple chains can be constructed across a cluster of nodes for better load balancing via consistent hashing or a more centralized directory approach.</li><li>However, these algorithms might still find load imbalances if particular objects are disproportionally popular.<br />All reads to a chain may then be handled by a potentially distant node, namely the chain’s tail.</li></ol><h4 id="how-does-cr-handle-client-requests"><a class="markdownIt-Anchor" href="#how-does-cr-handle-client-requests"></a> How does CR handle client requests?</h4><ol><li>The <em>head</em> of the chain handles all write operations from clients.<ul><li>When a node receives a write operation, it is propagated to the next node in the chain.</li><li>Once the write reaches the tail node, it has been applied to all replicas in the chain and is considered committed.</li><li>When the tail commits the write, a reply is sent to the client. The CR paper describes the tail sending a message directly to the client.</li></ul></li><li>The tail node handles all read operations so that a read can return only committed values.</li><li>The simple topology of CR makes write operations cheaper than other protocols, offering strong consistency.<br />Multiple concurrent writes can be pipelined down the chain, with transmission costs equally spread over all nodes.</li></ol><h4 id="why-can-cr-not-provide-a-read-from-intermediate-nodes"><a class="markdownIt-Anchor" href="#why-can-cr-not-provide-a-read-from-intermediate-nodes"></a> Why can CR not provide a read from intermediate nodes?</h4><ol><li>The reading result can violate the strong consistency.</li><li>Concurrent reads to different nodes and can see different writes as they are in the process of propagating down the chain.</li></ol><h2 id="craq-system-model"><a class="markdownIt-Anchor" href="#craq-system-model"></a> CRAQ System Model</h2><h3 id="how-does-craq-handle-write-requests"><a class="markdownIt-Anchor" href="#how-does-craq-handle-write-requests"></a> How does CRAQ handle write requests?</h3><ol><li>A node in CRAQ can store multiple versions of an object, each including a monotonically increasing version number and an additional attribute, whether the version is clean or dirty. All versions are initially marked as clean.</li><li>When a node receives a new version of an object via a write being propagated down the chain, the node appends this latest version to its list for the object.<ul><li>If the node is not the tail, it marks the version as dirty and propagates the write to its successor.</li><li>Otherwise, if the node is the tail, it marks the version as clean, at which time we call the object version (write) as committed.</li><li>The tail node can then notify all other nodes of the commit by sending an acknowledgment backward through the chain.</li></ul></li><li>When an acknowledgment message for an object version arrives at a node, the node marks the object version as clean. The node can then delete all prior versions of the object.</li><li>If the node has precisely one version for an object, the object is implicitly in the clean state; otherwise, the object is dirty, and the properly ordered version must be retrieved from the chain tail.</li></ol><h3 id="how-does-craq-handle-read-requests-to-guarantee-strong-consistency"><a class="markdownIt-Anchor" href="#how-does-craq-handle-read-requests-to-guarantee-strong-consistency"></a> How does CRAQ handle read requests to guarantee strong consistency?</h3><ol><li>When a node receives a read request for an object, the node returns this value if the latest known version of the requested object is clean.</li><li>If the latest version number of the object requested is dirty, the node contacts the tail and asks for the tail’s last committed version number (a version query). The node then returns that version of the object.</li><li>The tail could commit a new version between when it replies to the version request and when the intermediate node sends a reply to the client.<br />This does not violate strong consistency, as read operations are serialized concerning the tail.</li></ol><p><img src="/imgs/Distributed/CRAQ/read.png" alt="" /></p><h3 id="in-what-scenarios-does-craq-outperform-basic-cr"><a class="markdownIt-Anchor" href="#in-what-scenarios-does-craq-outperform-basic-cr"></a> In what scenarios does CRAQ outperform basic CR?</h3><ol><li>In read-mostly workloads, most of the read requests are handled solely by the C − 1 non-tail nodes (as clean reads), and thus, throughput in these scenarios scales linearly with chain size C.</li><li>In write-heavy workloads, most read requests to non-tail nodes are dirty. But these version queries are lighter-weight than full reads, allowing the tail to process them much faster before it becomes saturated.</li></ol><h3 id="how-does-craq-support-eventual-consistency"><a class="markdownIt-Anchor" href="#how-does-craq-support-eventual-consistency"></a> How does CRAQ support eventual consistency?</h3><ol><li><p>It allows read operations to a chain node to return the newest known object version.</p></li><li><p>It can also support eventual consistency with maximum-bounded inconsistency.</p><ul><li>The limit imposed can be based on time (relative to a node’s local clock) or absolute version numbers.</li></ul></li><li><p>If the chain is still available, this inconsistency is due to the returned version being newer than the last committed one.</p><p>If the system is partitioned and the node cannot participate in writes, the version may be older than the current committed one.</p></li></ol><h3 id="how-does-craq-recover-from-failure"><a class="markdownIt-Anchor" href="#how-does-craq-recover-from-failure"></a> How does CRAQ recover from failure?</h3><ol><li>Each chain node needs to know its predecessor and successor, as well as the chain head and tail.</li><li>When a head fails, its immediate successor takes over as the new chain head; likewise, the tail’s predecessor takes over when the tail fails.</li><li>If an intermediate node fails, drop it from the chain; the predecessor may need to re-send recent writes since the write request pipeline may have been broken from the failure server.</li></ol><h3 id="how-does-craq-manage-configuration"><a class="markdownIt-Anchor" href="#how-does-craq-manage-configuration"></a> How does CRAQ manage configuration?</h3><ol><li>An object’s identifier consists of a chain identifier and a key identifier.</li><li>Applications can specify their requirements in multiple ways:<ul><li>Implicit Datacenters &amp; Global Chain Size <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">{</mo><mi>n</mi><mi>u</mi><mi>m</mi><mi mathvariant="normal">_</mi><mi>d</mi><mi>a</mi><mi>t</mi><mi>a</mi><mi>c</mi><mi>e</mi><mi>n</mi><mi>t</mi><mi>e</mi><mi>r</mi><mi>s</mi><mo separator="true">,</mo><mi>c</mi><mi>h</mi><mi>a</mi><mi>i</mi><mi>n</mi><mi mathvariant="normal">_</mi><mi>s</mi><mi>i</mi><mi>z</mi><mi>e</mi><mo stretchy="false">}</mo></mrow><annotation encoding="application/x-tex">\{num\_datacenters, chain\_size\}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.06em;vertical-align:-0.31em;"></span><span class="mopen">{</span><span class="mord mathnormal">n</span><span class="mord mathnormal">u</span><span class="mord mathnormal">m</span><span class="mord" style="margin-right:0.02778em;">_</span><span class="mord mathnormal">d</span><span class="mord mathnormal">a</span><span class="mord mathnormal">t</span><span class="mord mathnormal">a</span><span class="mord mathnormal">c</span><span class="mord mathnormal">e</span><span class="mord mathnormal">n</span><span class="mord mathnormal">t</span><span class="mord mathnormal">e</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mord mathnormal">s</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal">c</span><span class="mord mathnormal">h</span><span class="mord mathnormal">a</span><span class="mord mathnormal">i</span><span class="mord mathnormal">n</span><span class="mord" style="margin-right:0.02778em;">_</span><span class="mord mathnormal">s</span><span class="mord mathnormal">i</span><span class="mord mathnormal" style="margin-right:0.04398em;">z</span><span class="mord mathnormal">e</span><span class="mclose">}</span></span></span></span>.<ul><li>Consistent hashing is used with unique datacenter identifiers to determine which datacenters store the chain.</li></ul></li><li>Explicit Datacenters &amp; Global Chain Size <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">{</mo><mi>c</mi><mi>h</mi><mi>a</mi><mi>i</mi><mi>n</mi><mi mathvariant="normal">_</mi><mi>s</mi><mi>i</mi><mi>z</mi><mi>e</mi><mo separator="true">,</mo><mi>d</mi><msub><mi>c</mi><mn>1</mn></msub><mo separator="true">,</mo><mi>d</mi><msub><mi>c</mi><mn>2</mn></msub><mo separator="true">,</mo><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mo separator="true">,</mo><mi>d</mi><msub><mi>c</mi><mi>N</mi></msub><mo stretchy="false">}</mo></mrow><annotation encoding="application/x-tex">\{chain\_size, dc_1, dc_2, ..., dc_N\}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.06em;vertical-align:-0.31em;"></span><span class="mopen">{</span><span class="mord mathnormal">c</span><span class="mord mathnormal">h</span><span class="mord mathnormal">a</span><span class="mord mathnormal">i</span><span class="mord mathnormal">n</span><span class="mord" style="margin-right:0.02778em;">_</span><span class="mord mathnormal">s</span><span class="mord mathnormal">i</span><span class="mord mathnormal" style="margin-right:0.04398em;">z</span><span class="mord mathnormal">e</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal">d</span><span class="mord"><span class="mord mathnormal">c</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal">d</span><span class="mord"><span class="mord mathnormal">c</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord">.</span><span class="mord">.</span><span class="mord">.</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal">d</span><span class="mord"><span class="mord mathnormal">c</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.32833099999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em;">N</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">}</span></span></span></span><ul><li>The order of the chain is the same as specified with the head within <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>d</mi><msub><mi>c</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">dc_1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.84444em;vertical-align:-0.15em;"></span><span class="mord mathnormal">d</span><span class="mord"><span class="mord mathnormal">c</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> and tail within <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>d</mi><msub><mi>c</mi><mi>N</mi></msub></mrow><annotation encoding="application/x-tex">dc_N</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.84444em;vertical-align:-0.15em;"></span><span class="mord mathnormal">d</span><span class="mord"><span class="mord mathnormal">c</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.32833099999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em;">N</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>.</li><li>Consistent hashing is used on the chain identifier to determine which nodes within a datacenter store objects are assigned to the chain.</li><li>Each datacenter <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>d</mi><msub><mi>c</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">dc_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.84444em;vertical-align:-0.15em;"></span><span class="mord mathnormal">d</span><span class="mord"><span class="mord mathnormal">c</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> has a node which connects to the tail of datacenter <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>d</mi><msub><mi>c</mi><mrow><mi>i</mi><mtext>−</mtext><mn>1</mn></mrow></msub></mrow><annotation encoding="application/x-tex">dc_{i−1}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.902771em;vertical-align:-0.208331em;"></span><span class="mord mathnormal">d</span><span class="mord"><span class="mord mathnormal">c</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.311664em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mord mtight">−</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.208331em;"><span></span></span></span></span></span></span></span></span></span> and a node that connects to the head of datacenter <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>d</mi><msub><mi>c</mi><mrow><mi>i</mi><mo>+</mo><mn>1</mn></mrow></msub></mrow><annotation encoding="application/x-tex">dc_{i+1}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.902771em;vertical-align:-0.208331em;"></span><span class="mord mathnormal">d</span><span class="mord"><span class="mord mathnormal">c</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.311664em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mbin mtight">+</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.208331em;"><span></span></span></span></span></span></span></span></span></span>.</li><li><code>chain_size</code> being <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>0</mn></mrow><annotation encoding="application/x-tex">0</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">0</span></span></span></span> indicates that the chain should use all nodes within each datacenter.</li></ul></li><li>Explicit Datacenter Chain Sizes <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">{</mo><mi>d</mi><msub><mi>c</mi><mn>1</mn></msub><mo separator="true">,</mo><mi>c</mi><mi>h</mi><mi>a</mi><mi>i</mi><mi>n</mi><mi mathvariant="normal">_</mi><mi>s</mi><mi>i</mi><mi>z</mi><msub><mi>e</mi><mn>1</mn></msub><mo separator="true">,</mo><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mo separator="true">,</mo><mi>d</mi><msub><mi>c</mi><mi>N</mi></msub><mo separator="true">,</mo><mi>c</mi><mi>h</mi><mi>a</mi><mi>i</mi><mi>n</mi><mi mathvariant="normal">_</mi><mi>s</mi><mi>i</mi><mi>z</mi><msub><mi>e</mi><mi>N</mi></msub><mo stretchy="false">}</mo></mrow><annotation encoding="application/x-tex">\{dc_1, chain\_size_1, ..., dc_N, chain\_size_N\}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.06em;vertical-align:-0.31em;"></span><span class="mopen">{</span><span class="mord mathnormal">d</span><span class="mord"><span class="mord mathnormal">c</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal">c</span><span class="mord mathnormal">h</span><span class="mord mathnormal">a</span><span class="mord mathnormal">i</span><span class="mord mathnormal">n</span><span class="mord" style="margin-right:0.02778em;">_</span><span class="mord mathnormal">s</span><span class="mord mathnormal">i</span><span class="mord mathnormal" style="margin-right:0.04398em;">z</span><span class="mord"><span class="mord mathnormal">e</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord">.</span><span class="mord">.</span><span class="mord">.</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal">d</span><span class="mord"><span class="mord mathnormal">c</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.32833099999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em;">N</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal">c</span><span class="mord mathnormal">h</span><span class="mord mathnormal">a</span><span class="mord mathnormal">i</span><span class="mord mathnormal">n</span><span class="mord" style="margin-right:0.02778em;">_</span><span class="mord mathnormal">s</span><span class="mord mathnormal">i</span><span class="mord mathnormal" style="margin-right:0.04398em;">z</span><span class="mord"><span class="mord mathnormal">e</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.32833099999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em;">N</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">}</span></span></span></span><ul><li>This allows for non-uniformity in chain load balancing.</li><li>The chain nodes within each datacenter are chosen in the same manner as the previous method and <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>c</mi><mi>h</mi><mi>a</mi><mi>i</mi><mi>n</mi><mi mathvariant="normal">_</mi><mi>s</mi><mi>i</mi><mi>z</mi><msub><mi>e</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">chain\_size_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.00444em;vertical-align:-0.31em;"></span><span class="mord mathnormal">c</span><span class="mord mathnormal">h</span><span class="mord mathnormal">a</span><span class="mord mathnormal">i</span><span class="mord mathnormal">n</span><span class="mord" style="margin-right:0.02778em;">_</span><span class="mord mathnormal">s</span><span class="mord mathnormal">i</span><span class="mord mathnormal" style="margin-right:0.04398em;">z</span><span class="mord"><span class="mord mathnormal">e</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> can also be set to <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>0</mn></mrow><annotation encoding="application/x-tex">0</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">0</span></span></span></span>.</li></ul></li></ul></li></ol><h3 id="how-does-craq-handle-transient-failure-eg-partition-failure"><a class="markdownIt-Anchor" href="#how-does-craq-handle-transient-failure-eg-partition-failure"></a> How does CRAQ handle transient failure (e.g., partition failure)?</h3><ol><li>In methods 2 and 3 above, <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>d</mi><msub><mi>c</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">dc_1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.84444em;vertical-align:-0.15em;"></span><span class="mord mathnormal">d</span><span class="mord"><span class="mord mathnormal">c</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> can be set as a master datacenter.<ul><li>If a datacenter is the master for a chain, writes to the chain will only be accepted by that datacenter during transient failures.</li></ul></li><li>When a master is not defined,<ul><li>Writes will only continue in a partition if the partition contains a majority of the nodes in the global chain.</li><li>The minority partition will become read-only for maximum bounded inconsistent read operations.</li></ul></li></ol><h3 id="how-should-craq-choose-nodes-within-a-datacenter"><a class="markdownIt-Anchor" href="#how-should-craq-choose-nodes-within-a-datacenter"></a> How should CRAQ choose nodes within a Datacenter?</h3><ol><li>In CRAQ’s current implementation, we place chains within a datacenter using consistent hashing, mapping potentially many chain identifiers to a single head node.</li><li>Another approach is to use the membership management service as a directory service in assigning and storing randomized chain membership, i.e., each chain can include some random set of server nodes.<ul><li>This approach improves the potential for parallel system recovery.</li><li>However, it would increase centralization and state and require storing more metadata information in the coordination service.</li></ul></li></ol><h3 id="how-does-craq-support-the-mini-transaction-of-single-key-operations"><a class="markdownIt-Anchor" href="#how-does-craq-support-the-mini-transaction-of-single-key-operations"></a> How does CRAQ support the mini-transaction of single-key operations?</h3><ol><li>For Prepend/Append and Increment/Decrement operations,<ul><li>The head of the chain storing the key’s object can apply the operation to the latest version of the object, even if the latest version is dirty, and then propagate a full replacement write down the chain.</li><li>The head can buffer the requests and batch the updates if these operations are frequent. These enhancements would be much more expensive using a traditional two-phase-commit protocol.</li></ul></li><li>For the test-and-set operation,<ul><li>The head of the chain checks if its most recent committed version number equals the version number specified in the operation.</li><li>If there are no outstanding uncommitted versions of the object, the head accepts the operation and propagates an update down the chain.</li><li>If there are outstanding writes, we reject the test-and-set operation, and clients are careful to back off their request rate if continuously rejected.</li></ul></li><li>The optimistic two-phase protocol must only be implemented with the chain heads, not all involved nodes.<ul><li>The chain heads can lock any keys involved in the mini-transaction until it is fully committed.</li><li>It reduces the write throughput of CRAQ as writes to the same object can no longer be pipelined.</li></ul></li></ol><h3 id="how-does-craq-lower-write-latency-with-multicast"><a class="markdownIt-Anchor" href="#how-does-craq-lower-write-latency-with-multicast"></a> How does CRAQ lower write latency with multicast?</h3><ol><li>This would be a network-layer multicast protocol within a datacenter, while application-layer multicast protocols may be better suited for wide-area chains.</li><li>No ordering or reliability guarantees are required from these multicast protocols.</li><li>The actual value can be multicast to the entire chain. Then, only a small metadata message needs to be propagated down the chain to ensure that all replicas have received a write before the tail.</li><li>Suppose a node does not receive the multicast for any reason. In that case, the node can fetch the object from its predecessor after receiving the write commit message and before further propagating the commit message.</li><li>When the tail receives a propagated write request, a multicast acknowledgment message can be sent to the multicast group instead of propagating it backward along the chain.</li></ol><h3 id="how-does-craq-use-zookeeper-to-manage-configuration"><a class="markdownIt-Anchor" href="#how-does-craq-use-zookeeper-to-manage-configuration"></a> How does CRAQ use ZooKeeper to manage configuration?</h3><ol><li><p>During initialization, a CRAQ node creates an ephemeral file in <code>/nodes/dc_name/node_id</code>.</p><ul><li><p>The content of the file contains the node’s IP address and port number.</p></li><li><p>CRAQ nodes can query <code>/nodes/dc_name</code> to determine the membership list for its datacenter. They create a watch on the children’s <code>/nodes/dc_name</code> list.</p></li></ul></li><li><p>When a CRAQ node receives a request to create a new chain, a file is created in <code>/chains/chain_id</code>.</p><ul><li>The chain’s placement strategy determines the file’s contents but only includes this chain configuration information, not the list of a chain’s current nodes.</li><li>Instead of letting nodes register their membership for each chain they belong to (<em>i.e.</em>, chain metadata explicitly names the chain’s current members), any node participating in the chain will query the chain file and place a watch on it.</li><li>This is based on the assumption that the number of chains will generally be at least an order of magnitude larger than the number of nodes in the system, or that chain dynamism may be significantly greater than nodes joining or leaving the system.</li></ul></li></ol><h3 id="how-do-nodes-communicate-with-each-other"><a class="markdownIt-Anchor" href="#how-do-nodes-communicate-with-each-other"></a> How do nodes communicate with each other?</h3><ol><li>The nodes within each datacenter organize themselves into a one-hop DHT using the identifiers generated when joining the system.<ul><li>A node’s chain predecessor and successor, the head node, and the tail node are defined as its predecessor and successor in the DHT ring.</li></ul></li><li>All RPC-based communication between nodes, or between nodes and clients, is over TCP connections.<ul><li>Each node maintains a pool of connected TCP connections with its chain’s predecessor, successor, and tail.</li><li>For chains that span multiple datacenters, the last node of one datacenter maintains a connection to the first node of its successor datacenter.</li><li>Any node that maintains a connection to a node outside of its datacenter must also place a watch on the node list of the external datacenter.</li></ul></li></ol><h1 id="evaluation"><a class="markdownIt-Anchor" href="#evaluation"></a> Evaluation</h1><ol><li><p>The main contribution is that it supports reading from intermediate nodes. So, the author measured the read throughput of CRAQ and compared it with basic CR.</p><p><img src="/imgs/Distributed/CRAQ/4.png" alt="" /><img src="/imgs/Distributed/CRAQ/6.png" alt="" /></p></li><li><p>The author also tested the factors affecting read throughput, i.e., the number of clients, nodes, and writes.</p><p><img src="/imgs/Distributed/CRAQ/5.png" alt="" /><img src="/imgs/Distributed/CRAQ/7.png" alt="" /></p></li><li><p>Another important test in a distributed system is how long it takes to recover and how it performs during the failure.</p><p><img src="/imgs/Distributed/CRAQ/10-13.png" alt="" /></p></li></ol>]]></content>
      
      
      <categories>
          
          <category> Paper Notebook </category>
          
          <category> Distributed System </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Distributed System </tag>
            
            <tag> Distributed Storage </tag>
            
            <tag> Consensus Algorithm </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Zookeeper</title>
      <link href="/2023/09/26/Paper/Distributed/Zookeeper/"/>
      <url>/2023/09/26/Paper/Distributed/Zookeeper/</url>
      
        <content type="html"><![CDATA[<p>Paper: <a href="http://nil.csail.mit.edu/6.824/2020/papers/zookeeper.pdf">ZooKeeper: Wait-free coordination for Internet-scale systems</a></p><p><ul class="markdownIt-TOC"><li><a href="#purpose">Purpose</a></li><li><a href="#model">Model</a><ul><li><a href="#zookeeper-service-overview">ZooKeeper service overview</a><ul><li><a href="#how-does-the-client-interact-with-the-zookeeper-server">How does the client interact with the ZooKeeper server?</a></li><li><a href="#what-are-the-flags-of-znodes">What are the flags of znodes?</a></li><li><a href="#what-are-the-differences-between-znodes-and-files-in-a-file-system">What are the differences between znodes and files in a file system?</a></li><li><a href="#what-does-zookeeper-guarantee">What does ZooKeeper guarantee?</a></li><li><a href="#how-to-change-the-configuration">How to change the configuration?</a></li><li><a href="#how-should-a-client-read-configurations">How should a client read configurations?</a></li></ul></li><li><a href="#implement-primitives">Implement primitives</a><ul><li><a href="#how-does-zookeeper-manage-configuration">How does ZooKeeper manage configuration?</a></li><li><a href="#how-does-zookeeper-manage-rendezvous">How does ZooKeeper manage rendezvous?</a></li><li><a href="#how-does-zookeeper-manage-group-membership">How does ZooKeeper manage group membership?</a></li><li><a href="#how-does-zookeeper-manage-mini-transactions">How does ZooKeeper manage mini-transactions?</a></li><li><a href="#how-does-zookeeper-implement-simple-locks">How does ZooKeeper implement simple locks?</a></li><li><a href="#how-does-zookeeper-implement-simple-locks-without-herd-effect">How does ZooKeeper implement simple locks without herd effect?</a></li><li><a href="#how-does-zookeeper-implement-readwrite-locks">How does ZooKeeper implement Read/Write locks?</a></li><li><a href="#what-is-the-difference-between-zookeeper-locks-and-thread-mutex-locks">What is the difference between ZooKeeper locks and thread mutex locks?</a></li><li><a href="#how-does-zookeeper-implement-a-double-barrier">How does ZooKeeper implement a double barrier?</a></li></ul></li><li><a href="#implementation-of-zookeeper">Implementation of ZooKeeper</a><ul><li><a href="#how-does-zookeeper-serve-requests">How does ZooKeeper serve requests?</a></li><li><a href="#how-does-zookeeper-manage-the-database">How does ZooKeeper manage the database?</a></li><li><a href="#how-does-the-request-processor-handle-write-requests">How does the request processor handle write requests?</a></li><li><a href="#how-do-servers-reach-an-agreement">How do servers reach an agreement?</a></li><li><a href="#how-does-zookeeper-take-a-snapshot">How does ZooKeeper take a snapshot?</a></li><li><a href="#how-does-zookeeper-handle-sync">How does ZooKeeper handle sync()</a></li><li><a href="#how-does-zookeeper-ensure-to-serve-data-at-least-as-updated-as-the-last-server-served-that-data">How does ZooKeeper ensure to serve data at least as updated as the last server served that data?</a></li><li><a href="#how-to-detect-client-session-failures">How to detect client session failures?</a></li></ul></li></ul></li><li><a href="#evaluation-and-results">Evaluation and results</a></li></ul></p><h1 id="purpose"><a class="markdownIt-Anchor" href="#purpose"></a> Purpose</h1><ol><li>Contribution<ul><li>Moved away from implementing specific primitives on the server side<ul><li>Opted for exposing an API that enables application developers to implement their primitives.</li><li>It enables new primitives without requiring changes to the service core.</li></ul></li><li>Moved away from blocking primitives.<ul><li>Manipulate simple wait-free data objects organized hierarchically as in file systems.</li></ul></li><li>Provide a per-client guarantee of FIFO execution of requests and linearizability for all writes.<ul><li>Read requests are satisfied by local servers.</li></ul></li></ul></li><li>Features<ul><li>Provide a simple and high-performance kernel for building more complex coordination primitives at the client.</li><li>Incorporate elements from group messaging, shared registers, and distributed lock services in a replicated centralized service.</li><li>It has the wait-free aspects of shared registers with an event-driven mechanism.</li><li>A simple pipelined architecture allows us to have hundreds or thousands of requests outstanding while still achieving low latency.</li><li>With asynchronous operations, a client can have multiple outstanding operations simultaneously.</li><li>Enables caching data on the client side with ZooKeeper watches to avoid the problem of delayed updates caused by slow or faulty clients.</li></ul></li></ol><h1 id="model"><a class="markdownIt-Anchor" href="#model"></a> Model</h1><h2 id="zookeeper-service-overview"><a class="markdownIt-Anchor" href="#zookeeper-service-overview"></a> ZooKeeper service overview</h2><p>Znode: an in-memory data node in the ZooKeeper data<br />Data tree: a hierarchical namespace to organize znodes</p><h3 id="how-does-the-client-interact-with-the-zookeeper-server"><a class="markdownIt-Anchor" href="#how-does-the-client-interact-with-the-zookeeper-server"></a> How does the client interact with the ZooKeeper server?</h3><ol><li><p>Clients submit requests to ZooKeeper through a client API using a ZooKeeper client library.</p><ul><li><code>create(path, data, flags)</code>: returns the name of the new znode</li><li><code>delete(path, version)</code>: Deletes the znode path if that znode is at the expected version.</li><li><code>exists(path, watch)</code>: The watch flag enables a client to set a watch on the znode.</li><li><code>getData(path, watch)</code>: Returns the data and meta-data, such as version information, associated with the znode. ZooKeeper does not set the watch if the znode does not exist.</li><li><code>setData(path, data, version)</code>: Writes data[] to znode path if the version number is the current znode version.</li><li><code>getChildren(path, watch)</code></li><li><code>sync(path)</code>: Waits for all updates pending at the start of the operation to propagate to the server the client is connected to. The path is currently ignored.</li></ul></li><li><p>All methods have synchronous and asynchronous versions available through the API.</p></li><li><p>If the actual version number of the znode does not match the expected version number the update fails with an unexpected version error.<br />If the version number is −1, it does not perform version checking.</p></li><li><p>The client library also manages the network connections between the client and ZooKeeper servers.</p></li></ol><h3 id="what-are-the-flags-of-znodes"><a class="markdownIt-Anchor" href="#what-are-the-flags-of-znodes"></a> What are the flags of znodes?</h3><ol><li><em>Regular</em>: Clients manipulate regular znodes by creating and deleting them explicitly</li><li><em>Ephemeral</em>: Clients create such znodes, and they either delete them explicitly or let the system remove them automatically when the session that makes them terminates</li><li><em>Sequential</em>: Those znodes in the same parent znode have a monotonically increasing counter appended to their name. The newer znode has a larger sequence value.</li><li><em>Watch</em><ul><li>A read operation with a watch flag set completes normally, except the server promises to notify the client when the information returned has changed.</li><li>Watches are one-time triggers associated with a session; they are unregistered once triggered, or the session closes.</li><li>Watches indicate a change has happened but do not provide the change.</li><li>Session events, such as connection loss events, are also sent to watch callbacks so that clients know that watch events may be delayed.</li></ul></li></ol><h3 id="what-are-the-differences-between-znodes-and-files-in-a-file-system"><a class="markdownIt-Anchor" href="#what-are-the-differences-between-znodes-and-files-in-a-file-system"></a> What are the differences between znodes and files in a file system?</h3><ol><li><p>Znodes map to abstractions of the client application, typically corresponding to meta-data used for coordination purposes.</p></li><li><p>Znodes allow clients to store information that can be used for meta-data or configuration in a distributed computation, such as the leadership of a replica group, which can be stored in a known location.</p></li><li><p>ZooKeeper does not use handles to access znodes. Instead, each request includes the full path on which the znode is being operated.</p><ul><li><p>It simplifies the API (no <code>open()</code> or <code>close()</code> methods)</p></li><li><p>It also eliminates the extra state that the server would need to maintain.</p></li></ul></li></ol><h3 id="what-does-zookeeper-guarantee"><a class="markdownIt-Anchor" href="#what-does-zookeeper-guarantee"></a> What does ZooKeeper guarantee?</h3><ol><li><p>This definition of its linearizability is called A-linearizability (asynchronous linearizability), which allows a client to have multiple outstanding operations.</p><ul><li><p><em>Linearizable writes</em>: all requests that update the state of ZooKeeper are serializable and respect precedence.</p></li><li><p><em>FIFO client order</em>: all requests from a given client are executed in the order that the client sent them.</p></li></ul></li><li><p>A-linearizability can guarantee no specific order for outstanding operations of the same client or a FIFO order.</p></li><li><p>A system that satisfies A-linearizability also satisfies linearizability. Because only update requests are A-linearizable, ZooKeeper processes read requests locally at each replica.</p></li></ol><h3 id="how-to-change-the-configuration"><a class="markdownIt-Anchor" href="#how-to-change-the-configuration"></a> How to change the configuration?</h3><ol><li><p>Two requirements:</p><ul><li>As the new leader starts making changes, we do not want other processes to start using the configuration that is being changed.</li><li>If the new leader dies before the configuration has been fully updated, we do not want the processes to use this partial configuration.</li></ul></li><li><p>The new leader can designate a path as the ready znode; other processes will only use the configuration when that znode exists.</p><ul><li>The new leader changes the configuration by deleting ready, updating the configuration znodes, and creating ready.</li><li>Given the FIFO client order guarantee, these changes can be pipelined and issued asynchronously to update the configuration state quickly.</li></ul></li></ol><h3 id="how-should-a-client-read-configurations"><a class="markdownIt-Anchor" href="#how-should-a-client-read-configurations"></a> How should a client read configurations?</h3><ol><li><p>If a client sees the ready exists before the new leader starts to make a change, it could read the partial configuration in progress and cannot notice anything.</p><ul><li>The client needs to set the watch flag when they check the existence of the ready znode.</li><li>Then, it will see a notification informing the client of the change before it can read any of the new configurations.</li></ul></li><li><p>If A changes the shared configuration in ZooKeeper and tells B of the change through the shared communication channel, B would expect to see the change when it re-reads the configuration.</p><ul><li>If B’s ZooKeeper replica is slightly behind A’s, the new configuration may not be visible.</li><li>B can ensure it sees the most up-to-date information by issuing a write before re-reading the configuration.</li><li><code>sync</code> causes a server to apply all pending write requests before processing the read without the overhead of a full write.</li></ul></li></ol><h2 id="implement-primitives"><a class="markdownIt-Anchor" href="#implement-primitives"></a> Implement primitives</h2><h3 id="how-does-zookeeper-manage-configuration"><a class="markdownIt-Anchor" href="#how-does-zookeeper-manage-configuration"></a> How does ZooKeeper manage configuration?</h3><ol><li>Configuration is stored in a znode, <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>z</mi><mi>c</mi></msub></mrow><annotation encoding="application/x-tex">z_c</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.04398em;">z</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:-0.04398em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">c</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>.</li><li>Processes start up with the full pathname of <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>z</mi><mi>c</mi></msub></mrow><annotation encoding="application/x-tex">z_c</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.04398em;">z</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:-0.04398em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">c</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>. Starting processes obtain their configuration by reading zc with the watch flag set to true.</li><li>If the configuration in <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>z</mi><mi>c</mi></msub></mrow><annotation encoding="application/x-tex">z_c</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.04398em;">z</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:-0.04398em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">c</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> is ever updated, the processes are notified, and the new configuration is read, again setting the watch flag to true.</li></ol><h3 id="how-does-zookeeper-manage-rendezvous"><a class="markdownIt-Anchor" href="#how-does-zookeeper-manage-rendezvous"></a> How does ZooKeeper manage rendezvous?</h3><ol><li>Use a rendezvous znode, <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>z</mi><mi>r</mi></msub></mrow><annotation encoding="application/x-tex">z_r</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.04398em;">z</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:-0.04398em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>, which is a node created by the client.</li><li>The client passes the full pathname of <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>z</mi><mi>r</mi></msub></mrow><annotation encoding="application/x-tex">z_r</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.04398em;">z</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:-0.04398em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> as a startup parameter of the master and worker processes.</li><li>When the master starts, it fills in <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>z</mi><mi>r</mi></msub></mrow><annotation encoding="application/x-tex">z_r</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.04398em;">z</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:-0.04398em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> with information about addresses and ports it is using.</li><li>When workers start, they read <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>z</mi><mi>r</mi></msub></mrow><annotation encoding="application/x-tex">z_r</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.04398em;">z</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:-0.04398em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> with the watch set to true.<ul><li>If <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>z</mi><mi>r</mi></msub></mrow><annotation encoding="application/x-tex">z_r</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.04398em;">z</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:-0.04398em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> has not been filled in yet, the worker waits to be notified when <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>z</mi><mi>r</mi></msub></mrow><annotation encoding="application/x-tex">z_r</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.04398em;">z</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:-0.04398em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> is updated.</li><li>If <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>z</mi><mi>r</mi></msub></mrow><annotation encoding="application/x-tex">z_r</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.04398em;">z</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:-0.04398em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> is an ephemeral node, master and worker processes can watch for <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>z</mi><mi>r</mi></msub></mrow><annotation encoding="application/x-tex">z_r</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.04398em;">z</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:-0.04398em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> to be deleted and cleaned up when the client ends.</li></ul></li></ol><h3 id="how-does-zookeeper-manage-group-membership"><a class="markdownIt-Anchor" href="#how-does-zookeeper-manage-group-membership"></a> How does ZooKeeper manage group membership?</h3><ol><li><p>Designate a znode, <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>z</mi><mi>g</mi></msub></mrow><annotation encoding="application/x-tex">z_g</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.716668em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.04398em;">z</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.15139200000000003em;"><span style="top:-2.5500000000000003em;margin-left:-0.04398em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03588em;">g</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span></span></span></span> to represent the group.</p></li><li><p>When a process member of the group starts, it creates an <code>ephemeral</code> child znode under <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>z</mi><mi>g</mi></msub></mrow><annotation encoding="application/x-tex">z_g</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.716668em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.04398em;">z</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.15139200000000003em;"><span style="top:-2.5500000000000003em;margin-left:-0.04398em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03588em;">g</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span></span></span></span>. Processes may put process information in the data of the child znode.</p></li><li><p>If each process has a unique name or identifier, that name is used as the name of the child znode; otherwise, the process creates the znode with the <code>SEQUENTIAL</code> flag to obtain a unique name assignment.</p></li></ol><h3 id="how-does-zookeeper-manage-mini-transactions"><a class="markdownIt-Anchor" href="#how-does-zookeeper-manage-mini-transactions"></a> How does ZooKeeper manage mini-transactions?</h3><ol><li>In a mini-transaction, we want the <code>getData</code> and <code>setData</code> to be atomic.</li><li>ZooKeeper can support mini-transactions using version numbers.</li></ol><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">while</span> <span class="literal">true</span>:</span><br><span class="line">X, v = <span class="title function_ invoke__">getData</span>(K)</span><br><span class="line">  <span class="keyword">if</span> <span class="title function_ invoke__">setData</span>(K, X+<span class="number">1</span>, v):</span><br><span class="line"><span class="keyword">break</span></span><br></pre></td></tr></table></figure><h3 id="how-does-zookeeper-implement-simple-locks"><a class="markdownIt-Anchor" href="#how-does-zookeeper-implement-simple-locks"></a> How does ZooKeeper implement simple locks?</h3><ol><li><p>The lock is represented by a znode. To acquire a lock, a client tries to create the designated znode with the <code>EPHEMERAL</code> flag.</p></li><li><p>If the creation succeeds, the client holds the lock. Otherwise, the client can read the znode with the watch flag set to be notified if the current leader dies.</p></li><li><p>A client releases the lock when it dies or explicitly deletes the znode.</p></li><li><p>Other clients waiting for a lock try again to acquire one once they observe the znode being deleted.</p></li></ol><h3 id="how-does-zookeeper-implement-simple-locks-without-herd-effect"><a class="markdownIt-Anchor" href="#how-does-zookeeper-implement-simple-locks-without-herd-effect"></a> How does ZooKeeper implement simple locks without herd effect?</h3><ol><li><p>Herd effect of simple locks: If many clients are waiting to acquire a lock, they will all vie for it when it is released, even though only one client can.</p></li><li><p>Define a lock znode l to implement such locks. Line up all the clients requesting the lock, and each obtains the lock to request arrival.</p><ul><li>Use the <code>SEQUENTIAL</code> flag to order the client’s attempt to acquire the lock with respect to all other attempts.</li><li>The client holds the lock if the client’s znode has the lowest sequence number.</li><li>Otherwise, the client waits for deletion of the znode that either has the lock or will receive the lock before this client’s znode.</li></ul></li><li><p>By only watching the znode that precedes the client’s znode, the herd effect can be avoided by only waking up one process when a lock is released or a lock request is abandoned.</p></li><li><p>Once the znode being watched by the client goes away, the client must check if it now holds the lock.</p><ul><li>The previous lock request may have been abandoned and there is a znode with a lower sequence number still waiting for or holding the lock.</li></ul></li><li><p>Releasing a lock is as simple as deleting the znode n that represents the lock request.</p></li><li><p>By browsing the ZooKeeper data, we can see the amount of lock contention, break locks, and debug locking problems.</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Lock</span></span><br><span class="line">n = create(l + “/lock-”, EPHEMERAL|SEQUENTIAL)</span><br><span class="line">C = getChildren(l, <span class="literal">false</span>)</span><br><span class="line"><span class="keyword">if</span> n is lowest znode in C, <span class="built_in">exit</span></span><br><span class="line">p = znode in C ordered just before n</span><br><span class="line"><span class="keyword">if</span> exists(p, <span class="literal">true</span>) wait <span class="keyword">for</span> watch event</span><br><span class="line"><span class="keyword">goto</span> <span class="number">2</span></span><br><span class="line"></span><br><span class="line"><span class="comment">//Unlock</span></span><br><span class="line">delete(n)</span><br></pre></td></tr></table></figure></li></ol><h3 id="how-does-zookeeper-implement-readwrite-locks"><a class="markdownIt-Anchor" href="#how-does-zookeeper-implement-readwrite-locks"></a> How does ZooKeeper implement Read/Write locks?</h3><ol><li><p>The write locks are similar to simple ones since they are all exclusive.</p></li><li><p>Since read locks may be shared, and only earlier write lock znodes prevent the client from obtaining a read lock, read locks only need to check that no lower write znode.</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Write lock</span></span><br><span class="line">n = create(l + “/write-”, EPHEMERAL|SEQUENTIAL)</span><br><span class="line">C = getChildren(l, <span class="literal">false</span>)</span><br><span class="line"><span class="keyword">if</span> n is lowest znode in C, <span class="built_in">exit</span></span><br><span class="line">p = znode in C ordered just before n</span><br><span class="line"><span class="keyword">if</span> exists(p, <span class="literal">true</span>) wait <span class="keyword">for</span> event</span><br><span class="line"><span class="keyword">goto</span> <span class="number">2</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// Read Lock</span></span><br><span class="line">n = create(l + “/read-”, EPHEMERAL|SEQUENTIAL)</span><br><span class="line">C = getChildren(l, <span class="literal">false</span>)</span><br><span class="line"><span class="keyword">if</span> no write znodes lower than n in C, <span class="built_in">exit</span></span><br><span class="line">p = write znode in C ordered just before n</span><br><span class="line"><span class="keyword">if</span> exists(p, <span class="literal">true</span>) wait <span class="keyword">for</span> event</span><br><span class="line"><span class="keyword">goto</span> <span class="number">3</span></span><br></pre></td></tr></table></figure></li></ol><h3 id="what-is-the-difference-between-zookeeper-locks-and-thread-mutex-locks"><a class="markdownIt-Anchor" href="#what-is-the-difference-between-zookeeper-locks-and-thread-mutex-locks"></a> What is the difference between ZooKeeper locks and thread mutex locks?</h3><ol><li>In ZooKeeper lock, the system automatically releases the locks if the lock holder fails. So, locks do not enforce the atomicity of other activities.</li><li>To make writes atomic, use the “ready” trick or mini-transactions.</li><li>For the master/leader election, a new leader must inspect the state and clean up.</li><li>Or use soft locks like MapReduce for performance but not correctness. Only one worker will do each task, which is OK to be done twice.</li></ol><h3 id="how-does-zookeeper-implement-a-double-barrier"><a class="markdownIt-Anchor" href="#how-does-zookeeper-implement-a-double-barrier"></a> How does ZooKeeper implement a double barrier?</h3><ol><li>Double barriers enable clients to synchronize a computation’s beginning and end.<ul><li>Enter barrier: At the beginning, a client must wait until the number of waiting clients exceeds the threshold before executing the computation.</li><li>Leave barrier: At the end, a client must wait until the number of finished clients exceeds the threshold before it can exit.</li></ul></li><li>Represent a barrier in ZooKeeper with a znode, referred to as <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>b</mi></mrow><annotation encoding="application/x-tex">b</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathnormal">b</span></span></span></span>.</li><li>Every process <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi></mrow><annotation encoding="application/x-tex">p</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord mathnormal">p</span></span></span></span> registers with <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>b</mi></mrow><annotation encoding="application/x-tex">b</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathnormal">b</span></span></span></span> on entry by creating a znode as a child of <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>b</mi></mrow><annotation encoding="application/x-tex">b</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathnormal">b</span></span></span></span>, and unregisters when it is ready to leave by removing the child.<ul><li>Processes can enter the barrier when the number of child znodes of <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>b</mi></mrow><annotation encoding="application/x-tex">b</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathnormal">b</span></span></span></span> exceeds the barrier threshold.</li><li>Processes can leave the barrier when all of the processes have removed their children.</li></ul></li><li>We use watches to wait for enter and exit conditions to be satisfied efficiently.<ul><li>To enter, processes watch for a ready child, created by the process that causes the number of children to exceed the barrier threshold.</li><li>To leave, processes watch for a particular child to disappear and only check the exit condition once that znode has been removed.</li></ul></li></ol><h2 id="implementation-of-zookeeper"><a class="markdownIt-Anchor" href="#implementation-of-zookeeper"></a> Implementation of ZooKeeper</h2><h3 id="how-does-zookeeper-serve-requests"><a class="markdownIt-Anchor" href="#how-does-zookeeper-serve-requests"></a> How does ZooKeeper serve requests?</h3><ol><li>Upon receiving a request, a server prepares it for execution in the request processor.</li><li>If a write request requires coordination among the servers, they use atomic broadcast to reach an agreement. Finally, servers commit changes to the ZooKeeper database that are fully replicated across all ensemble servers.<ul><li>When a server processes a write request, it sends and clears notifications relative to any watch corresponding to that update.</li><li>Only the server that a client is connected to tracks and triggers notifications for that client.</li><li>Servers process writes in order and does not concurrently process other writes or reads. This ensures a strict succession of notifications.</li></ul></li><li>In the case of read requests, a server reads the state of the local database and generates a response to the request.<ul><li>Each read request is processed and tagged with a <em>zxid</em> that corresponds to the last transaction seen by the server.</li><li><em>Zxid</em> defines the partial order of the read requests concerning the write requests.</li><li>For applications that require ZooKeeper not to serve stale data, they can call <code>sync()</code> followed by the read operation.</li></ul></li></ol><h3 id="how-does-zookeeper-manage-the-database"><a class="markdownIt-Anchor" href="#how-does-zookeeper-manage-the-database"></a> How does ZooKeeper manage the database?</h3><ol><li>The replicated database is an in-memory database containing the entire data tree.</li><li>Each znode in the tree stores a maximum of 1MB of data by default, but this maximum value is a configuration parameter that can be changed in specific cases.</li><li>For recoverability,<ul><li>Efficiently log updates to disk, and we force writes to be on the disk media before they are applied to the in-memory database.</li><li>A replay log (a write-ahead log) of committed operations is kept and periodically generates snapshots of the in-memory database.</li></ul></li></ol><h3 id="how-does-the-request-processor-handle-write-requests"><a class="markdownIt-Anchor" href="#how-does-the-request-processor-handle-write-requests"></a> How does the request processor handle write requests?</h3><ol><li>When the leader receives a write request, it calculates the state of the system when the write is applied and transforms it into a transaction that captures this new state.</li><li>The future state must be calculated because there may be outstanding transactions that have not yet been applied to the database.</li></ol><h3 id="how-do-servers-reach-an-agreement"><a class="markdownIt-Anchor" href="#how-do-servers-reach-an-agreement"></a> How do servers reach an agreement?</h3><ol><li>All requests that update ZooKeeper state are forwarded to the leader.</li><li>The leader executes the request and broadcasts the change to the ZooKeeper state through Zab.<ul><li>Zab uses, by default, simple majority quorums to decide on a proposal, so Zab and ZooKeeper can only work if a majority of servers are correct.</li><li>Zab guarantees that changes broadcast by a leader are delivered in the order they were sent. All changes from previous leaders are delivered to an established leader before it broadcasts them.</li><li>Because idempotent transactions are used, multiple delivery is acceptable as long as they are delivered in order.</li><li>ZooKeeper requires Zab to redeliver at least all messages delivered after the last snapshot starts.</li></ul></li><li>The server that receives the client request responds to the client when it delivers the corresponding state change.</li><li>Use TCP for transport so message order is maintained by the network.</li></ol><h3 id="how-does-zookeeper-take-a-snapshot"><a class="markdownIt-Anchor" href="#how-does-zookeeper-take-a-snapshot"></a> How does ZooKeeper take a snapshot?</h3><ol><li>ZooKeeper snapshots are called fuzzy snapshots since we do not lock the ZooKeeper state to take the snapshot.<br />Instead, we do a depth first scan of the tree atomically reading each znode’s data and meta-data and writing them to disk.</li><li>Since the resulting fuzzy snapshot may have applied some subset of the state changes delivered during the snapshot generation, the result may not correspond to the state of ZooKeeper at any time.</li><li>However, since state changes are idempotent, we can apply them twice as long as we apply the state changes in order.</li></ol><h3 id="how-does-zookeeper-handle-sync"><a class="markdownIt-Anchor" href="#how-does-zookeeper-handle-sync"></a> How does ZooKeeper handle sync()</h3><ol><li>It does not need to atomically broadcast sync as using a leader-based algorithm, and it simply places the <code>sync</code> operation at the end of the queue of requests between the leader and the server executing the call to sync.</li><li>The follower must be sure that the leader is still the leader.<ul><li>If pending transactions are committed, then the server does not suspect the leader.</li><li>If the pending queue is empty, the leader must issue a null transaction to commit and order the <code>sync</code> after that transaction.</li><li>Hence, no extra broadcast traffic is generated when the leader is under load.</li><li>Timeouts are set so leaders realize they are not leaders before followers abandon them, so it does not issue the null transaction.</li></ul></li></ol><h3 id="how-does-zookeeper-ensure-to-serve-data-at-least-as-updated-as-the-last-server-served-that-data"><a class="markdownIt-Anchor" href="#how-does-zookeeper-ensure-to-serve-data-at-least-as-updated-as-the-last-server-served-that-data"></a> How does ZooKeeper ensure to serve data at least as updated as the last server served that data?</h3><ol><li>Check the client’s last zxid against its last zxid.</li><li>If the client has a more recent view than the server, the server does not reestablish the session with the client until the server has caught up.</li></ol><h3 id="how-to-detect-client-session-failures"><a class="markdownIt-Anchor" href="#how-to-detect-client-session-failures"></a> How to detect client session failures?</h3><ol><li>The leader determines that there has been a failure if no other server receives anything from a client session within the session timeout.</li><li>If the client sends requests frequently enough, then sending any other message is unnecessary.<br />Otherwise, the client sends heartbeat messages during periods of low activity.</li><li>If the client cannot communicate with a server to send a request or heartbeat, it connects to a different ZooKeeper server to re-establish its session.</li><li>To prevent the session from timing out, the ZooKeeper client library sends a heartbeat after the session has been idle for <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>s</mi><mi mathvariant="normal">/</mi><mn>3</mn></mrow><annotation encoding="application/x-tex">s/3</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">s</span><span class="mord">/</span><span class="mord">3</span></span></span></span> ms and switch to a new server if it has not heard from a server for <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>2</mn><mi>s</mi><mi mathvariant="normal">/</mi><mn>3</mn></mrow><annotation encoding="application/x-tex">2s/3</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord">2</span><span class="mord mathnormal">s</span><span class="mord">/</span><span class="mord">3</span></span></span></span> ms, where <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>s</mi></mrow><annotation encoding="application/x-tex">s</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathnormal">s</span></span></span></span> is the session timeout in milliseconds.</li></ol><h1 id="evaluation-and-results"><a class="markdownIt-Anchor" href="#evaluation-and-results"></a> Evaluation and results</h1><ol><li><p>To show the system’s scalability, the author varied the number of servers that make up the ZooKeeper service but always kept the number of clients the same.</p><p>The throughput performance of a saturated system varies as the ratio of reads to writes is shown below.</p><img src="/imgs/Distributed/ZooKeeper/Throughput.png"></li><li><p>There are two reasons why write requests take longer than read requests.</p><ul><li>First, write requests must go through atomic broadcast, which requires extra processing and adds latency to requests.</li><li>The other reason for the longer processing of write requests is that servers must ensure that transactions are logged to a non-volatile store before sending acknowledgments back to the leader.</li></ul></li><li><p>The atomic broadcast protocol does most of the system’s work and thus limits the performance of ZooKeeper more than any other component.</p><p>To benchmark its performance, the author simulates clients by generating transactions directly at the leader, so there are no client connections, requests, or replies.</p><p>The result is as shown below:</p><img src="/imgs/Distributed/ZooKeeper/AtomicBroadcast.png"></li><li><p>The author also tested the system’s throughput when different failure events occurred.</p><p>The events are ① Failure and recovery of a follower; ② Failure and recovery of a different follower; ③ Failure of the leader; ④Failure of two followers (a, b) in the first two marks, and recovery at the third mark ©; ⑤ Failure of the leader; ⑥Recovery of the leader.</p><img src="/imgs/Distributed/ZooKeeper/Failures.png"></li><li><p>To assess the latency of requests, the author creates a worker process that sends a create, waits for it to finish, sends an asynchronous delete of the new node, and then starts the next create.</p><p>Then, the throughput can be calculated by dividing the number of create requests completed by the total time it took all the workers to complete them.</p><img src="/imgs/Distributed/ZooKeeper/Latency.png"></li><li><p>The author also measured the performance of primitives implemented with ZooKeeper. They measured the performance of barriers.</p><p>The time to process all barriers increases roughly linearly with the number of barriers, showing that concurrent access to the same part of the data tree did not produce any unexpected delay.</p><p>Latency increases proportionally to the number of clients. This is a consequence of not saturating the ZooKeeper service due to clients waiting on other clients.</p><img src="/imgs/Distributed/ZooKeeper/Barrier.png"></li></ol>]]></content>
      
      
      <categories>
          
          <category> Paper Notebook </category>
          
          <category> Distributed System </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Distributed System </tag>
            
            <tag> Distributed Storage </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Raft</title>
      <link href="/2023/09/26/Paper/Distributed/Raft/"/>
      <url>/2023/09/26/Paper/Distributed/Raft/</url>
      
        <content type="html"><![CDATA[<p>Paper: <a href="http://nil.csail.mit.edu/6.824/2020/papers/raft-extended.pdf">In Search of an Understandable Consensus Algorithm</a></p><p><ul class="markdownIt-TOC"><li><a href="#abstract">Abstract</a></li><li><a href="#purpose">Purpose</a></li><li><a href="#model">Model</a><ul><li><a href="#basics">Basics</a><ul><li><a href="#how-does-raft-implement-consensus-overall">How does Raft implement consensus overall?</a></li><li><a href="#what-are-the-states-of-each-server">What are the states of each server?</a></li><li><a href="#how-to-divide-the-terms">How to divide the terms?</a></li><li><a href="#how-do-terms-change">How do terms change?</a></li><li><a href="#how-does-raft-handle-follower-and-candidate-crashes">How does Raft handle follower and candidate crashes?</a></li><li><a href="#states-stored-on-servers">States stored on servers</a></li></ul></li><li><a href="#leader-election">Leader election</a><ul><li><a href="#how-do-the-servers-state-transit">How do the servers state transit?</a></li><li><a href="#how-to-elect-a-leader">How to elect a leader?</a></li><li><a href="#how-is-the-election-held">How is the election held?</a></li><li><a href="#how-to-determine-that-a-server-loses-the-election">How to determine that a server loses the election?</a></li><li><a href="#how-to-handle-a-split-vote">How to handle a split vote?</a></li><li><a href="#how-to-ensure-that-the-leader-of-any-given-term-contains-all-of-the-entries-committed-in-previous-terms">How to ensure that the leader of any given term contains all of the entries committed in previous terms?</a></li><li><a href="#what-are-the-limitations-of-broadcast-time-and-election-timeout">What are the limitations of broadcast time and election timeout?</a></li><li><a href="#requestvote-rpc">RequestVote RPC</a></li></ul></li><li><a href="#log-replication">Log replication</a><ul><li><a href="#how-are-client-requests-handled">How are client requests handled?</a></li><li><a href="#what-is-stored-in-a-log-entry">What is stored in a log entry?</a></li><li><a href="#how-to-apply-a-log-entry-to-the-state-machines">How to apply a log entry to the state machines?</a></li><li><a href="#how-to-determine-the-consistency-between-logs">How to determine the consistency between logs?</a></li><li><a href="#how-to-check-the-consistency-in-appendentries-rpcs">How to check the consistency in AppendEntries RPCs?</a></li><li><a href="#what-kinds-of-inconsistency-may-incur">What kinds of inconsistency may incur?</a></li><li><a href="#how-does-the-leader-handle-follower-inconsistencies">How does the leader handle follower inconsistencies?</a></li><li><a href="#how-does-appendentries-rpc-perform-a-consistency-check">How does AppendEntries RPC perform a consistency check?</a></li><li><a href="#how-to-handle-uncommitted-entries-from-previous-leaders">How to handle uncommitted entries from previous leaders?</a></li><li><a href="#appendentries-rpc">AppendEntries RPC</a></li></ul></li><li><a href="#log-compaction">Log compaction</a><ul><li><a href="#how-does-raft-compact-logs">How does Raft compact logs?</a></li><li><a href="#how-to-handle-the-appendentries-that-require-compated-entries">How to handle the AppendEntries that require compated entries?</a></li><li><a href="#how-to-install-the-snapshot-from-the-leader">How to install the snapshot from the leader?</a></li><li><a href="#when-should-a-server-take-a-snapshot">When should a server take a snapshot?</a></li><li><a href="#how-can-the-delays-of-normal-operations-caused-by-a-snapshot-be-reduced">How can the delays of normal operations caused by a snapshot be reduced?</a></li><li><a href="#installsnapshot-rpc">InstallSnapshot RPC</a></li></ul></li><li><a href="#client-interaction">Client interaction</a><ul><li><a href="#how-does-the-client-find-the-cluster-leader">How does the client find the cluster leader?</a></li><li><a href="#how-to-prevent-raft-from-executing-a-command-multiple-times">How to prevent Raft from executing a command multiple times?</a></li><li><a href="#how-to-prevent-returning-stale-data-to-a-read-only-operation">How to prevent returning stale data to a read-only operation?</a></li></ul></li></ul></li><li><a href="#experiments-and-results">Experiments and results</a></li><li><a href="#reproduce-and-unmentioned-parts">Reproduce and unmentioned parts</a></li></ul></p><h1 id="abstract"><a class="markdownIt-Anchor" href="#abstract"></a> Abstract</h1><ol><li><strong>Main idea</strong>: Understandability also matters for an algorithm to be implemented and deployed. Separate leader election and log replication parts in consensus to increase understandability. Linearizability is provided by restricting entries accepted by followers, and client commands are executed only once.</li><li><strong>Key findings</strong>: The key to the correctness of the system is that committed entries are durable in all nodes. We can easily induct it based on the Log Matching property and Leader Append-Only property. Another corner case is that leaders commit entries of previous terms only by committing entries from its term.</li><li><strong>The system</strong>: The elected leaders are restricted to be at least as up-to-date as majority nodes and only leaders can append entries from clients.</li><li><strong>Evaluation</strong>: The authors evaluated the understandability against Paxos, and the performance of elected leaders is measured.</li></ol><h1 id="purpose"><a class="markdownIt-Anchor" href="#purpose"></a> Purpose</h1><ol><li>Enhance the understandability of Paxos.<ul><li>Raft separates the critical consensus elements, such as leader election, log replication, and safety.</li><li>It enforces a stronger coherency to reduce the number of states that must be considered.</li></ul></li><li>Novel features: strong leader, leader election, membership changes.</li><li><strong>What are the common properties of consensus algorithms?</strong><ul><li>Safety: never returning an incorrect result under all non-Byzantine conditions, including network delays, partitions, packet loss, duplication, and reordering.</li><li>Available as long as the majority of the servers are operational and can communicate with each other and with clients.</li><li>They do not depend on timing to ensure the consistency of the logs: faulty clocks and extreme message delays can, at worst, cause availability problems.</li><li>A command can be completed as soon as a majority of the cluster has responded to a single round of remote procedure calls; a minority of slow servers need not impact overall system performance.</li></ul></li></ol><h1 id="model"><a class="markdownIt-Anchor" href="#model"></a> Model</h1><h2 id="basics"><a class="markdownIt-Anchor" href="#basics"></a> Basics</h2><h3 id="how-does-raft-implement-consensus-overall"><a class="markdownIt-Anchor" href="#how-does-raft-implement-consensus-overall"></a> How does Raft implement consensus overall?</h3><ol><li>First, a distinguished leader is elected, and then the leader is responsible for managing the replicated log.</li><li>The leader accepts log entries from clients, replicates them on other servers, and tells servers when it is safe to apply them to their state machines.</li><li>A leader can fail or become disconnected from the other servers, in which case a new leader is elected.</li></ol><h3 id="what-are-the-states-of-each-server"><a class="markdownIt-Anchor" href="#what-are-the-states-of-each-server"></a> What are the states of each server?</h3><ol><li>Each server is in one of three states at any given time: leader, follower, or candidate.</li><li>In normal operation, there is exactly one leader, and all other servers are followers.</li><li>Followers are passive: they issue no requests on their own but respond to requests from leaders and candidates.</li><li>The leader handles all client requests. If a client contacts a follower, the follower redirects it to the leader.</li><li>The candidate is used to elect a new leader.</li></ol><h3 id="how-to-divide-the-terms"><a class="markdownIt-Anchor" href="#how-to-divide-the-terms"></a> How to divide the terms?</h3><ol><li>Terms are numbered with consecutive integers. Each election begins a new term.</li><li>If an election results in a split vote, the term will end with no leader; a new term with a new election will begin shortly.</li><li>Terms act as a logical clock in Raft, allowing servers to detect obsolete information, such as stale leaders.</li></ol><h3 id="how-do-terms-change"><a class="markdownIt-Anchor" href="#how-do-terms-change"></a> How do terms change?</h3><ol><li>Each server stores a current term number, which increases monotonically over time.</li><li>Current terms are exchanged whenever servers communicate; if one server’s term is smaller than the other’s, it updates its current term to the larger value.</li><li>If a candidate or leader discovers its term is outdated, it immediately reverts to a follower state.</li><li>The request is rejected if a server receives a request with a stale term number.</li></ol><h3 id="how-does-raft-handle-follower-and-candidate-crashes"><a class="markdownIt-Anchor" href="#how-does-raft-handle-follower-and-candidate-crashes"></a> How does Raft handle follower and candidate crashes?</h3><ol><li>If a follower or candidate crashes, then future <code>RequestVote</code> and <code>AppendEntries</code> RPCs sent to it will fail. Raft handles these failures by retrying indefinitely.</li><li>If a server crashes after completing an RPC but before responding, it will receive the same RPC again after it restarts. Raft RPCs are idempotent, i.e., servers will ignore the RPCs that are already handled, so this causes no harm.</li></ol><h3 id="states-stored-on-servers"><a class="markdownIt-Anchor" href="#states-stored-on-servers"></a> States stored on servers</h3><ol><li>Persistent state on all servers: These states must be updated on stable storage before responding to RPCs, i.e., communicating with outside.<ul><li><code>currentTerm</code>: The latest term server has seen (initialized to 0 on first boot, increases monotonically)</li><li><code>votedFor</code>: the candidate that received the vote in the current term (or <code>null</code> if none)</li><li><code>log[]</code>: log entries</li></ul></li><li>Volatile state on all servers:<ul><li><code>commitIndex</code>: index of highest log entry known to be committed (initialized to 0, increases monotonically)</li><li><code>lastApplied</code>: index of highest log entry applied to state machine (initialized to 0, increases monotonically)</li></ul></li><li>Volatile state on leaders: These states need to be reinitialized after the election<ul><li><code>nextIndex[]</code>: for each server, the index of the next log entry to send to that server (initialized to leader last log index + 1)</li><li><code>matchIndex[]</code>: for each server, the index of the highest log entry known to be replicated on the server (initialized to 0, increases monotonically)</li></ul></li></ol><h2 id="leader-election"><a class="markdownIt-Anchor" href="#leader-election"></a> Leader election</h2><h3 id="how-do-the-servers-state-transit"><a class="markdownIt-Anchor" href="#how-do-the-servers-state-transit"></a> How do the servers state transit?</h3><ol><li>When servers start up, they begin as followers. A server remains in a follower state if it receives valid RPCs from a leader or candidate.</li><li>Leaders send periodic heartbeats (<code>AppendEntries</code> RPCs with no log entries) to all followers to maintain their authority.</li><li>Suppose a follower receives no communication over a period called the election timeout. In that case, it assumes there is no viable leader and becomes a candidate to initiate a new election.</li><li>A candidate who receives votes from a majority of the entire cluster becomes the new leader.<br /><img src="/imgs/Distributed/Raft/01.png" alt="" /></li></ol><h3 id="how-to-elect-a-leader"><a class="markdownIt-Anchor" href="#how-to-elect-a-leader"></a> How to elect a leader?</h3><ol><li>To begin an election, a follower increments its current term and transitions to the candidate state.</li><li>It then votes for itself and issues <code>RequestVote</code> RPCs parallel to each other cluster server.</li><li>The candidate continues in this state until one of three things happens.<ul><li>It wins the election.</li><li>Another server establishes itself as the leader.</li><li>A period of time goes by with no winner.</li></ul></li></ol><h3 id="how-is-the-election-held"><a class="markdownIt-Anchor" href="#how-is-the-election-held"></a> How is the election held?</h3><ol><li>Each server will vote for at most one candidate in a given term on a first-come-first-served basis to ensure that one candidate can win the election for a particular term.</li><li>A candidate wins an election if it receives votes from a majority of the servers in the whole cluster for the same term.</li><li>Once a candidate wins an election, it becomes the leader. It then sends heartbeat messages to all other servers to establish its authority and prevent new elections.</li></ol><h3 id="how-to-determine-that-a-server-loses-the-election"><a class="markdownIt-Anchor" href="#how-to-determine-that-a-server-loses-the-election"></a> How to determine that a server loses the election?</h3><ol><li>A candidate may receive an <code>AppendEntries</code> RPC from another server claiming to be the leader.</li><li>If the leader’s term is at least as large as the candidate’s current term, the candidate recognizes the leader as legitimate and returns to the follower state.</li><li>If the term in the RPC is smaller than the candidate’s current term, then the candidate rejects the RPC and continues in the candidate state.</li></ol><h3 id="how-to-handle-a-split-vote"><a class="markdownIt-Anchor" href="#how-to-handle-a-split-vote"></a> How to handle a split vote?</h3><ol><li>If many followers become candidates simultaneously, votes could be split so that no candidate obtains a majority.</li><li>Each candidate will time out and start a new election by incrementing their term and initiating another round of RequestVote RPCs.</li><li>Raft uses randomized election timeouts to ensure that split votes are rare and resolved quickly.<ul><li>Election timeouts are chosen randomly from a fixed interval at the start of an election, and it waits for that timeout to elapse before starting the next election.</li><li>In most cases, only a single server will time out; it wins the election and sends heartbeats before any other servers time out.</li></ul></li></ol><h3 id="how-to-ensure-that-the-leader-of-any-given-term-contains-all-of-the-entries-committed-in-previous-terms"><a class="markdownIt-Anchor" href="#how-to-ensure-that-the-leader-of-any-given-term-contains-all-of-the-entries-committed-in-previous-terms"></a> How to ensure that the leader of any given term contains all of the entries committed in previous terms?</h3><ol><li>A candidate must contact a majority of the cluster to be elected, meaning that every committed entry must be present in at least one of those servers.</li><li>If the candidate’s log is at least as up-to-date as any others in that majority, it will hold all the committed entries.</li><li>In the <code>RequestVote</code> RPC, the voter denies voting if its log is more up-to-date than the candidate’s.</li><li>Raft determines which of the two logs is more up-to-date by comparing the index and term of the last log entries.<ul><li>If the logs have last entries with different terms, then the log with the later term is more up-to-date.</li><li>If the logs end with the same term, the longer log is more up-to-date.</li></ul></li></ol><h3 id="what-are-the-limitations-of-broadcast-time-and-election-timeout"><a class="markdownIt-Anchor" href="#what-are-the-limitations-of-broadcast-time-and-election-timeout"></a> What are the limitations of broadcast time and election timeout?</h3><ol><li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>b</mi><mi>r</mi><mi>o</mi><mi>a</mi><mi>d</mi><mi>c</mi><mi>a</mi><mi>s</mi><mi>t</mi><mi>T</mi><mi>i</mi><mi>m</mi><mi>e</mi><mo>≪</mo><mi>e</mi><mi>l</mi><mi>e</mi><mi>c</mi><mi>t</mi><mi>i</mi><mi>o</mi><mi>n</mi><mi>T</mi><mi>i</mi><mi>m</mi><mi>e</mi><mi>o</mi><mi>u</mi><mi>t</mi><mo>≪</mo><mi>M</mi><mi>T</mi><mi>B</mi><mi>F</mi></mrow><annotation encoding="application/x-tex">broadcastTime\ll electionTimeout\ll MTBF</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.73354em;vertical-align:-0.0391em;"></span><span class="mord mathnormal">b</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mord mathnormal">o</span><span class="mord mathnormal">a</span><span class="mord mathnormal">d</span><span class="mord mathnormal">c</span><span class="mord mathnormal">a</span><span class="mord mathnormal">s</span><span class="mord mathnormal">t</span><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="mord mathnormal">i</span><span class="mord mathnormal">m</span><span class="mord mathnormal">e</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">≪</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.73354em;vertical-align:-0.0391em;"></span><span class="mord mathnormal">e</span><span class="mord mathnormal" style="margin-right:0.01968em;">l</span><span class="mord mathnormal">e</span><span class="mord mathnormal">c</span><span class="mord mathnormal">t</span><span class="mord mathnormal">i</span><span class="mord mathnormal">o</span><span class="mord mathnormal">n</span><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="mord mathnormal">i</span><span class="mord mathnormal">m</span><span class="mord mathnormal">e</span><span class="mord mathnormal">o</span><span class="mord mathnormal">u</span><span class="mord mathnormal">t</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">≪</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">M</span><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="mord mathnormal" style="margin-right:0.05017em;">B</span><span class="mord mathnormal" style="margin-right:0.13889em;">F</span></span></span></span></li><li>BbroadcastTime is the average time it takes a server to send RPCs in parallel to every server in the cluster and receive their responses. <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>e</mi><mi>l</mi><mi>e</mi><mi>c</mi><mi>t</mi><mi>i</mi><mi>o</mi><mi>n</mi><mi>T</mi><mi>i</mi><mi>m</mi><mi>e</mi><mi>o</mi><mi>u</mi><mi>t</mi></mrow><annotation encoding="application/x-tex">electionTimeout</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathnormal">e</span><span class="mord mathnormal" style="margin-right:0.01968em;">l</span><span class="mord mathnormal">e</span><span class="mord mathnormal">c</span><span class="mord mathnormal">t</span><span class="mord mathnormal">i</span><span class="mord mathnormal">o</span><span class="mord mathnormal">n</span><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="mord mathnormal">i</span><span class="mord mathnormal">m</span><span class="mord mathnormal">e</span><span class="mord mathnormal">o</span><span class="mord mathnormal">u</span><span class="mord mathnormal">t</span></span></span></span> is the election timeout. MTBF is the average time between failures for a single server.</li><li>The broadcast time should be an order of magnitude less than the election timeout so leaders can reliably send the heartbeat messages required to keep followers from starting elections.</li><li>The election timeout should be a few orders of magnitude less than MTBF so that the system makes steady progress.</li></ol><h3 id="requestvote-rpc"><a class="markdownIt-Anchor" href="#requestvote-rpc"></a> RequestVote RPC</h3><ol><li>Candidates invoke this to gather votes.</li><li>Arguments:<ul><li><code>term</code>: candidate’s term</li><li><code>candidateId</code>: candidate requesting a vote</li><li><code>lastLogIndex</code>: index of candidate’s last log entry</li><li><code>lastLogTerm</code>: term of candidate’s last log entry</li></ul></li><li>Results:<ul><li><code>term</code>: currentTerm, for candidate to update itself</li><li><code>voteGranted</code>: true means the candidate received a vote</li></ul></li><li>Receiver implementation:<ul><li>Reply <code>false</code> if <code>term &lt; currentTerm</code></li><li>If votedFor is <code>null</code> or <code>candidateId</code>, and the candidate’s log is at least as up-to-date as the receiver’s log, grant vote</li></ul></li></ol><h2 id="log-replication"><a class="markdownIt-Anchor" href="#log-replication"></a> Log replication</h2><h3 id="how-are-client-requests-handled"><a class="markdownIt-Anchor" href="#how-are-client-requests-handled"></a> How are client requests handled?</h3><ol><li>Each client request contains a command to be executed by the replicated state machines.</li><li>The leader appends the command to its log as a new entry, then issues <code>AppendEntries</code> RPCs parallel to each other server to replicate the entry.</li><li>When the entry has been safely replicated, the leader applies the entry to its state machine and returns the result of that execution to the client.</li><li>Suppose followers crash or run slowly or network packets are lost. In that case, the leader retries <code>AppendEntries</code> RPCs indefinitely (even after it has responded to the client) until all followers eventually store all log entries.</li></ol><h3 id="what-is-stored-in-a-log-entry"><a class="markdownIt-Anchor" href="#what-is-stored-in-a-log-entry"></a> What is stored in a log entry?</h3><ol><li>A command for state machine</li><li>A term number when the leader received entry.</li><li>An index to identify its position in the log. The index of the first log is 1.</li></ol><h3 id="how-to-apply-a-log-entry-to-the-state-machines"><a class="markdownIt-Anchor" href="#how-to-apply-a-log-entry-to-the-state-machines"></a> How to apply a log entry to the state machines?</h3><ol><li>The leader decides when applying a log entry to the state machines is safe.<ul><li>Such an entry is called <code>committed</code>.</li><li>Raft guarantees that committed entries are durable and will eventually be executed by all available state machines.</li></ul></li><li>A log entry is committed once the leader that created the entry has replicated it on a majority of the servers.</li><li>It also commits all preceding entries in the leader’s log, including entries created by previous leaders.</li><li>The leader keeps track of the highest index it knows to be committed, and it includes that index in future <code>AppendEntries</code> RPCs, including heartbeats, so that the other servers eventually find out that they should commit some new entries.</li><li>Once a follower learns that a log entry is committed, the entry is applied to its local state machine in log order.</li></ol><h3 id="how-to-determine-the-consistency-between-logs"><a class="markdownIt-Anchor" href="#how-to-determine-the-consistency-between-logs"></a> How to determine the consistency between logs?</h3><ol><li><strong>Log Matching property</strong>: If two logs contain an entry with the same index and term, the logs are identical in all entries up through the given index.</li><li>The Log Matching property is maintained through the following properties:<ul><li>If two entries in different logs have the same index and term, they store the same command.</li><li>If two entries in different logs have the same index and term, then the logs are identical in all preceding entries.</li></ul></li></ol><h3 id="how-to-check-the-consistency-in-appendentries-rpcs"><a class="markdownIt-Anchor" href="#how-to-check-the-consistency-in-appendentries-rpcs"></a> How to check the consistency in AppendEntries RPCs?</h3><ol><li>When sending an <code>AppendEntries</code> RPC, the leader includes the index and term of the entry in its log, which immediately precedes the new entries.</li><li>If the follower does not find an entry with the same index and term in its log, it refuses the new entries.</li></ol><h3 id="what-kinds-of-inconsistency-may-incur"><a class="markdownIt-Anchor" href="#what-kinds-of-inconsistency-may-incur"></a> What kinds of inconsistency may incur?</h3><ol><li>Leader crashes can leave the logs inconsistent. The old leader may not have fully replicated all the entries in its log.</li><li>A follower may be missing entries that are present on the leader; it may have extra entries that are not present on the leader or both.</li></ol><h3 id="how-does-the-leader-handle-follower-inconsistencies"><a class="markdownIt-Anchor" href="#how-does-the-leader-handle-follower-inconsistencies"></a> How does the leader handle follower inconsistencies?</h3><ol><li><strong>Leader Append-Only</strong> property: a leader never overwrites or deletes entries in its log.</li><li>The leader handles inconsistencies by forcing the followers’ logs to duplicate its own. Namely, conflicting entries in follower logs will be overwritten with entries from the leader’s log.</li><li>The leader must find the latest log entry where the two logs agree, delete any entries in the follower’s log after that point, and send the follower all of the leader’s entries after that point.</li><li>These actions happen in response to the consistency check performed by AppendEntries RPCs.</li><li>A leader does not need to take any special actions to restore log consistency when it comes to power. It just begins normal operation, and the logs automatically converge in response to failures of the AppendEntries consistency check.</li></ol><h3 id="how-does-appendentries-rpc-perform-a-consistency-check"><a class="markdownIt-Anchor" href="#how-does-appendentries-rpc-perform-a-consistency-check"></a> How does AppendEntries RPC perform a consistency check?</h3><ol><li>The leader maintains a nextIndex for each follower. When a leader first comes to power, it initializes all nextIndex values to the index just after the last one in its log, i.e., assuming all followers are as up-to-date as itself.</li><li>If a follower’s log is inconsistent with the leader’s, the consistency check will fail in the next <code>AppendEntries</code> RPC.</li><li>After a rejection, the leader decrements nextIndex and retries the <code>AppendEntries</code> RPC.</li><li>Eventually, <code>nextIndex</code> will reach a point where the leader and follower logs match. When this happens, <code>AppendEntries</code> will succeed, removing any conflicting entries in the follower’s log and appending entries from the leader’s log (if any).</li><li>Once <code>AppendEntries</code> succeeds, the follower’s log is consistent with the leader’s, and it will remain that way for the rest of the term.</li></ol><h3 id="how-to-handle-uncommitted-entries-from-previous-leaders"><a class="markdownIt-Anchor" href="#how-to-handle-uncommitted-entries-from-previous-leaders"></a> How to handle uncommitted entries from previous leaders?</h3><ol><li>If a leader crashes before committing an entry, future leaders will attempt to finish replicating the entry.</li><li>A leader cannot immediately conclude that an entry from a previous term <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>t</mi><mi>e</mi><mi>r</mi><msub><mi>m</mi><mi>p</mi></msub></mrow><annotation encoding="application/x-tex">term_p</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.9011879999999999em;vertical-align:-0.286108em;"></span><span class="mord mathnormal">t</span><span class="mord mathnormal">e</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mord"><span class="mord mathnormal">m</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.15139200000000003em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">p</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span></span></span></span> is committed once it is stored on a majority of servers.<ul><li>There could be other entries in a <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>t</mi><mi>e</mi><mi>r</mi><msub><mi>m</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">term_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.76508em;vertical-align:-0.15em;"></span><span class="mord mathnormal">t</span><span class="mord mathnormal">e</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mord"><span class="mord mathnormal">m</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> between <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>t</mi><mi>e</mi><mi>r</mi><msub><mi>m</mi><mi>p</mi></msub></mrow><annotation encoding="application/x-tex">term_p</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.9011879999999999em;vertical-align:-0.286108em;"></span><span class="mord mathnormal">t</span><span class="mord mathnormal">e</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mord"><span class="mord mathnormal">m</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.15139200000000003em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">p</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span></span></span></span> and the leader’s current term <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>t</mi><mi>e</mi><mi>r</mi><msub><mi>m</mi><mi>c</mi></msub></mrow><annotation encoding="application/x-tex">term_c</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.76508em;vertical-align:-0.15em;"></span><span class="mord mathnormal">t</span><span class="mord mathnormal">e</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mord"><span class="mord mathnormal">m</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">c</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>.</li><li>If nothing in the leader’s current term has reached an agreement after the leader dies, that server with <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>t</mi><mi>e</mi><mi>r</mi><msub><mi>m</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">term_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.76508em;vertical-align:-0.15em;"></span><span class="mord mathnormal">t</span><span class="mord mathnormal">e</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mord"><span class="mord mathnormal">m</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> may become the new leader, and it can overwrite entries of <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>t</mi><mi>e</mi><mi>r</mi><msub><mi>m</mi><mi>p</mi></msub></mrow><annotation encoding="application/x-tex">term_p</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.9011879999999999em;vertical-align:-0.286108em;"></span><span class="mord mathnormal">t</span><span class="mord mathnormal">e</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mord"><span class="mord mathnormal">m</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.15139200000000003em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">p</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span></span></span></span> although those entries are committed since <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>t</mi><mi>e</mi><mi>r</mi><msub><mi>m</mi><mi>i</mi></msub><mo>&gt;</mo><mi>t</mi><mi>e</mi><mi>r</mi><msub><mi>m</mi><mi>p</mi></msub></mrow><annotation encoding="application/x-tex">term_i&gt;term_p</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.76508em;vertical-align:-0.15em;"></span><span class="mord mathnormal">t</span><span class="mord mathnormal">e</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mord"><span class="mord mathnormal">m</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">&gt;</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.9011879999999999em;vertical-align:-0.286108em;"></span><span class="mord mathnormal">t</span><span class="mord mathnormal">e</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mord"><span class="mord mathnormal">m</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.15139200000000003em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">p</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span></span></span></span></li></ul></li><li>Raft never commits log entries from previous terms by counting replicas.</li><li>Only log entries from the leader’s current term are committed by counting replicas; once an entry from the current term has been committed, all prior entries are committed indirectly because of the Log Matching Property.</li></ol><h3 id="appendentries-rpc"><a class="markdownIt-Anchor" href="#appendentries-rpc"></a> AppendEntries RPC</h3><ol><li>Leader invokes this to replicate log entries; also used as heartbeat.</li><li>Arguments:<ul><li><code>term</code>: leader’s term</li><li><code>leaderId</code>: so follower can redirect clients</li><li><code>prevLogIndex</code>: index of log entry immediately preceding new ones.</li><li><code>prevLogTerm</code>: term of <code>prevLogIndex</code> entry</li><li><code>entries[]</code>: log entries to store (empty for hearbeat; may send more than one for efficiency)</li><li><code>leaderCommit</code>: leader’s <code>commitIndex</code></li></ul></li><li>Results:<ul><li><code>term</code>: <code>currentTerm</code>, for the leader to update itself</li><li><code>success</code>: true if the follower contained an entry matching <code>prevLogIndex</code> and <code>prevLogTerm</code></li></ul></li><li>Receiver implementation:<ul><li>Reply <code>false</code> if <code>term &lt; currentTerm</code></li><li>Reply <code>false</code> if log doesn’t contain an entry at <code>prevLogIndex</code> whose term matches <code>prevLogTerm</code></li><li>If an existing entry conflicts with a new one (same index but different terms), delete the existing entry and all that follow it.</li><li>Append any new entries that are not already in the log.</li><li>If <code>leaderCommit &gt; commitIndex</code>, set <code>commitIndex = min(leaderCommit, index of last new entry)</code>.</li></ul></li></ol><h2 id="log-compaction"><a class="markdownIt-Anchor" href="#log-compaction"></a> Log compaction</h2><h3 id="how-does-raft-compact-logs"><a class="markdownIt-Anchor" href="#how-does-raft-compact-logs"></a> How does Raft compact logs?</h3><ol><li>In snapshotting, the entire current system state is written to a snapshot on stable storage.</li><li>Once a server completes writing a snapshot, it may delete all log entries up through the last included index and any prior snapshot.</li><li>Each server takes snapshots independently, covering just the committed entries in its log.</li><li>Data still only flows from leaders to followers; followers can now reorganize their data.</li></ol><h3 id="how-to-handle-the-appendentries-that-require-compated-entries"><a class="markdownIt-Anchor" href="#how-to-handle-the-appendentries-that-require-compated-entries"></a> How to handle the AppendEntries that require compated entries?</h3><ol><li>Raft also includes a small amount of metadata in the snapshot.<ul><li>The <code>last included index</code> is the index of the last entry in the log that the snapshot replaces (the last entry the state machine had applied).</li><li>The <code>last included term</code> is the term of this entry.</li></ul></li><li>When the leader has already discarded the next log entry that it needs to send to a follower.</li><li>This situation is unlikely in normal operation: a follower that has kept up with the leader would already have this entry. However, an exceptionally slow follower or a new server joining the cluster would not.</li></ol><h3 id="how-to-install-the-snapshot-from-the-leader"><a class="markdownIt-Anchor" href="#how-to-install-the-snapshot-from-the-leader"></a> How to install the snapshot from the leader?</h3><ol><li>The leader uses a new RPC called <code>InstallSnapshot</code> to send snapshots to followers that are too far behind.</li><li>When a follower receives a snapshot with this RPC, it must decide what to do with its existing log entries.</li><li>If the snapshot contains new information not already in the recipient’s log<ul><li>The follower discards the entire log.</li><li>It is all superseded by the snapshot and may have uncommitted entries that conflict with the snapshot.</li></ul></li><li>If, instead, the follower receives a snapshot that describes a prefix of its log<ul><li>This could be due to retransmission or by mistake.</li><li>Log entries covered by the snapshot have been deleted, but entries following the snapshot are still valid and must be retained.</li></ul></li></ol><h3 id="when-should-a-server-take-a-snapshot"><a class="markdownIt-Anchor" href="#when-should-a-server-take-a-snapshot"></a> When should a server take a snapshot?</h3><ol><li>If a server snapshots too often, it wastes disk bandwidth and energy; if it snapshots too infrequently, it risks exhausting its storage capacity, increasing the time required to replay the log during restarts.</li><li>A straightforward strategy is to take a snapshot when the log reaches a fixed size in bytes.</li><li>If this size is significantly larger than a snapshot’s expected size, then the disk bandwidth overhead for snapshotting will be small.</li></ol><h3 id="how-can-the-delays-of-normal-operations-caused-by-a-snapshot-be-reduced"><a class="markdownIt-Anchor" href="#how-can-the-delays-of-normal-operations-caused-by-a-snapshot-be-reduced"></a> How can the delays of normal operations caused by a snapshot be reduced?</h3><ol><li>The solution is to use copy-on-write techniques to accept new updates without impacting the snapshot being written.</li><li>The operating system’s copy-on-write support (e.g., fork on Linux) can create an in-memory snapshot of the entire state machine.</li></ol><h3 id="installsnapshot-rpc"><a class="markdownIt-Anchor" href="#installsnapshot-rpc"></a> InstallSnapshot RPC</h3><ol><li>The leader invokes this to send chunks of snapshot to a follower. Leaders always send chunks in order.</li><li>Arguments:<ul><li><code>term</code>: leader’s term</li><li><code>leaderId</code>: so follower can redirect clients</li><li><code>lastIncludedIndex</code>: the snapshot replaces all entries up through and including this index</li><li><code>lastIncludedTerm</code>: term of <code>lastIncludedIndex</code></li><li><code>offset</code>: byte offset where the chunk is positioned in the snapshot file<ul><li>The whole snapshot file may be large and hence divided into several chunks.</li></ul></li><li><code>data[]</code>: raw bytes of the snapshot chunk, starting at offset</li><li><code>done</code>: <code>true</code> if this is the last chunk</li></ul></li><li>Results:<ul><li><code>term</code>: <code>currentTerm</code>, for the leader to update itself</li></ul></li><li>Receiver implementation:<ul><li>Reply immediately if <code>term &lt; currentTerm</code></li><li>Create a new snapshot file if the first chunk (offset is 0)</li><li>Write data into a snapshot file at the given offset.</li><li>Reply and wait for more data chunks if done is <code>false</code>.</li><li>Save the snapshot file, and discard any existing or partial snapshots with a smaller index.</li><li>If the existing log entry has the same index and term as the snapshot’s last included entry, retain log entries following it and reply</li><li>Discard the entire log.</li><li>Reset state machine using snapshot contents (and load snapshot’s cluster configuration)</li></ul></li></ol><h2 id="client-interaction"><a class="markdownIt-Anchor" href="#client-interaction"></a> Client interaction</h2><h3 id="how-does-the-client-find-the-cluster-leader"><a class="markdownIt-Anchor" href="#how-does-the-client-find-the-cluster-leader"></a> How does the client find the cluster leader?</h3><ol><li>When a client first starts up<ul><li>It connects to a randomly chosen server.</li><li>If the client’s first choice is not the leader, that server will reject the request and supply information about the most recent leader it has heard from.</li></ul></li><li>If the leader crashes<ul><li>Client requests will time out.</li><li>Clients then try again with randomly chosen servers.</li></ul></li></ol><h3 id="how-to-prevent-raft-from-executing-a-command-multiple-times"><a class="markdownIt-Anchor" href="#how-to-prevent-raft-from-executing-a-command-multiple-times"></a> How to prevent Raft from executing a command multiple times?</h3><ol><li>Our goal for Raft is to implement linearizable semantics, i.e., each operation appears to execute instantaneously, exactly once, at some point between its invocation and its response.<ul><li>One case of executing a command multiple times is if the leader crashes after committing the log entry but before responding to the client; the client will retry the command with a new leader, causing it to be executed a second time.</li></ul></li><li>The solution is for clients to assign unique serial numbers to every command.</li><li>Then, the state machine tracks the latest serial number processed for each client and the associated response.</li><li>If it receives a command with a serial number already executed, it responds immediately without re-executing the request.</li></ol><h3 id="how-to-prevent-returning-stale-data-to-a-read-only-operation"><a class="markdownIt-Anchor" href="#how-to-prevent-returning-stale-data-to-a-read-only-operation"></a> How to prevent returning stale data to a read-only operation?</h3><ol><li>The stale reading is because the leader responding to the request might have been superseded by a newer leader of which it is unaware.</li><li>A leader must have the latest information on which entries are committed.<ul><li>The Leader Completeness Property guarantees that a leader has all committed entries, but at the start of its term, it may not know which those are.</li><li>To find out, it needs to commit an entry from its term.</li><li>Raft handles this by having each leader commit a blank <em>no-op</em> entry into the log at the start of its term.</li></ul></li><li>A leader must check whether it has been deposed before processing a read-only request since its information may be stale if a more recent leader has been elected).<ul><li>Raft handles this by having the leader exchange heartbeat messages with a majority of the cluster before responding to read-only requests.</li><li>Alternatively, the leader could rely on the heartbeat mechanism to provide a lease, but this would rely on timing for safety (it assumes bounded clock skew).</li></ul></li></ol><h1 id="experiments-and-results"><a class="markdownIt-Anchor" href="#experiments-and-results"></a> Experiments and results</h1><ol><li>The main goal of Raft is to propose a consensus algorithm that is easier to understand than Paxos. Hence, the author measured this model’s understandability through learning student scores.</li><li>The most critical measure of a new system is its correctness. The author proved Raft’s correctness with formal specifications.</li><li>Finally, the author also measured the performance of Raft, which is similar to other consensus algorithms.</li><li>The election timeout will affect the system’s performance through the performance of the leader election. Hence, the author measured how the randomization and base election timeout would affect the performance.<ul><li>A small randomization in the election timeout is enough to avoid split votes. Using more randomness improves worst-case behavior.</li><li>Downtime can be reduced by reducing the election timeout.<ul><li>However, lowering the timeouts beyond 12 - 14 ms violates Raft’s timing requirement: leaders have difficulty broadcasting heartbeats before other servers start new elections. This can cause unnecessary leader changes and lower overall system availability.</li><li>The author recommends using a conservative election timeout such as 150–300ms; such timeouts are unlikely to cause unnecessary leader changes and will still provide good availability.</li></ul></li><li><img src="/imgs/Distributed/Raft/02.png" style="zoom:33%;" /></li></ul></li></ol><h1 id="reproduce-and-unmentioned-parts"><a class="markdownIt-Anchor" href="#reproduce-and-unmentioned-parts"></a> Reproduce and unmentioned parts</h1><p>Reference to Labs 2, 3, and 4 of MIT 6.824.</p>]]></content>
      
      
      <categories>
          
          <category> Paper Notebook </category>
          
          <category> Distributed System </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Distributed System </tag>
            
            <tag> Distributed Storage </tag>
            
            <tag> Consensus Algorithm </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Fault Tolerance VM</title>
      <link href="/2023/09/26/Paper/Distributed/Fault-Tolerance-VM/"/>
      <url>/2023/09/26/Paper/Distributed/Fault-Tolerance-VM/</url>
      
        <content type="html"><![CDATA[<p>Paper: <a href="http://nil.csail.mit.edu/6.824/2020/papers/vm-ft.pdf">The Design of a Practical System for Fault-Tolerance Virtual Machines</a></p><p><ul class="markdownIt-TOC"><li><a href="#purpose">Purpose</a></li><li><a href="#model">Model</a><ul><li><a href="#ft-design">FT design</a><ul><li><a href="#primary-backup-structure">Primary-backup structure</a><ul><li><a href="#what-is-the-usual-way-to-implement-fault-tolerance-via-a-primarybackup-approach">What is the usual way to implement fault tolerance via a primary/backup approach?</a></li><li><a href="#what-is-the-difference-between-physical-servers-and-vms-at-the-state-machine-level">What is the difference between physical servers and VMs at the state machine level?</a></li><li><a href="#what-is-the-basic-structure-of-ft-vms">What is the basic structure of FT VMs?</a></li></ul></li><li><a href="#ft-protocol">FT protocol</a><ul><li><a href="#how-does-vmware-backup-vm-replay">How does VMware backup VM replay?</a></li><li><a href="#what-if-the-backup-vm-executes-in-a-way-different-from-the-primary-vm">What if the backup VM executes in a way different from the primary VM?</a></li><li><a href="#will-the-output-rule-affect-the-vm-eg-stop-its-execution">Will the Output Rule affect the VM, e.g., stop its execution?</a></li><li><a href="#what-are-the-subtleties-of-executing-disk-reads-on-the-backup-vm">What are the subtleties of executing disk reads on the backup VM?</a></li></ul></li><li><a href="#detecting-and-responding-to-failure">Detecting and responding to failure</a><ul><li><a href="#how-to-handle-duplicate-outputs">How to handle duplicate outputs?</a></li><li><a href="#how-to-handle-backup-vm-failure">How to handle backup VM failure?</a></li><li><a href="#how-to-handle-primary-vm-failure">How to handle primary VM failure?</a></li><li><a href="#after-a-failover-how-will-the-new-primary-vm-communicate-with-the-external-world">After a failover, how will the new primary VM communicate with the external world?</a></li><li><a href="#how-to-detect-failure-of-primary-or-backup-vms">How to detect failure of primary or backup VMs?</a></li><li><a href="#how-to-avoid-split-brain-problems">How to avoid split-brain problems?</a></li></ul></li><li><a href="#alternative-non-shared-disk">Alternative: Non-shared disk</a><ul><li><a href="#what-is-the-difference-between-non-shared-disks-and-shared-disks">What is the difference between non-shared disks and shared disks?</a></li><li><a href="#in-what-case-will-a-non-shared-disk-be-useful">In what case will a non-shared disk be useful?</a></li><li><a href="#what-is-the-disadvantage-of-non-shared-disks">What is the disadvantage of non-shared disks?</a></li><li><a href="#how-to-solve-the-split-brain-situation">How to solve the split-brain situation?</a></li></ul></li></ul></li><li><a href="#implementation">Implementation</a><ul><li><a href="#starting-and-restarting">Starting and restarting</a><ul><li><a href="#what-requirements-need-to-be-satisfied-by-the-startup-mechanism">What requirements need to be satisfied by the startup mechanism?</a></li><li><a href="#how-to-implement-the-startup-mechanism">How to implement the startup mechanism?</a></li><li><a href="#how-to-choose-a-server-on-which-to-run-the-backup-vm">How to choose a server on which to run the backup VM?</a></li></ul></li><li><a href="#logging-channel">Logging channel</a><ul><li><a href="#how-to-control-primary-sending-log-entries-and-backup-receiving-entries">How to control primary sending log entries and backup receiving entries?</a></li><li><a href="#what-if-the-primary-log-buffer-is-full">What if the primary log buffer is full?</a></li><li><a href="#what-is-the-main-cause-of-the-buffer-of-primary-being-full">What is the main cause of the buffer of primary being full?</a></li><li><a href="#how-to-prevent-the-backup-vm-from-getting-too-far-behind-the-primary">How to prevent the backup VM from getting too far behind the primary?</a></li></ul></li><li><a href="#special-operations">Special operations</a><ul><li><a href="#how-to-deal-with-control-operations">How to deal with control operations?</a></li><li><a href="#how-to-implement-the-vmotion-for-primary-and-backup-vms">How to implement the VMotion for primary and backup VMs?</a></li></ul></li><li><a href="#issues-for-disk-ios">Issues for disk IOs</a><ul><li><a href="#how-many-kinds-of-races-may-occur">How many kinds of races may occur?</a></li><li><a href="#how-to-solve-the-non-determinism-caused-by-several-io-operations">How to solve the non-determinism caused by several IO operations?</a></li><li><a href="#how-to-solve-the-non-determinism-caused-by-io-operations-and-applicationos">How to solve the non-determinism caused by IO operations and application/OS?</a></li><li><a href="#how-does-the-newly-promoted-primary-vm-handle-those-outstanding-ios">How does the newly-promoted primary VM handle those outstanding IOs?</a></li></ul></li><li><a href="#issues-for-network-io">Issues for network IO</a><ul><li><a href="#how-to-solve-the-non-determinism-caused-by-asynchronous-updates">How to solve the non-determinism caused by asynchronous updates?</a></li><li><a href="#how-can-we-optimize-the-network-performance-while-running-ft">How can we optimize the network performance while running FT?</a></li></ul></li></ul></li></ul></li><li><a href="#experiments-and-results">Experiments and results</a></li></ul></p><h1 id="purpose"><a class="markdownIt-Anchor" href="#purpose"></a> Purpose</h1><ol><li>Contribution<ul><li>This paper implemented a system providing fault tolerance virtual machine (VM) based on replicating the execution of a primary VM vis a backup VM on another server. The system automatically restores redundancy after failure.</li><li>It reduces the performance of real applications by less than 10%. The data bandwidth needed to keep the primary and secondary VM executing in lockstep is less than 20 Mb/s for several real applications, which allows for implementing fault tolerance over a longer distance.</li><li>The system automatically restores redundancy after a failure by starting a new backup virtual machine on any available server in the local cluster.</li></ul></li><li>Limitation<ul><li>Only support uni-processor VMs. Recording and replaying the execution of a multi-processor VM have significant performance issues because nearly every access to shared memory can be a non-deterministic operation.</li><li>Only attempt to deal with fail-stop failure, which are server failures that can be detected before the failing server causes an incorrect externally visible action.</li></ul></li><li>Challenges<ul><li>Correctly capturing all the input and non-determinism necessary to ensure deterministic execution of a backup virtual machine.</li><li>Correctly applying the inputs and non-determinism to the backup virtual machine.</li><li>Doing so in a manner that doesn’t degrade performance.</li></ul></li></ol><h1 id="model"><a class="markdownIt-Anchor" href="#model"></a> Model</h1><h2 id="ft-design"><a class="markdownIt-Anchor" href="#ft-design"></a> FT design</h2><h3 id="primary-backup-structure"><a class="markdownIt-Anchor" href="#primary-backup-structure"></a> Primary-backup structure</h3><h4 id="what-is-the-usual-way-to-implement-fault-tolerance-via-a-primarybackup-approach"><a class="markdownIt-Anchor" href="#what-is-the-usual-way-to-implement-fault-tolerance-via-a-primarybackup-approach"></a> What is the usual way to implement fault tolerance via a primary/backup approach?</h4><ol><li><p>The backup server can always take over if the primary server fails.</p><ul><li>The problem is that the state of the backup server must be kept nearly identical to the primary server at all times. We say that the two VMs are in virtual lock-step.</li></ul></li><li><p>One way is to ship changes to all states of the primary. The bandwidth needed to send can be very large.</p></li><li><p>Another method is the state-machine approach.</p><ul><li><p>The idea is to model the servers as deterministic state machines that are kept in sync by starting them from the same initial state and ensuring that they receive the same input requests in the same order.</p></li><li><p>Some operations are not deterministic. Extra coordination must be used to ensure that they receive a primary and backup are kept in sync.</p></li><li><p>The extra information is far less than the state (mainly memory updates) changing in the primary.</p></li></ul></li></ol><h4 id="what-is-the-difference-between-physical-servers-and-vms-at-the-state-machine-level"><a class="markdownIt-Anchor" href="#what-is-the-difference-between-physical-servers-and-vms-at-the-state-machine-level"></a> What is the difference between physical servers and VMs at the state machine level?</h4><ol><li><p>Implementing coordination to ensure deterministic execution of physical servers is challenging, particularly as processor frequencies increase.</p></li><li><p>VM running on a hypervisor can be considered a well-defined state machine.</p></li><li><p>VMs still have non-deterministic operations. The hypervisor can capture all the necessary information about non-deterministic operations on the primary VM and replay these operations correctly on the backup VM.</p></li></ol><h4 id="what-is-the-basic-structure-of-ft-vms"><a class="markdownIt-Anchor" href="#what-is-the-basic-structure-of-ft-vms"></a> What is the basic structure of FT VMs?</h4><ol><li><p>The virtual disks for the VMs are on shared storage and accessible to the primary and backup VM for input and output.</p></li><li><p>Only the primary VM advertises its presence on the network, so all network inputs come to the primary VM. So do all other inputs.</p></li><li><p>All inputs, including incoming network packets, disk reads, keyboard, and mouse, only come to the primary VM. The primary VM sends all inputs it receives to the backup VM via a network connection known as the logging channel.</p><img src="/imgs/Distributed/FTVM/01.png" style="zoom:33%;" /></li></ol><h3 id="ft-protocol"><a class="markdownIt-Anchor" href="#ft-protocol"></a> FT protocol</h3><h4 id="how-does-vmware-backup-vm-replay"><a class="markdownIt-Anchor" href="#how-does-vmware-backup-vm-replay"></a> How does VMware backup VM replay?</h4><ol><li>VMware deterministic replay records the inputs of a VM and all possible non-determinism associated with the VM execution in a stream of log entries written to a log file.</li><li>For non-deterministic operations, sufficient information is logged to allow the operation to be reproduced with the same state change and output.</li><li>The exact instruction at which the event occurred is also recorded for non-deterministic events such as timer or IO completion interrupts. The event is delivered at the same point in the instruction stream during replay.</li><li>VMware deterministic replay does not need to use epochs where non-deterministic events are only delivered at the end. Each interrupt is recorded as it occurs and efficiently delivered with the appropriate instruction while being replayed.</li><li>Instead of writing the log entries to disk, we send them to the backup VM via the logging channel. The backup VM replays the entries in real-time.</li></ol><h4 id="what-if-the-backup-vm-executes-in-a-way-different-from-the-primary-vm"><a class="markdownIt-Anchor" href="#what-if-the-backup-vm-executes-in-a-way-different-from-the-primary-vm"></a> What if the backup VM executes in a way different from the primary VM?</h4><ol><li><p>The <em>Output Requirement</em>: if the backup VM ever takes over after a primary failure, the backup VM will continue executing in a way that is entirely consistent with all outputs that the primary VM has sent to the external world.</p></li><li><p>The Output Requirement can be ensured by</p><ul><li><p>Delaying any external output (typically a network packet) until the backup VM has received all information will allow it to replay execution at least to the point of that output operation.</p></li><li><p>One necessary condition is that the backup VM must have received all log entries generated before the output operation.</p></li></ul></li><li><p>Suppose we create a special log entry at each output operation. Then, the Output Requirement may be enforced by the Output Rule.</p><ul><li><em>Output Rule</em>: the primary VM may not send an output to the external world until the backup VM has received and acknowledged the log entry associated with the operation producing the output.</li></ul></li></ol><h4 id="will-the-output-rule-affect-the-vm-eg-stop-its-execution"><a class="markdownIt-Anchor" href="#will-the-output-rule-affect-the-vm-eg-stop-its-execution"></a> Will the Output Rule affect the VM, e.g., stop its execution?</h4><ol><li>It does not say anything about stopping the execution of the primary VM. We need only delay the sending of the output, but the VM itself can continue execution.</li><li>Since operating systems do non-blocking network and disk outputs with asynchronous interrupts to indicate completion, the VM can easily continue execution and will not necessarily be immediately affected by the delay in the output.</li></ol><h4 id="what-are-the-subtleties-of-executing-disk-reads-on-the-backup-vm"><a class="markdownIt-Anchor" href="#what-are-the-subtleties-of-executing-disk-reads-on-the-backup-vm"></a> What are the subtleties of executing disk reads on the backup VM?</h4><ol><li><p>By default, the primary VM will send the results of the disk read to the backup VM via the logging channel.</p></li><li><p>Executing disk reads on the backup VM can greatly reduce the traffic on the logging channel for workloads that do a lot of disk reads. It may also slow down the backup VM’s execution.</p></li><li><p>Some extra work must be done to deal with failed disk read operations.</p><ul><li><p>If the primary succeeds while the backup fails, the backup must keep retrying until success.</p></li><li><p>Suppose the backup succeeds while the primary fails. In that case, the contents of the target memory must be sent to the backup via the logging channel since the contents of the memory will be undetermined and not necessarily replicated by a successful disk read by the backup VM.</p></li></ul></li><li><p>If the primary VM does a read to a particular disk location, followed pretty soon by a write to the exact disk location, then the disk write must be delayed until the backup VM has executed the first disk read.</p></li></ol><h3 id="detecting-and-responding-to-failure"><a class="markdownIt-Anchor" href="#detecting-and-responding-to-failure"></a> Detecting and responding to failure</h3><h4 id="how-to-handle-duplicate-outputs"><a class="markdownIt-Anchor" href="#how-to-handle-duplicate-outputs"></a> How to handle duplicate outputs?</h4><ol><li>We cannot guarantee that all outputs are produced exactly once in a failover situation.</li><li>The network infrastructure (e.g., TCP) is designed to deal with lost packets and duplicate packets.</li></ol><h4 id="how-to-handle-backup-vm-failure"><a class="markdownIt-Anchor" href="#how-to-handle-backup-vm-failure"></a> How to handle backup VM failure?</h4><p>The primary VM will go live, i.e., leave recording mode, stop sending entries on the logging channel, and start executing normally.</p><h4 id="how-to-handle-primary-vm-failure"><a class="markdownIt-Anchor" href="#how-to-handle-primary-vm-failure"></a> How to handle primary VM failure?</h4><ol><li>The backup VM will continue replaying its execution from the log entries until it has consumed the last log entry.</li><li>The backup VM will stop replaying mode and execute as a regular VM. The backup VM has been promoted to the primary VM and is now missing a backup VM.</li></ol><h4 id="after-a-failover-how-will-the-new-primary-vm-communicate-with-the-external-world"><a class="markdownIt-Anchor" href="#after-a-failover-how-will-the-new-primary-vm-communicate-with-the-external-world"></a> After a failover, how will the new primary VM communicate with the external world?</h4><ol><li>VMware FT automatically advertises the MAC address of the new primary VM on the network so that physical network switches will know on what server that new primary VM is located.</li><li>The newly promoted primary VM may need to reissue some disk IOs.</li></ol><h4 id="how-to-detect-failure-of-primary-or-backup-vms"><a class="markdownIt-Anchor" href="#how-to-detect-failure-of-primary-or-backup-vms"></a> How to detect failure of primary or backup VMs?</h4><ol><li>VMware FT uses UDP heartbeating between servers running fault-tolerant VMs to detect when a server may have crashed.</li><li>In addition, VMware FT monitors the logging traffic sent from the primary to the backup VM and the acknowledgments sent from the backup VM to the primary VM. Because of regular timer interrupts, the logging traffic should be regular and never stop for a functioning guest OS.</li></ol><h4 id="how-to-avoid-split-brain-problems"><a class="markdownIt-Anchor" href="#how-to-avoid-split-brain-problems"></a> How to avoid split-brain problems?</h4><ol><li>When a primary or backup VM wants to go live, it executes an atomic test-and-set operation on the shared virtual disk.</li><li>If the operation succeeds, the VM is allowed to go live.</li><li>If the operation fails, the other VM must have already gone live, so the current VM halts itself (“commits suicide”).</li></ol><h3 id="alternative-non-shared-disk"><a class="markdownIt-Anchor" href="#alternative-non-shared-disk"></a> Alternative: Non-shared disk</h3><h4 id="what-is-the-difference-between-non-shared-disks-and-shared-disks"><a class="markdownIt-Anchor" href="#what-is-the-difference-between-non-shared-disks-and-shared-disks"></a> What is the difference between non-shared disks and shared disks?</h4><ol><li>In a shared disk, any write to the shared disk is considered a communication to the external world. Writes to the shared disk must be delayed.</li><li>In non-shared disks, the virtual disks are essentially considered part of the internal state of each VM. Disk writes of the primary do not have to be delayed according to the Output Rule.</li></ol><h4 id="in-what-case-will-a-non-shared-disk-be-useful"><a class="markdownIt-Anchor" href="#in-what-case-will-a-non-shared-disk-be-useful"></a> In what case will a non-shared disk be useful?</h4><ol><li>Shared storage is not accessible to the primary and backup VMs.</li><li>This may be because shared storage is unavailable, too expensive, or because the servers running the primary and backup VMs are far apart.</li></ol><h4 id="what-is-the-disadvantage-of-non-shared-disks"><a class="markdownIt-Anchor" href="#what-is-the-disadvantage-of-non-shared-disks"></a> What is the disadvantage of non-shared disks?</h4><ol><li>The two copies of the virtual disks must be explicitly synced up in some manner when fault tolerance is first enabled.</li><li>The disks can get out of sync after a failure, so they must be explicitly resynced when the backup VM is restarted after a failure.</li></ol><h4 id="how-to-solve-the-split-brain-situation"><a class="markdownIt-Anchor" href="#how-to-solve-the-split-brain-situation"></a> How to solve the split-brain situation?</h4><ol><li><p>There may be no shared storage to use for dealing with it. The system could use some other external tiebreaker.</p><ul><li>A third-party server that both servers can talk to.</li></ul></li><li><p>If the servers are part of a cluster with more than two nodes, the system could use a majority algorithm alternatively.</p><ul><li>A VM would only be allowed to go live if it runs on a server that is part of a communication sub-cluster containing most of the original nodes.</li></ul></li></ol><h2 id="implementation"><a class="markdownIt-Anchor" href="#implementation"></a> Implementation</h2><h3 id="starting-and-restarting"><a class="markdownIt-Anchor" href="#starting-and-restarting"></a> Starting and restarting</h3><h4 id="what-requirements-need-to-be-satisfied-by-the-startup-mechanism"><a class="markdownIt-Anchor" href="#what-requirements-need-to-be-satisfied-by-the-startup-mechanism"></a> What requirements need to be satisfied by the startup mechanism?</h4><ol><li>We also want to use it to restart a backup VM after a failure. Hence, this mechanism must be usable for a running primary VM in an arbitrary state.</li><li>We prefer that the mechanism does not significantly disrupt the execution of the primary VM.</li></ol><h4 id="how-to-implement-the-startup-mechanism"><a class="markdownIt-Anchor" href="#how-to-implement-the-startup-mechanism"></a> How to implement the startup mechanism?</h4><ol><li>VMware FT adapted a modified VMware VMotion that allows the migration of a running VM from one server to another with minimal disruption. However, after migration, the VMotion will destroy the local VM.</li><li>The FT VMotion clones a VM to a remote host rather than migrating it without destroying the local VM.</li><li>The FT VMotion also sets up a logging channel and causes the source VM to enter logging mode as the primary and the destination VM to enter replay mode as the new backup.</li></ol><h4 id="how-to-choose-a-server-on-which-to-run-the-backup-vm"><a class="markdownIt-Anchor" href="#how-to-choose-a-server-on-which-to-run-the-backup-vm"></a> How to choose a server on which to run the backup VM?</h4><ol><li>The primary VM informs the clustering service that it needs a new backup.</li><li>The clustering service determines the best server to run the backup VM based on resource usage and other constraints and invokes an FT VMotion to create the new backup VM.</li><li>VMware FT typically can re-establish VM redundancy within minutes of a server failure, all without any noticeable interruption in executing a fault-tolerant VM.</li></ol><h3 id="logging-channel"><a class="markdownIt-Anchor" href="#logging-channel"></a> Logging channel</h3><h4 id="how-to-control-primary-sending-log-entries-and-backup-receiving-entries"><a class="markdownIt-Anchor" href="#how-to-control-primary-sending-log-entries-and-backup-receiving-entries"></a> How to control primary sending log entries and backup receiving entries?</h4><ol><li>The hypervisors maintain a large buffer for logging entries for the primary and backup VMs.</li><li>The contents of the primary’s log buffer are flushed out to the logging channel as soon as possible, and log entries are read into the backup’s log buffer from the logging channel as soon as they arrive.</li><li>The backup sends acknowledgments back to the primary each time that it reads some log entries from the network into its log buffer.</li></ol><h4 id="what-if-the-primary-log-buffer-is-full"><a class="markdownIt-Anchor" href="#what-if-the-primary-log-buffer-is-full"></a> What if the primary log buffer is full?</h4><ol><li>It must stop execution until log entries can be flushed out.</li><li>This stop in execution is a natural flow-control mechanism that slows down the primary VM when it produces log entries at a rate that is too fast.</li><li>This pause can affect VM clients, and we must minimize the possibility that the primary log buffer fills up.</li></ol><h4 id="what-is-the-main-cause-of-the-buffer-of-primary-being-full"><a class="markdownIt-Anchor" href="#what-is-the-main-cause-of-the-buffer-of-primary-being-full"></a> What is the main cause of the buffer of primary being full?</h4><ol><li>One of the biggest reasons is that the backup VM is executing too slowly and consuming log entries too slowly.</li><li>In general, the backup VM must be able to replay an execution at roughly the same speed as the primary VM recording the execution.</li><li>The overhead of recording and replaying in VMware deterministic replay is roughly the same.</li><li>Suppose the server hosting the backup VM is heavily loaded with other VMs (and hence overcommitted on resources). In that case, the backup VM may not get enough CPU and memory resources to execute as fast as the primary VM.</li></ol><h4 id="how-to-prevent-the-backup-vm-from-getting-too-far-behind-the-primary"><a class="markdownIt-Anchor" href="#how-to-prevent-the-backup-vm-from-getting-too-far-behind-the-primary"></a> How to prevent the backup VM from getting too far behind the primary?</h4><ol><li>When sending acknowledgments, we also send additional information to determine the real-time execution lag between the primary and backup VMs.</li><li>Typically, the execution lag is less than 100 milliseconds.</li><li>If the backup VM starts having a significant execution lag (e.g., more than 1 second), VMware FT starts slowing down the primary VM by informing the scheduler to give it a slightly small amount of CPU.</li><li>Such slowdowns are rare and typically happen only when the system is under extreme stress.</li></ol><h3 id="special-operations"><a class="markdownIt-Anchor" href="#special-operations"></a> Special operations</h3><h4 id="how-to-deal-with-control-operations"><a class="markdownIt-Anchor" href="#how-to-deal-with-control-operations"></a> How to deal with control operations?</h4><ol><li><p>Most control operations should be applied to both machines.</p><ul><li><p>If the primary VM is explicitly powered off, the backup VM should also be stopped and not attempted to go live.</p></li><li><p>Any resource management change on the primary should be applied to the backup.</p></li></ul></li><li><p>VMotion is the only operation that can be done independently on the primary and backup VMs.</p><ul><li><p>The primary and backup VMs can be VMotioned independently to other hosts.</p></li><li><p>VMware FT ensures that neither VM is moved to the server where the other VM is.</p></li></ul></li></ol><h4 id="how-to-implement-the-vmotion-for-primary-and-backup-vms"><a class="markdownIt-Anchor" href="#how-to-implement-the-vmotion-for-primary-and-backup-vms"></a> How to implement the VMotion for primary and backup VMs?</h4><ol><li><p>A normal VMotion requires that all outstanding disk IOs be quiesced just as the final switchover on the VMotion occurs.</p></li><li><p>For a primary VM,</p><ul><li><p>The quiescing is easily handled by waiting until the physical IOs are complete and delivering these completions to the VM.</p></li><li><p>The backup VM must disconnect from the source primary and re-connect to the destination primary at the appropriate time.</p></li></ul></li><li><p>For a backup VM,</p><ul><li><p>There is no easy way to cause all IOs to be completed at any required point since the backup VM must replay the primary VM’s execution and complete IOs at the same execution point.</p></li><li><p>When a backup VM is at the final switchover point for a VMotion, it requests via the logging channel that the primary VM temporarily quiesce all its IOs.</p></li></ul></li></ol><h3 id="issues-for-disk-ios"><a class="markdownIt-Anchor" href="#issues-for-disk-ios"></a> Issues for disk IOs</h3><h4 id="how-many-kinds-of-races-may-occur"><a class="markdownIt-Anchor" href="#how-many-kinds-of-races-may-occur"></a> How many kinds of races may occur?</h4><ol><li><p>The first kind is caused by several IO operations.</p><ul><li><p>One reason is that disk operations are non-blocking and can execute in parallel. Simultaneous disk operations access the same disk location, causing races.</p></li><li><p>The other reason is that DMA is directly to/from the VM’s memory. Simultaneous disk operations access the same memory pages.</p></li></ul></li><li><p>The second kind is caused by IO operations and non-IO operations.</p><ul><li>The disk operations directly access the memory of a VM via DMA. Hence, a disk operation accesses the same memory pages as an application or OS in a VM, causing races.</li></ul></li></ol><h4 id="how-to-solve-the-non-determinism-caused-by-several-io-operations"><a class="markdownIt-Anchor" href="#how-to-solve-the-non-determinism-caused-by-several-io-operations"></a> How to solve the non-determinism caused by several IO operations?</h4><p>We should detect any such IO races and force such racing disk operations to execute sequentially in the same way on the primary and backup.</p><h4 id="how-to-solve-the-non-determinism-caused-by-io-operations-and-applicationos"><a class="markdownIt-Anchor" href="#how-to-solve-the-non-determinism-caused-by-io-operations-and-applicationos"></a> How to solve the non-determinism caused by IO operations and application/OS?</h4><ol><li><p>We need to temporarily set up page protection on pages that are targets of disk operations.</p></li><li><p>The page protections result in a trap if the VM happens to access a page that is also the target of an outstanding disk operation, and the VM can be paused until the disk operation completes.</p></li><li><p>Changing MMU protections on pages is expensive; we use bounce buffers.</p><ul><li><p>A bounce buffer is a temporary buffer that is the same size as the memory accessed by a disk operation.</p></li><li><p>A disk read operation is modified to read the specified data to the bounce buffer, and the data is copied to guest memory only as the IO completion is delivered.</p></li><li><p>For a disk write operation, the data to be sent is first copied to the bounce buffer, and the disk write is modified to write data from the bounce buffer.</p></li></ul></li><li><p>The bounce buffer can slow down disk operations, but a noticeable performance loss is not seen.</p></li></ol><h4 id="how-does-the-newly-promoted-primary-vm-handle-those-outstanding-ios"><a class="markdownIt-Anchor" href="#how-does-the-newly-promoted-primary-vm-handle-those-outstanding-ios"></a> How does the newly-promoted primary VM handle those outstanding IOs?</h4><ol><li>There is no way for the newly-promoted primary VM to be sure if the disk IOs were issued to the disk or completed successfully.</li><li>We could send an error completion that indicates that each IO failed since it is acceptable to return an error even if the IO was completed successfully. However, the guest OS might not respond well to errors from its local disk.</li><li>We can re-issue the pending IOs during the backup VM go-live process. Because we have eliminated all races and all IOs specify directly which memory and disk blocks are accessed, these disk operations can be re-issued even if they have already been completed successfully.</li></ol><h3 id="issues-for-network-io"><a class="markdownIt-Anchor" href="#issues-for-network-io"></a> Issues for network IO</h3><h4 id="how-to-solve-the-non-determinism-caused-by-asynchronous-updates"><a class="markdownIt-Anchor" href="#how-to-solve-the-non-determinism-caused-by-asynchronous-updates"></a> How to solve the non-determinism caused by asynchronous updates?</h4><ol><li><p>In a normal VM, the hypervisor asynchronously updates the state of the virtual machine’s network device.</p></li><li><p>For FT</p><ul><li><p>The code that asynchronously updates VM ring buffers with incoming packets has been modified to force the guest to trap them in the hypervisor, which can log the updates and then apply them to the VM.</p></li><li><p>The code that typically pulls packets out of transmit queues asynchronously is disabled, and instead, transmits are done through a trap to the hypervisor.</p></li></ul></li></ol><h4 id="how-can-we-optimize-the-network-performance-while-running-ft"><a class="markdownIt-Anchor" href="#how-can-we-optimize-the-network-performance-while-running-ft"></a> How can we optimize the network performance while running FT?</h4><ol><li><p>Reduce VM traps and interrupts with clustering optimizations.</p><ul><li><p>When the VM is streaming data at a sufficient bit rate, the hypervisor can do one transmit trap per group of packets and, in the best case, zero traps since it can transmit the packets as part of receiving new packets.</p></li><li><p>The hypervisor can reduce the number of interrupts to the VM for incoming packets by only posting the interrupt for a group of packets.</p></li></ul></li><li><p>Reduce the delay for transmitted packets.</p><ul><li><p>The key is to reduce the time required to send a log message to the backup and get an acknowledgment.</p></li><li><p>It is ensured that sending and receiving log entries and acknowledgments can all be done without any thread context switch.</p></li><li><p>The VMware vSphere hypervisor allows functions to be registered with the TCP stack that will be called from a deferred execution context (similar to a tasklet in Linux) whenever TCP data is received.</p></li><li><p>When the primary VM enqueues a packet to be transmitted, we force an immediate log flush of the associated output log entry by scheduling a deferred execution context to do the flush.</p></li></ul></li></ol><h1 id="experiments-and-results"><a class="markdownIt-Anchor" href="#experiments-and-results"></a> Experiments and results</h1><p>One important benchmark is the performance ratio between non-FT and FT systems and logging bandwidth between primary and backup. The performance ratio can show how efficient the FT protocol is, and logging bandwidth is usually a system bottleneck. The author measured them all in the following table. We can see that the FT protocol only decreases the performance by less than 10%</p><img src="/imgs/Distributed/FTVM/02.png" style="zoom:30%;" /><p>The typical idle logging bandwidth is 0.5-1.5 Mbits/sec. The idle bandwidth primarily results from recording the delivery of timer interrupts. For a VM with an active workload, the logging bandwidth is dominated by the network and disk inputs that must be sent to the backup - the network packets received and the disk blocks read from the disk. Hence, the logging bandwidth can be much higher than those measured in the table for applications with high network receive or disk read bandwidth. For these kinds of applications, the bandwidth of the logging channel could be a bottleneck.</p><p>The author also measured the bandwidth of logging channels with different capacities, as shown below. When FT is enabled to receive workloads, the logging bandwidth is very large since all incoming network packets must be sent to the logging channel. The logging bandwidth is much lower when FT is enabled for transmit workloads. Overall, FT can limit network bandwidths significantly at very high transmit and receive rates, but high absolute rates are still achievable.</p><img src="/imgs/Distributed/FTVM/03.png" style="zoom:30%;" />]]></content>
      
      
      <categories>
          
          <category> Paper Notebook </category>
          
          <category> Distributed System </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Distributed System </tag>
            
            <tag> Fault Tolerance </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>GFS</title>
      <link href="/2023/09/26/Paper/Distributed/GFS/"/>
      <url>/2023/09/26/Paper/Distributed/GFS/</url>
      
        <content type="html"><![CDATA[<p>Paper: <a href="http://nil.csail.mit.edu/6.824/2020/papers/gfs.pdf">The Google File System</a></p><p><ul class="markdownIt-TOC"><li><a href="#abstract">Abstract</a></li><li><a href="#purpose">Purpose</a></li><li><a href="#model">Model</a><ul><li><a href="#overview">Overview</a><ul><li><a href="#what-operations-are-supported">What operations are supported?</a></li><li><a href="#architecture">Architecture</a><ul><li><a href="#what-does-the-system-consist-of">What does the system consist of?</a></li><li><a href="#what-does-the-master-need-to-do">What does the master need to do?</a></li><li><a href="#how-can-the-master-be-prevented-from-becoming-a-bottleneck">How can the master be prevented from becoming a bottleneck?</a></li><li><a href="#what-is-the-advantage-of-large-chunk-size">What is the advantage of large chunk size?</a></li><li><a href="#what-is-the-disadvantage-of-large-chunk-size">What is the disadvantage of large chunk size?</a></li><li><a href="#when-will-the-hot-spot-problem-emerge">When will the hot spot problem emerge?</a></li></ul></li><li><a href="#consistency">Consistency</a><ul><li><a href="#how-do-we-define-a-file-region-as-being-consistent-or-defined">How do we define a file region as being consistent or defined?</a></li><li><a href="#how-many-consistency-rules-should-be-considered">How many consistency rules should be considered?</a></li><li><a href="#how-does-gfs-guarantee-the-second-rule">How does GFS guarantee the second rule?</a></li><li><a href="#what-is-the-side-effect-of-clients-caching-chunk-locations">What is the side-effect of clients caching chunk locations?</a></li></ul></li></ul></li><li><a href="#data-mutation">Data mutation</a><ul><li><a href="#control-data-flow">Control &amp; data flow</a><ul><li><a href="#how-do-we-minimize-management-overhead-at-the-master-of-data-mutation">How do we minimize management overhead at the master of data mutation?</a></li><li><a href="#what-do-leases-change">What do leases change?</a></li><li><a href="#how-does-the-control-flow">How does the control flow?</a></li><li><a href="#how-do-primary-and-secondary-servers-write-data">How do primary and secondary servers write data?</a></li><li><a href="#what-would-the-system-do-if-the-write-fails">What would the system do if the write fails?</a></li><li><a href="#what-if-a-write-is-large-or-straddles-a-chunk-boundary">What if a write is large or straddles a chunk boundary?</a></li><li><a href="#how-to-prevent-the-primary-become-bottleneck-of-pushing-data">How to prevent the primary become bottleneck of pushing data?</a></li><li><a href="#how-to-minimize-the-latency-of-pushing-data">How to minimize the latency of pushing data?</a></li></ul></li><li><a href="#write-and-record-append">Write and record append</a><ul><li><a href="#what-is-the-difference-between-write-and-record-append">What is the difference between write and record append?</a></li><li><a href="#how-does-typical-writing-happen">How does typical writing happen?</a></li><li><a href="#how-do-readers-deal-with-occasional-padding-and-duplicates">How do readers deal with occasional padding and duplicates?</a></li></ul></li><li><a href="#atomic-record-appends">Atomic record appends</a><ul><li><a href="#what-if-appending-causes-the-current-chunk-to-exceed-the-maximum-size">What if appending causes the current chunk to exceed the maximum size?</a></li><li><a href="#what-if-appending-fails-at-some-chunkservers">What if appending fails at some chunkservers?</a></li></ul></li><li><a href="#snapshot">Snapshot</a><ul><li><a href="#what-does-snapshot-do">What does snapshot do?</a></li><li><a href="#how-does-snapshot-be-implemented">How does snapshot be implemented?</a></li><li><a href="#how-do-clients-write-a-chunk-after-a-snapshot">How do clients write a chunk after a snapshot?</a></li></ul></li></ul></li><li><a href="#master">Master</a><ul><li><a href="#basic-operations">Basic operations</a><ul><li><a href="#how-does-the-client-communicate-with-the-master-specifically">How does the client communicate with the master specifically?</a></li><li><a href="#what-metadata-does-the-master-need-to-store">What metadata does the master need to store?</a></li><li><a href="#how-to-persist">How to persist?</a></li><li><a href="#how-does-gfs-manage-namespace">How does GFS manage namespace?</a></li><li><a href="#how-does-gfs-design-the-locking-scheme">How does GFS design the locking scheme?</a></li></ul></li><li><a href="#replica-management">Replica management</a><ul><li><a href="#how-to-place-replicas">How to place replicas?</a></li><li><a href="#what-factors-are-considered-when-creating-a-new-chunk">What factors are considered when creating a new chunk?</a></li><li><a href="#what-if-the-number-of-available-chunk-replicas-falls-below-a-user-specified-goal">What if the number of available chunk replicas falls below a user-specified goal?</a></li><li><a href="#what-if-cloning-traffic-from-overwhelming-client-traffic">What if cloning traffic from overwhelming client traffic?</a></li><li><a href="#how-to-keep-the-placement-of-replicas-in-balance">How to keep the placement of replicas in balance?</a></li></ul></li><li><a href="#deletion">Deletion</a><ul><li><a href="#how-to-delete-a-file">How to delete a file?</a></li><li><a href="#what-are-the-advantages-and-disadvantages-of-lazy-deletion-over-eager-deletion">What are the advantages and disadvantages of lazy deletion over eager deletion?</a></li><li><a href="#how-to-address-the-issues-of-reusing">How to address the issues of reusing?</a></li><li><a href="#how-to-handle-the-possible-stale-replicas">How to handle the possible stale replicas?</a></li></ul></li></ul></li><li><a href="#fault-tolerance">Fault tolerance</a><ul><li><a href="#how-to-handle-master-failure">How to handle master failure?</a></li><li><a href="#why-cannot-recover-data-using-other-chunk-replicas-why-each-chunkserver-must-independently-verify-the-integrity">Why cannot recover data using other chunk replicas? Why each chunkserver must independently verify the integrity?</a></li><li><a href="#how-to-ensure-data-integrity">How to ensure data integrity?</a></li><li><a href="#how-to-read-data-with-checksum">How to read data with checksum?</a></li><li><a href="#how-to-write-data-with-checksum">How to write data with checksum?</a></li><li><a href="#what-is-included-in-the-diagnostic-logs">What is included in the diagnostic logs?</a></li></ul></li><li><a href="#other-parts-unmentioned">Other parts (unmentioned)</a><ul><li><a href="#to-sum-up-what-is-the-metadata-of-the-master-and-where-are-they">To sum up, what is the metadata of the master, and where are they?</a></li><li><a href="#what-is-the-cause-of-a-split-brain-how-to-solve-it">What is the cause of a split-brain? How to solve it?</a></li><li><a href="#why-does-gfs-not-overwrite-those-failed-records-immediately-but-leave-padding-and-duplicates">Why does GFS not overwrite those failed records immediately but leave padding and duplicates?</a></li><li><a href="#gfs-is-a-weak-consistency-system-how-can-we-upgrade-it-to-a-strong-one">GFS is a weak consistency system; how can we upgrade it to a strong one?</a></li></ul></li></ul></li><li><a href="#experiments-and-results">Experiments and results</a><ul><li><a href="#micro-benchmarks">Micro-benchmarks</a><ul><li><a href="#read">Read</a></li><li><a href="#write">Write</a></li><li><a href="#record-append">Record append</a></li></ul></li><li><a href="#real-world-clusters">Real-world clusters</a></li></ul></li></ul></p><h1 id="abstract"><a class="markdownIt-Anchor" href="#abstract"></a> Abstract</h1><ol><li><strong>Main idea</strong>:</li><li><strong>Key findings</strong>:</li><li><strong>The system</strong>:</li><li><strong>Evaluation</strong>:</li></ol><h1 id="purpose"><a class="markdownIt-Anchor" href="#purpose"></a> Purpose</h1><ol><li>Contribution: provides fault tolerance while running on inexpensive commodity hardware, and it delivers high aggregate performance to a large number of clients.</li><li>Difference points in design space.<ul><li>This system integrated constant monitoring, error detection, fault tolerance, and automatic recovery.</li><li>Files are enormous by traditional standards. Design assumptions and parameters such as I/O operation and block sizes have to be revisited.</li><li>Most files are mutated by appending new data rather than overwriting existing data. Random writes within a file are practically nonexistent. Once written, the files are only read, and often only sequentially.</li></ul></li></ol><h1 id="model"><a class="markdownIt-Anchor" href="#model"></a> Model</h1><h2 id="overview"><a class="markdownIt-Anchor" href="#overview"></a> Overview</h2><h3 id="what-operations-are-supported"><a class="markdownIt-Anchor" href="#what-operations-are-supported"></a> What operations are supported?</h3><ol><li>Usual operations: <code>create</code>, <code>delete</code>, <code>open</code>, <code>close</code>, <code>read</code>, and <code>write</code></li><li><code>snapshot</code>: creates a copy of a file or a directory tree at a low cost</li><li><code>record append</code>: allows multiple clients to append data to the same file concurrently while guaranteeing the atomicity</li></ol><h3 id="architecture"><a class="markdownIt-Anchor" href="#architecture"></a> Architecture</h3><img src="/imgs/Distributed/GFS/01.png" style="zoom:33%;" /><h4 id="what-does-the-system-consist-of"><a class="markdownIt-Anchor" href="#what-does-the-system-consist-of"></a> What does the system consist of?</h4><ol><li>It consists of a single <em>master</em> and multiple <em>chunkservers</em> and is accessed by multiple <em>clients</em>.</li><li>Files are divided into fixed-size chunks. Each chunk is identified by an immutable and globally unique 64-bit chunk handle assigned by the master at the time of chunk creation.</li><li>Chunkservers store chunks on local disks as Linux files and read or write chunk data specified by a chunk handle and byte range. Each chunk is replicated on multiple chunkservers, three by default.</li><li>Neither the client nor the chunkserver caches file data. Caches offer little benefit while causing coherence issues. But clients do cache metadata.</li></ol><h4 id="what-does-the-master-need-to-do"><a class="markdownIt-Anchor" href="#what-does-the-master-need-to-do"></a> What does the master need to do?</h4><ol><li><p>The master maintains all file system metadata and controls system-wide activities.</p><ul><li><p>Metadata includes namespace, access control information, the mapping from files to chunks, and the current locations of chunks.</p></li><li><p>System-wide activities include chunk lease management, garbage collection of orphaned chunks, and chunk migration between chunkservers.</p></li></ul></li><li><p>The master periodically communicates with each chunkserver in HeartBeat messages to give instructions and collect its state.</p></li><li><p>Clients interact with the master for metadata operations, but all data-bearing communication goes directly to the chunkservers.</p></li></ol><h4 id="how-can-the-master-be-prevented-from-becoming-a-bottleneck"><a class="markdownIt-Anchor" href="#how-can-the-master-be-prevented-from-becoming-a-bottleneck"></a> How can the master be prevented from becoming a bottleneck?</h4><ol><li><p>The idea is to minimize its involvement in reads and writes.</p></li><li><p>A client asks the master which chunkservers to contact, caches this information for a limited time, and interacts directly with the chunkservers for subsequent operations.</p></li></ol><h4 id="what-is-the-advantage-of-large-chunk-size"><a class="markdownIt-Anchor" href="#what-is-the-advantage-of-large-chunk-size"></a> What is the advantage of large chunk size?</h4><ol><li><p>Reduce clients’ need to interact with the master because reads and writes on the same chunk require only one initial request to the master for chunk location information.</p></li><li><p>Reduce network overhead by keeping a persistent TCP connection to the chunkserver over an extended period.</p></li><li><p>Reduce the size of the metadata stored on the master.</p></li></ol><h4 id="what-is-the-disadvantage-of-large-chunk-size"><a class="markdownIt-Anchor" href="#what-is-the-disadvantage-of-large-chunk-size"></a> What is the disadvantage of large chunk size?</h4><ol><li><p>Wasting space due to internal fragmentation. This can be eased through lazy space allocation.</p></li><li><p>A small file consists of several chunks, perhaps just one. The chunkservers storing those chunks may become hot spots if many clients access the same file. This has not been a major issue.</p></li></ol><h4 id="when-will-the-hot-spot-problem-emerge"><a class="markdownIt-Anchor" href="#when-will-the-hot-spot-problem-emerge"></a> When will the hot spot problem emerge?</h4><ol><li><p>A more common case is that an executable was written to GFS as a single-chunk file and then simultaneously started on hundreds of machines.</p></li><li><p>We can fix this problem by storing such executables with a higher replication factor.</p></li></ol><h3 id="consistency"><a class="markdownIt-Anchor" href="#consistency"></a> Consistency</h3><h4 id="how-do-we-define-a-file-region-as-being-consistent-or-defined"><a class="markdownIt-Anchor" href="#how-do-we-define-a-file-region-as-being-consistent-or-defined"></a> How do we define a file region as being consistent or defined?</h4><ol><li><p>A file region is consistent if all clients always see the same data, regardless of which replicas they read from.</p></li><li><p>A region is defined after a file data mutation if consistent, and clients will see what the mutation writes.</p></li><li><p>Concurrent successful mutations leave the region undefined but consistent: all clients see the same data, but it may not reflect what any one mutation has written. Typically, it consists of mingled fragments from multiple mutations.</p></li></ol><h4 id="how-many-consistency-rules-should-be-considered"><a class="markdownIt-Anchor" href="#how-many-consistency-rules-should-be-considered"></a> How many consistency rules should be considered?</h4><ol><li>File namespace mutations (e.g., file creation) are atomic.</li><li>After a sequence of successful mutations, the mutated file region is guaranteed to be defined and contain the data written by the last mutation.</li></ol><h4 id="how-does-gfs-guarantee-the-second-rule"><a class="markdownIt-Anchor" href="#how-does-gfs-guarantee-the-second-rule"></a> How does GFS guarantee the second rule?</h4><ol><li>Applying mutations to a chunk in the same order on all its replicas.</li><li>Using chunk version numbers to detect any replica that has become stale because it has missed mutations while its chunkserver was down.</li><li>Stale replicas will never be involved in a mutation or given to clients asking the master for chunk locations. They are garbage collected at the earliest opportunity.</li></ol><h4 id="what-is-the-side-effect-of-clients-caching-chunk-locations"><a class="markdownIt-Anchor" href="#what-is-the-side-effect-of-clients-caching-chunk-locations"></a> What is the side-effect of clients caching chunk locations?</h4><ol><li>They may read from a stale replica before that information is refreshed.</li><li>This window is limited by the cache entry’s timeout and the next opening of the file.</li><li>As most files are append-only, a stale replica usually returns a premature end of chunk rather than outdated data.</li></ol><h2 id="data-mutation"><a class="markdownIt-Anchor" href="#data-mutation"></a> Data mutation</h2><h3 id="control-data-flow"><a class="markdownIt-Anchor" href="#control-data-flow"></a> Control &amp; data flow</h3><h4 id="how-do-we-minimize-management-overhead-at-the-master-of-data-mutation"><a class="markdownIt-Anchor" href="#how-do-we-minimize-management-overhead-at-the-master-of-data-mutation"></a> How do we minimize management overhead at the master of data mutation?</h4><ol><li>We use leases to maintain a consistent mutation order across replicas.</li><li>The master grants a chunk lease to one of the replicas, which we call the primary. The primary picks a serial order for all mutations to the chunk. All replicas follow this order when mutations are applied.</li><li>The client caches who leases a certain chunk for future mutations. It needs to contact the master again only when the primary becomes unreachable or replies that it no longer holds a lease.</li></ol><h4 id="what-do-leases-change"><a class="markdownIt-Anchor" href="#what-do-leases-change"></a> What do leases change?</h4><ol><li>A lease has an initial timeout of 60 seconds. However, as long as the chunk is being mutated, the primary can request and typically receive extensions from the master indefinitely.</li><li>These extension requests and grants are piggybacked on the HeartBeat messages regularly exchanged between the master and all chunkservers.</li><li>The master may sometimes try to revoke a lease before it expires (e.g. when the master wants to disable mutations on a file that is being renamed).</li><li>Even if the master loses communication with a primary, it can safely grant a new lease to another replica after the old lease expires.</li></ol><h4 id="how-does-the-control-flow"><a class="markdownIt-Anchor" href="#how-does-the-control-flow"></a> How does the control flow?</h4><ol><li><p>The client asks the master which chunkserver holds the current lease for the chunk and the locations of the other replicas. If no one has a lease, the master grants one to a replica it chooses</p></li><li><p>The master replies with the identity of the primary and the locations of the other (secondary) replicas.</p></li><li><p>The client pushes the data to all the replicas in any order instead of only sending it to the lease.</p></li><li><p>Once all the replicas have acknowledged receiving the data, the client sends a write request to the primary.</p></li><li><p>The primary forwards the write request to all secondary replicas.</p></li><li><p>The secondaries reply to the primary, indicating they have completed the operation.</p></li><li><p>The primary replies to the client. Any errors encountered at any of the replicas are reported to the client.</p><img src="/imgs/Distributed/GFS/02.png" style="zoom:25%;" /></li></ol><h4 id="how-do-primary-and-secondary-servers-write-data"><a class="markdownIt-Anchor" href="#how-do-primary-and-secondary-servers-write-data"></a> How do primary and secondary servers write data?</h4><ol><li><p>Each chunkserver will store the data from the client in an internal LRU buffer cache until the data is used or aged out.</p></li><li><p>The write request from the client to primary identifies the data pushed earlier to all of the replicas.</p></li><li><p>The primary assigns consecutive serial numbers to all the mutations it receives, possibly from multiple clients, which provides the necessary serialization.</p></li><li><p>The primary applies the mutation to its local state in serial number order.</p></li></ol><h4 id="what-would-the-system-do-if-the-write-fails"><a class="markdownIt-Anchor" href="#what-would-the-system-do-if-the-write-fails"></a> What would the system do if the write fails?</h4><ol><li><p>It would not have been assigned a serial number and forwarded if it had failed at the primary.</p></li><li><p>In other cases, the write may have succeeded at the primary and an arbitrary subset of the secondary replicas. The client request is considered to have failed, and the modified region is left in an inconsistent state.</p></li><li><p>The client code handles such errors by retrying the failed mutation. It will make a few attempts at steps 3 through 7 before falling back to a retry from the beginning of the write.</p></li></ol><h4 id="what-if-a-write-is-large-or-straddles-a-chunk-boundary"><a class="markdownIt-Anchor" href="#what-if-a-write-is-large-or-straddles-a-chunk-boundary"></a> What if a write is large or straddles a chunk boundary?</h4><ol><li>GFS client code breaks it down into multiple write operations.</li><li>They all follow the control flow described above but may be interleaved with and overwritten by concurrent operations from other clients.</li><li>The shared file region may end up containing fragments from different clients. However, the replicas will be identical because the individual operations are completed successfully in the same order on all replicas.</li></ol><h4 id="how-to-prevent-the-primary-become-bottleneck-of-pushing-data"><a class="markdownIt-Anchor" href="#how-to-prevent-the-primary-become-bottleneck-of-pushing-data"></a> How to prevent the primary become bottleneck of pushing data?</h4><ol><li>While control flows from the client to the primary and then to all secondaries, data is pushed linearly along a carefully picked chain of chunkservers in a pipelined fashion.</li><li>Decoupling the data flow from the control flow can improve performance by scheduling the expensive data flow based on the network topology, regardless of which chunkserver is the primary.</li><li>We aim to fully utilize each machine’s network bandwidth, avoid network bottlenecks and high-latency links, and minimize the latency to push through all the data.</li><li>Each machine forwards the data to the “closest” machine in the network topology that has not received it.</li><li>Our network topology is simple enough that “distances” can be accurately estimated from IP addresses.</li></ol><h4 id="how-to-minimize-the-latency-of-pushing-data"><a class="markdownIt-Anchor" href="#how-to-minimize-the-latency-of-pushing-data"></a> How to minimize the latency of pushing data?</h4><ol><li>We minimize latency by pipelining the data transfer over TCP connections. Once a chunkserver receives some data, it starts forwarding immediately.</li><li>Pipelining is especially helpful because we use a switched network with full-duplex links. Sending the data immediately does not reduce the receive rate.</li></ol><h3 id="write-and-record-append"><a class="markdownIt-Anchor" href="#write-and-record-append"></a> Write and record append</h3><h4 id="what-is-the-difference-between-write-and-record-append"><a class="markdownIt-Anchor" href="#what-is-the-difference-between-write-and-record-append"></a> What is the difference between write and record append?</h4><ol><li><p>A write causes data to be written at an application-specified file offset.</p></li><li><p>A record append causes data (the “record”) to be appended atomically at least once, even in the presence of concurrent mutations, but at an offset of GFS’s choosing.</p><ul><li><p>The offset is returned to the client and marks the beginning of a defined region that contains the record.</p></li><li><p>GFS may insert padding or record duplicates in between. They occupy regions considered inconsistent and are typically dwarfed by the amount of user data.</p></li></ul></li><li><p>A “regular” append is merely a write at an offset that the client believes to be the current end of the file.</p></li></ol><h4 id="how-does-typical-writing-happen"><a class="markdownIt-Anchor" href="#how-does-typical-writing-happen"></a> How does typical writing happen?</h4><ol><li>A writer generates a file from beginning to end. After writing all the data, it atomically renames the file to a permanent name or periodically checkpoints how much has been successfully written.</li><li>Checkpoints may also include application-level checksums. Readers verify and process only the file region up to the last checkpoint, which is in the defined state.</li><li>Checkpointing allows writers to restart incrementally and keeps readers from processing successfully written file data that is still incomplete.</li></ol><h4 id="how-do-readers-deal-with-occasional-padding-and-duplicates"><a class="markdownIt-Anchor" href="#how-do-readers-deal-with-occasional-padding-and-duplicates"></a> How do readers deal with occasional padding and duplicates?</h4><ol><li>Each record prepared by the writer contains extra information like checksums to verify its validity.</li><li>A reader can identify and discard extra padding and record fragments using the checksums.</li><li>Suppose it cannot tolerate the occasional duplicates. In that case, it can filter them out using unique identifiers in the records, often needed to name corresponding application entities such as web documents.</li></ol><h3 id="atomic-record-appends"><a class="markdownIt-Anchor" href="#atomic-record-appends"></a> Atomic record appends</h3><h4 id="what-if-appending-causes-the-current-chunk-to-exceed-the-maximum-size"><a class="markdownIt-Anchor" href="#what-if-appending-causes-the-current-chunk-to-exceed-the-maximum-size"></a> What if appending causes the current chunk to exceed the maximum size?</h4><ol><li>The primary checks if appending the record to the current chunk would cause the chunk to exceed the maximum size.</li><li>If so, it pads the chunk to the maximum size, tells secondaries to do the same, and replies to the client, indicating that the operation should be retried on the next chunk.</li><li>Suppose the record fits within the maximum size. In that case, the typical case is that the primary appends the data to its replica tells the secondaries to write the data at the exact offset where it has been, and finally replies successfully to the client.</li></ol><h4 id="what-if-appending-fails-at-some-chunkservers"><a class="markdownIt-Anchor" href="#what-if-appending-fails-at-some-chunkservers"></a> What if appending fails at some chunkservers?</h4><ol><li>Replicas of the same chunk may contain different data, possibly including duplicates of the same record as a whole or in part.</li><li>GFS does not guarantee that all replicas are bytewise identical. It only guarantees that the data is written at least once as an atomic unit.</li><li>The primary has succeeded if any secondary chunkserver can successfully append the record. Next time, the primary can choose an offset after the failed record.</li><li>Hence, after this, all replicas are at least as long as the end of the record, and therefore, any future record will be assigned a higher offset or a different chunk, even if a different replica later becomes the primary.</li></ol><h3 id="snapshot"><a class="markdownIt-Anchor" href="#snapshot"></a> Snapshot</h3><h4 id="what-does-snapshot-do"><a class="markdownIt-Anchor" href="#what-does-snapshot-do"></a> What does snapshot do?</h4><ol><li>The snapshot operation makes a copy of a file or a directory tree (the “source”) almost instantaneously while minimizing any interruptions of ongoing mutations.</li><li>Users use it to quickly create branch copies of massive data sets (often copies of those copies, recursively) or to checkpoint the current state before experimenting with changes that can later be committed or rolled back easily.</li></ol><h4 id="how-does-snapshot-be-implemented"><a class="markdownIt-Anchor" href="#how-does-snapshot-be-implemented"></a> How does snapshot be implemented?</h4><ol><li><p>It uses standard copy-on-write techniques.</p></li><li><p>Master revokes leases on the chunks in the files it is about to snapshot.</p><ul><li><p>This ensures that any subsequent writes to these chunks will require an interaction with the master to find the leaseholder.</p></li><li><p>This will give the master an opportunity to create a new copy of the chunk first.</p></li></ul></li><li><p>The master logs the operation to disk.</p></li><li><p>It then applies this log record to its in-memory state by duplicating the metadata for the source file or directory tree. The newly created snapshot files point to the same chunks as the source files.</p></li></ol><h4 id="how-do-clients-write-a-chunk-after-a-snapshot"><a class="markdownIt-Anchor" href="#how-do-clients-write-a-chunk-after-a-snapshot"></a> How do clients write a chunk after a snapshot?</h4><ol><li>The first time a client wants to write to a chunk C after the snapshot operation, it sends a request to the master to find the current lease holder.</li><li>The master notices that the reference count for chunk C is greater than one. It defers replying to the client request and instead picks a new chunk handle C’.</li><li>It then asks each chunkserver that has a current replica of C to create a new chunk called C’.</li><li>By creating the new chunk on the same chunkservers as the original, we ensure that the data can be copied locally, not over the network.</li><li>The master grants one of the replicas a lease on the new chunk C’ and replies to the client, which can write the chunk normally.</li></ol><h2 id="master"><a class="markdownIt-Anchor" href="#master"></a> Master</h2><h3 id="basic-operations"><a class="markdownIt-Anchor" href="#basic-operations"></a> Basic operations</h3><h4 id="how-does-the-client-communicate-with-the-master-specifically"><a class="markdownIt-Anchor" href="#how-does-the-client-communicate-with-the-master-specifically"></a> How does the client communicate with the master specifically?</h4><ol><li>The client translates the file name and byte offset specified by the application into a chunk index within the file.</li><li>It sends the master a request containing the file name and chunk index.</li><li>The master replies with the corresponding chunk handle and locations of the replicas.</li><li>The client caches this information using the file name and chunk index as the key.</li></ol><h4 id="what-metadata-does-the-master-need-to-store"><a class="markdownIt-Anchor" href="#what-metadata-does-the-master-need-to-store"></a> What metadata does the master need to store?</h4><ol><li><p>Stored persistently: the file and chunk namespace, the mapping from files to chunks</p><ul><li><p>The master will scan periodically through its entire state in the background.</p></li><li><p>Periodic scanning is to implement chunk garbage collection, re-replication in the presence of chunkserver failures, and chunk migration to balance load and disk space usage across chunkservers.</p></li><li><p>The number of chunks and, hence, the whole system’s capacity is limited by how much memory the master has. But not a serious limitation for less than <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>64</mn></mrow><annotation encoding="application/x-tex">64</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">6</span><span class="mord">4</span></span></span></span> bytes of metadata for each chunk.</p></li></ul></li><li><p>There is no need to persistently store the locations of each chunk’s replicas.</p><ul><li><p>The master asks each chunkserver about its chunks at master startup and whenever a chunkserver joins the cluster.</p></li><li><p>The master can keep itself up-to-date after that because it controls all chunk placement and monitors chunkserver status.</p></li></ul></li><li><p>Operation record</p><ul><li><p>The namespace and mapping are persistent by logging mutations into the operation log.</p></li><li><p>It is stored on the master’s local disk and replicated on remote machines.</p></li></ul></li></ol><h4 id="how-to-persist"><a class="markdownIt-Anchor" href="#how-to-persist"></a> How to persist?</h4><ol><li>Operation log<ul><li>The operation log contains a historical record of critical metadata changes. It is the only persistent record of critical metadata and serves as a logical timeline that defines the order of concurrent operations.</li><li>The system responds to a client operation only after flushing the corresponding log record locally and remotely to disk.</li><li>The master batches several log records together before flushing, reducing the impact of flushing and replication on overall system thoughput.</li></ul></li><li>Checkpoint<ul><li>To minimize startup time, we must keep the log small. The master checkpoints its state whenever the log grows beyond a certain size. It can recover by loading the latest checkpoint and replaying only the records afterward.</li><li>The checkpoint is in a compact B-tree-like form.</li><li>The master switches to a new log file and creates the latest checkpoint in a separate thread.</li><li>Older checkpoints and log files can be freely deleted, though we keep a few around to guard against catastrophes. A failure during checkpointing does not affect correctness because the recovery code detects and skips incomplete checkpoints.</li></ul></li></ol><h4 id="how-does-gfs-manage-namespace"><a class="markdownIt-Anchor" href="#how-does-gfs-manage-namespace"></a> How does GFS manage namespace?</h4><ol><li>GFS does not have a per-directory data structure that lists all the files in that directory. Nor does it support aliases for the same file or directory.</li><li>GFS logically represents its namespace as a lookup table mapping full pathnames to metadata. With prefix compression, this table can be efficiently represented in memory.</li><li>Each node in the namespace tree (an absolute file name or an absolute directory name) has an associated read-write lock.</li></ol><h4 id="how-does-gfs-design-the-locking-scheme"><a class="markdownIt-Anchor" href="#how-does-gfs-design-the-locking-scheme"></a> How does GFS design the locking scheme?</h4><ol><li>Suppose a master operation involves a specific file or directory. In that case, it will acquire read-locks on all the parent directories and either a read-lock or a write-lock on the leaf file or directory that it will operate directly.</li><li>File creation does not require a write lock on the parent directory because there is no “directory” or inode-like data structure to be protected from modification.</li><li>This locking scheme allows concurrent mutations in the same directory.</li></ol><h3 id="replica-management"><a class="markdownIt-Anchor" href="#replica-management"></a> Replica management</h3><h4 id="how-to-place-replicas"><a class="markdownIt-Anchor" href="#how-to-place-replicas"></a> How to place replicas?</h4><ol><li>There are two purposes: maximize data reliability and availability and maximize network bandwidth utilization.</li><li>It is not enough to spread replicas across machines, which only guards against disk or machine failures and fully utilizes each machine’s network bandwidth.</li><li>We must also spread chunk replicas across racks. This ensures that some replicas of a chunk will survive and remain available even if an entire rack is damaged or offline. It also means that traffic, especially reads, for a chunk can exploit the aggregate bandwidth of multiple racks.</li><li>On the other hand, write traffic has to flow through multiple racks, a tradeoff we make willingly.</li><li>An even safer way is to spread across data centers in different cities. It can guard against a city-level catastrophe.</li></ol><h4 id="what-factors-are-considered-when-creating-a-new-chunk"><a class="markdownIt-Anchor" href="#what-factors-are-considered-when-creating-a-new-chunk"></a> What factors are considered when creating a new chunk?</h4><ol><li>We want to place new replicas on chunkservers with below-average disk space utilization. Over time, this will equalize disk utilization across chunkservers.</li><li>We want to limit the number of “recent” creations on each chunkserver. Although creation itself is cheap, it reliably predicts imminent heavy write traffic because chunks are created when demanded by writes.</li><li>We want to spread replicas of a chunk across racks.</li></ol><h4 id="what-if-the-number-of-available-chunk-replicas-falls-below-a-user-specified-goal"><a class="markdownIt-Anchor" href="#what-if-the-number-of-available-chunk-replicas-falls-below-a-user-specified-goal"></a> What if the number of available chunk replicas falls below a user-specified goal?</h4><ol><li><p>The master would re-replicate the chunk.</p></li><li><p>Suppose there are many chunks below their goal. In that case, the master picks the highest priority chunk considering some factors and “clones” it by instructing some chunkserver to copy the chunk data directly from an existing valid replica.</p><ul><li><p>How far it is from its replication goal.</p></li><li><p>Prefer to re-replicate chunks for live files instead of chunks belonging to recently deleted files.</p></li><li><p>To minimize the impact of failures on running applications, we boost the priority of any chunk blocking client progress.</p></li></ul></li></ol><h4 id="what-if-cloning-traffic-from-overwhelming-client-traffic"><a class="markdownIt-Anchor" href="#what-if-cloning-traffic-from-overwhelming-client-traffic"></a> What if cloning traffic from overwhelming client traffic?</h4><ol><li>The master limits the number of active clone operations for the cluster and each chunkserver.</li><li>Each chunkserver limits its bandwidth on each clone operation by throttling its read requests to the source chunkserver.</li></ol><h4 id="how-to-keep-the-placement-of-replicas-in-balance"><a class="markdownIt-Anchor" href="#how-to-keep-the-placement-of-replicas-in-balance"></a> How to keep the placement of replicas in balance?</h4><ol><li>It examines the current replica distribution and moves replicas for better disk space and load balancing.</li><li>The master gradually fills up a new chunkserver rather than instantly swamps it with new chunks and the heavy write traffic that comes with them.</li><li>The master must also choose which existing replica to remove. It prefers to remove those on chunkservers with below-average free space.</li></ol><h3 id="deletion"><a class="markdownIt-Anchor" href="#deletion"></a> Deletion</h3><h4 id="how-to-delete-a-file"><a class="markdownIt-Anchor" href="#how-to-delete-a-file"></a> How to delete a file?</h4><ol><li><p>GFS does not immediately reclaim the available physical storage; it is just renamed to a hidden name that includes the deletion timestamp. It does so only lazily during regular garbage collection at both the file and chunk levels.</p></li><li><p>During the master’s regular scan of the file system namespace, any such hidden files are removed if they have existed for more than three days (the interval is configurable).</p><ul><li><p>Until then, the file can still be read under the new, special name and undeleted by renaming it to normal.</p></li><li><p>When the hidden file is removed from the namespace, its in-memory metadata is erased. This effectively severs its links to all its chunks.</p></li></ul></li><li><p>In a similar regular scan of the chunk namespace, the master identifies orphaned chunks (i.e., those not reachable from any file) and erases the metadata for those chunks.</p><ul><li><p>In a HeartBeat message exchanged with the master, each chunkserver reports a subset of the chunks it has, and the master replies with the identity of all chunks that are no longer present in the master’s metadata.</p></li><li><p>The chunkserver is free to delete its replicas of such chunks.</p></li></ul></li></ol><h4 id="what-are-the-advantages-and-disadvantages-of-lazy-deletion-over-eager-deletion"><a class="markdownIt-Anchor" href="#what-are-the-advantages-and-disadvantages-of-lazy-deletion-over-eager-deletion"></a> What are the advantages and disadvantages of lazy deletion over eager deletion?</h4><ol><li><p>It is simple and reliable in a large-scale distributed system where component failures are common.</p></li><li><p>It merges storage reclamation into the master’s regular background activities.</p></li><li><p>The delay in reclaiming storage protects against accidental, irreversible deletion.</p></li><li><p>The delay sometimes hinders user effort to fine-tune usage when storage is tight.</p></li><li><p>Applications that repeatedly create and delete temporary files may be unable to reuse the storage immediately.</p></li></ol><h4 id="how-to-address-the-issues-of-reusing"><a class="markdownIt-Anchor" href="#how-to-address-the-issues-of-reusing"></a> How to address the issues of reusing?</h4><ol><li><p>Expediting storage reclamation if a deleted file is explicitly deleted again.</p></li><li><p>Allow users to apply different replication and reclamation policies to different namespace parts.</p></li></ol><h4 id="how-to-handle-the-possible-stale-replicas"><a class="markdownIt-Anchor" href="#how-to-handle-the-possible-stale-replicas"></a> How to handle the possible stale replicas?</h4><ol><li><p>For each chunk, the master maintains a chunk version number to distinguish between up-to-date and stale replicas.</p></li><li><p>Whenever the master grants a new lease on a chunk, the chunk version number increases and informs the up-to-date replicas. This occurs before any client is notified before it can start writing to the chunk.</p></li><li><p>If one replica is unavailable, its chunk version number will not be advanced. The master will detect that this chunkserver has a stale replica when the chunkserver restarts and reports its set of chunks and associated version numbers.</p></li><li><p>The master removes stale replicas in its regular garbage collection. Before that, it effectively considers a stale replica not to exist when it replies to client requests for chunk information.</p></li><li><p>The master includes the chunk version number when it informs clients which chunkserver holds a lease on a chunk or instructs a chunkserver to read the chunk from another chunkserver in a cloning operation.</p></li></ol><h2 id="fault-tolerance"><a class="markdownIt-Anchor" href="#fault-tolerance"></a> Fault tolerance</h2><h3 id="how-to-handle-master-failure"><a class="markdownIt-Anchor" href="#how-to-handle-master-failure"></a> How to handle master failure?</h3><ol><li><p>The master state is replicated for reliability.</p><ul><li><p>When it fails, it can restart almost instantly.</p></li><li><p>When its machine or disk fails, monitoring infrastructure outside GFS starts a new master process elsewhere with the replicated operation log.</p></li><li><p>Clients use only the canonical name of the master, which is a DNS alias that can be changed if the master is relocated to another machine.</p></li></ul></li><li><p>“Shadow” masters provide read-only access to the file system even when the primary master is down.</p><ul><li><p>They enhance read availability for files not being actively mutated or applications that do not mind getting slightly stale results.</p></li><li><p>Since file content is read from chunkservers, applications do not observe stale content. What could be stale within short windows is file metadata.</p></li><li><p>To keep itself informed, a shadow master reads a replica of the growing operation log and applies the same sequence of changes to its data structures exactly as the primary does.</p></li><li><p>It depends on the primary master only for replica location updates resulting from the primary’s decisions to create and delete replicas.</p></li></ul></li></ol><h3 id="why-cannot-recover-data-using-other-chunk-replicas-why-each-chunkserver-must-independently-verify-the-integrity"><a class="markdownIt-Anchor" href="#why-cannot-recover-data-using-other-chunk-replicas-why-each-chunkserver-must-independently-verify-the-integrity"></a> Why cannot recover data using other chunk replicas? Why each chunkserver must independently verify the integrity?</h3><ol><li><p>It would be impractical to detect corruption by comparing replicas across chunkservers.</p></li><li><p>Divergent replicas may be legal: the semantics of GFS mutations, in particular atomic record append, do not guarantee identical replicas.</p></li></ol><h3 id="how-to-ensure-data-integrity"><a class="markdownIt-Anchor" href="#how-to-ensure-data-integrity"></a> How to ensure data integrity?</h3><ol><li><p>Each chunkserver uses checksumming to detect corruption of stored data. A chunk is broken up into 64 KB blocks. Each has a corresponding 32-bit checksum.</p></li><li><p>Checksums are kept in memory and stored persistently with logging, separate from user data.</p></li><li><p>During idle periods, chunkservers can scan and verify the contents of inactive chunks.</p></li></ol><h3 id="how-to-read-data-with-checksum"><a class="markdownIt-Anchor" href="#how-to-read-data-with-checksum"></a> How to read data with checksum?</h3><ol><li><p>The chunkserver verifies the checksum of data blocks that overlap the read range before returning any data to the requester, whether a client or another chunkserver.</p></li><li><p>If a block does not match the recorded checksum, the chunkserver returns an error to the requestor and reports the mismatch to the master.</p></li><li><p>In response, the requestor will read from other replicas, while the master will clone the chunk from another replica.</p></li><li><p>After a valid new replica is in place, the master instructs the chunkserver that reported the mismatch to delete its replica.</p></li></ol><h3 id="how-to-write-data-with-checksum"><a class="markdownIt-Anchor" href="#how-to-write-data-with-checksum"></a> How to write data with checksum?</h3><ol><li><p>For writes that append to the end of a chunk, we incrementally update the checksum for the last partial checksum block and compute new checksums for any new checksum blocks filled by the append.</p><ul><li>Even if the last partial checksum block is already corrupted and we fail to detect it now, the new checksum value will not match the stored data, and the corruption will be detected as usual when the block is next read.</li></ul></li><li><p>If a write overwrites an existing range of the chunk, we must read and verify the first and last blocks of the range being overwritten, then perform the write, and finally compute and record the new checksums.</p><ul><li>If we do not verify the first and last blocks before partially overwriting them, the new checksums may hide corruption in the regions not being overwritten.</li></ul></li></ol><h3 id="what-is-included-in-the-diagnostic-logs"><a class="markdownIt-Anchor" href="#what-is-included-in-the-diagnostic-logs"></a> What is included in the diagnostic logs?</h3><ol><li><p>GFS servers generate diagnostic logs that record significant events (such as chunkservers going up and down) and all RPC requests and replies.</p></li><li><p>The RPC logs include the exact requests and responses sent on the wire, except for the file data being read or written.</p></li></ol><h2 id="other-parts-unmentioned"><a class="markdownIt-Anchor" href="#other-parts-unmentioned"></a> Other parts (unmentioned)</h2><h3 id="to-sum-up-what-is-the-metadata-of-the-master-and-where-are-they"><a class="markdownIt-Anchor" href="#to-sum-up-what-is-the-metadata-of-the-master-and-where-are-they"></a> To sum up, what is the metadata of the master, and where are they?</h3><ol><li><p>File name: this is an array of chunk handles. It is stored on disk.</p></li><li><p>Handle: it contains a list of chunkservers, version number, primary, and lease expiration.</p><ul><li><p>Only the version number is stored on disk; the rest can be restored by asking chunkservers when the master is recovered.</p></li><li><p>Given that there might be stale chunks, we cannot ask chunkservers for the version number of a chunk.</p></li></ul></li><li><p>Lops and checkpoints are stored on disk.</p></li></ol><h3 id="what-is-the-cause-of-a-split-brain-how-to-solve-it"><a class="markdownIt-Anchor" href="#what-is-the-cause-of-a-split-brain-how-to-solve-it"></a> What is the cause of a split-brain? How to solve it?</h3><ol><li>The split brain is caused by network partition; the master cannot talk to the primary, while the primary can talk to clients. Hence the master mistakingly designates two primary for the same chunk.</li><li>The master knows when the lease will expire, so when the master cannot talk to the primary, it will wait until the lease expires before assigning another primary.</li></ol><h3 id="why-does-gfs-not-overwrite-those-failed-records-immediately-but-leave-padding-and-duplicates"><a class="markdownIt-Anchor" href="#why-does-gfs-not-overwrite-those-failed-records-immediately-but-leave-padding-and-duplicates"></a> Why does GFS not overwrite those failed records immediately but leave padding and duplicates?</h3><p>When it starts to write the next record, it may not know the fate of the prior record.</p><h3 id="gfs-is-a-weak-consistency-system-how-can-we-upgrade-it-to-a-strong-one"><a class="markdownIt-Anchor" href="#gfs-is-a-weak-consistency-system-how-can-we-upgrade-it-to-a-strong-one"></a> GFS is a weak consistency system; how can we upgrade it to a strong one?</h3><ol><li>Primary detects duplicate requests to ensure the failed write doesn’t show up twice.</li><li>When the primary asks a secondary to do something, the secondary actually does it and doesn’t just return an error (except the secondary has permanent damage, in which case, it should be removed)</li><li>The secondary only exposes data to readers once the primary is sure that all the secondaries will execute the append.</li><li>When the primary crashes, there will be some last set of operations that the primary launched for the secondaries. Still, the primary crashed before ensuring all operations are done—the new primary needs to explicitly resync with all secondaries.</li></ol><h1 id="experiments-and-results"><a class="markdownIt-Anchor" href="#experiments-and-results"></a> Experiments and results</h1><h2 id="micro-benchmarks"><a class="markdownIt-Anchor" href="#micro-benchmarks"></a> Micro-benchmarks</h2><p>The author first tested several micro-benchmarks, i.e., reads, writes, and record appends. These tests are that <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>N</mi></mrow><annotation encoding="application/x-tex">N</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">N</span></span></span></span> clients do those operations simultaneously. For reading, they read from the file system; for writing, they write to distinct files; for appending, they append to a single file. And test the aggregate throughputs of the system, comparing them with the network limit. The results are as follows:</p><p><img src="/imgs/Distributed/GFS/03.png" alt="" /></p><h3 id="read"><a class="markdownIt-Anchor" href="#read"></a> Read</h3><p>The reading efficiency drops because as the number of readers increases, so does the probability that multiple readers simultaneously read from the same chunkserver.</p><h3 id="write"><a class="markdownIt-Anchor" href="#write"></a> Write</h3><p>The limit plateaus of the write rate is 67 MB/s because we need to write each byte to 3 of the 16 chunkservers, each with a 12.5 MB/s input connection.</p><p>The network stack is the main culprit for a low write rate with only one client. It does not interact well with the pipelining scheme we use to push data to chunk replicas. Delays in propagating data from one replica to another reduce the overall write rate.</p><p>As the number of clients grows, it becomes more likely that multiple clients will write concurrently to the same chunkserver as the number of clients increases. Moreover, the collision has more potential for 16 writers than 16 readers because each involves three replicas.</p><p>Writes are slower than we would like. In practice, this has not been a major problem because even though it increases the latencies seen by individual clients, it does not significantly affect the aggregate write bandwidth delivered by the system to a large number of clients.</p><h3 id="record-append"><a class="markdownIt-Anchor" href="#record-append"></a> Record append</h3><p>The performance of record appends is limited by the network bandwidth of the chunkservers that store the last chunk of the file, independent of the number of clients.</p><p>The append rate drops primarily due to congestion and variances in network transfer rates seen by different clients.</p><p>The chunkserver network congestion in our experiment is not a significant issue in practice because a client can progress on writing one file. In contrast, the chunkservers for another file are busy.</p><h2 id="real-world-clusters"><a class="markdownIt-Anchor" href="#real-world-clusters"></a> Real-world clusters</h2><p>The author also measured the performance of real-world clusters. First, the author measured their storage usage and the size of metadata. Then, the read rate, write rate, and the rate of operations sent to the master were measured. The results show that the master can easily keep up with this rate and, therefore, is not a bottleneck for these workloads.</p><p><img src="/imgs/Distributed/GFS/04.png" style="zoom: 33%;" /><img src="/imgs/Distributed/GFS/05.png" style="zoom: 31%;" /></p><p>After a chunkserver fails, some chunks become underreplicated and must be cloned to restore their replication levels. To test the recovery time, the author killed a single chunkserver containing 15000 chunks of 600 GB data.</p><p>To limit the impact on running applications and provide leeway for scheduling decisions, our default parameters limit this cluster to 91 concurrent clonings (40% of the number of chunkservers) where each clone operation is allowed to consume at most 6.25 MB/s (50 Mbps). All chunks were restored in 23.2 minutes at an effective replication rate of 440 MB/s.</p><p>Finally, the author also measured the workload of chunkserver and master and broke down the workload of chunkserver by size, the same as that of master by type. Table 4 shows the distribution of operations by size, and Table 5 shows the total amount of data transferred in operations of various sizes.</p><p><img src="/imgs/Distributed/GFS/06.png" style="zoom:25%;" /><img src="/imgs/Distributed/GFS/07.png" style="zoom:25%;" /><img src="/imgs/Distributed/GFS/08.png" style="zoom: 31%;" /></p>]]></content>
      
      
      <categories>
          
          <category> Paper Notebook </category>
          
          <category> Distributed System </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Distributed System </tag>
            
            <tag> Distributed Storage </tag>
            
            <tag> File System </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>MapReduce</title>
      <link href="/2023/09/26/Paper/Distributed/MapReduce/"/>
      <url>/2023/09/26/Paper/Distributed/MapReduce/</url>
      
        <content type="html"><![CDATA[<p>Paper: <a href="http://nil.csail.mit.edu/6.824/2020/papers/mapreduce.pdf">MapReduce: Simplified Data Processing on Large Clusters</a></p><p><ul class="markdownIt-TOC"><li><a href="#abstract">Abstract</a></li><li><a href="#purpose">Purpose</a></li><li><a href="#model">Model</a><ul><li><a href="#paper-ideas">Paper ideas</a><ul><li><a href="#what-do-users-need-to-do">What do users need to do?</a></li><li><a href="#what-does-the-run-time-system-need-to-do">What does the run-time system need to do?</a></li><li><a href="#how-does-the-system-run">How does the system run?</a></li><li><a href="#what-does-the-master-need-to-do">What does the master need to do?</a></li><li><a href="#how-to-handle-worker-failure">How to handle worker failure?</a></li><li><a href="#how-to-handle-master-failure">How to handle master failure?</a></li><li><a href="#how-to-partition-reduce-tasks">How to partition reduce tasks?</a></li><li><a href="#how-do-we-ensure-that-nobody-observes-partially-written-files-during-crashes">How do we ensure that nobody observes partially written files during crashes?</a></li><li><a href="#how-to-handle-straggler-problems">How to handle straggler problems?</a></li></ul></li><li><a href="#reproduce">Reproduce</a><ul><li><a href="#how-do-we-assign-map-tasks">How do we assign map tasks?</a></li><li><a href="#how-do-we-assign-reduce-tasks">How do we assign reduce tasks?</a></li><li><a href="#when-can-workers-stop-requesting-more-map-tasksreduce-tasks">When can workers stop requesting more map tasks/reduce tasks?</a></li></ul></li></ul></li><li><a href="#experiments-and-results">Experiments and results</a></li></ul></p><h1 id="abstract"><a class="markdownIt-Anchor" href="#abstract"></a> Abstract</h1><ol><li><strong>Main idea</strong>: Asking the user to write a simple Map and Reduce functions. The distributed executing framework supporting parallel scheduling is provided as a standard library that will run those functions automatically.</li><li><strong>Key findings</strong>: Map and Reduce are easier to write and depend on the specific application. Despite their different implementations, their distribution and parallelism are similar and can be handled by a common framework.</li><li><strong>The system</strong>: A master will assign and monitor each task and node while several workers will perform the Map and Reduce phases sequentially.</li><li><strong>Evaluation</strong>: The system is evaluated on grep and sort tasks with benchmarks of disk I/O speed and duration of each phase.</li></ol><h1 id="purpose"><a class="markdownIt-Anchor" href="#purpose"></a> Purpose</h1><ol><li>Issues: Hard to parallel computation, distribute data, and handle server failures</li><li>Contribution: Proposed an interface where users only need to write relatively simple Map and Reduce functions, and the system will parallel and distribute automatically.</li></ol><h1 id="model"><a class="markdownIt-Anchor" href="#model"></a> Model</h1><h2 id="paper-ideas"><a class="markdownIt-Anchor" href="#paper-ideas"></a> Paper ideas</h2><h3 id="what-do-users-need-to-do"><a class="markdownIt-Anchor" href="#what-do-users-need-to-do"></a> What do users need to do?</h3><ol><li>Users need to provide a Map function and a Reduce function.</li><li>The map function will read the original data as key-value pairs, take one pair as input each time, and output intermediate key-value pairs, i.e. <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>m</mi><mi>a</mi><mi>p</mi><mo stretchy="false">(</mo><mi>k</mi><mn>1</mn><mo separator="true">,</mo><mi>v</mi><mn>1</mn><mo stretchy="false">)</mo><mo>→</mo><mi>l</mi><mi>i</mi><mi>s</mi><mi>t</mi><mo stretchy="false">(</mo><mi>k</mi><mn>2</mn><mo separator="true">,</mo><mi>v</mi><mn>2</mn><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">map(k1,v1)\rightarrow list(k2,v2)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">m</span><span class="mord mathnormal">a</span><span class="mord mathnormal">p</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.03148em;">k</span><span class="mord">1</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">v</span><span class="mord">1</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">→</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.01968em;">l</span><span class="mord mathnormal">i</span><span class="mord mathnormal">s</span><span class="mord mathnormal">t</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.03148em;">k</span><span class="mord">2</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">v</span><span class="mord">2</span><span class="mclose">)</span></span></span></span></li><li>The reduce function will take the intermediate key and a list of all intermediate values for that key as input and merge these values to form a smaller set of values, i.e. <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>r</mi><mi>e</mi><mi>d</mi><mi>u</mi><mi>c</mi><mi>e</mi><mo stretchy="false">(</mo><mi>k</mi><mn>2</mn><mo separator="true">,</mo><mi>l</mi><mi>i</mi><mi>s</mi><mi>t</mi><mo stretchy="false">(</mo><mi>v</mi><mn>2</mn><mo stretchy="false">)</mo><mo stretchy="false">)</mo><mo>→</mo><mi>l</mi><mi>i</mi><mi>s</mi><mi>t</mi><mo stretchy="false">(</mo><mi>v</mi><mn>2</mn><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">reduce(k2,list(v2))\rightarrow list(v2)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mord mathnormal">e</span><span class="mord mathnormal">d</span><span class="mord mathnormal">u</span><span class="mord mathnormal">c</span><span class="mord mathnormal">e</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.03148em;">k</span><span class="mord">2</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal" style="margin-right:0.01968em;">l</span><span class="mord mathnormal">i</span><span class="mord mathnormal">s</span><span class="mord mathnormal">t</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.03588em;">v</span><span class="mord">2</span><span class="mclose">)</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">→</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.01968em;">l</span><span class="mord mathnormal">i</span><span class="mord mathnormal">s</span><span class="mord mathnormal">t</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.03588em;">v</span><span class="mord">2</span><span class="mclose">)</span></span></span></span></li><li>Users must implement the Mapper and Reducer as an interface provided by the system and pass them to the MapReduce specification. After passing the input and output files, invoke the <code>MapReduce</code> function to execute.</li></ol><h3 id="what-does-the-run-time-system-need-to-do"><a class="markdownIt-Anchor" href="#what-does-the-run-time-system-need-to-do"></a> What does the run-time system need to do?</h3><ol><li>Partition data</li><li>Schedule across a set of machines.</li><li>Handle machine failures</li><li>Manage inter-machine communication.</li></ol><h3 id="how-does-the-system-run"><a class="markdownIt-Anchor" href="#how-does-the-system-run"></a> How does the system run?</h3><ol><li>When the <code>MapReduce</code> function is invoked, one <strong>master</strong> and several <strong>worker</strong> processes will be forked.</li><li>The master will assign work to workers, either a Map or Reduce work.</li><li>Master tries to make most of the <code>(3) read</code> run locally. In the <code>(5) remote read</code>, network communication is inevitable.<br /><img src="/imgs/Distributed/MapReduce/01.png" style="zoom: 50%;" /></li></ol><h3 id="what-does-the-master-need-to-do"><a class="markdownIt-Anchor" href="#what-does-the-master-need-to-do"></a> What does the master need to do?</h3><ol><li>Master pings every worker periodically and marks those who have not responded in a certain amount of time as failed.</li><li>Track the state of each map task and reduce task (idle, in progress, or completed) and the identity of the worker machine (for non-idle tasks).</li><li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>M</mi></mrow><annotation encoding="application/x-tex">M</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">M</span></span></span></span> is the number of map tasks, while <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>R</mi></mrow><annotation encoding="application/x-tex">R</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.00773em;">R</span></span></span></span> is the number of reduce tasks. The master must make <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>O</mi><mo stretchy="false">(</mo><mi>M</mi><mo>+</mo><mi>R</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">O(M+R)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">O</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.10903em;">M</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="mclose">)</span></span></span></span> scheduling decisions, and keeps <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>O</mi><mo stretchy="false">(</mo><mi>M</mi><mo>∗</mo><mi>R</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">O(M*R)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">O</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.10903em;">M</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="mclose">)</span></span></span></span> state in memory (all map task/reduce task pair).</li></ol><h3 id="how-to-handle-worker-failure"><a class="markdownIt-Anchor" href="#how-to-handle-worker-failure"></a> How to handle worker failure?</h3><ol><li>What kinds of worker failure need re-execution?<ul><li>Any tasks in progress</li><li>Completed map tasks must also be re-executed since their output is stored on the local disks and is inaccessible.</li><li>Completed reduce tasks don’t need to be re-executed since their output is stored on the global file system.</li></ul></li><li>The master will mark the state of those tasks that need re-execution to idle and can assign them to other workers in the future.</li></ol><h3 id="how-to-handle-master-failure"><a class="markdownIt-Anchor" href="#how-to-handle-master-failure"></a> How to handle master failure?</h3><ol><li>One way is to make the master write periodic checkpoints of the master data structure.</li><li>Given that there is only a single master, its failure is unlikely. Therefore, another way is to abort the MapReduce computation if the master fails, and clients can try again later. (This is the way the author takes)</li></ol><h3 id="how-to-partition-reduce-tasks"><a class="markdownIt-Anchor" href="#how-to-partition-reduce-tasks"></a> How to partition reduce tasks?</h3><p>The number of reduce tasks/output files (<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>R</mi></mrow><annotation encoding="application/x-tex">R</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.00773em;">R</span></span></span></span>) is specified by the users. The default partitioning uses hashing, namely partitioning according to <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>h</mi><mi>a</mi><mi>s</mi><mi>h</mi><mo stretchy="false">(</mo><mi>k</mi><mi>e</mi><mi>y</mi><mo stretchy="false">)</mo><mtext> </mtext><mi>m</mi><mi>o</mi><mi>d</mi><mtext> </mtext><mi>R</mi></mrow><annotation encoding="application/x-tex">hash(key)\ mod\ R</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">h</span><span class="mord mathnormal">a</span><span class="mord mathnormal">s</span><span class="mord mathnormal">h</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.03148em;">k</span><span class="mord mathnormal">e</span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="mclose">)</span><span class="mspace"> </span><span class="mord mathnormal">m</span><span class="mord mathnormal">o</span><span class="mord mathnormal">d</span><span class="mspace"> </span><span class="mord mathnormal" style="margin-right:0.00773em;">R</span></span></span></span>.</p><h3 id="how-do-we-ensure-that-nobody-observes-partially-written-files-during-crashes"><a class="markdownIt-Anchor" href="#how-do-we-ensure-that-nobody-observes-partially-written-files-during-crashes"></a> How do we ensure that nobody observes partially written files during crashes?</h3><p>Each worker first writes their results to a temporary file. Then, rename it once all writes are completed.</p><h3 id="how-to-handle-straggler-problems"><a class="markdownIt-Anchor" href="#how-to-handle-straggler-problems"></a> How to handle straggler problems?</h3><ol><li>Straggler: a machine that takes an unusually long to complete one of the last few map or reduce tasks. A bad disk may cause this; its scheduling system schedules it for different tasks.</li><li>So when a MapReduce operation is close to completion, the master schedules backup executions of the remaining in-progress tasks.</li></ol><h2 id="reproduce"><a class="markdownIt-Anchor" href="#reproduce"></a> Reproduce</h2><p>This reproduction part is based on Lab 1 of MIT 6.824.</p><h3 id="how-do-we-assign-map-tasks"><a class="markdownIt-Anchor" href="#how-do-we-assign-map-tasks"></a> How do we assign map tasks?</h3><p>Each worker will request for more map tasks when it becomes idle, and the master will assign files directly to them.</p><h3 id="how-do-we-assign-reduce-tasks"><a class="markdownIt-Anchor" href="#how-do-we-assign-reduce-tasks"></a> How do we assign reduce tasks?</h3><ol><li>When workers are notified that there are no more map tasks, they request reduce tasks. This time, the master won’t assign files directly. Instead, the master will only assign a number in the range from <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>0</mn></mrow><annotation encoding="application/x-tex">0</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">0</span></span></span></span> to <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>R</mi><mo>−</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">R-1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.76666em;vertical-align:-0.08333em;"></span><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">1</span></span></span></span>. Then, each worker will try to read intermediate files from each worker according to their number automatically.</li><li>This requires those map workers to store their output in a previously agreed file name to reduce workers’ requests.</li></ol><h3 id="when-can-workers-stop-requesting-more-map-tasksreduce-tasks"><a class="markdownIt-Anchor" href="#when-can-workers-stop-requesting-more-map-tasksreduce-tasks"></a> When can workers stop requesting more map tasks/reduce tasks?</h3><ol><li>Only after all map tasks are completed can workers stop requesting more map tasks and begin to request reduced tasks since reduced tasks may depend on those unfinished map tasks. So, workers’ lifecycles can be partitioned into two phases: the map phase and the reduce phase.</li><li>Also, only after all reduced tasks are completed can workers stop requesting more reduced tasks and quit the program. This is because those executing yet uncompleted tasks may fail, and when that happens, we need other workers to re-execute those tasks.</li><li>Similarly, reduce workers cannot delete those intermediate files right after they read them. Because if they fail, their successor needs to read those files.</li></ol><h1 id="experiments-and-results"><a class="markdownIt-Anchor" href="#experiments-and-results"></a> Experiments and results</h1><ol><li><strong>What to notice when configuring a cluster?</strong><ul><li>Need to reserve some memory for other tasks running on the cluster. The author reserved <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1</mn><mo>−</mo><mn>1.5</mn></mrow><annotation encoding="application/x-tex">1-1.5</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.72777em;vertical-align:-0.08333em;"></span><span class="mord">1</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">1</span><span class="mord">.</span><span class="mord">5</span></span></span></span> GB out of <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>4</mn></mrow><annotation encoding="application/x-tex">4</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">4</span></span></span></span> GB.</li><li>Best test when the CPUs, disks, and network were mostly idle.</li></ul></li><li>The author tested two representative situations, grep and sort.</li><li>In the grep test, the execution time includes a minute of startup overhead over <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>150</mn></mrow><annotation encoding="application/x-tex">150</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">1</span><span class="mord">5</span><span class="mord">0</span></span></span></span> seconds of total time. The overhead is due to the propagation of the program to all worker machines and delays interacting with GFS to open the set of input files and to get the information needed for the locality optimization.<br /><img src="/imgs/Distributed/MapReduce/02.png" style="zoom: 33%;" /></li><li>In the sort test,<ul><li>It only consists of less than <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>50</mn></mrow><annotation encoding="application/x-tex">50</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">5</span><span class="mord">0</span></span></span></span> lines of user code</li><li>The entire computation time, including startup overhead, is similar to the best-reported result.</li><li>The author tested three kinds of rates: the rate of reading by map workers (<em>input rate</em>), the rate of communicating intermediate files between map workers and reduce workers (<em>shuffle rate</em>), and the rate of writing output files by reduce workers (<em>output rate</em>). These are the I/O parts that affect the performance significantly.<ul><li>The input rate is less than grep because sort map tasks require more time to write intermediate output to their local disks.</li><li>Because of locality optimization, the input rate is higher than the shuffle rate and the output rate.</li><li>The shuffle rate is higher than the output rate because the output phase writes replicas due to the mechanism for reliability of the underlying file system.</li></ul></li><li>The author also tested when <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>200</mn></mrow><annotation encoding="application/x-tex">200</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">2</span><span class="mord">0</span><span class="mord">0</span></span></span></span> out of <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1746</mn></mrow><annotation encoding="application/x-tex">1746</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">1</span><span class="mord">7</span><span class="mord">4</span><span class="mord">6</span></span></span></span> workers are killed for several minutes. The underlying cluster scheduler immediately restarted new worker processes on these machines (only the processes were killed; the machines were still functioning correctly). The entire computation time increases of <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>5</mn><mi mathvariant="normal">%</mi></mrow><annotation encoding="application/x-tex">5\%</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.80556em;vertical-align:-0.05556em;"></span><span class="mord">5</span><span class="mord">%</span></span></span></span> over the normal execution time.<br /><img src="/imgs/Distributed/MapReduce/03.png" style="zoom:50%;" /></li></ul></li></ol>]]></content>
      
      
      <categories>
          
          <category> Paper Notebook </category>
          
          <category> Distributed System </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Distributed System </tag>
            
            <tag> Distributed Computation </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>17 Distributed OLAP Databases</title>
      <link href="/2023/09/03/Courses/15445/17-Distributed-OLAP-Databases/"/>
      <url>/2023/09/03/Courses/15445/17-Distributed-OLAP-Databases/</url>
      
        <content type="html"><![CDATA[<p><ul class="markdownIt-TOC"><li><a href="#how-should-we-divide-tables">How should we divide tables?</a></li><li><a href="#execution-models">Execution models</a><ul><li><a href="#how-to-execute-when-required-data-are-in-different-nodes">How to execute when required data are in different nodes?</a></li><li><a href="#how-to-handle-query-faults">How to handle query faults?</a></li><li><a href="#when-pushing-a-query-to-data-what-are-the-queries">When pushing a query to data, what are the queries?</a></li></ul></li><li><a href="#distributed-join-algorithms">Distributed Join Algorithms</a><ul><li><a href="#how-to-perform-distributed-joins">How to perform distributed joins?</a></li><li><a href="#what-is-semi-join">What is semi-join?</a></li></ul></li><li><a href="#cloud-systems">Cloud systems</a><ul><li><a href="#what-is-the-difference-for-dbmss-running-in-cloud-systems">What is the difference for DBMSs running in cloud systems?</a></li><li><a href="#how-to-store-data-of-different-schema">How to store data of different schema?</a></li><li><a href="#how-to-share-data-between-systems">How to share data between systems?</a></li></ul></li></ul></p><h1 id="how-should-we-divide-tables"><a class="markdownIt-Anchor" href="#how-should-we-divide-tables"></a> How should we divide tables?</h1><ol><li>The first schema is the star schema.<ul><li>Star schemas contain two types of tables: fact tables and dimension tables.</li><li>The fact table contains multiple “events” that occur in the application. It will contain minimal unique information per event.</li><li>The remaining attributes will be foreign key references to outer dimension tables.</li><li>In a star schema, there can only be one dimension-level out of the fact table.</li></ul></li><li>The second schema is the snowflake schema.<ul><li>It allows for more than one dimension out of the fact table.</li></ul></li><li>Snowflake schemas take up less storage space. Denormalized data models may incur integrity and consistency violations.</li><li>Snowflake schemas require more joins to get the data needed for a query. Queries on star schemas will usually be faster.</li></ol><h1 id="execution-models"><a class="markdownIt-Anchor" href="#execution-models"></a> Execution models</h1><h2 id="how-to-execute-when-required-data-are-in-different-nodes"><a class="markdownIt-Anchor" href="#how-to-execute-when-required-data-are-in-different-nodes"></a> How to execute when required data are in different nodes?</h2><ol><li>The first approach is to push the query to data.<ul><li>Send the query (or a portion of it) to the node that contains the data.</li><li>The result is then sent back to where the query is being executed, which uses local data and the data sent to it to complete the query.</li><li>Perform as much filtering and processing as possible where data resides before transmitting over the network.</li><li>This is more common in a shared-nothing system.</li></ul></li><li>The second approach is to pull data to query.<ul><li>Bring the data to the node and execute a query that needs processing.</li><li>This usually is what a shared disk system would do.</li><li>The problem with this is that the data size relative to the query size could be very different.</li></ul></li></ol><h2 id="how-to-handle-query-faults"><a class="markdownIt-Anchor" href="#how-to-handle-query-faults"></a> How to handle query faults?</h2><ol><li>The data a node receives from remote sources is cached in the buffer pool.<ul><li>When the buffer pool runs out of memory, the DBMS can write some pages out to disk in some ephemeral pages.</li><li>This allows the DBMS to support intermediate results larger than the amount of memory available.</li><li>Ephemeral pages are not persisted after a restart.</li></ul></li><li>Most shared-nothing distributed OLAP DBMSs are designed to assume that nodes do not fail during query execution.<ul><li>If one node fails during query execution, then the whole query fails.</li></ul></li><li>The DBMS could take a snapshot of the intermediate results for a query during execution to allow it to recover if nodes fail.<ul><li>Most DMBSs do not want to pay the penalty of writing intermediate results to disk for quick queries.</li><li>This is adopted if the query takes a long time.</li></ul></li><li>In shared-disk distributed OLAP DMBSs, they can write results to the shared disk to prevent performing the same calculation again. However, the frequency of writing to disk is also a trade-off.</li></ol><h2 id="when-pushing-a-query-to-data-what-are-the-queries"><a class="markdownIt-Anchor" href="#when-pushing-a-query-to-data-what-are-the-queries"></a> When pushing a query to data, what are the queries?</h2><ol><li>The DBMSs only need to push fragments of the query instead of the whole query.</li><li>The first approach is pushing physical operators.<ul><li>Generate a single query plan and then break it up into partition-specific fragments.</li><li>Most systems implement this approach.</li></ul></li><li>The second approach is pushing another SQL query.<ul><li>The DBMS will rewrite the original query into partition-specific queries.</li><li>This approach allows for local optimization at each node.</li></ul></li></ol><h1 id="distributed-join-algorithms"><a class="markdownIt-Anchor" href="#distributed-join-algorithms"></a> Distributed Join Algorithms</h1><h2 id="how-to-perform-distributed-joins"><a class="markdownIt-Anchor" href="#how-to-perform-distributed-joins"></a> How to perform distributed joins?</h2><ol><li>One approach is to put entire tables on a single node and then perform the join.<ul><li>You lose the parallelism of a distributed DBMS.</li><li>It has expensive data transferring over the network.</li></ul></li><li>The DBMS needs to get the proper tuples on the same node to join tables. The DBMS executes the single-node join algorithms once the data is at the node.</li><li>The best scenario is that one table is replicated at every node.<ul><li>Each node joins its local data in parallel and then sends its results to a coordinating node.</li></ul></li><li>The second scenario is that tables are partitioned on the join attribute.<ul><li>Each node only needs to acquire tuples of the second table that will match the tuples of the left table already in it.</li><li>Each node performs the join on local data and then sends it to a coordinator node for coalescing.</li></ul></li><li>The third scenario is that both tables are partitioned on different keys while one of the tables is small.<ul><li>The DBMS will broadcast that table to all nodes.</li></ul></li><li>The worst scenario is that neither table is partitioned on the join key.<ul><li>The DBMS copies the tables by shuffling them across nodes.</li></ul></li></ol><h2 id="what-is-semi-join"><a class="markdownIt-Anchor" href="#what-is-semi-join"></a> What is semi-join?</h2><ol><li>If the result only contains columns from the left table, the DBMSs use semi-join to minimize the amount of data sent during joins.</li><li>This is like a projection pushdown. The DBMS transmits only the necessary columns of the left table to other nodes.</li><li>For DBMSs that do not support <code>SEMI JOIN</code>, we can fake it with <code>EXISTS</code>.<ul><li>Wrap the <code>WHERE</code> clause predicates with <code>EXISTS (SELECT 1 from S WHERE predicates)</code>.</li></ul></li></ol><h1 id="cloud-systems"><a class="markdownIt-Anchor" href="#cloud-systems"></a> Cloud systems</h1><h2 id="what-is-the-difference-for-dbmss-running-in-cloud-systems"><a class="markdownIt-Anchor" href="#what-is-the-difference-for-dbmss-running-in-cloud-systems"></a> What is the difference for DBMSs running in cloud systems?</h2><ol><li>The first approach is managed DBMS.<ul><li>No significant modification to the DBMS to be aware that it is running in a cloud environment.</li></ul></li><li>The second approach is cloud-native DBMS.<ul><li>The system is designed explicitly to run in a cloud environment.</li><li>Usually based on a shared-disk architecture.</li></ul></li><li>A “serverless” DBMS evicts tenants when they become idle rather than always maintaining compute resources for each customer.</li></ol><h2 id="how-to-store-data-of-different-schema"><a class="markdownIt-Anchor" href="#how-to-store-data-of-different-schema"></a> How to store data of different schema?</h2><ol><li>A Data Lake is a centralized repository for storing large amounts of structured, semi-structured, and unstructured data without defining a schema or ingesting the data into proprietary internal formats.</li><li>Data lakes are usually faster at ingesting data, as they do not immediately require transformation. Yet, when fetching data, they must look up the catalog before transforming it into the desired schema.</li><li>They require the user to write their transformation pipelines.</li></ol><h2 id="how-to-share-data-between-systems"><a class="markdownIt-Anchor" href="#how-to-share-data-between-systems"></a> How to share data between systems?</h2><ol><li>Most DBMSs use a proprietary on-disk binary file format for their databases.</li><li>The only way to share data between systems is to convert data into a common text-based format.</li><li>New open-source binary file formats make it easier to access data across systems.</li></ol>]]></content>
      
      
      <categories>
          
          <category> Open Courses </category>
          
          <category> CMU 15-445/645 Database System </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Distributed System </tag>
            
            <tag> Database System </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>16 Distributed OLTP Databases</title>
      <link href="/2023/09/02/Courses/15445/16-Distributed-OLTP-Databases/"/>
      <url>/2023/09/02/Courses/15445/16-Distributed-OLTP-Databases/</url>
      
        <content type="html"><![CDATA[<p><ul class="markdownIt-TOC"><li><a href="#what-is-the-difference-between-oltp-and-olap">What is the difference between OLTP and OLAP?</a></li><li><a href="#2-phase-commit-2pc">2-Phase Commit (2PC)</a><ul><li><a href="#what-is-the-procedure-of-2pc">What is the procedure of 2PC?</a></li><li><a href="#what-would-happen-if-some-nodes-crash-during-2pc">What would happen if some nodes crash during 2PC?</a></li><li><a href="#how-to-recover-from-a-crash-during-2pc">How to recover from a crash during 2PC?</a></li><li><a href="#how-can-we-optimize-2pc-to-reduce-communication">How can we optimize 2PC to reduce communication?</a></li><li><a href="#what-is-the-difference-between-2pc-and-paxos">What is the difference between 2PC and Paxos?</a></li></ul></li><li><a href="#replication">Replication</a><ul><li><a href="#how-can-we-execute-readwrite-with-replication">How can we execute read/write with replication?</a></li><li><a href="#when-should-notify-the-application-of-the-result">When should notify the application of the result?</a></li><li><a href="#when-should-propagate-updates-between-nodes">When should propagate updates between nodes?</a></li><li><a href="#what-should-be-sent-to-the-followers">What should be sent to the followers?</a></li></ul></li></ul></p><h1 id="what-is-the-difference-between-oltp-and-olap"><a class="markdownIt-Anchor" href="#what-is-the-difference-between-oltp-and-olap"></a> What is the difference between OLTP and OLAP?</h1><ol><li>OLTP is the front-end database communicating and interacting with the outside world, e.g., applications. OLAP is the back-end database used to analyze the data in those front-end databases.</li><li>OLTP often executes repetitive, short-lived read/write transactions, while OLAP executes long-running, read-only queries involving complex joins.</li><li>Before going into the OLAP system, data in OLTP databases need an intermediate step called ETL, or Extract, Transform, and Load, which combines the OLTP databases into a universal schema for the data warehouse.</li></ol><h1 id="2-phase-commit-2pc"><a class="markdownIt-Anchor" href="#2-phase-commit-2pc"></a> 2-Phase Commit (2PC)</h1><h2 id="what-is-the-procedure-of-2pc"><a class="markdownIt-Anchor" href="#what-is-the-procedure-of-2pc"></a> What is the procedure of 2PC?</h2><ol><li>When an application sends a commit request to the coordinator, the coordinator tells other nodes to go into the first phase, the preparation phase.</li><li>When participants are ready, they will reply to the coordinator with acknowledgment.</li><li>If the coordinator receives an acknowledgment from all participants, they can begin the second commit phase.<ul><li>The coordinator will respond to the application successfully after receiving all participants’ acknowledgment of the commit phase.</li></ul></li><li>If the coordinator receives abort messages from any participants, the coordinator responds to the application with an abort message and begins the abort phase.<ul><li>As usual, participants need to reply with acknowledgment to the coordinator in the abort phase.</li></ul></li></ol><h2 id="what-would-happen-if-some-nodes-crash-during-2pc"><a class="markdownIt-Anchor" href="#what-would-happen-if-some-nodes-crash-during-2pc"></a> What would happen if some nodes crash during 2PC?</h2><ol><li>If the coordinator crashes, participants must decide what to do after a timeout: either abort or elect a new coordinator.<ul><li>The system is not available during this timeout.</li></ul></li><li>If one of the participants crashes, the coordinator assumes it responded with an abort if it hasn’t sent an acknowledgment yet.<ul><li>Nodes use a timeout to determine that the participant is dead.</li></ul></li></ol><h2 id="how-to-recover-from-a-crash-during-2pc"><a class="markdownIt-Anchor" href="#how-to-recover-from-a-crash-during-2pc"></a> How to recover from a crash during 2PC?</h2><ol><li>Each node records each phase’s inbound/outbound messages and outcomes in a non-volatile storage log.</li><li>On recovery, examine the log for 2PC messages.<ul><li>If the local transaction is prepared, contact the coordinator.</li><li>If the local transaction is not prepared, abort it.</li><li>If the local transaction is committed and the node is the coordinator, send a <code>COMMIT</code> message to nodes.</li></ul></li></ol><h2 id="how-can-we-optimize-2pc-to-reduce-communication"><a class="markdownIt-Anchor" href="#how-can-we-optimize-2pc-to-reduce-communication"></a> How can we optimize 2PC to reduce communication?</h2><ol><li>The first method is early prepare voting.<ul><li>If you send a query to a remote node that you know will be the last one you execute there, then that node will also return their vote for the prepare phase with the query result.</li><li>This is rare because database applications are rarely written with the idea of the last query.</li><li>However, this can be used in RPC sorts of things where we can be sure that this process will terminate after executing a certain query.</li></ul></li><li>The second method is early ACK after preparation.<ul><li>Suppose all nodes vote to commit a transaction. In that case, the coordinator can send the client an acknowledgment that their transaction was successful before the commit phase finishes, i.e., send an acknowledgment to the client after receiving all participant acknowledgments.</li><li>This could cause a small window of clients receiving success yet not seeing modifications from servers because the commit phase is not yet finished.</li></ul></li></ol><h2 id="what-is-the-difference-between-2pc-and-paxos"><a class="markdownIt-Anchor" href="#what-is-the-difference-between-2pc-and-paxos"></a> What is the difference between 2PC and Paxos?</h2><ol><li>2-phase commit is a degenerate case of Paxos.<ul><li>Paxos uses <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>2</mn><mi>F</mi><mo>+</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">2F + 1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.76666em;vertical-align:-0.08333em;"></span><span class="mord">2</span><span class="mord mathnormal" style="margin-right:0.13889em;">F</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">1</span></span></span></span> coordinators and makes progress as long as at least <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>F</mi><mo>+</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">F + 1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.76666em;vertical-align:-0.08333em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">F</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">1</span></span></span></span> of them are working properly.</li><li>2-phase commit sets <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>F</mi><mo>=</mo><mn>0</mn></mrow><annotation encoding="application/x-tex">F = 0</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">F</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">0</span></span></span></span>.</li></ul></li><li>2-phase commit blocks if the coordinator fails after the prepared message is sent until the coordinator recovers.<br />Paxos remains non-blocking if a majority of participants are alive, provided there is a sufficiently long period without further failures.</li><li>A 2-phase commit requires all nodes to agree on the commit, while Paxos only requires majority agreement.</li><li>In a 2-phase commit, each node may have different data, executing different commands. However, in Paxos, all nodes are only replications.</li></ol><h1 id="replication"><a class="markdownIt-Anchor" href="#replication"></a> Replication</h1><h2 id="how-can-we-execute-readwrite-with-replication"><a class="markdownIt-Anchor" href="#how-can-we-execute-readwrite-with-replication"></a> How can we execute read/write with replication?</h2><ol><li>The first approach is primary-replica.<ul><li>All updates go to a designated primary for each object. The primary propagates updates to its replicas without an atomic commit protocol.</li><li>Read-only transactions may allow access to replicas.</li><li>If the primary goes down, then hold an election to select a new primary.</li></ul></li><li>The second approach is multi-primary.<ul><li>Transactions can update data objects at any replica.</li><li>Replicas must synchronize with each other using an atomic commit protocol.</li></ul></li></ol><h2 id="when-should-notify-the-application-of-the-result"><a class="markdownIt-Anchor" href="#when-should-notify-the-application-of-the-result"></a> When should notify the application of the result?</h2><ol><li>When a transaction is committed on a replicated database, the DBMS decides whether to wait for its changes to propagate to other nodes before sending the acknowledgment to the application.</li><li>The first propagation level is synchronous, which leads to strong consistency.<ul><li>The primary sends updates to replicas and then waits for them to acknowledge that they fully applied (i.e., logged) the changes before sending an acknowledgment to the application.</li></ul></li><li>The second propagation level is asynchronous, which leads to eventual consistency.<ul><li>The primary immediately returns the acknowledgment to the client without waiting for replicas to apply the changes.</li></ul></li></ol><h2 id="when-should-propagate-updates-between-nodes"><a class="markdownIt-Anchor" href="#when-should-propagate-updates-between-nodes"></a> When should propagate updates between nodes?</h2><ol><li>The first approach is continuous.<ul><li>The DBMS sends log messages immediately as it generates them.</li><li>It also needs to send a commit/abort message.</li></ul></li><li>The second approach is to commit.<ul><li>The DBMS only sends the log messages for a transaction to the replicas once the transaction is committed.</li><li>Do not waste time sending log records for aborted transactions.</li><li>It assumes that a transaction’s log records fit entirely in memory.</li></ul></li></ol><h2 id="what-should-be-sent-to-the-followers"><a class="markdownIt-Anchor" href="#what-should-be-sent-to-the-followers"></a> What should be sent to the followers?</h2><ol><li>The first choice is active-active.<ul><li>A transaction executes at each replica independently.</li><li>Check at the end whether the transaction ends with the same result at each replica.</li></ul></li><li>The second choice is active-passive.<ul><li>Each transaction executes at a single location and propagates the changes to the replica.</li><li>Can either do physical or logical replication.</li></ul></li></ol>]]></content>
      
      
      <categories>
          
          <category> Open Courses </category>
          
          <category> CMU 15-445/645 Database System </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Distributed System </tag>
            
            <tag> Database System </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>15 Introduction to Distributed Databases</title>
      <link href="/2023/08/31/Courses/15445/15-Introduction-to-Distributed-Databases/"/>
      <url>/2023/08/31/Courses/15445/15-Introduction-to-Distributed-Databases/</url>
      
        <content type="html"><![CDATA[<p><ul class="markdownIt-TOC"><li><a href="#system-architecture">System architecture</a><ul><li><a href="#what-will-system-architecture-affect">What will system architecture affect?</a></li><li><a href="#what-is-shared-memory-architecture">What is shared memory architecture?</a></li><li><a href="#what-is-shared-disk-architecture">What is shared disk architecture?</a></li><li><a href="#what-is-shared-nothing-architecture">What is shared-nothing architecture?</a></li></ul></li><li><a href="#design-issues">Design issues</a><ul><li><a href="#what-are-the-design-issues-of-distributed-databases">What are the design issues of distributed databases?</a></li><li><a href="#what-do-nodes-look-like">What do nodes look like?</a></li><li><a href="#how-to-coordinate-execution">How to coordinate execution?</a></li></ul></li><li><a href="#partitioning-schemes">Partitioning Schemes</a><ul><li><a href="#what-do-we-desire-when-partitioning-a-database">What do we desire when partitioning a database?</a></li><li><a href="#how-can-we-partition-the-database">How can we partition the database?</a></li><li><a href="#how-can-we-optimize-horizontal-partitioning">How can we optimize horizontal partitioning?</a></li></ul></li></ul></p><h1 id="system-architecture"><a class="markdownIt-Anchor" href="#system-architecture"></a> System architecture</h1><h2 id="what-will-system-architecture-affect"><a class="markdownIt-Anchor" href="#what-will-system-architecture-affect"></a> What will system architecture affect?</h2><ol><li>A distributed DBMS’s system architecture specifies what shared resources are directly accessible to CPUs.</li><li>This affects how CPUs coordinate with each other and where they retrieve/store objects in the database.</li><li>There are four architectures: shared everything, shared memory, shared disk, and shared nothing.</li><li>In shared everything architecture, CPU, memories, and disks are all local. This is more of a parallel architecture than a distributed architecture.</li></ol><h2 id="what-is-shared-memory-architecture"><a class="markdownIt-Anchor" href="#what-is-shared-memory-architecture"></a> What is shared memory architecture?</h2><ol><li>CPUs have access to common memory address space via a fast interconnect.</li><li>Each processor has a global view of all the in-memory data structures.<ul><li>Each process’s memory scope is the same memory address space multiple processes can modify.</li></ul></li><li>Each DBMS instance on a processor must “know” about the other instances.</li><li>In practice, most DBMSs do not use this architecture, as it is provided at the OS/kernel level.</li></ol><img src="/imgs/15445/Distributed/shared_mem.png" width="30%"><h2 id="what-is-shared-disk-architecture"><a class="markdownIt-Anchor" href="#what-is-shared-disk-architecture"></a> What is shared disk architecture?</h2><ol><li>All CPUs can access a single logical disk directly via an interconnect, but each has its own private memories.</li><li>It can scale the execution layer independently from the storage layer.<ul><li>The advantage of shared disk over shared nothing is that it can easily scale up with the compute and storage layers independently.</li><li>What we want to persist after a crash is in the storage layer.</li><li>Theoretically, we can kill or add front-end nodes without losing the database or, add storage disks / change the storage layer by modifying compute nodes.</li></ul></li><li>It must send messages between CPUs to learn about their current state.</li><li>This architecture is commonly used in OLAP systems. Many DBSMs begin to think that shared disk architecture is better than shared nothing.</li></ol><img src="/imgs/15445/Distributed/shared_disk.png" width="30%"><h2 id="what-is-shared-nothing-architecture"><a class="markdownIt-Anchor" href="#what-is-shared-nothing-architecture"></a> What is shared-nothing architecture?</h2><ol><li>Each DBMS instance has its own CPU, memory, and local disk.</li><li>Nodes only communicate with each other via network.<ul><li>When executing a query that requires data from different nodes, the DBMS can either send data up to the node connected with the application or that node can ask another node to execute the query and return the result.</li></ul></li><li>All data in the database are sharded into different nodes.<ul><li>When adding a new node into the architecture, that node is initially empty. The DBMS must re-shard data so that they are distributed evenly.</li><li>It is more difficult to increase capacity because the DBMS has to move data to new nodes physically.</li><li>It might have a small window for queries to receive false positives because part of the data was in that node and is now moving to another node.</li></ul></li><li>It is also difficult to ensure consistency across all nodes in the DBMS since the nodes must coordinate with each other regarding the state of transactions.</li><li>However, it can potentially achieve better performance and be more efficient than other types of distributed DBMS architectures.</li></ol><img src="/imgs/15445/Distributed/shared_nothing.png" width="30%"><h1 id="design-issues"><a class="markdownIt-Anchor" href="#design-issues"></a> Design issues</h1><h2 id="what-are-the-design-issues-of-distributed-databases"><a class="markdownIt-Anchor" href="#what-are-the-design-issues-of-distributed-databases"></a> What are the design issues of distributed databases?</h2><ol><li>How does the application find data?</li><li>Where does the application send queries?</li><li>How to execute queries on distributed data? Push query to data? Or pull data to query?</li><li>How does the DBMS ensure correctness?</li><li>How do we divide the database across resources?</li></ol><h2 id="what-do-nodes-look-like"><a class="markdownIt-Anchor" href="#what-do-nodes-look-like"></a> What do nodes look like?</h2><ol><li>The first approach is homogenous nodes.<ul><li>Every node in the cluster can perform the same set of tasks, albeit on potentially different partitions of data.</li><li>Makes provisioning and failover “easier” since any node can replace other nodes.</li></ul></li><li>The second approach is heterogeneous nodes.<ul><li>Nodes are assigned specific tasks.</li><li>It can allow a single physical node to host multiple “virtual” node types for dedicated tasks.</li><li>A heterogeneous node design has two kinds of nodes: router and config server.<ul><li>The router can directly access shards of the database, yet it does not know where the data is wanted.</li><li>The config server knows the data contained in each shard. However, it is not responsible for retrieving them.</li></ul></li></ul></li></ol><h2 id="how-to-coordinate-execution"><a class="markdownIt-Anchor" href="#how-to-coordinate-execution"></a> How to coordinate execution?</h2><ol><li>If our DBMS supports multi-operation and distributed transactions, we need a way to coordinate their execution in the system.</li><li>The first approach is a centralized coordinator. A centralized coordinator receives commands from the application.<ul><li>The first design requires applications to handle transactions.<ul><li>The client communicates with the coordinator to acquire locks on the partitions that the client wants to access.</li><li>Once it receives an acknowledgment from the coordinator, the client sends its queries to those partitions.</li><li>Once all queries for a given transaction are done, the client sends a commit request to the coordinator.</li><li>The coordinator then communicates with the partitions involved in the transaction to determine whether the transaction is allowed to be committed.</li></ul></li><li>Another design uses middleware to accept query requests and route queries to correct partitions.</li></ul></li><li>The second approach is decentralized.<ul><li>The client directly sends queries to one of the partitions, which will be the leader node for that transaction.</li><li>The leader node will coordinate communicating with other partitions and committing.</li></ul></li></ol><h1 id="partitioning-schemes"><a class="markdownIt-Anchor" href="#partitioning-schemes"></a> Partitioning Schemes</h1><h2 id="what-do-we-desire-when-partitioning-a-database"><a class="markdownIt-Anchor" href="#what-do-we-desire-when-partitioning-a-database"></a> What do we desire when partitioning a database?</h2><ol><li>Applications should not be required to know where data is physically located in a distributed DBMS.<ul><li>Any query that runs on a single-node DBMS should produce the same result on a distributed DBMS.</li><li>The DBMS executes query fragments on each partition and then combines the results to produce a single answer.</li></ul></li><li>In practice, developers need to be aware of the communication costs of queries to avoid excessively “expensive” data movement.</li><li>The DBMS can partition a database physically for shared nothing or logically for shared disk.<ul><li>In Logical partitioning, each node is responsible for certain designated data. They cannot access data out of their duty. However, data are stored in independent storage nodes, which computation nodes can all access.</li><li>In physical partitioning, data out of their duty cannot be accessed directly since they are stored in the local disk of other nodes.</li></ul></li></ol><h2 id="how-can-we-partition-the-database"><a class="markdownIt-Anchor" href="#how-can-we-partition-the-database"></a> How can we partition the database?</h2><ol><li>The first method is the naive table partitioning.<ul><li>Assign an entire table to a single node.</li><li>It assumes that each node has enough storage space for an entire table.</li><li>This is ideal if queries never join data across tables stored on different nodes and access patterns are uniform.</li></ul></li><li>The second method is vertical partitioning.<ul><li>Split a table’s attributes into separate partitions.</li><li>It must store tuple information to reconstruct the original record.</li></ul></li><li>The third method is horizontal partitioning.<ul><li>Split a table’s tuples into disjoint subsets based on some partitioning key and scheme.</li><li>Choose column(s) that divides the database equally in terms of size, load, or usage.</li><li>It can partition based on hashing, ranges, or predicates.</li></ul></li></ol><h2 id="how-can-we-optimize-horizontal-partitioning"><a class="markdownIt-Anchor" href="#how-can-we-optimize-horizontal-partitioning"></a> How can we optimize horizontal partitioning?</h2><ol><li>The main problem is that the DBMS needs to reshuffle data when adding a new storage node.</li><li>We can use the consistent hashing.<ul><li>The hashing value is between <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>0</mn></mrow><annotation encoding="application/x-tex">0</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">0</span></span></span></span> and <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1</mn></mrow><annotation encoding="application/x-tex">1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">1</span></span></span></span> forming a circle.</li><li>Each nodes are assigned a value between <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>0</mn></mrow><annotation encoding="application/x-tex">0</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">0</span></span></span></span> and <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1</mn></mrow><annotation encoding="application/x-tex">1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">1</span></span></span></span>. Data are stored in the node with the closest value to its hashing values going in clockwise order.</li><li>When adding a node, only one node needs to transmit data to the new node instead of transmitting data between all pairs of nodes.</li></ul></li><li>With consistent hashing, we can support replication easily.<ul><li>Store data in the first batch of nodes with the closest value in clockwise order.</li></ul></li></ol>]]></content>
      
      
      <categories>
          
          <category> Open Courses </category>
          
          <category> CMU 15-445/645 Database System </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Distributed System </tag>
            
            <tag> Database System </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>14 Database Recovery</title>
      <link href="/2023/08/30/Courses/15445/14-Database-Recovery/"/>
      <url>/2023/08/30/Courses/15445/14-Database-Recovery/</url>
      
        <content type="html"><![CDATA[<p><ul class="markdownIt-TOC"><li><a href="#what-are-the-main-ideas-of-aries">What are the main ideas of ARIES?</a></li><li><a href="#record-logs">Record logs</a><ul><li><a href="#what-are-the-lsns">What are the LSNs?</a></li><li><a href="#how-to-handle-transaction-commits">How to handle transaction commits?</a></li><li><a href="#how-to-handle-transaction-abort">How to handle transaction abort?</a></li></ul></li><li><a href="#fuzzy-checkpoints">Fuzzy checkpoints</a><ul><li><a href="#how-can-we-improve-the-naive-checkpoints">How can we improve the naive checkpoints?</a></li><li><a href="#how-can-we-checkpoint-without-stalling-transactions">How can we checkpoint without stalling transactions?</a></li></ul></li><li><a href="#recovery">Recovery</a><ul><li><a href="#how-does-aries-recover-from-the-crash">How does ARIES recover from the crash?</a></li><li><a href="#what-does-the-analysis-phase-do">What does the analysis phase do?</a></li><li><a href="#what-does-the-redo-phase-do">What does the redo phase do?</a></li><li><a href="#what-does-the-undo-phase-do">What does the undo phase do?</a></li></ul></li></ul></p><h1 id="what-are-the-main-ideas-of-aries"><a class="markdownIt-Anchor" href="#what-are-the-main-ideas-of-aries"></a> What are the main ideas of ARIES?</h1><ol><li>ARIES: Algorithms for Recovery and Isolation Exploiting Semantics</li><li>Write-Ahead Logging:<ul><li>Any change is recorded in the log on stable storage before the database change is written to disk.</li><li>Must use steal and no-force buffer pool policies.<ul><li>Logs are forced to be flushed into the disk, while modified pages are not.</li><li>Force is also correct, but it damages runtime performance, making no one use it.</li></ul></li></ul></li><li>Repeating History During Redo: On DBMS restart, retrace actions and restore the database to the exact state before the crash.</li><li>Logging Changes During Undo: Record undo actions to log to ensure action is not repeated in the event of repeated failures.</li></ol><h1 id="record-logs"><a class="markdownIt-Anchor" href="#record-logs"></a> Record logs</h1><h2 id="what-are-the-lsns"><a class="markdownIt-Anchor" href="#what-are-the-lsns"></a> What are the LSNs?</h2><ol><li>Every log record now includes a globally unique, monotonically increasing log sequence number (LSN).<ul><li>LSNs represent the physical order in which transactions make changes to the database.</li></ul></li><li>Various components in the system keep track of LSNs that pertain to them.<ul><li>In memory, the system uses <code>flushedLSN</code> to track the last LSN in the log on disk.</li><li>In each disk page, <code>pageLSN</code> is used to track the newest update to that page, while <code>recLSN</code> is tracking the oldest update to that page since it was last flushed.</li><li>Each transaction maintains the <code>lastLSN</code> representing the latest record of that transaction.</li><li>There is also a MasterRecord in the disk, meaning the LSN of the latest checkpoint.</li></ul></li><li>Before the DBMS can write page x to disk, it must flush the log at least to the point where <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi><mi>a</mi><mi>g</mi><mi>e</mi><mi>L</mi><mi>S</mi><msub><mi>N</mi><mi>x</mi></msub><mo>≤</mo><mi>f</mi><mi>l</mi><mi>u</mi><mi>s</mi><mi>h</mi><mi>e</mi><mi>d</mi><mi>L</mi><mi>S</mi><mi>N</mi></mrow><annotation encoding="application/x-tex">pageLSN_x ≤ flushedLSN</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8777699999999999em;vertical-align:-0.19444em;"></span><span class="mord mathnormal">p</span><span class="mord mathnormal">a</span><span class="mord mathnormal" style="margin-right:0.03588em;">g</span><span class="mord mathnormal">e</span><span class="mord mathnormal">L</span><span class="mord mathnormal" style="margin-right:0.05764em;">S</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.10903em;">N</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:-0.10903em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">x</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">≤</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="mord mathnormal" style="margin-right:0.01968em;">l</span><span class="mord mathnormal">u</span><span class="mord mathnormal">s</span><span class="mord mathnormal">h</span><span class="mord mathnormal">e</span><span class="mord mathnormal">d</span><span class="mord mathnormal">L</span><span class="mord mathnormal" style="margin-right:0.05764em;">S</span><span class="mord mathnormal" style="margin-right:0.10903em;">N</span></span></span></span>.</li><li>Update the <code>pageLSN</code> every time a transaction modifies a record in the page.</li><li>Update the <code>flushedLSN</code> in memory every time the DBMS writes out the WAL buffer to disk.</li></ol><h2 id="how-to-handle-transaction-commits"><a class="markdownIt-Anchor" href="#how-to-handle-transaction-commits"></a> How to handle transaction commits?</h2><ol><li>When a transaction is committed, the DBMS writes a <code>COMMIT</code> record to log and guarantees that all log records up to the transaction’s <code>COMMIT</code> record are flushed to disk.<ul><li>Log flushes are sequential, synchronous writes to disk.</li></ul></li><li>When the commit succeeds, write a special <code>TXN-END</code> record to log.<ul><li>Indicates that no new log record for a transaction will appear in the log ever again.</li><li>This does not need to be flushed immediately.</li></ul></li></ol><h2 id="how-to-handle-transaction-abort"><a class="markdownIt-Anchor" href="#how-to-handle-transaction-abort"></a> How to handle transaction abort?</h2><ol><li>Another <code>prevLSN</code> is added to log records pointing to the previous LSN for that transaction to make it easy to walk through its records.</li><li>First, write an <code>ABORT</code> record to log for the transaction.<ul><li>Following that, we must record the steps taken to undo the transaction.<ul><li>A <code>CLR</code> describes the actions taken to undo the actions of a previous update record.</li><li>It has all the fields of an update log record plus the <code>undoNext</code> pointer pointing to the next-to-be-undone LSN.</li><li><code>CLR</code>s are added to log records, but the DBMS does not wait for them to be flushed before notifying the application that the transaction was aborted.</li></ul></li><li>Lastly, write a <code>TXN-END</code> record.</li></ul></li><li>We need to analyze the transaction’s updates in reverse order to add <code>CLR</code> records.<ul><li>Write a <code>CLR</code> entry to the log for each update record and restore the old value.</li><li><code>CLR</code>s never need to be undone.</li></ul></li></ol><h1 id="fuzzy-checkpoints"><a class="markdownIt-Anchor" href="#fuzzy-checkpoints"></a> Fuzzy checkpoints</h1><h2 id="how-can-we-improve-the-naive-checkpoints"><a class="markdownIt-Anchor" href="#how-can-we-improve-the-naive-checkpoints"></a> How can we improve the naive checkpoints?</h2><ol><li>The naive checkpoint needs to halt the start of any new transactions and wait until all active transactions finish executing.</li><li>We can only pause modifying transactions while the DBMS takes the checkpoint.<ul><li>This can be done by preventing queries from acquiring a write latch on table/index pages.</li><li>Don’t have to wait until all transactions finish before taking the checkpoint.</li></ul></li><li>We must record the internal state as of the beginning of the checkpoint.<ul><li>Active Transaction Table (ATT): What transactions were running when we took the checkpoint.</li><li>Dirty Page Table (DPT): What pages are dirty.</li></ul></li><li>ATT is maintained at runtime and recovery. There is an entry per currently active transaction.<ul><li>Each entry contains<ul><li><code>transactionId</code>: Unique transaction identifier</li><li><code>status</code>: The current “mode” of the transaction</li><li><code>lastLSN</code>: The most recent LSN created by the transaction.</li></ul></li><li>Remove the entry after the <code>TXN-END</code> record.</li><li>Txn Status Codes<ul><li><code>R</code>: Running</li><li><code>C</code>: Committing</li><li><code>U</code>: Candidate for undo</li></ul></li><li><code>U</code> is the default mode in recovery.<ul><li>When replaying the log, we cannot see what’s coming up, assuming we will not see a transaction commit record.</li><li>Flip to commit when we see a transaction commit record.</li></ul></li></ul></li><li>DPT contains one entry per dirty page in the buffer pool, including <code>recLSN</code>.<ul><li><code>recLSN</code> is the LSN of the log record that first caused the page to be dirty.</li></ul></li><li>Each checkpoint record includes ATT and DPT in it.</li></ol><h2 id="how-can-we-checkpoint-without-stalling-transactions"><a class="markdownIt-Anchor" href="#how-can-we-checkpoint-without-stalling-transactions"></a> How can we checkpoint without stalling transactions?</h2><ol><li>In a fuzzy checkpoint, two kinds of records track checkpoint boundaries.<ul><li><code>CHECKPOINT-BEGIN</code> indicates the start of the checkpoint. Recovery begins from here.</li><li><code>CHECKPOINT-END</code> contains ATT and DPT at the moment of <code>CHECKPOINT-BEGIN</code>.</li></ul></li><li>The <code>LSN</code> of the <code>CHECKPOINT-BEGIN</code> record is written in the MasterRecord when it is complete.</li><li>Any transaction after the checkpoint starts is excluded from the ATT in the <code>CHECKPOINT-END</code> record.</li></ol><h1 id="recovery"><a class="markdownIt-Anchor" href="#recovery"></a> Recovery</h1><h2 id="how-does-aries-recover-from-the-crash"><a class="markdownIt-Anchor" href="#how-does-aries-recover-from-the-crash"></a> How does ARIES recover from the crash?</h2><ol><li>The first phase is analysis.<ul><li>Examine the WAL in a forward direction, starting at MasterRecord to identify dirty pages in the buffer pool and active transactions at the time of the crash.</li><li>This is to figure out which transactions committed or failed since checkpoint.</li></ul></li><li>The second phase is the redo phase.<ul><li>Repeat all actions starting from an appropriate point in the log in the forward direction.</li><li>This phase is to repeat all actions, even transactions that will abort.</li></ul></li><li>The last phase is undo.<ul><li>Reverse the actions of transactions that were not committed before the crash in reverse order.</li><li>This phase is to reverse the effects of failed transactions.</li></ul></li><li>If crashes happen during recovery, just rerun recovery.</li></ol><img src="/imgs/15445/Recovery/aries.png" width="20%"><h2 id="what-does-the-analysis-phase-do"><a class="markdownIt-Anchor" href="#what-does-the-analysis-phase-do"></a> What does the analysis phase do?</h2><ol><li>Scan the log forward from the <code>CHECKPOINT-END</code> of the last successful checkpoint.</li><li>If the DBMS finds a <code>TXN-END</code> record, remove its corresponding transaction from ATT.</li><li>For all other records,<ul><li>Suppose the transaction is not in ATT; add it with the status <code>UNDO</code>. On commit, change transaction status to <code>COMMIT</code>.</li><li>For update log records, if the page <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>P</mi></mrow><annotation encoding="application/x-tex">P</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span></span></span></span> not in DPT, add <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>P</mi></mrow><annotation encoding="application/x-tex">P</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span></span></span></span> to DPT, set its <code>recLSN=LSN</code>.</li></ul></li><li>At the end of the Analysis Phase,<ul><li>ATT identifies which transactions were active at the time of the crash.</li><li>DPT identifies which dirty pages might not have made it to disk.</li></ul></li></ol><h2 id="what-does-the-redo-phase-do"><a class="markdownIt-Anchor" href="#what-does-the-redo-phase-do"></a> What does the redo phase do?</h2><ol><li>The goal is to repeat history to reconstruct the database state at the moment of the crash.</li><li>Scan forward from the log record containing the smallest <code>recLSN</code> in DPT.</li><li>For each update log record or <code>CLR</code> with a given LSN, redo the action unless the affected page is not in DPT or the affected page is in DPT but that record’s LSN is less than the page’s <code>recLSN</code>.<ul><li>If the affected page is not in DPT, that modification is already flushed in the disk.</li><li>If that record’s LSN is less than the page’s <code>recLSN</code>, that page is dirty due to some updates after the record. The modification of that record is also flushed into the disk.</li></ul></li><li>To redo an action,<ul><li>Reapply logged update.</li><li>Set <code>pageLSN</code> to log the record’s LSN.</li><li>No additional logging, no forced flushes.</li><li>To improve performance, we can assume that it will not crash again and that all changes to the disk will be flushed asynchronously in the background.</li></ul></li><li>At the end of the Redo Phase, write <code>TXN-END</code> log records for all transactions with status <code>C</code> and remove them from the ATT.</li></ol><h2 id="what-does-the-undo-phase-do"><a class="markdownIt-Anchor" href="#what-does-the-undo-phase-do"></a> What does the undo phase do?</h2><ol><li>Undo all active transactions at the time of the crash and, therefore, will never commit.</li><li>These are all the transactions with <code>U</code> status in the ATT after the Analysis Phase.</li><li>Process them in reverse LSN order using the <code>lastLSN</code> to speed up traversal.</li><li>Write a <code>CLR</code> for every modification.</li><li>To improve performance,<ul><li>Lazily rollback changes before new transactions access pages.</li><li>Rewrite the application to avoid long-running transactions, which will never be used.</li></ul></li></ol>]]></content>
      
      
      <categories>
          
          <category> Open Courses </category>
          
          <category> CMU 15-445/645 Database System </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Database System </tag>
            
            <tag> Durability </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>13 Database Logging</title>
      <link href="/2023/08/29/Courses/15445/13-Database-Logging/"/>
      <url>/2023/08/29/Courses/15445/13-Database-Logging/</url>
      
        <content type="html"><![CDATA[<p><ul class="markdownIt-TOC"><li><a href="#crash">Crash</a><ul><li><a href="#how-to-recover-from-the-crash">How to recover from the crash?</a></li><li><a href="#what-are-the-possible-classifications-of-failures">What are the possible classifications of failures?</a></li></ul></li><li><a href="#naive-solution">Naive solution</a><ul><li><a href="#what-buffer-pool-policies-can-we-choose">What buffer pool policies can we choose?</a></li><li><a href="#what-are-the-pros-and-cons-of-no-steal-and-force-policy">What are the pros and cons of no-steal and force policy?</a></li><li><a href="#how-does-shadow-paging-work">How does shadow paging work?</a></li><li><a href="#what-are-the-disadvantages-of-shadow-paging">What are the disadvantages of shadow paging?</a></li><li><a href="#how-does-a-journal-file-work">How does a journal file work?</a></li></ul></li><li><a href="#write-ahead-log">Write-ahead log</a><ul><li><a href="#what-is-the-main-idea-of-wal">What is the main idea of WAL?</a></li><li><a href="#how-to-write-under-wal-protocol">How to write under WAL protocol?</a></li><li><a href="#how-to-reduce-flushing-the-log-buffer">How to reduce flushing the log buffer?</a></li><li><a href="#how-to-store-changes">How to store changes?</a></li><li><a href="#what-is-the-log-structured-system">What is the log-structured system?</a></li><li><a href="#how-to-prevent-wal-from-growing-forever">How to prevent WAL from growing forever?</a></li><li><a href="#what-is-the-problem-with-this-naive-checkpoint-protocol">What is the problem with this naive checkpoint protocol?</a></li></ul></li></ul></p><h1 id="crash"><a class="markdownIt-Anchor" href="#crash"></a> Crash</h1><h2 id="how-to-recover-from-the-crash"><a class="markdownIt-Anchor" href="#how-to-recover-from-the-crash"></a> How to recover from the crash?</h2><ol><li>Recovery algorithms are techniques to ensure database consistency, transaction atomicity, and durability despite failures.</li><li>The DBMS needs to ensure the following:<ul><li>The changes for any transaction are durable once the DBMS has told somebody it has been committed.</li><li>No partial changes are durable if the transaction is aborted.</li></ul></li><li>Recovery algorithms have two parts:<ul><li>The first is the runtime part: Actions during normal transaction processing to ensure the DBMS can recover from a failure.</li><li>The second is the startup part: Actions after a failure to recover the database to a state that ensures atomicity, consistency, and durability.</li></ul></li></ol><h2 id="what-are-the-possible-classifications-of-failures"><a class="markdownIt-Anchor" href="#what-are-the-possible-classifications-of-failures"></a> What are the possible classifications of failures?</h2><ol><li>Transaction failures:<ul><li>Logical errors: Transactions cannot be completed due to internal error conditions (e.g., integrity constraint violation).</li><li>Internal state errors: DBMS must terminate an active transaction due to an error condition (e.g., deadlock).</li></ul></li><li>System failures:<ul><li>Software failure: Problem with the OS or DBMS implementation (e.g., uncaught divide-by-zero exception).</li><li>Hardware failure: The computer hosting the DBMS crashes (e.g., the power plug gets pulled).</li><li>Fail-stop assumption: Non-volatile storage contents are assumed not to be corrupted by system crashes.</li></ul></li><li>Storage media failure:<ul><li>Non-repairable hardware failure: A head crash or similar disk failure destroys all or part of non-volatile storage.</li><li>Destruction is assumed to be detectable (e.g., disk controllers use checksums to detect failures).</li><li>No DBMS can recover from this! The database must be restored from the archived version.</li><li>Stable storage is a non-existent form of non-volatile storage that survives all possible failure scenarios.</li></ul></li></ol><h1 id="naive-solution"><a class="markdownIt-Anchor" href="#naive-solution"></a> Naive solution</h1><h2 id="what-buffer-pool-policies-can-we-choose"><a class="markdownIt-Anchor" href="#what-buffer-pool-policies-can-we-choose"></a> What buffer pool policies can we choose?</h2><ol><li>Steal policy:<ul><li>Whether the DBMS allows an uncommitted transaction to overwrite an object’s most recent committed value in non-volatile storage.</li><li>Steal: Is allowed</li><li>No-steal: Is not allowed</li></ul></li><li>Force policy:<ul><li>Whether the DBMS requires that all updates made by a transaction are reflected on non-volatile storage before the transaction can commit.</li><li>Force: Is required</li><li>No-force: Is not required</li></ul></li><li>Undo: The process of removing the effects of an incomplete or aborted transaction.</li><li>Redo: The process of re-applying the effects of a committed transaction for durability.</li><li>Stead and no-force policy has the best runtime performance since it does not need to wait for conflicted uncommitted transactions and does not necessarily have to flush when committed.</li><li>The no-steal and force policy has the best recovery performance since it does not need to undo and redo anything.</li></ol><h2 id="what-are-the-pros-and-cons-of-no-steal-and-force-policy"><a class="markdownIt-Anchor" href="#what-are-the-pros-and-cons-of-no-steal-and-force-policy"></a> What are the pros and cons of no-steal and force policy?</h2><ol><li>This approach is the easiest to implement:<ul><li>Never have to undo changes of an aborted transaction because the changes were not written to disk.</li><li>Never have to redo changes of a committed transaction because all the changes are guaranteed to be written to disk at commit time (assuming atomic hardware writes).</li></ul></li><li>An uncommitted transaction and another committing transaction may have written the same page. Then, the buffer pool manager must copy that page with only modifications from the committing transaction and write that copied page to non-volatile storage.</li><li>The disadvantages are as follows:<ul><li>Copying data is expensive.</li><li>The buffer pool manager needs to be aware of the context.</li><li>Cannot support write sets that exceed the amount of physical memory available.</li></ul></li></ol><h2 id="how-does-shadow-paging-work"><a class="markdownIt-Anchor" href="#how-does-shadow-paging-work"></a> How does shadow paging work?</h2><ol><li>Instead of copying the entire database, the DBMS copies pages on write to create two versions<ul><li>Master: Contains only changes from committed transactions. Read-only transactions access the current master.</li><li>Shadow: Temporary database with changes made from uncommitted transactions.</li></ul></li><li>Active modifying transaction copies the page table as the shadow page table.<ul><li>When it tries to modify a page, it will copy that page and modify the shadow page table to point to the newly copied page.</li><li>To install updates when a transaction commits, overwrite the root so it points to the shadow, thereby swapping the master and shadow. Then, DMBS needs to collect some garbage.</li></ul></li><li>The buffer pool policy is no-steal and force.</li><li>The DBMS needs to remove the shadow pages to support rollbacks and recovery. Leave the master and the DB root pointer alone in the undo phase; redo is unnecessary.</li></ol><h2 id="what-are-the-disadvantages-of-shadow-paging"><a class="markdownIt-Anchor" href="#what-are-the-disadvantages-of-shadow-paging"></a> What are the disadvantages of shadow paging?</h2><ol><li>Copying the entire page table is expensive:<ul><li>We can use a page table structured like a B+tree (LMDB). There is no need to copy the entire tree; only to copy paths in the tree that lead to updated leaf nodes.</li></ul></li><li>Commit overhead is high:<ul><li>Need to flush every updated page, page table, and root.</li><li>Data gets fragmented, which is bad for sequential scans.</li><li>Require the DBMS to perform writes to random non-contiguous pages on disk.</li><li>Need garbage collection.</li></ul></li><li>Only supports one writer transaction at a time or transactions in a batch. If two concurrent writers write on the same page, they all copy from the master version, causing only one write to be reflected on the committed database.</li></ol><h2 id="how-does-a-journal-file-work"><a class="markdownIt-Anchor" href="#how-does-a-journal-file-work"></a> How does a journal file work?</h2><ol><li>When a transaction modifies a page, the DBMS copies the original page to a separate journal file before overwriting the master version.</li><li>After restarting, if a journal file exists, then the DBMS restores it to undo changes from uncommitted transactions.</li></ol><h1 id="write-ahead-log"><a class="markdownIt-Anchor" href="#write-ahead-log"></a> Write-ahead log</h1><h2 id="what-is-the-main-idea-of-wal"><a class="markdownIt-Anchor" href="#what-is-the-main-idea-of-wal"></a> What is the main idea of WAL?</h2><ol><li>Maintain a log file separate from data files containing the changes transactions make to the database.<ul><li>Assume that the log is on stable storage.</li><li>The log contains enough information to perform the necessary undo and redo actions to restore the database.</li></ul></li><li>DBMS must write to disk the log file records that correspond to changes made to a database object before it can flush that object to disk.<ul><li>The buffer pool policy is steal and no-force.</li></ul></li></ol><h2 id="how-to-write-under-wal-protocol"><a class="markdownIt-Anchor" href="#how-to-write-under-wal-protocol"></a> How to write under WAL protocol?</h2><ol><li>The DBMS stages all a transaction’s log records in volatile storage backed by a buffer pool.<ul><li>All log records pertaining to an updated page are written to non-volatile storage before the page itself is over-written in non-volatile storage.</li><li>A transaction is not considered committed until all its log records have been written to stable storage.</li></ul></li><li>A <code>&lt;BEGIN&gt;</code> record is written to the log for each transaction to mark its starting point.<ul><li>Most DBMS only writes <code>&lt;BEGIN&gt;</code> on the first write command of a transaction instead of at the beginning.</li></ul></li><li>When a transaction finishes, the DBMS will write a <code>&lt;COMMIT&gt;</code> record on the log and ensure all log records are flushed before it returns an acknowledgment to the application.</li><li>Each log entry contains information about the change to a single object.<ul><li>Transaction ID, object ID, before value (for undo) and after value (for redo).</li></ul></li></ol><h2 id="how-to-reduce-flushing-the-log-buffer"><a class="markdownIt-Anchor" href="#how-to-reduce-flushing-the-log-buffer"></a> How to reduce flushing the log buffer?</h2><ol><li>Flushing the log buffer to disk every time a transaction commits will become a bottleneck.</li><li>The DBMS can use the group commit optimization to batch multiple log flushes together to amortize overhead.<ul><li>When the buffer is full, flush it to disk. Or if there is a timeout.</li><li>Log records from different transactions are mixed. This is fine since we can sort them out by recorded transaction ID.</li></ul></li></ol><h2 id="how-to-store-changes"><a class="markdownIt-Anchor" href="#how-to-store-changes"></a> How to store changes?</h2><ol><li>The first logging scheme is physical logging.<ul><li>Record the byte-level changes made to a specific page.</li></ul></li><li>The second is logical logging.<ul><li>Record the high-level operations executed by transactions, e.g., queries.</li><li>Logical logging requires less data written in each log record than physical logging.</li><li>Difficult to implement recovery with logical logging if you have concurrent transactions running at lower isolation levels.<ul><li>The crash may happen in the middle of a query.</li><li>It is hard to determine which parts of the database may have been modified by a query before the crash.</li></ul></li><li>It also takes longer to recover because you must re-execute every transaction all over again.</li></ul></li><li>The last is physiological logging.<ul><li>Hybrid approach with byte-level changes for a single tuple identified by page ID and slot number.</li></ul></li></ol><h2 id="what-is-the-log-structured-system"><a class="markdownIt-Anchor" href="#what-is-the-log-structured-system"></a> What is the log-structured system?</h2><ol><li>Log-structured DBMSs do not have dirty pages.<ul><li>Any page retrieved from the disk is immutable.</li><li>All modifications are reflected through logs.</li></ul></li><li>The DBMS buffers log records in in-memory pages (MemTable).<ul><li>If this buffer is full, it must be flushed to disk. However, it may contain changes from uncommitted transactions.</li></ul></li><li>These DBMSs maintain a separate WAL to recreate the MemTable on the crash.</li></ol><h2 id="how-to-prevent-wal-from-growing-forever"><a class="markdownIt-Anchor" href="#how-to-prevent-wal-from-growing-forever"></a> How to prevent WAL from growing forever?</h2><ol><li>If the WAL grows forever after a crash, the DBMS must replay the entire log, which will take a long time.</li><li>The DBMS periodically takes a checkpoint where it flushes all buffers out to disk.</li><li>In blocking / consistent checkpoint protocol,<ul><li>Procedure<ul><li>Pause all queries</li><li>Flush all WAL records in memory to disk.</li><li>Flush all modified pages in the buffer pool to disk.</li><li>Write a <code>&lt;CHECKPOINT&gt;</code> entry to WAL and flush it to disk.</li><li>Resume queries</li></ul></li><li>On recovery, we can use the <code>&lt;CHECKPOINT&gt;</code> record as the starting point for analyzing the WAL.<ul><li>Any transaction that is committed before the checkpoint is ignored.</li><li>Redo transactions that are committed after checkpoint and undo transactions not committed before the crash.</li></ul></li></ul></li></ol><h2 id="what-is-the-problem-with-this-naive-checkpoint-protocol"><a class="markdownIt-Anchor" href="#what-is-the-problem-with-this-naive-checkpoint-protocol"></a> What is the problem with this naive checkpoint protocol?</h2><ol><li>The DBMS must stall transactions when it takes a checkpoint to ensure a consistent snapshot.<ul><li>Too often checkpointing causes the runtime performance to degrade because the system spends too much time flushing buffers.</li><li>But waiting a long time is just as bad since the checkpoint will be large and slow, which makes recovery time much longer.</li></ul></li><li>Scanning the log to find uncommitted transactions can take a long time.</li></ol>]]></content>
      
      
      <categories>
          
          <category> Open Courses </category>
          
          <category> CMU 15-445/645 Database System </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Database System </tag>
            
            <tag> Durability </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>12 Multi-Version Concurrency Control</title>
      <link href="/2023/08/22/Courses/15445/12-Multi-Version-Concurrency-Control/"/>
      <url>/2023/08/22/Courses/15445/12-Multi-Version-Concurrency-Control/</url>
      
        <content type="html"><![CDATA[<p><ul class="markdownIt-TOC"><li><a href="#multi-version-logic">Multi-version logic</a><ul><li><a href="#what-does-multi-version-mean">What does multi-version mean?</a></li><li><a href="#how-to-maintain-multi-version-logically">How to maintain multi-version logically?</a></li><li><a href="#what-isolation-can-mvcc-support">What isolation can MVCC support?</a></li></ul></li><li><a href="#design-decisions">Design decisions</a><ul><li><a href="#what-concurrency-control-protocol-can-be-used">What concurrency control protocol can be used?</a></li><li><a href="#how-are-versions-stored">How are versions stored?</a></li><li><a href="#how-to-perform-garbage-collection">How to perform garbage collection?</a></li><li><a href="#how-to-manage-indexes">How to manage indexes?</a></li><li><a href="#how-to-delete-a-tuple">How to delete a tuple?</a></li></ul></li></ul></p><h1 id="multi-version-logic"><a class="markdownIt-Anchor" href="#multi-version-logic"></a> Multi-version logic</h1><h2 id="what-does-multi-version-mean"><a class="markdownIt-Anchor" href="#what-does-multi-version-mean"></a> What does multi-version mean?</h2><ol><li><p>The DBMS maintains multiple physical versions of a single logical object in the database.</p><ul><li><p>When a transaction writes to an object, the DBMS creates a new version of that object.</p></li><li><p>When a transaction reads an object, it reads the newest version that existed when it started.</p></li></ul></li><li><p>Writers do not block readers, and readers do not block writers.</p></li><li><p>Read-only transactions can read a consistent snapshot without acquiring locks using timestamps to determine visibility.</p></li><li><p>Multi-version can easily support time-travel queries on a snapshot version of the database.</p></li></ol><h2 id="how-to-maintain-multi-version-logically"><a class="markdownIt-Anchor" href="#how-to-maintain-multi-version-logically"></a> How to maintain multi-version logically?</h2><ol><li>Each version describes the current version number, the value for this version, and the lifetime range, i.e., the beginning and end timestamps.</li><li>The end timestamp is marked infinity for the newest version.</li><li>When a transaction writes an object:<ul><li>First, it creates a new entry with a new version number and sets its begin timestamp as its timestamp and end timestamp as infinity.</li><li>Then, it marks the end timestamp of the last version as its timestamp.</li><li>Physically, this transaction should modify the last version to point to this new version. Hence, it must wait for the transaction that has created the previous version to commit before beginning its commit phase.</li></ul></li></ol><h2 id="what-isolation-can-mvcc-support"><a class="markdownIt-Anchor" href="#what-isolation-can-mvcc-support"></a> What isolation can MVCC support?</h2><ol><li><code>SNAPSHOT ISOLATION</code> is another isolation supported by Oracle.<ul><li>It guarantees that all reads made in a transaction see a consistent snapshot of the database when the transaction started.</li><li>A transaction will commit only if its writes do not conflict with any concurrent updates made since that snapshot.</li></ul></li><li>It is susceptible to write skew anomaly.<ul><li>Two concurrent transactions modify different objects, resulting in race conditions.</li><li>If a transaction wants to modify all values to <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1</mn></mrow><annotation encoding="application/x-tex">1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">1</span></span></span></span> while another transaction wants to modify all values to <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>0</mn></mrow><annotation encoding="application/x-tex">0</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">0</span></span></span></span>. The first transaction changes all <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>0</mn></mrow><annotation encoding="application/x-tex">0</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">0</span></span></span></span>s, and the second transaction changes all <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1</mn></mrow><annotation encoding="application/x-tex">1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">1</span></span></span></span>s. When their result merges with the database, it would be the <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1</mn></mrow><annotation encoding="application/x-tex">1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">1</span></span></span></span>s and <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>0</mn></mrow><annotation encoding="application/x-tex">0</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">0</span></span></span></span>s are flipped instead of all being <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1</mn></mrow><annotation encoding="application/x-tex">1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">1</span></span></span></span>s or <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>0</mn></mrow><annotation encoding="application/x-tex">0</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">0</span></span></span></span>s.</li></ul></li></ol><h1 id="design-decisions"><a class="markdownIt-Anchor" href="#design-decisions"></a> Design decisions</h1><h2 id="what-concurrency-control-protocol-can-be-used"><a class="markdownIt-Anchor" href="#what-concurrency-control-protocol-can-be-used"></a> What concurrency control protocol can be used?</h2><ol><li>All aforementioned protocols can be used in MVCC.</li><li>Timestamp ordering assigns transaction timestamps to determine what they can see.</li><li>Optimistic concurrency control uses a private workspace for new versions.</li><li>Two-phase locking requires transactions to acquire an appropriate lock on a physical version before they can read/write a logical tuple.</li></ol><h2 id="how-are-versions-stored"><a class="markdownIt-Anchor" href="#how-are-versions-stored"></a> How are versions stored?</h2><ol><li>The DBMS uses the tuples’ pointer field to create a version chain per logical tuple.<ul><li>This allows the DBMS to find the version visible to a particular transaction at runtime.</li><li>Indexes always point to the “head” of the chain.</li></ul></li><li>The first approach is append-only storage: New versions are appended to the same table space.<ul><li>The versions of different logical tuples are inter-mixed.</li><li>On every update, append a new version of the tuple into an empty space in the table.</li><li>If the chain is from oldest to newest, the DBMS must traverse the chain on look-ups. However, the update does not need to update the index.</li><li>Or, the chain can be from oldest to newest. The pros and cons are contrary to the last scenario.</li></ul></li><li>The second approach is time-travel storage: Old versions are copied to separate table space.<ul><li>On every update, copy the current version to the time-travel table. Update pointers. Then, Overwrite the master version in the main table and update pointers.</li></ul></li><li>The third approach is delta storage: The original values of the modified attributes are copied into a separate delta record space.<ul><li>On every update, copy only the values modified to the delta storage and overwrite the master version.</li><li>Transactions can recreate old versions by applying the delta in reverse order.</li></ul></li></ol><h2 id="how-to-perform-garbage-collection"><a class="markdownIt-Anchor" href="#how-to-perform-garbage-collection"></a> How to perform garbage collection?</h2><ol><li>The DBMS needs to remove reclaimable physical versions from the database over time.<ul><li>Reclaimable means that no active transaction in the DBMS can see an aborted transaction created that version (SI) or the version.</li><li>The DBMS can only reclaim versions created by an aborted transaction to support time-travel queries.</li></ul></li><li>To look for expired versions, the implementation has two choices.</li><li>The first approach is tuple-level: Find old versions by examining tuples directly.<ul><li>In a background vacuuming manner, separate thread(s) periodically scan the table and look for reclaimable versions. This design works with any storage.</li><li>In a cooperative cleaning manner, worker threads identify reclaimable versions as they traverse the version chain. It only works with oldest-to-newest.</li></ul></li><li>The second approach is transaction-level: transactions keep track of their old versions on updates, so the DBMS does not have to scan tuples to determine visibility.<ul><li>Each transaction keeps track of its read/write set. On commit/abort, the transaction provides this information to a centralized vacuum worker.</li><li>The DBMS periodically determines when all versions created by a finished transaction are no longer visible.</li></ul></li></ol><h2 id="how-to-manage-indexes"><a class="markdownIt-Anchor" href="#how-to-manage-indexes"></a> How to manage indexes?</h2><ol><li>Primary key indexes point to the version chain head.<ul><li>How often the DBMS must update the primary key index depends on whether the system creates new versions when a tuple is updated.</li><li>If a transaction updates a tuple’s primary key attribute(s), then this is treated as a <code>DELETE</code> followed by an <code>INSERT</code>.</li></ul></li><li>Secondary indexes may use the physical address to the version chain head like a primary key index.</li><li>The secondary indexes may also use logical pointers.<ul><li>It uses a fixed identifier per tuple that does not change, e.g., primary key or tuple ID.</li><li>This would require an extra indirection layer.</li></ul></li></ol><h2 id="how-to-delete-a-tuple"><a class="markdownIt-Anchor" href="#how-to-delete-a-tuple"></a> How to delete a tuple?</h2><ol><li>The DBMS physically deletes a tuple from the database only when all versions of a logically deleted tuple are not visible.</li><li>If a tuple is deleted, a new version cannot be after the latest version.</li><li>There are two ways to denote that a tuple has been logically deleted at some point in time.<ul><li>The first way is to maintain a deleted flag to indicate that the logical tuple has been deleted after the newest physical version. The flag can either be in a tuple header or a separate column.</li><li>The second tombstone tuple way is to create an empty physical version to indicate that a logical tuple is deleted.<ul><li>It uses a separate pool for tombstone tuples with only a special bit pattern in the version chain pointer to reduce the storage overhead.</li></ul></li></ul></li></ol>]]></content>
      
      
      <categories>
          
          <category> Open Courses </category>
          
          <category> CMU 15-445/645 Database System </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Concurrency Control </tag>
            
            <tag> Database System </tag>
            
            <tag> Transaction </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>11 Timestamp Ordering Concurrency Control</title>
      <link href="/2023/08/20/Courses/15445/11-Timestamp-Ordering-Concurrency-Control/"/>
      <url>/2023/08/20/Courses/15445/11-Timestamp-Ordering-Concurrency-Control/</url>
      
        <content type="html"><![CDATA[<p><ul class="markdownIt-TOC"><li><a href="#to-protocols">T/O Protocols</a><ul><li><a href="#what-is-the-difference-between-2pl-and-to">What is the difference between 2PL and T/O?</a></li><li><a href="#basic-to-protocol">Basic T/O protocol</a><ul><li><a href="#what-is-the-main-idea-of-basic-to-protocol">What is the main idea of basic T/O protocol?</a></li><li><a href="#how-does-basic-to-check-each-operation">How does basic T/O check each operation?</a></li><li><a href="#can-we-optimize-the-write-rule-to-decrease-the-possibility-of-abort">Can we optimize the write rule to decrease the possibility of abort?</a></li><li><a href="#what-are-the-issues-of-basic-to">What are the issues of basic T/O?</a></li></ul></li><li><a href="#optimistic-concurrency-control">Optimistic concurrency control</a><ul><li><a href="#what-is-the-main-idea-of-occ">What is the main idea of OCC?</a></li><li><a href="#what-will-happen-in-the-validation-phase">What will happen in the validation phase?</a></li><li><a href="#what-are-the-issues-of-occ">What are the issues of OCC?</a></li></ul></li></ul></li><li><a href="#the-phantom-problem">The phantom problem</a><ul><li><a href="#what-is-the-phantom-problem">What is the phantom problem?</a></li><li><a href="#how-can-we-solve-the-phantom-problem">How can we solve the phantom problem?</a></li><li><a href="#what-are-isolation-levels">What are isolation levels?</a></li></ul></li></ul></p><h1 id="to-protocols"><a class="markdownIt-Anchor" href="#to-protocols"></a> T/O Protocols</h1><h2 id="what-is-the-difference-between-2pl-and-to"><a class="markdownIt-Anchor" href="#what-is-the-difference-between-2pl-and-to"></a> What is the difference between 2PL and T/O?</h2><ol><li>2PL determines the serializability order of conflicting operations at runtime while transactions execute, while T/O determines the serializability order of transactions before they execute.<ul><li>If <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>T</mi><mi>S</mi><mo stretchy="false">(</mo><msub><mi>T</mi><mi>i</mi></msub><mo stretchy="false">)</mo><mo>&lt;</mo><mi>T</mi><mi>S</mi><mo stretchy="false">(</mo><msub><mi>T</mi><mi>j</mi></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">TS(T_i) &lt; TS(T_j)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="mord mathnormal" style="margin-right:0.05764em;">S</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">&lt;</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.036108em;vertical-align:-0.286108em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="mord mathnormal" style="margin-right:0.05764em;">S</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.311664em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span>, then the DBMS must ensure that the execution schedule is equivalent to a serial schedule where <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>T</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">T_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> appears before <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>T</mi><mi>j</mi></msub></mrow><annotation encoding="application/x-tex">T_j</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.969438em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.311664em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span></span></span></span>.</li><li>Different schemes assign timestamps at different times during the transaction.</li><li>Timestamps can be implemented using different strategies: system/wall clock, logical counter, or hybrid.</li></ul></li><li>2PL is pessimistic. It assumes that conflicts between transactions are very common.<ul><li>Hence, it uses locks to prevent conflicts.</li></ul></li><li>Timestamp ordering (T/O) is a more optimistic way. It assumes that conflicts between transactions are rare.<ul><li>Hence, it allows each transaction to execute all operations they want and validate their legitimacy after each transaction committing and before applying anything to the main database.</li></ul></li></ol><h2 id="basic-to-protocol"><a class="markdownIt-Anchor" href="#basic-to-protocol"></a> Basic T/O protocol</h2><h3 id="what-is-the-main-idea-of-basic-to-protocol"><a class="markdownIt-Anchor" href="#what-is-the-main-idea-of-basic-to-protocol"></a> What is the main idea of basic T/O protocol?</h3><ol><li>Txns read and write objects without locks.</li><li>The timestamp of each transaction is assigned at the <code>BEGIN</code> command.</li><li>Every object <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>X</mi></mrow><annotation encoding="application/x-tex">X</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.07847em;">X</span></span></span></span> is tagged with a timestamp of the last transaction that successfully read/write<ul><li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>W</mi><mo>−</mo><mi>T</mi><mi>S</mi><mo stretchy="false">(</mo><mi>X</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">W-TS(X)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.76666em;vertical-align:-0.08333em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="mord mathnormal" style="margin-right:0.05764em;">S</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class="mclose">)</span></span></span></span>: Write timestamp on <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>X</mi></mrow><annotation encoding="application/x-tex">X</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.07847em;">X</span></span></span></span></li><li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>R</mi><mo>−</mo><mi>T</mi><mi>S</mi><mo stretchy="false">(</mo><mi>X</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">R-TS(X)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.76666em;vertical-align:-0.08333em;"></span><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="mord mathnormal" style="margin-right:0.05764em;">S</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class="mclose">)</span></span></span></span>: Read timestamp on <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>X</mi></mrow><annotation encoding="application/x-tex">X</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.07847em;">X</span></span></span></span></li></ul></li><li>Check timestamps for every operation. If a transaction tries to access an object “from the future,” it aborts and restarts.</li></ol><h3 id="how-does-basic-to-check-each-operation"><a class="markdownIt-Anchor" href="#how-does-basic-to-check-each-operation"></a> How does basic T/O check each operation?</h3><ol><li>When <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>T</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">T_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> wants to read <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>X</mi></mrow><annotation encoding="application/x-tex">X</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.07847em;">X</span></span></span></span>:<ul><li>If <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>T</mi><mi>S</mi><mo stretchy="false">(</mo><msub><mi>T</mi><mi>i</mi></msub><mo stretchy="false">)</mo><mo>&lt;</mo><mi>W</mi><mo>−</mo><mi>T</mi><mi>S</mi><mo stretchy="false">(</mo><mi>X</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">TS(T_i)&lt;W-TS(X)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="mord mathnormal" style="margin-right:0.05764em;">S</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">&lt;</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.76666em;vertical-align:-0.08333em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="mord mathnormal" style="margin-right:0.05764em;">S</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class="mclose">)</span></span></span></span>, abort <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>T</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">T_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> and restart it with a new TS to prevent it from starvation.<ul><li>This condition means that this <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>T</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">T_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> is trying to read something from the future.</li></ul></li><li>Else, allow <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>T</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">T_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> to read <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>X</mi></mrow><annotation encoding="application/x-tex">X</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.07847em;">X</span></span></span></span>, and update <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>R</mi><mo>−</mo><mi>T</mi><mi>S</mi><mo stretchy="false">(</mo><mi>X</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">R-TS(X)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.76666em;vertical-align:-0.08333em;"></span><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="mord mathnormal" style="margin-right:0.05764em;">S</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class="mclose">)</span></span></span></span> to <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>m</mi><mi>a</mi><mi>x</mi><mo stretchy="false">(</mo><mi>R</mi><mo>−</mo><mi>T</mi><mi>S</mi><mo stretchy="false">(</mo><mi>X</mi><mo stretchy="false">)</mo><mo separator="true">,</mo><mi>T</mi><mi>S</mi><mo stretchy="false">(</mo><msub><mi>T</mi><mi>i</mi></msub><mo stretchy="false">)</mo><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">max(R-TS(X), TS(T_i))</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">m</span><span class="mord mathnormal">a</span><span class="mord mathnormal">x</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="mord mathnormal" style="margin-right:0.05764em;">S</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class="mclose">)</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="mord mathnormal" style="margin-right:0.05764em;">S</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mclose">)</span></span></span></span>.</li><li>A local copy of <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>X</mi></mrow><annotation encoding="application/x-tex">X</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.07847em;">X</span></span></span></span> is made to ensure repeatable reads for <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>T</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">T_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>.</li></ul></li><li>When <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>T</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">T_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> wants to write <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>X</mi></mrow><annotation encoding="application/x-tex">X</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.07847em;">X</span></span></span></span>:<ul><li>If <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>T</mi><mi>S</mi><mo stretchy="false">(</mo><msub><mi>T</mi><mi>i</mi></msub><mo stretchy="false">)</mo><mo>&lt;</mo><mi>R</mi><mo>−</mo><mi>T</mi><mi>S</mi><mo stretchy="false">(</mo><mi>X</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">TS(T_i)&lt;R-TS(X)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="mord mathnormal" style="margin-right:0.05764em;">S</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">&lt;</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.76666em;vertical-align:-0.08333em;"></span><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="mord mathnormal" style="margin-right:0.05764em;">S</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class="mclose">)</span></span></span></span> or <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>T</mi><mi>S</mi><mo stretchy="false">(</mo><msub><mi>T</mi><mi>i</mi></msub><mo stretchy="false">)</mo><mo>&lt;</mo><mi>W</mi><mo>−</mo><mi>T</mi><mi>S</mi><mo stretchy="false">(</mo><mi>X</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">TS(T_i)&lt;W-TS(X)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="mord mathnormal" style="margin-right:0.05764em;">S</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">&lt;</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.76666em;vertical-align:-0.08333em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="mord mathnormal" style="margin-right:0.05764em;">S</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class="mclose">)</span></span></span></span>, abort and restart <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>T</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">T_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>.<ul><li>The first condition means that another transaction from the future cannot see the write from <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>T</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">T_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> in the past.</li><li>The second condition means that another transaction from the future already wrote this object and <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>T</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">T_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> cannot overwrite it in the past.</li></ul></li><li>Else, allow <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>T</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">T_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> to write <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>X</mi></mrow><annotation encoding="application/x-tex">X</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.07847em;">X</span></span></span></span> and update <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>W</mi><mo>−</mo><mi>T</mi><mi>S</mi><mo stretchy="false">(</mo><mi>X</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">W-TS(X)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.76666em;vertical-align:-0.08333em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="mord mathnormal" style="margin-right:0.05764em;">S</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class="mclose">)</span></span></span></span>.</li><li>Also, a local copy is made.</li></ul></li></ol><h3 id="can-we-optimize-the-write-rule-to-decrease-the-possibility-of-abort"><a class="markdownIt-Anchor" href="#can-we-optimize-the-write-rule-to-decrease-the-possibility-of-abort"></a> Can we optimize the write rule to decrease the possibility of abort?</h3><ol><li>Thomas write rule: If <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>T</mi><mi>S</mi><mo stretchy="false">(</mo><msub><mi>T</mi><mi>i</mi></msub><mo stretchy="false">)</mo><mo>&lt;</mo><mi>W</mi><mo>−</mo><mi>T</mi><mi>S</mi><mo stretchy="false">(</mo><mi>X</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">TS(T_i) &lt; W-TS(X)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="mord mathnormal" style="margin-right:0.05764em;">S</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">&lt;</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.76666em;vertical-align:-0.08333em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="mord mathnormal" style="margin-right:0.05764em;">S</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class="mclose">)</span></span></span></span>, ignore the write to allow the transaction to continue executing without aborting.<ul><li>The thought is that we can see this violation as an immediate write from a future transaction right after the successful write from <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>T</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">T_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>.</li><li>The effects are similar, i.e., no one sees what does <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>T</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">T_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> write.</li></ul></li><li>If <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>T</mi><mi>S</mi><mo stretchy="false">(</mo><msub><mi>T</mi><mi>i</mi></msub><mo stretchy="false">)</mo><mo>&lt;</mo><mi>R</mi><mo>−</mo><mi>T</mi><mi>S</mi><mo stretchy="false">(</mo><mi>X</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">TS(T_i)&lt;R-TS(X)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="mord mathnormal" style="margin-right:0.05764em;">S</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">&lt;</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.76666em;vertical-align:-0.08333em;"></span><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="mord mathnormal" style="margin-right:0.05764em;">S</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class="mclose">)</span></span></span></span>, we still need to abort <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>T</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">T_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>.</li></ol><h3 id="what-are-the-issues-of-basic-to"><a class="markdownIt-Anchor" href="#what-are-the-issues-of-basic-to"></a> What are the issues of basic T/O?</h3><ol><li>There is high overhead from copying data to the transaction’s workspace and updating timestamps. Every read requires the transaction to write to the database.</li><li>Long-running transactions can get starved. The likelihood that a transaction will read something from a newer transaction increases.</li><li>If you assume that conflicts between transactions are rare and that most transactions are short-lived, forcing transactions to acquire locks or update timestamps adds unnecessary overhead.</li></ol><h2 id="optimistic-concurrency-control"><a class="markdownIt-Anchor" href="#optimistic-concurrency-control"></a> Optimistic concurrency control</h2><h3 id="what-is-the-main-idea-of-occ"><a class="markdownIt-Anchor" href="#what-is-the-main-idea-of-occ"></a> What is the main idea of OCC?</h3><ol><li>OCC assumes that the number of conflicts is low. Especially when:<ul><li>All transactions are read-only (ideal).</li><li>Txns access disjoint subsets of data.</li><li>The database is large, and the workload is not skewed.</li></ul></li><li>The DBMS creates a private workspace for each transaction.<ul><li>Any object read is copied into the workspace. Modifications are applied to the workspace.</li><li>When a transaction is committed, the DBMS compares the workspace write set to see whether it conflicts with other transactions.</li><li>The write set is installed into the “global” database if there are no conflicts.</li></ul></li><li>OCC has three phases:<ul><li>Read Phase: Track the read/write sets of transactions and store their writes in a private workspace, i.e., execution of transaction content.</li><li>Validation Phase: When a transaction commits, check whether it conflicts with other transactions.</li><li>Write Phase: If validation succeeds, apply private changes to the database. Otherwise, abort and restart the transaction.<ul><li>Serial Commits: Use a global latch to limit a single transaction to be in the Validation/Write phases at a time.</li><li>Parallel Commits: Use fine-grained write latches to support parallel Validation/Write phases. Txns acquire latches in primary key order to avoid deadlocks.</li></ul></li></ul></li></ol><h3 id="what-will-happen-in-the-validation-phase"><a class="markdownIt-Anchor" href="#what-will-happen-in-the-validation-phase"></a> What will happen in the validation phase?</h3><ol><li>When transaction <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>T</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">T_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> invokes <code>COMMIT</code>, the DBMS checks if it conflicts with other transactions.<ul><li>The DBMS needs to guarantee only serializable schedules are permitted.</li><li>Check other transactions for RW and WW conflicts and ensure that conflicts are in one direction (e.g., older→younger).</li></ul></li><li>There are two approaches to valid:<ul><li>In backward validation, check whether the committing transaction intersects its read/write sets with any transactions already committed.<br /><img src="/imgs/15445/TO/backward.png" width="50%"></li><li>In forward validation, check whether the committing transaction intersects its read/write sets with any active transactions that have not yet been committed.<br /><img src="/imgs/15445/TO/forward.png" width="50%"></li></ul></li><li>Each transaction’s timestamp is assigned at the beginning of the validation phase. Check the timestamp ordering of the committing transaction with all other concerned transactions. When <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>T</mi><mi>S</mi><mo stretchy="false">(</mo><msub><mi>T</mi><mi>i</mi></msub><mo stretchy="false">)</mo><mo>&lt;</mo><mi>T</mi><mi>S</mi><mo stretchy="false">(</mo><msub><mi>T</mi><mi>j</mi></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">TS(T_i)&lt;TS(T_j)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="mord mathnormal" style="margin-right:0.05764em;">S</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">&lt;</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.036108em;vertical-align:-0.286108em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="mord mathnormal" style="margin-right:0.05764em;">S</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.311664em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span>, there are only three cases:<ul><li>If <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>T</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">T_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> completes all three phases before <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>T</mi><mi>j</mi></msub></mrow><annotation encoding="application/x-tex">T_j</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.969438em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.311664em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span></span></span></span> begins its execution. This means that there is serial ordering.</li><li>If <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>T</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">T_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> completes before <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>T</mi><mi>j</mi></msub></mrow><annotation encoding="application/x-tex">T_j</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.969438em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.311664em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span></span></span></span> starts its Write phase, then we require that <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>T</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">T_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> does not write to any object read by <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>T</mi><mi>j</mi></msub></mrow><annotation encoding="application/x-tex">T_j</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.969438em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.311664em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span></span></span></span>, i.e. <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>W</mi><mi>r</mi><mi>i</mi><mi>t</mi><mi>e</mi><mi>S</mi><mi>e</mi><mi>t</mi><mo stretchy="false">(</mo><msub><mi>T</mi><mi>i</mi></msub><mo stretchy="false">)</mo><mo>∩</mo><mi>R</mi><mi>e</mi><mi>a</mi><mi>d</mi><mi>S</mi><mi>e</mi><mi>t</mi><mo stretchy="false">(</mo><msub><mi>T</mi><mi>j</mi></msub><mo stretchy="false">)</mo><mo>=</mo><mi mathvariant="normal">∅</mi></mrow><annotation encoding="application/x-tex">WriteSet(T_i)\cap ReadSet(T_j)=\empty</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mord mathnormal">i</span><span class="mord mathnormal">t</span><span class="mord mathnormal">e</span><span class="mord mathnormal" style="margin-right:0.05764em;">S</span><span class="mord mathnormal">e</span><span class="mord mathnormal">t</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">∩</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1.036108em;vertical-align:-0.286108em;"></span><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="mord mathnormal">e</span><span class="mord mathnormal">a</span><span class="mord mathnormal">d</span><span class="mord mathnormal" style="margin-right:0.05764em;">S</span><span class="mord mathnormal">e</span><span class="mord mathnormal">t</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.311664em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.80556em;vertical-align:-0.05556em;"></span><span class="mord">∅</span></span></span></span>.<ul><li>At this condition, we can conclude that <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>T</mi><mi>j</mi></msub></mrow><annotation encoding="application/x-tex">T_j</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.969438em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.311664em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span></span></span></span> cannot see anything written by <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>T</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">T_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>. Therefore, if <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>T</mi><mi>j</mi></msub></mrow><annotation encoding="application/x-tex">T_j</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.969438em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.311664em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span></span></span></span> read anything written by <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>T</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">T_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>, it is a violation.</li></ul></li><li>If <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>T</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">T_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> completes its Read phase before <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>T</mi><mi>j</mi></msub></mrow><annotation encoding="application/x-tex">T_j</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.969438em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.311664em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span></span></span></span>​ completes its Read phase, then we require that <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>T</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">T_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> does not write to any object that is either read or written by <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>T</mi><mi>j</mi></msub></mrow><annotation encoding="application/x-tex">T_j</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.969438em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.311664em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span></span></span></span>.<ul><li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>W</mi><mi>r</mi><mi>i</mi><mi>t</mi><mi>e</mi><mi>S</mi><mi>e</mi><mi>t</mi><mo stretchy="false">(</mo><msub><mi>T</mi><mi>i</mi></msub><mo stretchy="false">)</mo><mo>∩</mo><mi>R</mi><mi>e</mi><mi>a</mi><mi>d</mi><mi>S</mi><mi>e</mi><mi>t</mi><mo stretchy="false">(</mo><msub><mi>T</mi><mi>j</mi></msub><mo stretchy="false">)</mo><mo>=</mo><mi mathvariant="normal">∅</mi></mrow><annotation encoding="application/x-tex">WriteSet(T_i) \cap ReadSet(T_j) = \empty</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mord mathnormal">i</span><span class="mord mathnormal">t</span><span class="mord mathnormal">e</span><span class="mord mathnormal" style="margin-right:0.05764em;">S</span><span class="mord mathnormal">e</span><span class="mord mathnormal">t</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">∩</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1.036108em;vertical-align:-0.286108em;"></span><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="mord mathnormal">e</span><span class="mord mathnormal">a</span><span class="mord mathnormal">d</span><span class="mord mathnormal" style="margin-right:0.05764em;">S</span><span class="mord mathnormal">e</span><span class="mord mathnormal">t</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.311664em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.80556em;vertical-align:-0.05556em;"></span><span class="mord">∅</span></span></span></span> and <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>W</mi><mi>r</mi><mi>i</mi><mi>t</mi><mi>e</mi><mi>S</mi><mi>e</mi><mi>t</mi><mo stretchy="false">(</mo><msub><mi>T</mi><mi>i</mi></msub><mo stretchy="false">)</mo><mo>∩</mo><mi>W</mi><mi>r</mi><mi>i</mi><mi>t</mi><mi>e</mi><mi>S</mi><mi>e</mi><mi>t</mi><mo stretchy="false">(</mo><msub><mi>T</mi><mi>j</mi></msub><mo stretchy="false">)</mo><mo>=</mo><mi mathvariant="normal">∅</mi></mrow><annotation encoding="application/x-tex">WriteSet(T_i) \cap WriteSet(T_j) = \empty</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mord mathnormal">i</span><span class="mord mathnormal">t</span><span class="mord mathnormal">e</span><span class="mord mathnormal" style="margin-right:0.05764em;">S</span><span class="mord mathnormal">e</span><span class="mord mathnormal">t</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">∩</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1.036108em;vertical-align:-0.286108em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mord mathnormal">i</span><span class="mord mathnormal">t</span><span class="mord mathnormal">e</span><span class="mord mathnormal" style="margin-right:0.05764em;">S</span><span class="mord mathnormal">e</span><span class="mord mathnormal">t</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.311664em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.80556em;vertical-align:-0.05556em;"></span><span class="mord">∅</span></span></span></span>.</li><li>Anything wrote by <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>T</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">T_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> should be seen by <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>T</mi><mi>j</mi></msub></mrow><annotation encoding="application/x-tex">T_j</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.969438em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.311664em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span></span></span></span> and should not conflict with what <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>T</mi><mi>j</mi></msub></mrow><annotation encoding="application/x-tex">T_j</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.969438em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.311664em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span></span></span></span> intends to write.</li><li>OCC wants more than just serializable orders. Similar to the Thomas write rule, if we allow the write sets to have something in common, it would still be serializable, yet in conflict.</li></ul></li></ul></li></ol><h3 id="what-are-the-issues-of-occ"><a class="markdownIt-Anchor" href="#what-are-the-issues-of-occ"></a> What are the issues of OCC?</h3><ol><li>High overhead for copying data locally.</li><li>Validation/Write phase bottlenecks.</li><li>Aborts are more wasteful than in 2PL because they only occur after a transaction has been executed.</li></ol><h1 id="the-phantom-problem"><a class="markdownIt-Anchor" href="#the-phantom-problem"></a> The phantom problem</h1><h2 id="what-is-the-phantom-problem"><a class="markdownIt-Anchor" href="#what-is-the-phantom-problem"></a> What is the phantom problem?</h2><ol><li>In the above transaction management protocols, we assume that the total number of tuples in a table is fixed, i.e., transactions will not execute insertion or deletion.</li><li>Insertions or deletions result in different results for the same range of scan queries, e.g., count, maximum.<ul><li>The reason is that transactions can only lock on existing records, not one underway.</li></ul></li></ol><h2 id="how-can-we-solve-the-phantom-problem"><a class="markdownIt-Anchor" href="#how-can-we-solve-the-phantom-problem"></a> How can we solve the phantom problem?</h2><ol><li>The first approach is to re-execute scans.<ul><li>The DBMS tracks the <code>WHERE</code> clause for all queries that the transaction executes. Retain the scan set for every range query in a transaction.</li><li>Upon committing, re-execute the scan portion of each query and check whether it generates the same result.</li><li>This could double the execution time for all queries, which may be unacceptable.</li></ul></li><li>The second approach is by predicate locking.<ul><li>Shared lock on the predicate in a <code>WHERE</code> clause of a <code>SELECT</code> query.</li><li>Exclusive lock on the predicate in a <code>WHERE</code> clause of any <code>UPDATE</code>, <code>INSERT</code>, or <code>DELETE</code> query.</li><li>Prevent any query changing the result of the locked predicate from executing.</li></ul></li><li>The third approach is index locking.<ul><li>Key-value locks only cover a single existing key-value in an index, while gap locks cover those virtual keys for non-existent values.</li><li>Key-range locks take multiple key-value and gap locks to lock on a range.</li><li>Hierarchical locking allows a transaction to hold wider key-range locks with different locking modes to reduce the number of visits to the lock manager.</li></ul></li><li>If there is no suitable index, then the transaction must obtain the following:<ul><li>A lock on every page in the table to prevent a record’s attributes from being changed to fit the predicates.</li><li>The lock for the table itself prevents records that fit the predicates from being added or deleted.</li></ul></li></ol><h2 id="what-are-isolation-levels"><a class="markdownIt-Anchor" href="#what-are-isolation-levels"></a> What are isolation levels?</h2><ol><li>We may use a weaker level of consistency to improve scalability.</li><li>It provides for greater concurrency at the cost of exposing transactions to uncommitted changes: dirty reads, unrepeatable reads, and phantom reads.</li><li>The four isolation levels are as shown below:<br /><img src="/imgs/15445/TO/isolation.png" width="50%"></li><li>Each isolation level requires different locks to implement:<ul><li><code>SERIALIZABLE</code>: Obtain all locks first, plus index locks, plus strict 2PL.</li><li><code>REPEATABLE READS</code>: Same as above, but no index locks.</li><li><code>READ COMMITTED</code>: Same as above, but S locks are released immediately.</li><li><code>READ UNCOMMITTED</code>: Same as above, but allows dirty reads (no S locks).</li></ul></li></ol>]]></content>
      
      
      <categories>
          
          <category> Open Courses </category>
          
          <category> CMU 15-445/645 Database System </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Concurrency Control </tag>
            
            <tag> Database System </tag>
            
            <tag> Transaction </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>10 Two-Phase Locking</title>
      <link href="/2023/08/04/Courses/15445/10-Two-Phase-Locking/"/>
      <url>/2023/08/04/Courses/15445/10-Two-Phase-Locking/</url>
      
        <content type="html"><![CDATA[<p><ul class="markdownIt-TOC"><li><a href="#two-phase-locking">Two-phase Locking</a><ul><li><a href="#how-can-we-guarantee-serialization-without-knowing-the-entire-schedule-ahead-of-time">How can we guarantee serialization without knowing the entire schedule ahead of time?</a></li><li><a href="#what-is-the-problem-with-releasing-locks-and-acquiring-them-later-again">What is the problem with releasing locks and acquiring them later again?</a></li><li><a href="#what-is-the-problem-of-two-phase-locking">What is the problem of two-phase locking?</a></li></ul></li><li><a href="#deadlock">Deadlock</a><ul><li><a href="#how-to-detect-and-resolve-deadlocks">How to detect and resolve deadlocks?</a></li><li><a href="#how-to-prevent-deadlocks">How to prevent deadlocks?</a></li></ul></li><li><a href="#lock-granularity">Lock granularity</a><ul><li><a href="#what-are-the-database-objects">What are the database objects?</a></li><li><a href="#how-to-support-multiple-granularities">How to support multiple granularities?</a></li><li><a href="#how-to-use-locks">How to use locks?</a></li></ul></li></ul></p><h1 id="two-phase-locking"><a class="markdownIt-Anchor" href="#two-phase-locking"></a> Two-phase Locking</h1><h2 id="how-can-we-guarantee-serialization-without-knowing-the-entire-schedule-ahead-of-time"><a class="markdownIt-Anchor" href="#how-can-we-guarantee-serialization-without-knowing-the-entire-schedule-ahead-of-time"></a> How can we guarantee serialization without knowing the entire schedule ahead of time?</h2><ol><li>We can use locks to protect database objects.<ul><li>When a transaction wants to access some objects, it needs to acquire locks of those objects from a centralized lock manager.</li><li>Locks are issued by applications and handled in the lock manager, while latches are issued and acquired locally. Hence, locks are more expensive than latches, even if they are free.</li></ul></li><li>There are <code>S-LOCK</code> and <code>X-LOCK</code>.<ul><li><code>S-LOCKs</code> are shared locks for reads, while <code>X-LOCKs</code> are exclusive locks for writes.</li><li>Their compatibility matrix is as follows:<br /><img src="/imgs/15445/2pl/sx_comp_matrix.png" width="50%"></li></ul></li><li>The lock manager keeps track of what transactions hold, what locks are locked, and what transactions are waiting to acquire any locks.<ul><li>The lock manager grants or blocks requests when transactions request or upgrade locks. The lock manager updates its internal lock table when transactions release or downgrade locks.</li><li>The lock manager is responsible for detecting deadlock and choosing some transactions to kill.</li></ul></li></ol><h2 id="what-is-the-problem-with-releasing-locks-and-acquiring-them-later-again"><a class="markdownIt-Anchor" href="#what-is-the-problem-with-releasing-locks-and-acquiring-them-later-again"></a> What is the problem with releasing locks and acquiring them later again?</h2><ol><li>This may cause inconsistent reads for a transaction when another transaction modified the object when the lock was available.</li><li>This problem can be solved by two-phase locking.<ul><li>The first phase is growing:<ul><li>Each transaction requests or upgrades the locks it needs from the DBMS’s lock manager. The lock manager grants/denies lock requests.</li></ul></li><li>The second phase is shrinking:<ul><li>The transaction can only release or downgrade the locks that it previously acquired. It cannot acquire new locks.</li></ul></li></ul></li><li>Two-phase locking is sufficient to guarantee conflict serializability because it generates schedules whose precedence graph is acyclic.</li></ol><h2 id="what-is-the-problem-of-two-phase-locking"><a class="markdownIt-Anchor" href="#what-is-the-problem-of-two-phase-locking"></a> What is the problem of two-phase locking?</h2><ol><li>It is subject to cascading aborts caused by dirty reads.<ul><li>When a transaction modifies an object and releases the lock before it is aborted, the modified object is exposed to other transactions.</li><li>When the modifier is aborted, all other transactions using the modified object need to abort.</li></ul></li><li>This can be solved by strong strict two-phase locking (rigorous two-phase locking).<ul><li>The transaction can only release locks after it ends, i.e., committed or aborted.</li></ul></li><li>A schedule is strict if a value written by a transaction is not read or overwritten by other transactions until that transaction finishes.<ul><li>Its advantages are that it does not incur cascading aborts, and aborted transactions can be undone by restoring the original values of modified tuples.</li><li>However, it allows only conflict serializable schedules, but it is often stronger than needed for some apps. Most DBMSs prefer correctness before performance.</li></ul></li></ol><h1 id="deadlock"><a class="markdownIt-Anchor" href="#deadlock"></a> Deadlock</h1><h2 id="how-to-detect-and-resolve-deadlocks"><a class="markdownIt-Anchor" href="#how-to-detect-and-resolve-deadlocks"></a> How to detect and resolve deadlocks?</h2><ol><li>The two-phase locking may lead to deadlocks.</li><li>The DBMS creates a waits-for graph to keep track of what locks each transaction is waiting to acquire<ul><li>Nodes are transactions. Edge from <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>T</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">T_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> to <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>T</mi><mi>j</mi></msub></mrow><annotation encoding="application/x-tex">T_j</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.969438em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.311664em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span></span></span></span> if <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>T</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">T_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> is waiting for <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>T</mi><mi>j</mi></msub></mrow><annotation encoding="application/x-tex">T_j</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.969438em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.311664em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span></span></span></span> to release a lock.</li><li>The system periodically checks for cycles in the waits-for graph and then decides how to break it.</li></ul></li><li>When the DBMS detects a deadlock, it will select a “victim” transaction to rollback to break the cycle.<ul><li>Depending on how it was invoked, the victim transaction will either restart or abort (more common).</li><li>There is a trade-off between the frequency of checking for deadlocks and how long transactions wait before deadlocks are broken.</li></ul></li><li>Selecting the proper victim depends on a lot of different variables.<ul><li>By age (lowest timestamp)</li><li>By progress (least/most queries executed)</li><li>By the number of items already locked</li><li>By the number of transactions that we have to rollback with it</li><li>We also should consider the # of times a transaction has been restarted in the past to prevent starvation.</li></ul></li><li>After selecting a victim transaction to abort, the DBMS can also decide how far to rollback the transaction’s changes.<ul><li>The first approach is to rollback the entire transaction and tell the application that it was aborted.</li><li>The second approach is rolling back a portion of a transaction to break the deadlock and then attempting to re-execute the undone queries.</li></ul></li></ol><h2 id="how-to-prevent-deadlocks"><a class="markdownIt-Anchor" href="#how-to-prevent-deadlocks"></a> How to prevent deadlocks?</h2><ol><li>When a transaction tries to acquire a lock held by another transaction, the DBMS kills one to prevent a deadlock.</li><li>Assign priorities based on timestamps, e.g., older timestamp means higher priority.</li><li>The first kind of rule is Wait-Die (“Old Waits for Young”)<ul><li>If requesting a transaction has higher priority than holding a transaction, then requesting a transaction waits for the holding transaction. Otherwise, requesting transaction aborts.</li></ul></li><li>The second kind of rule is Wound-Wait (“Young Waits for Old”)<ul><li>If requesting a transaction has higher priority than holding a transaction, then holding the transaction aborts and releases the lock. Otherwise, requesting transaction waits.</li></ul></li><li>In this case, only one “type” of direction is allowed when waiting for a lock.</li><li>When a transaction restarts, its new priority remains its original timestamp to prevent it from getting starved for resources like an old man at a corrupt senior center.</li></ol><h1 id="lock-granularity"><a class="markdownIt-Anchor" href="#lock-granularity"></a> Lock granularity</h1><h2 id="what-are-the-database-objects"><a class="markdownIt-Anchor" href="#what-are-the-database-objects"></a> What are the database objects?</h2><ol><li>Depending on the lock granularity, it can be attributes, tuples, pages, or tables.</li><li>The trade-off is between parallelism versus overhead of requesting and lock manager processing.</li><li>In a hierarchical lock scheme, the objects from top-layer to lower-layer are database, table, page, tuple, and attribute.</li></ol><h2 id="how-to-support-multiple-granularities"><a class="markdownIt-Anchor" href="#how-to-support-multiple-granularities"></a> How to support multiple granularities?</h2><ol><li>With only <code>S-LOCK</code> and <code>X-LOCK</code>, we have to check the locks of all children when we try to lock a higher-level node.</li><li>An intention lock allows a higher-level node to be locked in a shared or exclusive mode without checking all descendent nodes.</li><li>If a node is locked in an intention mode, then some transaction explicitly locks at a lower level in the tree.<ul><li>Intention-Shared (<code>IS</code>) indicates explicit locking at a lower level with shared locks.</li><li>Intention-Exclusive (<code>IX</code>) indicates explicit locking at a lower level with exclusive locks.</li><li>Shared+Intention-Exclusive (<code>SIX</code>) indicates that the subtree rooted by that node is locked explicitly in shared mode, and explicit locking is being done at a lower level with exclusive-mode locks.</li><li>Their compatibility matrix is as follows:<br /><img src="/imgs/15445/2pl/intention.png" width="50%"></li></ul></li><li>Each transaction obtains an appropriate lock at the highest level of the database hierarchy.<ul><li>The transaction must hold at least <code>IS</code> on the parent node to get an <code>S</code> or <code>IS</code> lock on a node.</li><li>It must hold at least <code>IX</code> on the parent node to get <code>X</code>, <code>IX</code>, or <code>SIX</code> on a node.</li></ul></li><li>Multiple lock granularities are shown in the <code>S</code>, <code>X</code>, and <code>SIX</code> locks on higher-level objects.<ul><li>Intention-Shared (<code>IS</code>): Intent to get <code>S</code> lock(s) at a finer granularity.</li><li>Intention-Exclusive (<code>IX</code>): Intent to get <code>X</code> lock(s) at a finer granularity.</li><li>Shared+Intention-Exclusive (<code>SIX</code>): Like <code>S</code> and <code>IX</code> at the same time.</li></ul></li></ol><h2 id="how-to-use-locks"><a class="markdownIt-Anchor" href="#how-to-use-locks"></a> How to use locks?</h2><ol><li>Applications typically don’t acquire a transaction’s locks manually (i.e., explicit SQL commands).<ul><li>Sometimes, you need to provide the DBMS with hints to help it improve concurrency.</li><li>Explicit locks are also helpful when making major changes to the database.</li></ul></li><li>Lock escalation: The DBMS can automatically switch to coarser-grained locks when a transaction acquires too many low-level locks. This reduces the number of requests that the lock manager must process.</li></ol>]]></content>
      
      
      <categories>
          
          <category> Open Courses </category>
          
          <category> CMU 15-445/645 Database System </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Concurrency Control </tag>
            
            <tag> Database System </tag>
            
            <tag> Transaction </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Project #3: Query Execution</title>
      <link href="/2023/08/02/OpenSource/BusTub/Project-3-Query-Execution/"/>
      <url>/2023/08/02/OpenSource/BusTub/Project-3-Query-Execution/</url>
      
        <content type="html"><![CDATA[<p><ul class="markdownIt-TOC"><li><a href="#executors">Executors</a><ul><li><a href="#overall">Overall</a></li><li><a href="#scan">Scan</a></li><li><a href="#modification">Modification</a></li><li><a href="#aggregation">Aggregation</a></li><li><a href="#nestedloopjoin">NestedLoopJoin</a></li><li><a href="#hashjoin">HashJoin</a></li><li><a href="#sort-top-n">Sort &amp; Top-N</a></li></ul></li><li><a href="#optimizer">Optimizer</a><ul><li><a href="#nested-loop-join">Nested loop join</a></li><li><a href="#order-by">Order by</a></li><li><a href="#projection">Projection</a></li><li><a href="#filter">Filter</a></li></ul></li></ul></p><h1 id="executors"><a class="markdownIt-Anchor" href="#executors"></a> Executors</h1><h2 id="overall"><a class="markdownIt-Anchor" href="#overall"></a> Overall</h2><ol><li>The planner for each operation stores the necessary information to calculate the correct output.</li><li>The executor class for each operation stores the corresponding plan and other information to determine what tuple will be returned.<ul><li>All executors must override the <code>Init()</code> and <code>Next(Tuple *tuple, RID *rid)</code>.</li><li><code>Init()</code> is used to initialize the information to determine what tuple will be returned. It is separated from the constructor because its parent executor may need to fetch the tuples of the current executor several times.</li></ul></li><li>The <code>ExecutorContext</code> in each executor stores the metadata of the database system, including catalog and buffer pool manager.<ul><li>Catalog maintains the tables and indexes in the current database.</li><li>We can register a new table or index through a catalog or acquire metadata of a table (TableInfo) or index (IndexInfo) from the catalog.</li></ul></li><li><code>TableInfo</code> stores the name, OID, schema of the table, and a pointer for <code>TableHeap</code>.<ul><li>We can manipulate a table through its <code>TableHeap</code>.</li><li>The <code>TableHeap</code> provides methods to insert or get tuples and update or get tuple metadata.<ul><li>We need to mark the <code>is_deleted_</code> flag in its metadata to delete a tuple as <code>true</code>.</li><li>To update a tuple, we need to delete it first and insert the newly updated tuple into the table again.</li><li><code>TableHeap</code> also provides <code>MakeIterator()</code> to iterate through the table.</li></ul></li></ul></li><li>The <code>IndexInfo</code> stores the name and OID of the index, the schema for the index key, the name of the table, and a pointer of the <code>Index</code>.<ul><li>We can manipulate an index through its <code>Index</code>.</li><li>The <code>Index</code> provides methods to insert or delete an entry from the index and get index metadata.<ul><li>The metadata includes the names of the index and table, the mapping relation between the key schema and tuple schema, and the schema of the indexed key.</li><li>The <code>Index</code> is the abstract class of all kinds of index implementations. To use a specific known index implementation, we can <code>dynamic_cast</code> it.</li></ul></li></ul></li><li>This system supports <code>ArithmeticExpression</code>, <code>ColumnValueExpression</code>, <code>ComparisonExpression</code>, <code>ConstantValueExpression</code>, <code>LogicExpression</code>, <code>StringExpression</code>.<ul><li>The <code>AbstractExpression</code> provides an <code>Evaluate</code> method to calculate the desired <code>Value</code> according to the provided one <code>Tuple</code> and <code>Schema</code>.<ul><li>The <code>ArithmeticExpression</code> only supports <code>PLUS</code> and <code>MINUS</code> operation of two <code>Value</code>s.</li><li>The <code>ColumnValueExpression</code> returns the <code>Value</code> of the designated column.</li><li>The <code>ComparisonExpression</code> supports the comparison result of two <code>Values</code>s of <code>equal, not equal, less, less or equal, greater, greater or equal</code>.</li><li>The <code>ConstantValueExpression</code> returns a single constant <code>Value</code>.</li><li>The <code>LogicExpression</code> supports the <code>AND/OR</code> of two <code>Value</code>s.</li><li>The <code>StringExpression</code> converts a string to lower-case or upper-case.</li></ul></li><li>The <code>AbstractExpression</code> also provides an <code>EvaluateJoin</code> method to calculate the join condition of two <code>Tuple</code>s. They support the same functions as <code>Evaluation</code>, except that they consider two tuples.</li><li><code>ArithmeticExpression</code>, <code>ComparisonExpression</code>, <code>LogicExpression</code>, and <code>LogicExpression</code> may have child-expressions. During evaluation, they will first perform child expressions recursively.</li></ul></li></ol><h2 id="scan"><a class="markdownIt-Anchor" href="#scan"></a> Scan</h2><ol><li>In sequential scans, we only need to know which table to scan.<ul><li>The object ID and name of the table are stored in the planner.</li><li>In the <code>Init()</code>, the table metadata (<code>TableInfo</code>) is fetched from the catalog, and the corresponding iterator of the table is created.</li><li>In the <code>Next(Tuple *tuple, RID *rid)</code>, if the iterator is not at the end, we need to find the first tuple with <code>is_deleted_</code> being <code>false</code> and matching with <code>filter_predicate_</code>.</li></ul></li><li>In the index scan, we need to know which index to scan and which table to fetch the tuple.<ul><li>The OID of the index is stored in the planner, while the table name is stored in <code>IndexInfo</code>.</li><li>To fetch the iterator of the index, we need to cast the <code>Index</code> into the specific implementation.</li><li>Each iterator points to <code>(key, RecordID)</code> pair. We can fetch the tuple with the <code>GetTuple</code> of the <code>TableHeap</code>.</li><li>As long as the iterator is not at the end, we must find the first tuple with <code>is_deleted_</code> being <code>false</code>.</li></ul></li></ol><h2 id="modification"><a class="markdownIt-Anchor" href="#modification"></a> Modification</h2><ol><li>We will modify the table and all the associated indexes in the modification executors.<ul><li>The table OIDs are stored in the corresponding planner, while we can fetch all indexes of that table with the name of the table in <code>TableInfo</code>.</li><li>The indexed keys can be acquired using the <code>KeyFromTuple</code> method of <code>Tuple</code>. The stored values are RecordIDs.</li></ul></li><li>All the modification executors only return one row representing the number of modified tuples. Hence, the executor should handle all the modifications in one <code>Next</code> call.<ul><li>When no modification is performed, we should also return one row of <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>0</mn></mrow><annotation encoding="application/x-tex">0</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">0</span></span></span></span>.</li><li>To distinguish between no modification and modification already finished in the last call, we should have a flag representing whether or not we have already modified the table.</li></ul></li><li>The tuples to insert or delete are acquired from the child executor in the insert executor and delete executor.</li><li>The update planner has a target expression for each output column.<ul><li>After acquiring the original tuple from the child executor, we can evaluate each output column with target expressions.</li><li>The expressions can be any expressions here.</li><li>When updating indexes, the old ones must be deleted before insertion.</li></ul></li></ol><h2 id="aggregation"><a class="markdownIt-Anchor" href="#aggregation"></a> Aggregation</h2><ol><li>The aggregations are implemented with a hash table.<ul><li>The hash table hashes the aggregate keys to the aggregate result.</li><li>When inserting a tuple into the hash table, it updates the aggregate result according to the aggregate function and the aggregate values from the tuple.</li><li>To use <code>std::hash</code>, the key is <code>AggregateKey</code> containing a vector of <code>Value</code> describing the group-by keys, while the value is <code>AggregateValue</code> containing another vector of <code>Value</code> describing aggregate values.<ul><li>The <code>AggregateKey</code> needs to override the <code>==</code> operator and provide the <code>()</code> operator in <code>struct std::hash&lt;bustub::AggregateKey&gt;</code> to calculate the hash value of <code>AggregateKey</code>.</li></ul></li></ul></li><li>Aggregations are pipeline breakers. Hence, the build phase could be performed in the Init(), where all tuples from the child executor are read and inserted into the hash table to calculate the outputs.<ul><li>If no tuple is inserted, the aggregation executor must return the default values for each aggregate function.</li><li>The aggregation planner has two vectors of <code>AbstractExpressionRef</code> to fetch the aggregate keys and aggregate values from tuples received from the child executor for aggregate computation. They are all <code>ColumnExpression</code>.</li></ul></li><li>In the <code>Next(Tuple *tuple, RID *rid)</code>, we must iterate over the hash table and output a tuple combining the aggregate keys and results.</li></ol><h2 id="nestedloopjoin"><a class="markdownIt-Anchor" href="#nestedloopjoin"></a> NestedLoopJoin</h2><ol><li><p>The executor must iterate over the left child executor and the right child executor.</p><ul><li>When the right child executor has emitted all tuples, the join executor will try to fetch a new tuple from the left child executor and re-initialize the right child executor for the following comparison.</li><li>Since we do not always fetch from the left child executor when the <code>Next</code> is called, we need to record the current left tuple when it is fetched.</li><li>To distinguish between the status of no more left tuples and those that have not fetched any left tuples yet, we can fetch the first left tuple in <code>Init()</code>.</li><li>To mark the status of no more left tuples, i.e., no more tuples to emit, we need a flag to record the status of left tuples and the returned value of the <code>Next</code> left child executor.</li></ul></li><li><p>For the left join, if an outer tuple does not match any inner tuple, we still need to emit the concatenation of that outer tuple with an all-null inner tuple.</p></li><li><p>The predicate expression of the executor can be either a <code>LogicExpression</code> or <code>ComparisonExpression</code>.</p></li></ol><h2 id="hashjoin"><a class="markdownIt-Anchor" href="#hashjoin"></a> HashJoin</h2><ol><li>Similar to aggregations, we need a hash table for the outer table. We define <code>JoinKey</code> and <code>JoinBucket</code> to hash.<ul><li>We store all tuples with the same values in the attributes of the join condition.</li><li>We must also record whether one tuple is used to support left join.<ul><li>When a tuple is matched with some inner tuple, all tuples in the same bucket must also matched. Hence, we only need to record the usage of each <code>JoinBucket</code>.</li><li>For left join, when there are no more right tuples, the executor still needs to iterate through the hash table to see if any bucket is unused.</li></ul></li><li>Similar to aggregation, <code>HashJoin</code> must build the hash table based on the outer table in <code>Init()</code>.</li></ul></li><li>Unlike <code>NestedLoopJoin</code>, the plan of HashJoin only needs to know how to fetch columns from each tuple to determine whether those tuples are matched.<ul><li>The expressions of the <code>HashJoin</code> planner are only <code>ColumnValueExpression</code>.</li></ul></li></ol><h2 id="sort-top-n"><a class="markdownIt-Anchor" href="#sort-top-n"></a> Sort &amp; Top-N</h2><ol><li>The compare function needs specific expressions to fetch designated columns from each tuple.<ul><li>Hence, we cannot implement only a non-static member function or a function with expressions as one of the parameters.</li><li>We need to implement a structure with an override <code>()</code> operator. The expressions are passed to the object in initialization.</li><li>For <code>priority_queue</code>, two nodes will be swapped when the comparison function returns true.</li></ul></li><li>In <code>Init()</code>, we must fetch and sort all tuples from the child executor.<ul><li>For the Top-N executor, the heap size should not be larger than <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>N</mi></mrow><annotation encoding="application/x-tex">N</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">N</span></span></span></span>. The heap after the <code>Init()</code> is the counter-order of the output order. Hence, we still need a stack to support output in <code>Next</code>.</li></ul></li></ol><h1 id="optimizer"><a class="markdownIt-Anchor" href="#optimizer"></a> Optimizer</h1><ol><li>When optimizing a plan, the root plan is passed to the optimizer, and the optimizer will perform a DFS of the plan tree.</li><li>Each optimizer tries to recognize the pattern they must handle and produce a new plan when matched.</li></ol><h2 id="nested-loop-join"><a class="markdownIt-Anchor" href="#nested-loop-join"></a> Nested loop join</h2><ol><li>To optimize nested loop join with hash join, the optimizer must find a nested loop join and separate all the conditions from <code>LogicExpression</code> into <code>ComparisonExpression</code>.<ul><li>If all the <code>ComparisonExpression</code> are <code>ComparisonType::Equal</code>, we can create a new plan of <code>HashJoin</code> with <code>left_key_expressions</code> and <code>right_key_expressions</code> extracted from those <code>ComparisonExpression</code>.</li></ul></li><li>Push down predicates of nested loop join to reduce the output of children of join and the complexity of join.<ul><li>Only predicates that only involve one side of the input of the join operator can be pushed down.</li><li>Some predicates need to be pushed into the left child, some to the right child, and some remain in the join.</li><li>To push down the predicate, we can create a new FilterPlanNode as a child of join and father of the original child.</li></ul></li><li>Nested loop join can be replaced by hash join when the predicates are all equal conditions.</li><li>If the parent planner of a nested loop join is an aggregation planner, and that aggregation planner involves only data from one side, we can push down that aggregation as one of the children of join.<ul><li>The insight is that aggregation usually outputs fewer rows than input since aggregation groups rows before sending one row for each group.</li><li>The columns in the mathematical expressions need to be modified according to the side of aggregation.</li></ul></li></ol><h2 id="order-by"><a class="markdownIt-Anchor" href="#order-by"></a> Order by</h2><ol><li>To optimize the sorted limit into top-N, we need to check whether the child of a limit plan is a sort.</li><li>When sorting the table, instead of executing sort algorithms, we may use the existing index to traverse the table.<ul><li>It can only be used when the desired order is ascending, or default and the child of the sorting planner is the SeqScan planner.</li></ul></li></ol><h2 id="projection"><a class="markdownIt-Anchor" href="#projection"></a> Projection</h2><ol><li><code>SELECT *</code>, aggregations, or renaming the columns in the planner may cause multiple identical project planners.<ul><li>The child of the projection planner is not required to be a projection.</li><li>We can remove the projection planner if it has the same schema as its child except for the column name.</li><li>Then, the output schema of the child is replaced by the output schema of the projection.</li></ul></li><li>The child of the projection planner may be emitting unnecessary columns.<ul><li>Besides the naive projection, a projection planner could also perform arithmetical expressions.</li><li>If the child is another projection, we can merge them and express the new projection under the column schema of the child’s input schema.</li><li>If the child is an aggregation planner, it only needs to calculate those necessary aggregations.</li></ul></li></ol><h2 id="filter"><a class="markdownIt-Anchor" href="#filter"></a> Filter</h2><ol><li>Always true filters can be eliminated to avoid re-evaluation for every row.</li><li>The filter planner with a child of sequential scan can be merged to reduce the data transmission between executors.</li><li>When the predicate of sequential scan is all equal conditions, and a corresponding index exists, the sequential scan can be replaced by an index scan to avoid scanning the entire table.<ul><li>It needs to modify the <code>IndexScanPlanner</code> and the <code>IndexScanExecutor</code> to support scanning only the row designated by the equal conditions.</li></ul></li></ol>]]></content>
      
      
      <categories>
          
          <category> Open Source Code </category>
          
          <category> BusTub </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Database System </tag>
            
            <tag> Executor </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>09 Concurrency Control</title>
      <link href="/2023/07/16/Courses/15445/09-Concurrency-Control/"/>
      <url>/2023/07/16/Courses/15445/09-Concurrency-Control/</url>
      
        <content type="html"><![CDATA[<p><ul class="markdownIt-TOC"><li><a href="#concurrency-control-recovery">Concurrency control &amp; recovery</a><ul><li><a href="#what-do-we-want-from-concurrency-control-recovery">What do we want from concurrency control &amp; recovery?</a></li><li><a href="#how-do-applications-issue-changes-to-a-dbms">How do applications issue changes to a DBMS?</a></li><li><a href="#what-does-the-dbms-want-to-prevent-when-supporting-concurrency">What does the DBMS want to prevent when supporting concurrency?</a></li></ul></li><li><a href="#correctness">Correctness</a><ul><li><a href="#what-are-the-correctness-criteria">What are the correctness criteria?</a></li><li><a href="#how-to-ensure-atomicity">How to ensure atomicity?</a></li><li><a href="#what-is-consistency">What is consistency?</a></li><li><a href="#isolation">Isolation</a><ul><li><a href="#what-do-we-want-from-isolation">What do we want from isolation?</a></li><li><a href="#how-to-decide-whether-a-schedule-matches-isolation">How to decide whether a schedule matches isolation?</a></li><li><a href="#what-conflicts-do-we-want-to-prevent">What conflicts do we want to prevent?</a></li><li><a href="#how-do-we-determine-whether-a-schedule-is-conflict-serializable">How do we determine whether a schedule is conflict serializable?</a></li><li><a href="#how-do-we-determine-whether-a-schedule-is-view-serializable">How do we determine whether a schedule is view serializable?</a></li></ul></li></ul></li></ul></p><h1 id="concurrency-control-recovery"><a class="markdownIt-Anchor" href="#concurrency-control-recovery"></a> Concurrency control &amp; recovery</h1><h2 id="what-do-we-want-from-concurrency-control-recovery"><a class="markdownIt-Anchor" href="#what-do-we-want-from-concurrency-control-recovery"></a> What do we want from concurrency control &amp; recovery?</h2><ol><li>The concurrency control is responsible for the lost update problem.<ul><li>How can we avoid race conditions when updating records at the same time?</li><li>This involves the buffer pool manager layer, access methods layer, and operator execution layer.</li></ul></li><li>Recovery is responsible for durability problems.<ul><li>How can we ensure the correct state in case of a power failure?</li><li>This involves the disk manager layer and buffer pool manager layer.</li></ul></li></ol><h2 id="how-do-applications-issue-changes-to-a-dbms"><a class="markdownIt-Anchor" href="#how-do-applications-issue-changes-to-a-dbms"></a> How do applications issue changes to a DBMS?</h2><ol><li>A transaction is the execution of a sequence of one or more operations (e.g., SQL queries) on a database to perform some higher-level function.<ul><li>Transaction is the basic unit of change in a DBMS. Partial transactions are not allowed.</li><li>A new transaction starts with the <code>BEGIN</code> command.</li><li>The transaction stops with either <code>COMMIT</code> or <code>ABORT</code>:<ul><li>If committed, the DBMS either saves all the transaction’s changes <strong>or aborts</strong> it.</li><li>If aborted, all changes are undone so that it’s as if the transaction was never executed at all.</li><li>Abort can be either self-inflicted or caused by the DBMS.</li></ul></li></ul></li><li>In a strawman system, each transaction is executed one-by-one as they arrive at the DBMS.<ul><li>Before a transaction starts, copy the entire database to a new file and make all changes.<ul><li>If the transaction completes successfully, overwrite the original file with the new one.</li><li>If the transaction fails, remove the dirty copy.</li></ul></li><li>The problem with this system is that there is no concurrency, and copying the entire database can be expensive if it is large.</li></ul></li><li>Besides correctness and fairness, we also want the DBMS to allow concurrent execution of independent transactions to provide better utilization/throughput and increase user response times.</li></ol><h2 id="what-does-the-dbms-want-to-prevent-when-supporting-concurrency"><a class="markdownIt-Anchor" href="#what-does-the-dbms-want-to-prevent-when-supporting-concurrency"></a> What does the DBMS want to prevent when supporting concurrency?</h2><ol><li>Arbitrary interleaving of operations can lead to temporary inconsistency and permanent inconsistency.<ul><li>Temporary inconsistency is unavoidable and fine as long as no other transactions can see it.</li><li>Permanent inconsistency is unacceptable.</li></ul></li><li>The DBMS is only concerned about what data is read/written from/to the database. Changes to the “outside world,” e.g., sending an email, are beyond the scope of the DBMS.</li></ol><h1 id="correctness"><a class="markdownIt-Anchor" href="#correctness"></a> Correctness</h1><h2 id="what-are-the-correctness-criteria"><a class="markdownIt-Anchor" href="#what-are-the-correctness-criteria"></a> What are the correctness criteria?</h2><ol><li><strong>Atomicity</strong>: All actions in the transaction happen, or none happen, i.e., “all or nothing.”</li><li><strong>Consistency</strong>: If each transaction is consistent and the DB starts consistent, it ends up consistent.</li><li><strong>Isolation</strong>: Execution of one transaction is isolated from that of other transactions.</li><li><strong>Durability</strong>: If a transaction commits, its effects persist.</li></ol><h2 id="how-to-ensure-atomicity"><a class="markdownIt-Anchor" href="#how-to-ensure-atomicity"></a> How to ensure atomicity?</h2><ol><li>The first approach is logging (Write Ahead Log / WAL).<ul><li>DBMS logs all actions to undo the actions of aborted transactions.</li><li>Maintain undo records both in memory and on disk.</li><li>When the DBMS returns from a crash, partial transactions need to be undoed according to the undo records.</li></ul></li><li>Another approach is shadow paging.<ul><li>DBMS makes copies of pages, and transactions make changes to those copies.</li><li>Only when the transaction is committed is the page made visible to others by modifying the pointer in the directory.</li><li>It does not need extra operations when it comes back from a crash.</li></ul></li></ol><h2 id="what-is-consistency"><a class="markdownIt-Anchor" href="#what-is-consistency"></a> What is consistency?</h2><ol><li>At a high level, consistency means the “world” represented by the database is logically correct. All questions (i.e., queries) the application asks about the data will return logically correct results.</li><li>There are two notions of consistency.<ul><li>Database consistency means the database accurately models the real world and follows integrity constraints.<ul><li>Transactions in the future see the effects of transactions committed in the past inside the database.</li><li>The DBMS designer should maintain this consistency.</li></ul></li><li>Transaction consistency means that if the database is consistent before the transaction starts, it will also be consistent after.<ul><li>The application programmer is responsible for this consistency. The DBMS does not know the semantics of correctness.</li></ul></li></ul></li></ol><h2 id="isolation"><a class="markdownIt-Anchor" href="#isolation"></a> Isolation</h2><h3 id="what-do-we-want-from-isolation"><a class="markdownIt-Anchor" href="#what-do-we-want-from-isolation"></a> What do we want from isolation?</h3><ol><li>Users submit transactions, and each transaction executes as if it were running by itself, i.e., it is executed in a strawman system where no other transaction is executing simultaneously.</li><li>Isolation provides an easier programming model to reason about.</li><li>However, the DBMS achieves concurrency by interleaving the actions (reads/writes of DB objects) of transactions. Hence, we need to schedule interleave transactions but still make it appear they ran one at a time.</li><li>There is no guarantee that <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>T</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">T_1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> will execute before <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>T</mi><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">T_2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> or vice-versa if both are submitted together. The net effect must be equivalent to these two transactions running serially in some order.</li></ol><h3 id="how-to-decide-whether-a-schedule-matches-isolation"><a class="markdownIt-Anchor" href="#how-to-decide-whether-a-schedule-matches-isolation"></a> How to decide whether a schedule matches isolation?</h3><ol><li>If the schedule is equivalent to some serial execution, we can consider it correct.</li><li>For any database state, if the effect of executing the first schedule is identical to the effect of executing the second schedule, we say these two schedules are equivalent.</li><li>A schedule is serializable if it is equivalent to some serial execution of the transactions.<ul><li>If each transaction preserves consistency, every serializable schedule preserves consistency.</li></ul></li><li>There are two levels of serializability: conflict serializability (most commonly used) and view serializability.</li></ol><h3 id="what-conflicts-do-we-want-to-prevent"><a class="markdownIt-Anchor" href="#what-conflicts-do-we-want-to-prevent"></a> What conflicts do we want to prevent?</h3><ol><li>Two operations conflict if They are by different transactions and are on the same object while one is a write.</li><li>A read-write conflict will cause unrepeatable reading.<ul><li>Transaction gets different values when reading the same object multiple times.</li><li>The conflict is between the write from one transaction and a repeated following read from another transaction, i.e., this is actually <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>r</mi><mi>e</mi><mi>a</mi><msub><mi>d</mi><mn>1</mn></msub><mo>−</mo><mi>w</mi><mi>r</mi><mi>i</mi><mi>t</mi><mi>e</mi><mo>−</mo><mi>r</mi><mi>e</mi><mi>a</mi><msub><mi>d</mi><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">read_1-write-read_2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.84444em;vertical-align:-0.15em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mord mathnormal">e</span><span class="mord mathnormal">a</span><span class="mord"><span class="mord mathnormal">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.74285em;vertical-align:-0.08333em;"></span><span class="mord mathnormal" style="margin-right:0.02691em;">w</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mord mathnormal">i</span><span class="mord mathnormal">t</span><span class="mord mathnormal">e</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.84444em;vertical-align:-0.15em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mord mathnormal">e</span><span class="mord mathnormal">a</span><span class="mord"><span class="mord mathnormal">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> conflict where the conflict is between <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>w</mi><mi>r</mi><mi>i</mi><mi>t</mi><mi>e</mi><mo>−</mo><mi>r</mi><mi>e</mi><mi>a</mi><msub><mi>d</mi><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">write-read_2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.74285em;vertical-align:-0.08333em;"></span><span class="mord mathnormal" style="margin-right:0.02691em;">w</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mord mathnormal">i</span><span class="mord mathnormal">t</span><span class="mord mathnormal">e</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.84444em;vertical-align:-0.15em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mord mathnormal">e</span><span class="mord mathnormal">a</span><span class="mord"><span class="mord mathnormal">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>.</li><li>If there is only one read, it is not a read-write conflict. The first read will never be a read-write conflict.</li></ul></li></ol><ul><li>A write-read conflict will cause a dirty read.<ul><li>One transaction reads data written by another transaction that has not been committed yet.</li><li>The problem will happen when the read transaction is committed before the write transaction aborts.</li><li>If the write transaction is successfully committed, there is no problem. But we cannot know that when we commit the read transaction first.</li></ul></li><li>A write-write conflict will cause a lost update.<ul><li>One transaction overwrites uncommitted data from another uncommitted transaction.</li><li>This may cause the result to become a combination of two partial transactions.</li><li>There is no problem when every data written by <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>T</mi><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">T_2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> is the last write to that data, i.e., every data written by <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>T</mi><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">T_2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> is not overwritten by <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>T</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">T_1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>. The problem happens when <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>T</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">T_1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> overwrites some data of <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>T</mi><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">T_2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> while <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>T</mi><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">T_2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> overwrites some data of <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>T</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">T_1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>.</li></ul></li></ul><h3 id="how-do-we-determine-whether-a-schedule-is-conflict-serializable"><a class="markdownIt-Anchor" href="#how-do-we-determine-whether-a-schedule-is-conflict-serializable"></a> How do we determine whether a schedule is conflict serializable?</h3><ol><li>When there are only two schedules:<ul><li>Two schedules are conflict equivalent if and only if they involve the same actions of the same transactions and every pair of conflicting actions is ordered the same way.</li><li>Schedule S is conflict serializable if S is conflict equivalent to some serial schedule.</li><li>We can transform S into a serial schedule by swapping consecutive non-conflicting operations of different transactions.</li></ul></li><li>For more schedules, we can use the dependency graphs.<ul><li>Create one node per transaction in the graph.</li><li>Create an edge from <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>T</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">T_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> to <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>T</mi><mi>j</mi></msub></mrow><annotation encoding="application/x-tex">T_j</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.969438em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.311664em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span></span></span></span> if an operation <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>O</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">O_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02778em;">O</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> of <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>T</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">T_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> conflicts with an<br />operation <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>O</mi><mi>j</mi></msub></mrow><annotation encoding="application/x-tex">O_j</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.969438em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02778em;">O</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.311664em;"><span style="top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span></span></span></span> of <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>T</mi><mi>j</mi></msub></mrow><annotation encoding="application/x-tex">T_j</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.969438em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.311664em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span></span></span></span> and <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>O</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">O_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02778em;">O</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> appears earlier in the schedule than <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>O</mi><mi>j</mi></msub></mrow><annotation encoding="application/x-tex">O_j</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.969438em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02778em;">O</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.311664em;"><span style="top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span></span></span></span>.</li><li>A schedule is conflict serializable if and only if its dependency graph is acyclic.</li></ul></li></ol><h3 id="how-do-we-determine-whether-a-schedule-is-view-serializable"><a class="markdownIt-Anchor" href="#how-do-we-determine-whether-a-schedule-is-view-serializable"></a> How do we determine whether a schedule is view serializable?</h3><ol><li>Schedules <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>S</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">S_1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05764em;">S</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.05764em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> and <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>S</mi><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">S_2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05764em;">S</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.05764em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> are view equivalent if:<ul><li>If <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>T</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">T_1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> reads the initial value of A in <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>S</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">S_1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05764em;">S</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.05764em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>, then <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>T</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">T_1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> also reads the initial value of A in <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>S</mi><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">S_2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05764em;">S</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.05764em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>.</li><li>If <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>T</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">T_1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> reads the value of A written by <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>T</mi><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">T_2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> in <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>S</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">S_1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05764em;">S</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.05764em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>, then <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>T</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">T_1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> also reads the value of A written by <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>T</mi><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">T_2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> in <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>S</mi><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">S_2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05764em;">S</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.05764em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>.</li><li>If <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>T</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">T_1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> writes the final value of A in <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>S</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">S_1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05764em;">S</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.05764em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>, then <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>T</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">T_1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> also writes the final value of A in <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>S</mi><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">S_2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05764em;">S</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.05764em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>.</li></ul></li><li>In a word, each transaction is different schedules that read the same values written by the same transaction, and at the end of all transactions, all data are written by the same transaction in the same value.</li><li>View Serializability allows for (slightly) more schedules than Conflict Serializability does. Neither definition allows all serializable schedules.</li></ol>]]></content>
      
      
      <categories>
          
          <category> Open Courses </category>
          
          <category> CMU 15-445/645 Database System </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Concurrency Control </tag>
            
            <tag> Database System </tag>
            
            <tag> Transaction </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>08 Query Planning &amp; Optimization</title>
      <link href="/2023/07/15/Courses/15445/08-Query-Planning-Optimization/"/>
      <url>/2023/07/15/Courses/15445/08-Query-Planning-Optimization/</url>
      
        <content type="html"><![CDATA[<p><ul class="markdownIt-TOC"><li><a href="#query-planning">Query planning</a><ul><li><a href="#what-are-the-logical-plans-and-physical-plans">What are the logical plans and physical plans?</a></li><li><a href="#what-is-the-process-flow-of-query-execution">What is the process flow of query execution?</a></li><li><a href="#how-does-the-optimizer-work">How does the optimizer work?</a></li></ul></li><li><a href="#heuristics-optimization">Heuristics optimization</a><ul><li><a href="#how-should-we-optimize-logical-plans">How should we optimize logical plans?</a></li><li><a href="#how-should-we-optimize-for-nested-sub-queries">How should we optimize for nested sub-queries?</a></li><li><a href="#how-can-we-rewrite-expression">How can we rewrite expression?</a></li></ul></li><li><a href="#cost-based-search">Cost-based search</a><ul><li><a href="#cost-estimation">Cost estimation</a><ul><li><a href="#what-cost-do-we-care">What cost do we care?</a></li><li><a href="#how-does-dbms-estimate-the-costs">How does DBMS estimate the costs?</a></li><li><a href="#what-statistics-does-the-dbms-maintain">What statistics does the DBMS maintain?</a></li></ul></li><li><a href="#query-optimization">Query optimization</a><ul><li><a href="#how-do-we-perform-cost-based-optimization">How do we perform cost-based optimization?</a></li><li><a href="#how-does-bottom-up-optimization-work">How does bottom-up optimization work?</a></li><li><a href="#how-does-top-down-optimization-work">How does top-down optimization work?</a></li></ul></li></ul></li></ul></p><h1 id="query-planning"><a class="markdownIt-Anchor" href="#query-planning"></a> Query planning</h1><h2 id="what-are-the-logical-plans-and-physical-plans"><a class="markdownIt-Anchor" href="#what-are-the-logical-plans-and-physical-plans"></a> What are the logical plans and physical plans?</h2><ol><li>The optimizer maps a logical algebra expression to the optimal equivalent physical algebra expression.</li><li>Physical operators define a specific execution strategy using an access path, i.e., a specific algorithm.<ul><li>They depend on the physical format of the data they process, i.e., sorting and compression.</li></ul></li></ol><h2 id="what-is-the-process-flow-of-query-execution"><a class="markdownIt-Anchor" href="#what-is-the-process-flow-of-query-execution"></a> What is the process flow of query execution?</h2><ol><li>The application is connected to the database system and sends a SQL query, which may be rewritten to a different format in SQL rewriter.</li><li>The SQL string is parsed into tokens that make up the syntax tree.</li><li>The binder converts named objects in the syntax tree to internal identifiers by consulting the system catalog.</li><li>The binder emits a logical plan, which may be fed to a tree rewriter for additional schema info.</li><li>The logical plan is given to the optimizer, which will select the most efficient procedure to execute the plan.</li></ol><img src="/imgs/15445/Optimizer/architecture.png" width="50%"><h2 id="how-does-the-optimizer-work"><a class="markdownIt-Anchor" href="#how-does-the-optimizer-work"></a> How does the optimizer work?</h2><ol><li>One way is heuristics/rules.<ul><li>Rewrite the query to remove stupid/inefficient things.</li><li>These techniques may need to examine the catalog, but they do not need to examine data.</li></ul></li><li>Another way is the cost-based search.<ul><li>We need a model to estimate the cost of executing a plan.</li><li>Enumerate multiple equivalent plans for a query and pick the one with the lowest cost.</li></ul></li></ol><h1 id="heuristics-optimization"><a class="markdownIt-Anchor" href="#heuristics-optimization"></a> Heuristics optimization</h1><h2 id="how-should-we-optimize-logical-plans"><a class="markdownIt-Anchor" href="#how-should-we-optimize-logical-plans"></a> How should we optimize logical plans?</h2><ol><li>Split conjunctive predicates.<ul><li>Decompose predicates into their simplest forms to make it easier for the optimizer to move them around.</li></ul></li><li>Predicate pushdown<ul><li>Move the predicate to the lowest applicable point in the plan.</li></ul></li><li>Replace cartesian products with joins.<ul><li>Replace all Cartesian Products with inner joins using the join predicates.</li></ul></li><li>Projection pushdown<ul><li>This eliminates redundant attributes before pipeline breakers to reduce materialization costs and the data passed around.</li></ul></li></ol><h2 id="how-should-we-optimize-for-nested-sub-queries"><a class="markdownIt-Anchor" href="#how-should-we-optimize-for-nested-sub-queries"></a> How should we optimize for nested sub-queries?</h2><ol><li>Rewrite to de-correlate and flatten them.<ul><li>For example, an <code>EXISTS</code> sub-query in the <code>WHERE</code> clause may be rewritten as an inner-join.</li></ul></li><li>Decompose nested queries and store results in a temporary table.<ul><li>For those sub-queries uncorrelated with an outer query, the optimizer breaks up queries into blocks and then concentrates on one block at a time.</li><li>Sub-queries are written to a temporary table and discarded after the query finishes.</li></ul></li></ol><h2 id="how-can-we-rewrite-expression"><a class="markdownIt-Anchor" href="#how-can-we-rewrite-expression"></a> How can we rewrite expression?</h2><ol><li>This is implemented using if/then/else clauses or a pattern-matching rule engine.<ul><li>Search for expressions that match a pattern. When a match is found, rewrite the expression. Halt if there are no more rules that match.</li></ul></li><li>One approach is replacing impossible or unnecessary predicates with false ones.</li><li>Another approach is merging predicates, e.g., numeric ranging predicates.</li></ol><h1 id="cost-based-search"><a class="markdownIt-Anchor" href="#cost-based-search"></a> Cost-based search</h1><h2 id="cost-estimation"><a class="markdownIt-Anchor" href="#cost-estimation"></a> Cost estimation</h2><h3 id="what-cost-do-we-care"><a class="markdownIt-Anchor" href="#what-cost-do-we-care"></a> What cost do we care?</h3><ol><li>Physical Costs<ul><li>Predict CPU cycles, I/O, cache misses, RAM consumption, and network messages.</li><li>This cost depends heavily on hardware.</li></ul></li><li>Logical Costs<ul><li>Estimate output size per operator.</li><li>This cost is independent of the operator algorithm since algorithms are physical.</li><li>It needs estimations for operator result sizes.</li></ul></li><li>Algorithmic Costs<ul><li>Mainly the complexity of the operator algorithm implementation.</li></ul></li><li>We may use a combination of multiple costs that are weighted by magic constant factors.<ul><li>Some assumptions are that processing a tuple in memory is <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>400</mn><mo>×</mo></mrow><annotation encoding="application/x-tex">400\times</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.72777em;vertical-align:-0.08333em;"></span><span class="mord">4</span><span class="mord">0</span><span class="mord">0</span><span class="mord">×</span></span></span></span> faster than reading a tuple from a disk, and sequential I/O is <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>4</mn><mo>×</mo></mrow><annotation encoding="application/x-tex">4\times</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.72777em;vertical-align:-0.08333em;"></span><span class="mord">4</span><span class="mord">×</span></span></span></span> faster than random I/O.</li><li>The most commonly used cost is the combination of physical costs and logical costs.</li></ul></li></ol><h3 id="how-does-dbms-estimate-the-costs"><a class="markdownIt-Anchor" href="#how-does-dbms-estimate-the-costs"></a> How does DBMS estimate the costs?</h3><ol><li>The DBMS stores internal statistics about tables, attributes, and indexes in its internal catalog.<ul><li>Different systems update them at different times.</li></ul></li><li>Then, DBMS derives a predicate’s selection cardinality (selectivity), the fraction of tuples that qualify.</li><li>We can make some assumptions to estimate selectivity.<ul><li>Uniform data: The distribution of values (except for the heavy hitters) is the same. May maintain a heavy hitter list that stores the most common values and assume that the occurrence of the rest of the data is the same.</li><li>Independent predicates: The predicates on attributes are independent, i.e., the conjunction of predicates can result in the multiplication or addition of probabilities.</li><li>Inclusion principle: The domain of join keys overlaps such that each key in the inner relation will also exist in the outer table.</li><li>These assumptions may not be true.</li></ul></li></ol><h3 id="what-statistics-does-the-dbms-maintain"><a class="markdownIt-Anchor" href="#what-statistics-does-the-dbms-maintain"></a> What statistics does the DBMS maintain?</h3><ol><li>Histograms:<ul><li>The naive and most accurate way is to maintain an occurrence count per value in a column.</li><li>Equi-width histograms maintain counts for a group of values. All buckets have the same width, i.e., the same number of values.</li><li>Equi-depth histograms vary the width of buckets so that the total number of occurrences for each bucket is roughly the same.</li><li>Equi-width or equi-depth histograms use the total count of a bucket divided by the number of values in that bucket as the count of each value.</li></ul></li><li>Sketches:<ul><li>Probabilistic data structure that gives an approximate count for a given value.</li><li>The cost-model can replace histograms with sketches to improve its selectivity estimate accuracy.</li></ul></li><li>Sampling:<ul><li>DBMS maintains a small subset of each table that it then uses to evaluate expressions to compute selectivity.</li><li>The selectivity is estimated by running the same query on the sample table.</li><li>The sample table is updated when the underlying tables change significantly.</li></ul></li></ol><h2 id="query-optimization"><a class="markdownIt-Anchor" href="#query-optimization"></a> Query optimization</h2><h3 id="how-do-we-perform-cost-based-optimization"><a class="markdownIt-Anchor" href="#how-do-we-perform-cost-based-optimization"></a> How do we perform cost-based optimization?</h3><ol><li>After performing rule-based rewriting, the DBMS will enumerate different plans for the query and estimate their costs.<ul><li>After exhausting all plans or some timeout, it chooses the best plan it has seen for the query.</li><li>The time spent on the search should be significantly smaller than the time spent executing the query. DBMS can set a time threshold to end the search.</li></ul></li><li>DBMS mainly enumerates the access methods (sequential scan, binary search / clustered indexes, index scan) and evaluation order.</li><li>Query planning for OLTP queries is easy because they are <strong>sargable</strong> (Search Argument Able).<ul><li>It is usually just picking the best index.</li><li>Joins are almost always on foreign key relationships with a small cardinality.</li></ul></li><li>There are two choices for multi-relation query planning.<ul><li>Bottom-up optimization: Start with nothing and then build up the plan to get to the desired outcome.</li><li>Top-down optimization: Start with the outcome you want, then work down the tree to find the optimal plan that gets you to that goal.</li></ul></li></ol><h3 id="how-does-bottom-up-optimization-work"><a class="markdownIt-Anchor" href="#how-does-bottom-up-optimization-work"></a> How does bottom-up optimization work?</h3><ol><li>Break the query into blocks and generate the logical operators for each block. For each logical operator, generate a set of physical operators that implement it.</li><li>Relations or temporary relations can layer the whole diagram, i.e., results of logical operators.</li><li>We can visualize the whole optimization diagram as a tree with different layers.<ul><li>The top layer is the query output, and the bottom contains all the relations.</li><li>The middle layers are the enumerations of different ordering. Each layer only performs one more operator than its last layer.</li><li>Hence, each pair of layers is connected to an undetermined physical operator.</li></ul></li><li>From the bottom layer up, we enumerate the possible physical algorithm of each logical operator.<ul><li>Then, estimate the cost of all possible physical algorithms.</li><li>Leave only the more efficient physical algorithm for each logical operator after comparing with only the possible physical algorithms of the same logical operator.</li></ul></li><li>When it reaches the top layer, we can determine the most efficient path of all possible paths.</li><li>Then, iteratively construct a “left-deep” join tree that minimizes the estimated amount of work to execute the plan.<ul><li>Generate a left-deep tree to take advantage of the pipeline.</li></ul></li></ol><h3 id="how-does-top-down-optimization-work"><a class="markdownIt-Anchor" href="#how-does-top-down-optimization-work"></a> How does top-down optimization work?</h3><ol><li>Start with a logical plan of what we want the query to be.</li><li>Perform a branch-and-bound search to traverse the plan tree by converting logical operators into physical operators.<ul><li>Traversing from logical operator to logical operator enumerates different orderings.</li><li>Traversing from logical operators to physical operators enumerates different physical algorithms.</li><li>The layers are similar to bottom-up optimization.</li><li>When we meet a logical operator, we must estimate the cost of all possible physical algorithms.<ul><li>So, for each physical algorithm, we must go deeper until the bottom to calculate the estimation.</li><li>For the sub-logical operators in the physical algorithm, we will enumerate its optimal execution in the lower levels.</li></ul></li><li>During the search, we can cut off a branch if its cost is already more expensive than another branch we have already seen.</li></ul></li></ol>]]></content>
      
      
      <categories>
          
          <category> Open Courses </category>
          
          <category> CMU 15-445/645 Database System </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Database System </tag>
            
            <tag> Executor </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>07 Query Execution</title>
      <link href="/2023/07/12/Courses/15445/07-Query-Execution/"/>
      <url>/2023/07/12/Courses/15445/07-Query-Execution/</url>
      
        <content type="html"><![CDATA[<p><ul class="markdownIt-TOC"><li><a href="#sequential-execution">Sequential Execution</a><ul><li><a href="#processing-model">Processing model</a><ul><li><a href="#what-does-the-processing-model-do">What does the processing model do?</a></li><li><a href="#how-does-the-iterator-model-execute">How does the iterator model execute?</a></li><li><a href="#how-does-the-materialization-model-execute">How does the materialization model execute?</a></li><li><a href="#how-does-the-vectorization-model-execute">How does the vectorization model execute?</a></li></ul></li><li><a href="#access-methods">Access methods</a><ul><li><a href="#how-can-we-optimize-sequential-scans-with-data-skipping">How can we optimize sequential scans with data skipping?</a></li><li><a href="#what-is-a-multi-index-scan">What is a multi-index scan?</a></li></ul></li><li><a href="#modification-queries">Modification queries</a><ul><li><a href="#how-should-we-execute-update-and-delete-queries">How should we execute update and delete queries?</a></li><li><a href="#how-should-we-execute-insert-queries">How should we execute insert queries?</a></li></ul></li><li><a href="#how-to-evaluate-expressions">How to evaluate expressions?</a></li></ul></li><li><a href="#parallel-execution">Parallel execution</a><ul><li><a href="#parallel-and-distributed">Parallel and distributed</a><ul><li><a href="#why-care-about-parallel-execution">Why care about parallel execution?</a></li><li><a href="#what-are-the-similarities-and-differences-between-parallel-and-distributed-dbms">What are the similarities and differences between parallel and distributed DBMS?</a></li></ul></li><li><a href="#process-model">Process model</a><ul><li><a href="#what-does-the-process-model-of-parallel-dbmss-need-to-do">What does the process model of parallel DBMSs need to do?</a></li><li><a href="#what-is-the-process-per-worker-model">What is the process per worker model?</a></li><li><a href="#what-is-the-thread-per-worker-model">What is the thread per worker model?</a></li><li><a href="#what-is-considered-when-dbms-scheduling-threads">What is considered when DBMS scheduling threads?</a></li><li><a href="#what-is-the-embedded-dbms-model">What is the embedded DBMS model?</a></li></ul></li><li><a href="#query-level-parallelism">Query-level parallelism</a><ul><li><a href="#what-are-the-query-level-parallelisms">What are the query-level parallelisms?</a></li><li><a href="#how-can-we-achieve-intra-query-parallelism">How can we achieve intra-query parallelism?</a></li></ul></li><li><a href="#io-parallelism">I/O parallelism</a><ul><li><a href="#what-is-the-problem-of-query-level-parallelism">What is the problem of query-level parallelism?</a></li><li><a href="#how-can-we-parallel-ios-with-multi-disk">How can we parallel I/Os with multi-disk?</a></li><li><a href="#how-can-we-partition-the-database">How can we partition the database?</a></li></ul></li></ul></li></ul></p><h1 id="sequential-execution"><a class="markdownIt-Anchor" href="#sequential-execution"></a> Sequential Execution</h1><h2 id="processing-model"><a class="markdownIt-Anchor" href="#processing-model"></a> Processing model</h2><h3 id="what-does-the-processing-model-do"><a class="markdownIt-Anchor" href="#what-does-the-processing-model-do"></a> What does the processing model do?</h3><ol><li>The processing model defines how the system executes a query plan, i.e., how to traverse the query plan tree.</li><li>There are two processing directions:<ul><li>Top-to-Bottom: Start with the root and “pull” data from its children. Tuples are always passed with function calls.</li><li>Bottom-to-Top: Start with leaf nodes and push data to their parents. Allows for tighter control of caches/registers in pipelines.</li></ul></li><li>There are three commonly used models: the iterator model (volcano/pipeline model), the materialization model, and the vectorized/batch model.</li></ol><h3 id="how-does-the-iterator-model-execute"><a class="markdownIt-Anchor" href="#how-does-the-iterator-model-execute"></a> How does the iterator model execute?</h3><ol><li><p>In the iterator model, operators are executed top-to-down.</p></li><li><p>Each query plan operator implements a <code>Next()</code> function. On each invocation, the operator returns either a single tuple or a <code>null</code> marker if there are no more tuples.</p><ul><li><p>The operator implements a loop that calls <code>Next()</code> on its children to retrieve their tuples and then process them.</p></li><li><p><code>Next()</code> is first called on the root operator, and the nodes on the tree will call the <code>Next()</code> on their children recursively.</p></li></ul></li><li><p>This model allows for up pipelining. However, some operators must block until their children emit all their tuples.</p><ul><li>Joins must wait until all tuples in the leaf child are processed and build the hash table to process tuples from the right child further. Hence, the tuples from the left child must block the pipeline, while those from the right child can enable the pipeline.</li><li>Subqueries and ordering (<code>Order By</code>) clauses must also block the pipeline. These are called pipeline breakers.</li></ul></li><li><p>Output control works easily with this approach. We only need to add constraints on the root operator.</p></li></ol><h3 id="how-does-the-materialization-model-execute"><a class="markdownIt-Anchor" href="#how-does-the-materialization-model-execute"></a> How does the materialization model execute?</h3><ol><li><p>In the materialization model, operators are called bottom-to-up.</p></li><li><p>Each query plan operator implements an <code>Output()</code> function.</p><ul><li><p>On each invocation, the operator processes its input all at once and then emits its output all at once.</p></li><li><p>The operator materializes its output as a single result.</p></li><li><p>The operators can send either a materialized row or a single column.</p></li></ul></li><li><p>The DBMS can push down hints (e.g., <code>LIMIT</code>) to avoid scanning too many tuples.</p></li><li><p>The output can be either whole tuples (NSM) or subsets of columns (DSM).</p></li><li><p>This model is better for OLTP workloads because queries only access a small number of tuples at a time, which means lower execution and coordination overhead and fewer function calls.</p><ul><li>It is not good for OLAP queries with large intermediate results.</li></ul></li></ol><h3 id="how-does-the-vectorization-model-execute"><a class="markdownIt-Anchor" href="#how-does-the-vectorization-model-execute"></a> How does the vectorization model execute?</h3><ol><li>The problem with the iterator model is that it can only process one tuple at a time when we can take multiple tuples and vectorize them to process in parallel (SIMD).</li><li>The vectorization model is similar to the iterator model except that each operator emits a batch of tuples instead of a single tuple.</li><li>This is ideal for OLAP queries because it greatly reduces the number of invocations per operator.<ul><li>It allows operators to use vectorized (SIMD) instructions more easily to process tuple batches.</li></ul></li></ol><h2 id="access-methods"><a class="markdownIt-Anchor" href="#access-methods"></a> Access methods</h2><h3 id="how-can-we-optimize-sequential-scans-with-data-skipping"><a class="markdownIt-Anchor" href="#how-can-we-optimize-sequential-scans-with-data-skipping"></a> How can we optimize sequential scans with data skipping?</h3><ol><li><p>The first approach is approximate queries.</p><ul><li><p>This method is lossy and may return incorrect results, but it is OK.</p></li><li><p>Execute queries on a sampled subset of the entire table to produce approximate results.</p></li></ul></li><li><p>The second approach is zone maps.</p><ul><li>This method is lossless.</li><li>Pre-computed aggregates are used for the attribute values on a page. DBMS checks the zone map first to decide whether it wants to access the page.</li><li>The trade-off is between page size and filter efficacy.</li></ul></li></ol><h3 id="what-is-a-multi-index-scan"><a class="markdownIt-Anchor" href="#what-is-a-multi-index-scan"></a> What is a multi-index scan?</h3><ol><li>If there are multiple indexes that the DBMS can use for a query, one method for DBMS to execute is to try to filter tuples with an index with the least number of tuples matches and filter other indexes based on the filtered tuples of previous indexes.<ul><li>This is ideal in the case that some indexes have little tuples that match. Filtering those indexes first can significantly reduce the number of tuples to process in the following indexes.</li></ul></li><li>If all indexes have a lot of matching tuples, we can use another method:<ul><li>Compute sets of Record IDs using each matching index. Combine these sets based on the query’s predicates (union or intersect). Retrieve the records and apply any remaining predicates.</li><li>In this way, we can reduce a log of I/O and memory space by only fetching Record IDs in the first phase instead of fetching the entire tuple.</li></ul></li></ol><h2 id="modification-queries"><a class="markdownIt-Anchor" href="#modification-queries"></a> Modification queries</h2><h3 id="how-should-we-execute-update-and-delete-queries"><a class="markdownIt-Anchor" href="#how-should-we-execute-update-and-delete-queries"></a> How should we execute update and delete queries?</h3><ol><li>Operators that modify the database (<code>INSERT</code>, <code>UPDATE</code>, <code>DELETE</code>) are responsible for modifying the target table and its indexes.<ul><li>The output of these operators can either be Record IDs or tuple data (i.e., <code>RETURNING</code>).</li></ul></li><li>To update or delete, child operators pass Record IDs to target tuples.<ul><li>The operator should remove the corresponding item from the index.</li><li>Then, the operator can modify the tuple or remove the tuple.</li><li>The update should re-insert the modified tuple into the index again.</li></ul></li><li>Updates have a possible Halloween problem:<ul><li>When we re-insert the modified tuple, its new place may be ahead of the cursor, i.e., we will pass the new tuple again in the future.<ul><li>For example, when the index is sorted according to an attribute, the modification increases that attribute.</li></ul></li><li>An update operation changes the physical location of a tuple, which causes a scan operator to visit the tuple multiple times. It can occur on clustered tables or index scans.</li><li>The solution is to keep track of previously seen tuples (e.g., through Record IDs).</li></ul></li></ol><h3 id="how-should-we-execute-insert-queries"><a class="markdownIt-Anchor" href="#how-should-we-execute-insert-queries"></a> How should we execute insert queries?</h3><ol><li>The first choice is to materialize tuples inside of the operator.<ul><li>The insert operator needs to implement its method of how to materialize tuples.</li></ul></li><li>The second choice is for the operator to insert any tuple passed in from child operators.<ul><li>The insert operator only needs to accept tuples from its children instead of implementing itself.</li></ul></li></ol><h2 id="how-to-evaluate-expressions"><a class="markdownIt-Anchor" href="#how-to-evaluate-expressions"></a> How to evaluate expressions?</h2><ol><li>The DBMS represents a <code>WHERE</code> clause as an expression tree.</li><li>The nodes in the tree represent different expression types: Comparisons (<code>=, &lt;, &gt;, !=</code>), conjunction (<code>AND</code>), disjunction (<code>OR</code>), arithmetic operators (<code>+, -, *, /, %</code>), constant values, tuple attribute references.</li><li>When evaluating the expression, DFS through the expression tree from the root.<ul><li>The performance is poor because the DBMS traverses the tree, and for each node it visits, it must figure out what the operator needs to do.</li></ul></li><li>A better approach is to evaluate the expression directly.<ul><li>Compile a function of the express (e.g., JIT compilation). In evaluation, DBMS executes the compiled function instead of traversing the tree.</li></ul></li></ol><h1 id="parallel-execution"><a class="markdownIt-Anchor" href="#parallel-execution"></a> Parallel execution</h1><h2 id="parallel-and-distributed"><a class="markdownIt-Anchor" href="#parallel-and-distributed"></a> Parallel and distributed</h2><h3 id="why-care-about-parallel-execution"><a class="markdownIt-Anchor" href="#why-care-about-parallel-execution"></a> Why care about parallel execution?</h3><ol><li>It increased performance for potentially the same hardware resources, i.e., to gain higher throughput and lower latency.</li><li>It increased the responsiveness of the system.</li><li>It potentially lowers the total cost of ownership (TCO).<ul><li>Fewer machines means less parts / physical footprint / energy consumption.</li></ul></li></ol><h3 id="what-are-the-similarities-and-differences-between-parallel-and-distributed-dbms"><a class="markdownIt-Anchor" href="#what-are-the-similarities-and-differences-between-parallel-and-distributed-dbms"></a> What are the similarities and differences between parallel and distributed DBMS?</h3><ol><li>Similarities:<ul><li>The database is spread across multiple resources to improve different aspects of the DBMS.</li><li>They need to make the database appear as a single logical instance to the application, regardless of physical organization.</li><li>SQL query for a single-resource DBMS should generate the same result on a parallel or distributed DBMS.</li></ul></li><li>Differences:<ul><li>For parallel DBMSs, resources are physically close to each other. Hence, resources communicate over high-speed interconnect. And communication is assumed to be cheap and reliable.</li><li>For distributed DBMSs, resources can be far from each other. Resources communicate using slow(er) interconnect. Therefore, communication costs and problems cannot be ignored. And communication is considered unreliable.</li></ul></li></ol><h2 id="process-model"><a class="markdownIt-Anchor" href="#process-model"></a> Process model</h2><h3 id="what-does-the-process-model-of-parallel-dbmss-need-to-do"><a class="markdownIt-Anchor" href="#what-does-the-process-model-of-parallel-dbmss-need-to-do"></a> What does the process model of parallel DBMSs need to do?</h3><ol><li>It defines how the system is architected to support concurrent requests from a multi-user application.</li><li>A worker is the DBMS component responsible for executing tasks on behalf of the client and returning the results.</li><li>There are three approaches: process per DBMS worker, thread per DBMS worker, and embedded DBMS.</li></ol><h3 id="what-is-the-process-per-worker-model"><a class="markdownIt-Anchor" href="#what-is-the-process-per-worker-model"></a> What is the process per worker model?</h3><ol><li>Each worker is a separate OS process. Hence, this model relies entirely on the OS scheduler.</li><li>When an application connects with DBMS, it connects with a dispatcher process. The dispatcher picks the application processes. Then, the application communicates with the process directly.</li><li>The processes can use shared-memory for global data structures.</li><li>The advantage of this model is that a process crash does not take down the entire system.</li></ol><h3 id="what-is-the-thread-per-worker-model"><a class="markdownIt-Anchor" href="#what-is-the-thread-per-worker-model"></a> What is the thread per worker model?</h3><ol><li>The whole DBMS is a single process with multiple worker threads in this model.</li><li>DBMS (mostly) manages its scheduling by controlling what each thread is doing.<ul><li>This also means less overhead per context switch and that DBMS does not have to manage shared memory.</li></ul></li><li>There may or may not be a dispatcher thread in the front.<ul><li>Applications may connect to the dispatcher, and the dispatcher immediately forwards the request to another thread while the application does not know about it.</li><li>Or applications can use the same scheme as the process per worker model.</li></ul></li><li>In this model, a thread crash may kill the entire system.</li></ol><h3 id="what-is-considered-when-dbms-scheduling-threads"><a class="markdownIt-Anchor" href="#what-is-considered-when-dbms-scheduling-threads"></a> What is considered when DBMS scheduling threads?</h3><p>The DBMS decides where, when, and how to execute each query plan.</p><ol><li>How many tasks should it use?</li><li>How many CPU cores should it use?</li><li>What CPU core should the tasks execute on?</li><li>Where should a task store its output?</li></ol><h3 id="what-is-the-embedded-dbms-model"><a class="markdownIt-Anchor" href="#what-is-the-embedded-dbms-model"></a> What is the embedded DBMS model?</h3><ol><li>In the aforementioned and most common systems, applications are in separate machines. They are connected through TCP or socket. Even if the applications crashed, DBMS remains running.</li><li>In embedded DBMS, DBMS runs inside of the same address space as the application. The application is (mostly) responsible for threads and scheduling.</li><li>The application may support outside connections.</li></ol><h2 id="query-level-parallelism"><a class="markdownIt-Anchor" href="#query-level-parallelism"></a> Query-level parallelism</h2><h3 id="what-are-the-query-level-parallelisms"><a class="markdownIt-Anchor" href="#what-are-the-query-level-parallelisms"></a> What are the query-level parallelisms?</h3><ol><li>Inter-Query: Execute multiple disparate queries simultaneously.<ul><li>This parallelism increases throughput and reduces latency. It improves overall performance by allowing multiple queries to execute simultaneously.</li><li>If queries are read-only, almost no explicit coordination between queries is required. Buffer pool can handle most of the sharing if necessary.</li><li>If multiple queries update the database simultaneously, this is hard to do correctly.</li></ul></li><li>Intra-Query: Execute the operations of a single query in parallel.<ul><li>This parallelism decreases latency for long-running queries, especially for OLAP queries. It improves the performance of a single query by executing its operators in parallel.</li><li>Organize operators in terms of a producer/consumer paradigm.</li></ul></li></ol><h3 id="how-can-we-achieve-intra-query-parallelism"><a class="markdownIt-Anchor" href="#how-can-we-achieve-intra-query-parallelism"></a> How can we achieve intra-query parallelism?</h3><ol><li>The first approach is using intra-operator (horizontal) parallelism.<ul><li>Decompose operators into independent fragments that perform the same function on different subsets of data.</li><li>Those decomposed operators are copied for each thread in the generated query plan.</li><li>The DBMS inserts an exchange operator into the query plan to coalesce/split results from multiple children/parent operators. The exchange operators are similar with barriers stating that data cannot be sent to the parent until all results are received.</li><li>There are three kinds of exchange operators:<ul><li>Gather: Combine the results from multiple workers into a single output stream.</li><li>Distribute: Split a single input stream into multiple output streams.</li><li>Repartition: Shuffle multiple input streams across multiple output streams.</li></ul></li></ul></li><li>The second approach is using inter-operator (vertical / pipeline) parallelism.<ul><li>Operations are overlapped with pipeline data from one stage to the next without materialization.</li><li>Each operator is a worker. Workers execute operators from different segments of a query plan at the same time.</li></ul></li><li>We can also combine these two approaches, which is called bushy parallelism.</li></ol><h2 id="io-parallelism"><a class="markdownIt-Anchor" href="#io-parallelism"></a> I/O parallelism</h2><h3 id="what-is-the-problem-of-query-level-parallelism"><a class="markdownIt-Anchor" href="#what-is-the-problem-of-query-level-parallelism"></a> What is the problem of query-level parallelism?</h3><ol><li>Using additional processes/threads to execute queries in parallel won’t help if the disk is always the main bottleneck.</li><li>It can sometimes worsen the DBMS’s performance if a worker is accessing different segments of the disk simultaneously.</li></ol><h3 id="how-can-we-parallel-ios-with-multi-disk"><a class="markdownIt-Anchor" href="#how-can-we-parallel-ios-with-multi-disk"></a> How can we parallel I/Os with multi-disk?</h3><ol><li><p>Split the DBMS across multiple storage devices to improve disk bandwidth latency.</p><ul><li>There are many options<ul><li>Multiple disks per database, one database per disk, one relation per disk, and split relation across multiple disks.</li><li>The main trade-off is the number of disks and I/O parallelism.</li></ul></li></ul></li><li><p>Configure OS/hardware to store the DBMS’s files across multiple storage<br />devices, e.g., storage appliances, RAID configuration.</p><ul><li><p>This is transparent to the DBMS.</p></li><li><p>RAID 0 strips data into different disks. Each disk stores different data.</p></li><li><p>RAID 1 mirrors data in different disks. Each disk stores the same data.</p></li></ul></li></ol><h3 id="how-can-we-partition-the-database"><a class="markdownIt-Anchor" href="#how-can-we-partition-the-database"></a> How can we partition the database?</h3><ol><li>Some DBMSs allow you to specify the disk location of each individual database.<ul><li>The buffer pool manager maps a page to a disk location.</li><li>This is also easy to do at the filesystem level if the DBMS stores each database in a separate directory.</li><li>The DBMS recovery log file might still be shared if transactions can update multiple databases.</li></ul></li><li>Logical splitting splits a single logical table into disjoint physical segments stored/managed separately.<ul><li>Partitioning should (ideally) be transparent to the application.</li><li>The application should only access logical tables and not have to worry about how things are physically stored.</li></ul></li></ol>]]></content>
      
      
      <categories>
          
          <category> Open Courses </category>
          
          <category> CMU 15-445/645 Database System </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Database System </tag>
            
            <tag> Executor </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Project #2: B+Tree</title>
      <link href="/2023/07/07/OpenSource/BusTub/Project-2-B-Tree/"/>
      <url>/2023/07/07/OpenSource/BusTub/Project-2-B-Tree/</url>
      
        <content type="html"><![CDATA[<p><ul class="markdownIt-TOC"><li><a href="#btree-page">B+Tree Page</a></li><li><a href="#btree-search">B+Tree search</a></li><li><a href="#btree-insert">B+Tree insert</a></li><li><a href="#btree-delete">B+Tree delete</a></li></ul></p><h1 id="btree-page"><a class="markdownIt-Anchor" href="#btree-page"></a> B+Tree Page</h1><ol><li><p>The <code>size_</code> in each page means the number of stored values, not keys, i.e., in internal nodes, <code>size_</code> is <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1</mn></mrow><annotation encoding="application/x-tex">1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">1</span></span></span></span> larger than the number of keys.</p></li><li><p><code>KeyComparator</code> accepts two keys to compare, which will return <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>0</mn></mrow><annotation encoding="application/x-tex">0</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">0</span></span></span></span> when they are equal, <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>−</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">-1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.72777em;vertical-align:-0.08333em;"></span><span class="mord">−</span><span class="mord">1</span></span></span></span> for the first key “smaller” than the second key, <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1</mn></mrow><annotation encoding="application/x-tex">1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">1</span></span></span></span> for the second key being larger.</p></li><li><p>We need to design the semantic of the binary search that will be used in search, insert, and delete a key inside a node.</p><ul><li>In the leaf node:<ul><li>For search and delete, we want this function to tell us the index of the key if it exists.</li><li>For insert, we want this function to indicate the index to which we need to place the key.</li></ul></li><li>In the internal node:<ul><li>For the search, we only want it to inform us of the child that might have the given key.</li><li>For the insert, we want it to return the page ID to find a proper leaf page to store the key in forward search and give the index we need to place the split key when the backward split is required.</li><li>For delete, we want it the same as for insert in the forward search and to provide the index to help merge two children when the backward merge is required.</li></ul></li><li>In the following implementation of binary search, it will return the index of the key if it exists, or it will return the largest index with a smaller key.<ul><li>Notably, if the given key is smaller than all keys in the node, it will return <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>−</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">-1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.72777em;vertical-align:-0.08333em;"></span><span class="mord">−</span><span class="mord">1</span></span></span></span>.</li><li>In the internal node, we would expect the smallest possible result is <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>0</mn></mrow><annotation encoding="application/x-tex">0</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">0</span></span></span></span> since the first key is <code>NULL,</code> which should be smaller than any other.</li></ul></li></ul><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">auto</span> <span class="title">BinarySearch</span><span class="params">(KeyType key, KeyComparator comparator)</span> <span class="type">const</span> -&gt; <span class="type">int</span> </span>&#123;</span><br><span class="line">  <span class="type">int</span> lo = <span class="number">0</span>;</span><br><span class="line">  <span class="type">int</span> hi = <span class="built_in">GetSize</span>();</span><br><span class="line">  <span class="keyword">while</span> (lo &lt; hi) &#123;</span><br><span class="line">    <span class="type">int</span> mid = (lo + hi) / <span class="number">2</span>;</span><br><span class="line">    <span class="keyword">if</span> (<span class="number">0</span> &lt; mid &amp;&amp; <span class="built_in">comparator</span>(key, array_[mid].first) &lt; <span class="number">0</span>) &#123;</span><br><span class="line">      hi = mid;</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">      lo = mid + <span class="number">1</span>;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">return</span> lo - <span class="number">1</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p><code>FindNextPageID</code> will provide the proper child for the caller to access to find a certain key.</p><ul><li>For a leaf node, this will only be used in the B+Tree search. If the binary search result is <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>−</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">-1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.72777em;vertical-align:-0.08333em;"></span><span class="mord">−</span><span class="mord">1</span></span></span></span>, we can conclude that that key does not exist and should tell the caller that.</li><li>For an internal node, this will be used in the B+Tree search or the forward search in insert and delete. If the binary search result is <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>−</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">-1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.72777em;vertical-align:-0.08333em;"></span><span class="mord">−</span><span class="mord">1</span></span></span></span>, then we should return the first value to indicate the key is smaller than all keys.</li></ul></li><li><p><code>InsertKey</code> should</p></li></ol><h1 id="btree-search"><a class="markdownIt-Anchor" href="#btree-search"></a> B+Tree search</h1><ol><li>The thought is simple: we go down from the root until hit a leaf node. If the key is in the leaf node, return the value. Otherwise, the key does not exist.</li><li>For concurrency control, we can only release a page’s latch after acquiring its child’s latch.<ul><li>This can be implemented with the move assignment operation of <code>PageGuard</code>. In the execution, the right expression will first acquire the latch of the next page, then destroy the original page guard of the left variable.</li></ul></li></ol><h1 id="btree-insert"><a class="markdownIt-Anchor" href="#btree-insert"></a> B+Tree insert</h1><ol><li><p>For concurrency control, I implemented both optimistic and pessimistic schemes.</p><ul><li><p>The program will first try with optimistic search with only a write latch on the leaf node.</p></li><li><p>If the leaf node may overflow, release all latches and start again trying to acquire a write latch for all nodes.</p></li></ul></li><li><p>In the optimistic search, we can use the queue in <code>Context</code>.</p><ul><li>When fetched a new page guard, we pushed it to the back of <code>ctx.read_set_</code> and popped the front element out of the queue. We need to access the last element of the queue every time to find the next page to read.</li><li>When we realize we have reached the leaf node, we hold a read latch for that page. Hence, we still need to release the read latch and re-acquire the write latch, i.e., we cannot release the latch of the last internal page when we first acquire the leaf page.</li><li>The solution is to release the latch before reading the “grandchild” of it.</li></ul></li><li><p>In the pessimistic search, we must acquire a write latch for all pages we want to access.</p><ul><li>We can check whether a node is safe after acquiring its write latch. If the node is safe, we can release all latches acquired before it, including the header page.</li></ul></li><li><p>In the insert function, there are three cases to handle:</p><ul><li>The first case is that this is an empty tree, i.e., the root_page_id_ in the header page is invalid. We need to create a new page for the node and update the header page.</li><li>The second case is that the leaf node won’t overflow where a simple insertion is enough.</li><li>The last case is that the leaf node might overflow.</li></ul></li><li><p>When the leaf node might overflow:</p><ul><li>After acquiring the write latches, we need to check whether there is an overflow again in case the other thread already handled overflow, causing an unexpected split.</li><li><code>SolveLeafOverflow</code><ul><li>When a leaf reaches max size after insertion, it will immediately split. So, this is used after the insertion.</li><li>It will create a new page to store the larger half of the nodes and return the first key in the new page to insert to its parent node to indicate to this page.</li><li>Also, it needs to take care of the sibling pointers between leaf nodes. The new page will point to what the original page points to. The original page will point to the new page.</li></ul></li><li><code>SolveInternalOverflow</code><ul><li>Internal nodes won’t split immediately when they reach the maximum size. This means that internal nodes must split before insertion; otherwise, the address will overflow.</li><li>The process is similar to the leaf case, except it will choose a proper page to insert the key after splitting. (Or it does not need to split if it is a safe node).</li></ul></li></ul></li></ol><h1 id="btree-delete"><a class="markdownIt-Anchor" href="#btree-delete"></a> B+Tree delete</h1><ol><li>The concurrency control is similar to the insert operation, except that the condition of whether a node is safe differs.</li><li>Compare with insertion,<ul><li>if the tree is empty, there is nothing else to do;</li><li>If the leaf node won’t underflow, a simple deletion is enough;</li><li>If the leaf node might underflow, we need to handle it and possibly follow cascade underflow.</li></ul></li><li>When the leaf node might overflow:<ul><li>Similar to the insertion situation, we must re-acquire write latches and check whether another thread handles the underflow.</li><li>If the underflowed leaf is the root, i.e., the tree has only one node, we do not need to do anything further.</li><li><code>SolveLeafUnderflow</code><ul><li>There are three situations: the left sibling can borrow a key, the right sibling can borrow a key, or neither sibling can borrow a key.</li><li>When we can borrow a key, the underflow is solved easily, and there is no more cascading. We need to modify the key in the parent node that separates the two involved nodes to the new first key of the right node.</li><li>When merging with one of the siblings, we must also handle the pointers between leaf nodes. If we move the data of the left node to the right node and delete the left node, it is hard for us to modify the pointer of the left of the left node. Instead, if we delete the right node, we only need to modify the left node’s pointer to the right node’s original pointer.</li><li>If a leaf only has a left sibling or right sibling to merge with, then we do not have a choice.</li></ul></li><li><code>SolveInternalUnderflow</code><ul><li>The process is similar to SolveLeafUnderflow, except for how to borrow a key.</li><li>When a node borrows a key to its left sibling, it will borrow the first valid key and the fire value, i.e., <code>array_[1].first</code> and <code>array_[0].second</code>.</li><li>When a node borrows a key to its right sibling, it will borrow the last key-value pair. The node accpeting those keys will use the key as its first valid key and the value as its first valid value.</li><li>We must set the corresponding key in the parent node to the borrowed key.</li></ul></li></ul></li></ol>]]></content>
      
      
      <categories>
          
          <category> Open Source Code </category>
          
          <category> BusTub </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Database System </tag>
            
            <tag> Data Structure </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>06 Operator Algorithms</title>
      <link href="/2023/06/28/Courses/15445/06-Operator-Algorithms/"/>
      <url>/2023/06/28/Courses/15445/06-Operator-Algorithms/</url>
      
        <content type="html"><![CDATA[<p><ul class="markdownIt-TOC"><li><a href="#execute-queries">Execute queries</a><ul><li><a href="#how-are-queries-planned">How are queries planned?</a></li><li><a href="#what-is-the-assumption-of-algorithms-in-database-systems">What is the assumption of algorithms in database systems?</a></li></ul></li><li><a href="#sort">Sort</a><ul><li><a href="#what-implementation-should-we-use-to-execute-a-query-containing-an-order-by-with-a-limit">What implementation should we use to execute a query containing an ORDER BY with a LIMIT?</a></li><li><a href="#what-if-the-data-is-too-large-to-fit-in-memory-for-any-clause-including-order-by-with-a-limit">What if the data is too large to fit in memory? (for any clause including ORDER BY with a LIMIT)</a></li><li><a href="#how-to-perform-an-external-merge-sort">How to perform an external merge sort?</a></li><li><a href="#how-can-we-hide-the-disk-io">How can we hide the disk I/O?</a></li><li><a href="#how-can-we-optimize-comparison">How can we optimize comparison?</a></li><li><a href="#how-to-use-btree-for-sorting-since-it-is-sorted">How to use B+Tree for sorting since it is sorted?</a></li></ul></li><li><a href="#aggregations">Aggregations</a><ul><li><a href="#how-can-we-implement-aggregations">How can we implement aggregations?</a></li><li><a href="#how-to-do-hashing-when-spilling-data-onto-a-disk">How to do hashing when spilling data onto a disk?</a></li></ul></li><li><a href="#join">Join</a><ul><li><a href="#why-do-we-need-to-join">Why do we need to join?</a></li><li><a href="#what-are-join-algorithms-doing">What are join algorithms doing?</a></li><li><a href="#what-are-the-outputs-of-join-algorithms">What are the outputs of join algorithms?</a></li><li><a href="#how-can-we-measure-the-cost-of-join">How can we measure the cost of join?</a></li><li><a href="#join-algorithms">Join algorithms</a><ul><li><a href="#nested-loop-join">Nested loop join</a><ul><li><a href="#what-is-the-most-naive-algorithm">What is the most naive algorithm?</a></li><li><a href="#how-can-we-better-use-the-data-already-read-from-disk">How can we better use the data already read from disk?</a></li><li><a href="#how-can-we-take-advantage-of-more-buffer-space">How can we take advantage of more buffer space?</a></li><li><a href="#can-we-avoid-sequential-scans-by-using-an-index">Can we avoid sequential scans by using an index?</a></li></ul></li><li><a href="#sort-merge-join">Sort-merge join</a><ul><li><a href="#what-is-the-process-of-sort-merge-join">What is the process of sort-merge join?</a></li><li><a href="#how-do-the-two-cursors-move">How do the two cursors move?</a></li><li><a href="#when-is-sort-merge-join-useful">When is sort-merge join useful?</a></li></ul></li><li><a href="#hash-join">Hash join</a><ul><li><a href="#how-does-hash-join-work">How does hash join work?</a></li><li><a href="#how-big-of-a-table-can-we-hash-using-this-approach">How big of a table can we hash using this approach?</a></li><li><a href="#can-we-optimize-the-search-for-tuples-that-do-not-have-any-match">Can we optimize the search for tuples that do not have any match?</a></li><li><a href="#what-if-we-lack-the-memory-to-fit-the-entire-hash-table">What if we lack the memory to fit the entire hash table?</a></li></ul></li></ul></li></ul></li></ul></p><h1 id="execute-queries"><a class="markdownIt-Anchor" href="#execute-queries"></a> Execute queries</h1><h2 id="how-are-queries-planned"><a class="markdownIt-Anchor" href="#how-are-queries-planned"></a> How are queries planned?</h2><ol><li>The operators are arranged in an abstract syntax tree. Data flows from the leaves of the tree up towards the root.</li><li>The leaf nodes are access methods, e.g., scanning index and scanning table, feeding data up along its path to its parent node to do the processing.</li><li>The output of the root node is the result of the query.</li><li>This tree only describes a logical plan, i.e., instead of telling what implementation to use, it is just the logical flow we want. SQL only declares a logical plan, while the database system’s job is figuring out the optimal execution.</li></ol><h2 id="what-is-the-assumption-of-algorithms-in-database-systems"><a class="markdownIt-Anchor" href="#what-is-the-assumption-of-algorithms-in-database-systems"></a> What is the assumption of algorithms in database systems?</h2><ol><li>Just like it cannot assume that a table fits entirely in memory, a disk-oriented DBMS cannot assume that query results fit in memory.</li><li>We will use the buffer pool to implement algorithms that need to spill to disk.</li><li>We will also prefer algorithms that maximize the amount of sequential I/O.</li></ol><h1 id="sort"><a class="markdownIt-Anchor" href="#sort"></a> Sort</h1><h2 id="what-implementation-should-we-use-to-execute-a-query-containing-an-order-by-with-a-limit"><a class="markdownIt-Anchor" href="#what-implementation-should-we-use-to-execute-a-query-containing-an-order-by-with-a-limit"></a> What implementation should we use to execute a query containing an ORDER BY with a LIMIT?</h2><ol><li>The DBMS only needs to scan the data once to find the top-N elements.</li><li>The ideal scenario for heapsort is when the top-N elements fit in memory so that the DBMS only has to maintain an in-memory sorted priority queue while scanning the data.</li></ol><h2 id="what-if-the-data-is-too-large-to-fit-in-memory-for-any-clause-including-order-by-with-a-limit"><a class="markdownIt-Anchor" href="#what-if-the-data-is-too-large-to-fit-in-memory-for-any-clause-including-order-by-with-a-limit"></a> What if the data is too large to fit in memory? (for any clause including ORDER BY with a LIMIT)</h2><ol><li>We do not want to use quick sort in this scenario since data spilling to disk will cause too many random access.</li><li>We can use external merge sort that splits data into separate runs, sorts them individually, and then combines them into longer sorted runs.</li><li>A run is a list of key/value pairs.<ul><li>Keys are the attribute(s) used to compare and compute the sort order.</li><li>Values have two choices: it can either be the actual tuple data (i.e., early materialization) or be the Record IDs (i.e., late materialization)<ul><li>The advantage of early materialization is that it can produce results faster, while the disadvantage is that it needs to copy more data during the procedure.</li><li>The advantage of late materialization is that it can only fetch wanted data while it needs to find the actual data elsewhere (probably involving another disk I/O).</li></ul></li></ul></li></ol><h2 id="how-to-perform-an-external-merge-sort"><a class="markdownIt-Anchor" href="#how-to-perform-an-external-merge-sort"></a> How to perform an external merge sort?</h2><ol><li>Data is broken up into <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>N</mi></mrow><annotation encoding="application/x-tex">N</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">N</span></span></span></span> pages. The DBMS has a finite number of <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>B</mi></mrow><annotation encoding="application/x-tex">B</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.05017em;">B</span></span></span></span> buffer pool pages to hold input and output data.</li><li>In the first phase, sort chunks of data that fit in memory and then write back the sorted chunks to a file on disk.<ul><li>In the first pass, we can read all <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>B</mi></mrow><annotation encoding="application/x-tex">B</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.05017em;">B</span></span></span></span> pages of the table into memory, sort pages into runs, and write them back to disk.</li><li>Do not sort in the buffer since we do not wish other threads to see some partially sorted data, which may cause errors. Copy the data to somewhere else and copy it back to the buffer after it is sorted.</li></ul></li><li>In the second phase, combine sorted runs into larger chunks.<ul><li>In the following passes, each pass use <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>B</mi><mo>−</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">B-1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.76666em;vertical-align:-0.08333em;"></span><span class="mord mathnormal" style="margin-right:0.05017em;">B</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">1</span></span></span></span> pages for input and <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1</mn></mrow><annotation encoding="application/x-tex">1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">1</span></span></span></span> page for output.</li><li>Recursively merge pairs of runs into runs <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>B</mi><mo>−</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">B-1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.76666em;vertical-align:-0.08333em;"></span><span class="mord mathnormal" style="margin-right:0.05017em;">B</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">1</span></span></span></span>-times as long.</li></ul></li><li>In general, the first pass creates <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">⌈</mo><mi>N</mi><mi mathvariant="normal">/</mi><mi>B</mi><mo stretchy="false">⌉</mo></mrow><annotation encoding="application/x-tex">\lceil N/B\rceil</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">⌈</span><span class="mord mathnormal" style="margin-right:0.10903em;">N</span><span class="mord">/</span><span class="mord mathnormal" style="margin-right:0.05017em;">B</span><span class="mclose">⌉</span></span></span></span> sorted runs of size <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>B</mi></mrow><annotation encoding="application/x-tex">B</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.05017em;">B</span></span></span></span> and the following passes are <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">(</mo><mi>B</mi><mo>−</mo><mn>1</mn><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">(B-1)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.05017em;">B</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord">1</span><span class="mclose">)</span></span></span></span>-way merge.<ul><li>The number of passes is <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1</mn><mo>+</mo><mo stretchy="false">⌈</mo><msub><mo><mi>log</mi><mo>⁡</mo></mo><mrow><mi>B</mi><mo>−</mo><mn>1</mn></mrow></msub><mo stretchy="false">⌈</mo><mi>N</mi><mi mathvariant="normal">/</mi><mi>B</mi><mo stretchy="false">⌉</mo><mo stretchy="false">⌉</mo></mrow><annotation encoding="application/x-tex">1+\lceil\log_{B-1}\lceil N/B\rceil\rceil</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.72777em;vertical-align:-0.08333em;"></span><span class="mord">1</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1.052471em;vertical-align:-0.302471em;"></span><span class="mopen">⌈</span><span class="mop"><span class="mop">lo<span style="margin-right:0.01389em;">g</span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.23419099999999998em;"><span style="top:-2.45586em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.05017em;">B</span><span class="mbin mtight">−</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.302471em;"><span></span></span></span></span></span></span><span class="mopen">⌈</span><span class="mord mathnormal" style="margin-right:0.10903em;">N</span><span class="mord">/</span><span class="mord mathnormal" style="margin-right:0.05017em;">B</span><span class="mclose">⌉</span><span class="mclose">⌉</span></span></span></span>.</li><li>The total I/O cost is <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>2</mn><mi>N</mi><mo>⋅</mo><mo stretchy="false">(</mo><mi>n</mi><mi>u</mi><mi>m</mi><mi>b</mi><mi>e</mi><mi>r</mi><mtext> </mtext><mi>o</mi><mi>f</mi><mtext> </mtext><mi>p</mi><mi>a</mi><mi>s</mi><mi>s</mi><mi>e</mi><mi>s</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">2N\cdot (number\ of\ passes)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord">2</span><span class="mord mathnormal" style="margin-right:0.10903em;">N</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord mathnormal">n</span><span class="mord mathnormal">u</span><span class="mord mathnormal">m</span><span class="mord mathnormal">b</span><span class="mord mathnormal">e</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mspace"> </span><span class="mord mathnormal">o</span><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="mspace"> </span><span class="mord mathnormal">p</span><span class="mord mathnormal">a</span><span class="mord mathnormal">s</span><span class="mord mathnormal">s</span><span class="mord mathnormal">e</span><span class="mord mathnormal">s</span><span class="mclose">)</span></span></span></span>.</li></ul></li><li>In a 2-way external merge sort, instead of sorting the <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>B</mi></mrow><annotation encoding="application/x-tex">B</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.05017em;">B</span></span></span></span> pages into a run in the first pass, each page is sorted into a run.<ul><li>So, the number of passes is <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1</mn><mo>+</mo><mo stretchy="false">⌈</mo><msub><mo><mi>log</mi><mo>⁡</mo></mo><mn>2</mn></msub><mi>N</mi><mo stretchy="false">⌉</mo></mrow><annotation encoding="application/x-tex">1+\lceil\log_2N\rceil</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.72777em;vertical-align:-0.08333em;"></span><span class="mord">1</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">⌈</span><span class="mop"><span class="mop">lo<span style="margin-right:0.01389em;">g</span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.20696799999999996em;"><span style="top:-2.4558600000000004em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.24414em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">N</span><span class="mclose">⌉</span></span></span></span>.</li></ul></li></ol><h2 id="how-can-we-hide-the-disk-io"><a class="markdownIt-Anchor" href="#how-can-we-hide-the-disk-io"></a> How can we hide the disk I/O?</h2><ol><li>A typical setup is using <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>3</mn></mrow><annotation encoding="application/x-tex">3</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">3</span></span></span></span> pages (<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>2</mn></mrow><annotation encoding="application/x-tex">2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">2</span></span></span></span> for input pages and <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1</mn></mrow><annotation encoding="application/x-tex">1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">1</span></span></span></span> for output page). Even if we have more buffer space available (<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>B</mi><mo>&gt;</mo><mn>3</mn></mrow><annotation encoding="application/x-tex">B&gt;3</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.72243em;vertical-align:-0.0391em;"></span><span class="mord mathnormal" style="margin-right:0.05017em;">B</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">&gt;</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">3</span></span></span></span>), it does not effectively utilize them if the worker must block disk I/O.</li><li>We can prefetch the next run in the background and store it in a second buffer while the system processes the current run.</li><li>This method continuously utilizes the disk to reduce the wait time for I/O requests at each step.</li></ol><h2 id="how-can-we-optimize-comparison"><a class="markdownIt-Anchor" href="#how-can-we-optimize-comparison"></a> How can we optimize comparison?</h2><ol><li>The first approach is code specialization.<ul><li>Instead of providing a comparison function as a pointer to the sorting algorithm, create a hardcoded version of the sort that is specific to a key type.</li></ul></li><li>For string keys, the second approach is suffix truncation.<ul><li>First, compare a binary prefix of keys instead of a slower string comparison.</li><li>Fallback to a slower version if prefixes are equal.</li></ul></li></ol><h2 id="how-to-use-btree-for-sorting-since-it-is-sorted"><a class="markdownIt-Anchor" href="#how-to-use-btree-for-sorting-since-it-is-sorted"></a> How to use B+Tree for sorting since it is sorted?</h2><ol><li>If the table that must be sorted already has a B+Tree index on the sort attribute(s), then we can use that to accelerate sorting.</li><li>Retrieve tuples in desired order by traversing the tree’s leaf pages.<ul><li>For clustered B+Tree, this is always better than external sorting because there is no computational cost, and all disk access is sequential.</li><li>For non-clustered B+Tree, this is almost always a bad idea. In general, one I/O per data record.</li></ul></li></ol><h1 id="aggregations"><a class="markdownIt-Anchor" href="#aggregations"></a> Aggregations</h1><h2 id="how-can-we-implement-aggregations"><a class="markdownIt-Anchor" href="#how-can-we-implement-aggregations"></a> How can we implement aggregations?</h2><ol><li>The DBMS needs a way to find tuples with the same distinguishing attributes for grouping quickly.</li><li>We can use the aforementioned sorting algorithms for aggregations specified with an <code>ORDER BY</code> clause.</li><li>Hashing is a better alternative for queries that do not need the data to be ordered, e.g., forming groups in <code>GROUP BY</code> or removing duplicates in <code>DISTINCT</code>. Hashing can be computationally cheaper than sorting.<ul><li>For each record, check whether there is an entry in the hash table. For <code>DISTINCT</code>, discard the duplicate. For <code>GROUP BY</code>, perform aggregate computation.</li></ul></li></ol><h2 id="how-to-do-hashing-when-spilling-data-onto-a-disk"><a class="markdownIt-Anchor" href="#how-to-do-hashing-when-spilling-data-onto-a-disk"></a> How to do hashing when spilling data onto a disk?</h2><ol><li>The first phase is partition. Divide tuples into buckets based on the hash key. Write them out to disk when they get full.<ul><li>Use a hash function <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>h</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">h_1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.84444em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> to split tuples into partitions on the disk.</li><li>A partition is one or more pages that contain a set of keys with the same hash value.</li><li>Assume that we have <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>B</mi></mrow><annotation encoding="application/x-tex">B</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.05017em;">B</span></span></span></span> buffers. We will use <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>B</mi><mo>−</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">B-1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.76666em;vertical-align:-0.08333em;"></span><span class="mord mathnormal" style="margin-right:0.05017em;">B</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">1</span></span></span></span> buffers for the partitions and <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1</mn></mrow><annotation encoding="application/x-tex">1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">1</span></span></span></span> buffer for the input data.</li></ul></li><li>The second phase is ReHash. Build an in-memory hash table for each partition and compute the aggregation.<ul><li>For each partition on the disk, read it into memory and build an in-memory hash table based on a second hash function <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>h</mi><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">h_2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.84444em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>.</li><li>Then, go through each bucket of this hash table to bring together matching tuples.</li><li>Each time, we can use <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>B</mi><mo>−</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">B-1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.76666em;vertical-align:-0.08333em;"></span><span class="mord mathnormal" style="margin-right:0.05017em;">B</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">1</span></span></span></span> pages as input pages and <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1</mn></mrow><annotation encoding="application/x-tex">1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">1</span></span></span></span> page as output page.<ul><li>In each round, we can read in <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>B</mi><mo>−</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">B-1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.76666em;vertical-align:-0.08333em;"></span><span class="mord mathnormal" style="margin-right:0.05017em;">B</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">1</span></span></span></span> partitions.</li><li>After each round is finished, we can clear the hash table since the next <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>B</mi><mo>−</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">B-1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.76666em;vertical-align:-0.08333em;"></span><span class="mord mathnormal" style="margin-right:0.05017em;">B</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">1</span></span></span></span> partitions definitely won’t have the same keys as in the last round.</li></ul></li></ul></li><li>During the ReHash phase, store pairs of the form <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">(</mo><mi>G</mi><mi>r</mi><mi>o</mi><mi>u</mi><mi>p</mi><mi>K</mi><mi>e</mi><mi>y</mi><mo>→</mo><mi>R</mi><mi>u</mi><mi>n</mi><mi>n</mi><mi>i</mi><mi>n</mi><mi>g</mi><mi>V</mi><mi>a</mi><mi>l</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">(GroupKey→RunningVal)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord mathnormal">G</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mord mathnormal">o</span><span class="mord mathnormal">u</span><span class="mord mathnormal">p</span><span class="mord mathnormal" style="margin-right:0.07153em;">K</span><span class="mord mathnormal">e</span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">→</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="mord mathnormal">u</span><span class="mord mathnormal">n</span><span class="mord mathnormal">n</span><span class="mord mathnormal">i</span><span class="mord mathnormal">n</span><span class="mord mathnormal" style="margin-right:0.03588em;">g</span><span class="mord mathnormal" style="margin-right:0.22222em;">V</span><span class="mord mathnormal">a</span><span class="mord mathnormal" style="margin-right:0.01968em;">l</span><span class="mclose">)</span></span></span></span>.<ul><li>When we want to insert a new tuple into the hash table if we find a matching <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>G</mi><mi>r</mi><mi>o</mi><mi>u</mi><mi>p</mi><mi>K</mi><mi>e</mi><mi>y</mi></mrow><annotation encoding="application/x-tex">GroupKey</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8777699999999999em;vertical-align:-0.19444em;"></span><span class="mord mathnormal">G</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mord mathnormal">o</span><span class="mord mathnormal">u</span><span class="mord mathnormal">p</span><span class="mord mathnormal" style="margin-right:0.07153em;">K</span><span class="mord mathnormal">e</span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span></span></span></span>, update the <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>R</mi><mi>u</mi><mi>n</mi><mi>n</mi><mi>i</mi><mi>n</mi><mi>g</mi><mi>V</mi><mi>a</mi><mi>l</mi></mrow><annotation encoding="application/x-tex">RunningVal</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="mord mathnormal">u</span><span class="mord mathnormal">n</span><span class="mord mathnormal">n</span><span class="mord mathnormal">i</span><span class="mord mathnormal">n</span><span class="mord mathnormal" style="margin-right:0.03588em;">g</span><span class="mord mathnormal" style="margin-right:0.22222em;">V</span><span class="mord mathnormal">a</span><span class="mord mathnormal" style="margin-right:0.01968em;">l</span></span></span></span> appropriately. Else, insert a new <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">(</mo><mi>G</mi><mi>r</mi><mi>o</mi><mi>u</mi><mi>p</mi><mi>K</mi><mi>e</mi><mi>y</mi><mo>→</mo><mi>R</mi><mi>u</mi><mi>n</mi><mi>n</mi><mi>i</mi><mi>n</mi><mi>g</mi><mi>V</mi><mi>a</mi><mi>l</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">(GroupKey→RunningVal)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord mathnormal">G</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mord mathnormal">o</span><span class="mord mathnormal">u</span><span class="mord mathnormal">p</span><span class="mord mathnormal" style="margin-right:0.07153em;">K</span><span class="mord mathnormal">e</span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">→</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="mord mathnormal">u</span><span class="mord mathnormal">n</span><span class="mord mathnormal">n</span><span class="mord mathnormal">i</span><span class="mord mathnormal">n</span><span class="mord mathnormal" style="margin-right:0.03588em;">g</span><span class="mord mathnormal" style="margin-right:0.22222em;">V</span><span class="mord mathnormal">a</span><span class="mord mathnormal" style="margin-right:0.01968em;">l</span><span class="mclose">)</span></span></span></span>.</li><li>The running totals of different aggregation functions are as follows:<ul><li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>A</mi><mi>V</mi><mi>G</mi><mo stretchy="false">(</mo><mi>c</mi><mi>o</mi><mi>l</mi><mo stretchy="false">)</mo><mo>→</mo><mo stretchy="false">(</mo><mi>C</mi><mi>O</mi><mi>U</mi><mi>N</mi><mi>T</mi><mo separator="true">,</mo><mi>S</mi><mi>U</mi><mi>M</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">AVG(col)\rightarrow (COUNT,SUM)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">A</span><span class="mord mathnormal" style="margin-right:0.22222em;">V</span><span class="mord mathnormal">G</span><span class="mopen">(</span><span class="mord mathnormal">c</span><span class="mord mathnormal">o</span><span class="mord mathnormal" style="margin-right:0.01968em;">l</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">→</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.07153em;">C</span><span class="mord mathnormal" style="margin-right:0.02778em;">O</span><span class="mord mathnormal" style="margin-right:0.10903em;">U</span><span class="mord mathnormal" style="margin-right:0.10903em;">N</span><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal" style="margin-right:0.05764em;">S</span><span class="mord mathnormal" style="margin-right:0.10903em;">U</span><span class="mord mathnormal" style="margin-right:0.10903em;">M</span><span class="mclose">)</span></span></span></span></li><li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>S</mi><mi>U</mi><mi>M</mi><mo stretchy="false">(</mo><mi>c</mi><mi>o</mi><mi>l</mi><mo stretchy="false">)</mo><mo>→</mo><mo stretchy="false">(</mo><mi>S</mi><mi>U</mi><mi>M</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">SUM(col)\rightarrow(SUM)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.05764em;">S</span><span class="mord mathnormal" style="margin-right:0.10903em;">U</span><span class="mord mathnormal" style="margin-right:0.10903em;">M</span><span class="mopen">(</span><span class="mord mathnormal">c</span><span class="mord mathnormal">o</span><span class="mord mathnormal" style="margin-right:0.01968em;">l</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">→</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.05764em;">S</span><span class="mord mathnormal" style="margin-right:0.10903em;">U</span><span class="mord mathnormal" style="margin-right:0.10903em;">M</span><span class="mclose">)</span></span></span></span></li><li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>C</mi><mi>O</mi><mi>U</mi><mi>N</mi><mi>T</mi><mo stretchy="false">(</mo><mi>c</mi><mi>o</mi><mi>l</mi><mo stretchy="false">)</mo><mo>→</mo><mo stretchy="false">(</mo><mi>C</mi><mi>O</mi><mi>U</mi><mi>N</mi><mi>T</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">COUNT(col)\rightarrow(COUNT)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.07153em;">C</span><span class="mord mathnormal" style="margin-right:0.02778em;">O</span><span class="mord mathnormal" style="margin-right:0.10903em;">U</span><span class="mord mathnormal" style="margin-right:0.10903em;">N</span><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="mopen">(</span><span class="mord mathnormal">c</span><span class="mord mathnormal">o</span><span class="mord mathnormal" style="margin-right:0.01968em;">l</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">→</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.07153em;">C</span><span class="mord mathnormal" style="margin-right:0.02778em;">O</span><span class="mord mathnormal" style="margin-right:0.10903em;">U</span><span class="mord mathnormal" style="margin-right:0.10903em;">N</span><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="mclose">)</span></span></span></span></li><li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>M</mi><mi>I</mi><mi>N</mi><mo stretchy="false">(</mo><mi>c</mi><mi>o</mi><mi>l</mi><mo stretchy="false">)</mo><mo>→</mo><mo stretchy="false">(</mo><mi>M</mi><mi>I</mi><mi>N</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">MIN(col)\rightarrow(MIN)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">M</span><span class="mord mathnormal" style="margin-right:0.07847em;">I</span><span class="mord mathnormal" style="margin-right:0.10903em;">N</span><span class="mopen">(</span><span class="mord mathnormal">c</span><span class="mord mathnormal">o</span><span class="mord mathnormal" style="margin-right:0.01968em;">l</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">→</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.10903em;">M</span><span class="mord mathnormal" style="margin-right:0.07847em;">I</span><span class="mord mathnormal" style="margin-right:0.10903em;">N</span><span class="mclose">)</span></span></span></span></li><li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>M</mi><mi>A</mi><mi>X</mi><mo stretchy="false">(</mo><mi>c</mi><mi>o</mi><mi>l</mi><mo stretchy="false">)</mo><mo>→</mo><mo stretchy="false">(</mo><mi>M</mi><mi>A</mi><mi>X</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">MAX(col)\rightarrow(MAX)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">M</span><span class="mord mathnormal">A</span><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class="mopen">(</span><span class="mord mathnormal">c</span><span class="mord mathnormal">o</span><span class="mord mathnormal" style="margin-right:0.01968em;">l</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">→</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.10903em;">M</span><span class="mord mathnormal">A</span><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class="mclose">)</span></span></span></span></li></ul></li></ul></li></ol><h1 id="join"><a class="markdownIt-Anchor" href="#join"></a> Join</h1><h2 id="why-do-we-need-to-join"><a class="markdownIt-Anchor" href="#why-do-we-need-to-join"></a> Why do we need to join?</h2><ol><li>Tables are normalized in a relational database to avoid unnecessary repetition of information.</li><li>The join operator reconstructs the original tuples without any information loss.</li><li>Join is an important operator in both OLAP and OLTP systems. Especially for the OLAP system, joining could take up to <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>15</mn><mo>∼</mo><mn>50</mn><mi mathvariant="normal">%</mi></mrow><annotation encoding="application/x-tex">15\sim 50\%</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">1</span><span class="mord">5</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">∼</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.80556em;vertical-align:-0.05556em;"></span><span class="mord">5</span><span class="mord">0</span><span class="mord">%</span></span></span></span> of time.</li></ol><h2 id="what-are-join-algorithms-doing"><a class="markdownIt-Anchor" href="#what-are-join-algorithms-doing"></a> What are join algorithms doing?</h2><ol><li>The most important kind is binary joins using inner equijoin algorithms.<ul><li>Binary means that the operator takes two tables as input.</li><li>Inner means it matches a certain tuple in the left table with another in the right.</li><li>Equijoin means that the condition of matching two tuples is the equivalence of some attributes.</li></ul></li><li>There are also other joins.<ul><li>Multi-way joins take more than two tables as input, primarily in the research literature.</li><li>Besides equijoin, there could also be anti-join, non-equijoin, etc.</li></ul></li><li>Compared with cross-product, join is more efficient and can be carefully optimized.</li></ol><h2 id="what-are-the-outputs-of-join-algorithms"><a class="markdownIt-Anchor" href="#what-are-the-outputs-of-join-algorithms"></a> What are the outputs of join algorithms?</h2><ol><li>In <code>R JOIN S</code>, for tuple <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>r</mi><mo>∈</mo><mi>R</mi></mrow><annotation encoding="application/x-tex">r \in R</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5782em;vertical-align:-0.0391em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.00773em;">R</span></span></span></span> and tuple <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>s</mi><mo>∈</mo><mi>S</mi></mrow><annotation encoding="application/x-tex">s \in S</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5782em;vertical-align:-0.0391em;"></span><span class="mord mathnormal">s</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.05764em;">S</span></span></span></span> that match on join attributes, concatenate <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>r</mi></mrow><annotation encoding="application/x-tex">r</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span></span></span></span> and <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>s</mi></mrow><annotation encoding="application/x-tex">s</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathnormal">s</span></span></span></span> together into a new tuple.</li><li>The output contents can vary depending on the query’s processing model, storage model, or data requirements.</li><li>Basically, there are two choices that are similar in terms of sort.<ul><li>Early materialization<ul><li>Copy the values for the attributes in outer and inner tuples into a new output tuple.</li><li>Subsequent query plan operators never need to return to the base tables to get more data.</li></ul></li><li>Late materialization<ul><li>Only copy the join keys and the matching tuples’ Record IDs.</li><li>This is ideal for column stores because the DBMS does not copy data not needed for the query.</li></ul></li></ul></li></ol><h2 id="how-can-we-measure-the-cost-of-join"><a class="markdownIt-Anchor" href="#how-can-we-measure-the-cost-of-join"></a> How can we measure the cost of join?</h2><ol><li>We can measure the join cost by the number of I/Os to compute the join.</li><li>Output costs are ignored since they depend on the data.</li><li>In the following analysis, we assume there are <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>m</mi></mrow><annotation encoding="application/x-tex">m</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathnormal">m</span></span></span></span> tuples stored in <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>M</mi></mrow><annotation encoding="application/x-tex">M</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">M</span></span></span></span> pages in table <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>R</mi></mrow><annotation encoding="application/x-tex">R</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.00773em;">R</span></span></span></span>, <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi></mrow><annotation encoding="application/x-tex">n</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathnormal">n</span></span></span></span> tuples stored in <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>N</mi></mrow><annotation encoding="application/x-tex">N</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">N</span></span></span></span> pages in table <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>S</mi></mrow><annotation encoding="application/x-tex">S</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.05764em;">S</span></span></span></span>.</li></ol><h2 id="join-algorithms"><a class="markdownIt-Anchor" href="#join-algorithms"></a> Join algorithms</h2><h3 id="nested-loop-join"><a class="markdownIt-Anchor" href="#nested-loop-join"></a> Nested loop join</h3><h4 id="what-is-the-most-naive-algorithm"><a class="markdownIt-Anchor" href="#what-is-the-most-naive-algorithm"></a> What is the most naive algorithm?</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> <span class="built_in">tuple</span> r <span class="keyword">in</span> R:</span><br><span class="line">  <span class="keyword">for</span> <span class="built_in">tuple</span> s <span class="keyword">in</span> S:</span><br><span class="line">    emit, <span class="keyword">if</span> r <span class="keyword">and</span> s <span class="keyword">match</span></span><br></pre></td></tr></table></figure><ol><li>For <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>R</mi><mo>⋈</mo><mi>S</mi></mrow><annotation encoding="application/x-tex">R\bowtie S</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68833em;vertical-align:-0.005em;"></span><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">⋈</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.05764em;">S</span></span></span></span>, he left the table <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>R</mi></mrow><annotation encoding="application/x-tex">R</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.00773em;">R</span></span></span></span> in the outer loop is called the outer table, and <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>S</mi></mrow><annotation encoding="application/x-tex">S</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.05764em;">S</span></span></span></span> is called the inner table.</li><li>For every tuple in <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>R</mi></mrow><annotation encoding="application/x-tex">R</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.00773em;">R</span></span></span></span>, it scans <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>S</mi></mrow><annotation encoding="application/x-tex">S</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.05764em;">S</span></span></span></span> once. The cost is <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>M</mi><mo>+</mo><mo stretchy="false">(</mo><mi>m</mi><mo>⋅</mo><mi>N</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">M+(m\cdot N)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.76666em;vertical-align:-0.08333em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">M</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord mathnormal">m</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">N</span><span class="mclose">)</span></span></span></span>.</li><li>If we use the smaller table with fewer tuples as the outer table, we can perform better since the number of pages is significantly smaller than the number of tuples.</li></ol><h4 id="how-can-we-better-use-the-data-already-read-from-disk"><a class="markdownIt-Anchor" href="#how-can-we-better-use-the-data-already-read-from-disk"></a> How can we better use the data already read from disk?</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> block B_R <span class="keyword">in</span> R:</span><br><span class="line">  <span class="keyword">for</span> block B_S <span class="keyword">in</span> S:</span><br><span class="line">    <span class="keyword">for</span> <span class="built_in">tuple</span> r <span class="keyword">in</span> B_R:</span><br><span class="line">      <span class="keyword">for</span> <span class="built_in">tuple</span> s <span class="keyword">in</span> B_S:</span><br><span class="line">        emit, <span class="keyword">if</span> r <span class="keyword">and</span> s <span class="keyword">match</span></span><br></pre></td></tr></table></figure><ol><li>For every read block <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>B</mi><mi>R</mi></msub></mrow><annotation encoding="application/x-tex">B_R</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05017em;">B</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.32833099999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.05017em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.00773em;">R</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> and <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>B</mi><mi>S</mi></msub></mrow><annotation encoding="application/x-tex">B_S</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05017em;">B</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.32833099999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.05017em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05764em;">S</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>, we try to compute as much as possible, i.e., pair all tuples in <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>B</mi><mi>R</mi></msub></mrow><annotation encoding="application/x-tex">B_R</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05017em;">B</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.32833099999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.05017em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.00773em;">R</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> with all tuples in <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>B</mi><mi>S</mi></msub></mrow><annotation encoding="application/x-tex">B_S</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05017em;">B</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.32833099999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.05017em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05764em;">S</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>.</li><li>Every block in R scans S once. The cost is <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>M</mi><mo>+</mo><mo stretchy="false">(</mo><mi>M</mi><mo>⋅</mo><mi>N</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">M+(M\cdot N)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.76666em;vertical-align:-0.08333em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">M</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.10903em;">M</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">N</span><span class="mclose">)</span></span></span></span>.</li><li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>M</mi><mo>⋅</mo><mi>N</mi></mrow><annotation encoding="application/x-tex">M\cdot N</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">M</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">N</span></span></span></span> won’t be affected by the order of tables. However, the first term can be smaller if we let the smaller table with fewer pages be the outer table.</li></ol><h4 id="how-can-we-take-advantage-of-more-buffer-space"><a class="markdownIt-Anchor" href="#how-can-we-take-advantage-of-more-buffer-space"></a> How can we take advantage of more buffer space?</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> B-<span class="number">2</span> pages p_R <span class="keyword">in</span> R:</span><br><span class="line">  <span class="keyword">for</span> page p_S <span class="keyword">in</span> S:</span><br><span class="line">    <span class="keyword">for</span> <span class="built_in">tuple</span> r <span class="keyword">in</span> B_2 pages:</span><br><span class="line">      <span class="keyword">for</span> <span class="built_in">tuple</span> s <span class="keyword">in</span> p_S:</span><br><span class="line">        emit, <span class="keyword">if</span> r <span class="keyword">and</span> s <span class="keyword">match</span></span><br></pre></td></tr></table></figure><ol><li>Use <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>B</mi><mo>−</mo><mn>2</mn></mrow><annotation encoding="application/x-tex">B-2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.76666em;vertical-align:-0.08333em;"></span><span class="mord mathnormal" style="margin-right:0.05017em;">B</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">2</span></span></span></span> buffers for scanning the outer table. Use one buffer for the inner table and one buffer for storing<br />output.</li><li>The cost is <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>M</mi><mo>+</mo><mo stretchy="false">(</mo><mo stretchy="false">⌈</mo><mi>M</mi><mi mathvariant="normal">/</mi><mo stretchy="false">(</mo><mi>B</mi><mo>−</mo><mn>2</mn><mo stretchy="false">)</mo><mo stretchy="false">⌉</mo><mo>⋅</mo><mi>N</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">M+(\lceil M/(B-2)\rceil\cdot N)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.76666em;vertical-align:-0.08333em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">M</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mopen">⌈</span><span class="mord mathnormal" style="margin-right:0.10903em;">M</span><span class="mord">/</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.05017em;">B</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord">2</span><span class="mclose">)</span><span class="mclose">⌉</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">N</span><span class="mclose">)</span></span></span></span>.</li><li>If the outer relation completely fits in memory, the cost is <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>M</mi><mo>+</mo><mi>N</mi></mrow><annotation encoding="application/x-tex">M+N</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.76666em;vertical-align:-0.08333em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">M</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">N</span></span></span></span>.</li></ol><h4 id="can-we-avoid-sequential-scans-by-using-an-index"><a class="markdownIt-Anchor" href="#can-we-avoid-sequential-scans-by-using-an-index"></a> Can we avoid sequential scans by using an index?</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> <span class="built_in">tuple</span> r <span class="keyword">in</span> R:</span><br><span class="line">  <span class="keyword">for</span> <span class="built_in">tuple</span> s <span class="keyword">in</span> Index(r_i = s_j):</span><br><span class="line">    emit, <span class="keyword">if</span> r <span class="keyword">and</span> s <span class="keyword">match</span></span><br></pre></td></tr></table></figure><p>Assume the cost of each index probe is some constant <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>C</mi></mrow><annotation encoding="application/x-tex">C</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.07153em;">C</span></span></span></span> per tuple. The cost is <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>M</mi><mo>+</mo><mo stretchy="false">(</mo><mi>m</mi><mo>⋅</mo><mi>C</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">M+(m\cdot C)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.76666em;vertical-align:-0.08333em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">M</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord mathnormal">m</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.07153em;">C</span><span class="mclose">)</span></span></span></span></p><h3 id="sort-merge-join"><a class="markdownIt-Anchor" href="#sort-merge-join"></a> Sort-merge join</h3><h4 id="what-is-the-process-of-sort-merge-join"><a class="markdownIt-Anchor" href="#what-is-the-process-of-sort-merge-join"></a> What is the process of sort-merge join?</h4><ol><li>The first phase is to sort both tables using the join key(s).</li><li>In the second phase, we step through the two sorted tables with cursors and emit matching tuples.</li><li>The sort cost of the outer table is <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>2</mn><mi>M</mi><mo>⋅</mo><mo stretchy="false">(</mo><mn>1</mn><mo>+</mo><mo stretchy="false">⌈</mo><msub><mo><mi>log</mi><mo>⁡</mo></mo><mrow><mi>B</mi><mo>−</mo><mn>1</mn></mrow></msub><mo stretchy="false">⌈</mo><mi>M</mi><mi mathvariant="normal">/</mi><mi>B</mi><mo stretchy="false">⌉</mo><mo stretchy="false">⌉</mo><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">2M\cdot(1+\lceil \log_{B-1}\lceil M/B\rceil\rceil)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord">2</span><span class="mord mathnormal" style="margin-right:0.10903em;">M</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord">1</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1.052471em;vertical-align:-0.302471em;"></span><span class="mopen">⌈</span><span class="mop"><span class="mop">lo<span style="margin-right:0.01389em;">g</span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.23419099999999998em;"><span style="top:-2.45586em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.05017em;">B</span><span class="mbin mtight">−</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.302471em;"><span></span></span></span></span></span></span><span class="mopen">⌈</span><span class="mord mathnormal" style="margin-right:0.10903em;">M</span><span class="mord">/</span><span class="mord mathnormal" style="margin-right:0.05017em;">B</span><span class="mclose">⌉</span><span class="mclose">⌉</span><span class="mclose">)</span></span></span></span> and the sort cost of the inner table is <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>2</mn><mi>N</mi><mo>⋅</mo><mo stretchy="false">(</mo><mn>1</mn><mo>+</mo><mo stretchy="false">⌈</mo><msub><mo><mi>log</mi><mo>⁡</mo></mo><mrow><mi>B</mi><mo>−</mo><mn>1</mn></mrow></msub><mo stretchy="false">⌈</mo><mi>N</mi><mi mathvariant="normal">/</mi><mi>B</mi><mo stretchy="false">⌉</mo><mo stretchy="false">⌉</mo><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">2N\cdot (1+\lceil\log_{B-1}\lceil N/B \rceil \rceil)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord">2</span><span class="mord mathnormal" style="margin-right:0.10903em;">N</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord">1</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1.052471em;vertical-align:-0.302471em;"></span><span class="mopen">⌈</span><span class="mop"><span class="mop">lo<span style="margin-right:0.01389em;">g</span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.23419099999999998em;"><span style="top:-2.45586em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.05017em;">B</span><span class="mbin mtight">−</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.302471em;"><span></span></span></span></span></span></span><span class="mopen">⌈</span><span class="mord mathnormal" style="margin-right:0.10903em;">N</span><span class="mord">/</span><span class="mord mathnormal" style="margin-right:0.05017em;">B</span><span class="mclose">⌉</span><span class="mclose">⌉</span><span class="mclose">)</span></span></span></span>.</li><li>The merge cost is <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>M</mi><mo>+</mo><mi>N</mi></mrow><annotation encoding="application/x-tex">M+N</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.76666em;vertical-align:-0.08333em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">M</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">N</span></span></span></span>.<ul><li>The worst case for the merging phase is when the join attribute of all the tuples in both relations contains the same value.</li></ul></li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">sort R,S on join keys</span><br><span class="line">cursor_R points to R_sorted, cursor_S points to S_sorted</span><br><span class="line"><span class="keyword">while</span> cursor_R <span class="keyword">and</span> cursor_S:</span><br><span class="line">  <span class="keyword">if</span> cursor_R &gt; cursor_S:</span><br><span class="line">    increment cursor_S</span><br><span class="line">  <span class="keyword">if</span> cursor_R &lt; cursor_S:</span><br><span class="line">    increment cursor_R</span><br><span class="line">    possible backtrack cursor_S</span><br><span class="line">  <span class="keyword">elif</span> cursor_R <span class="keyword">and</span> surcor_s <span class="keyword">match</span>:</span><br><span class="line">    emit</span><br><span class="line">    increment cursor_s</span><br></pre></td></tr></table></figure><h4 id="how-do-the-two-cursors-move"><a class="markdownIt-Anchor" href="#how-do-the-two-cursors-move"></a> How do the two cursors move?</h4><ol><li>The cursor of the outer table will only move forward. Specifically, it will only move forward when we can ensure that we have matched the current tuple with all possible tuples, i.e., when we have a larger inner tuple.</li><li>The cursor of the inner table may move both forward and backward.<ul><li>It moves forward when some later tuple in the inner table may match with the current tuple in an outer tuple, i.e., when an inner tuple is smaller than the outer tuple or when they match (there are possibly more matches in the following).</li><li>It moves backward when there might have been some missing matches in the past, i.e., when the outer cursor moves forward, the key is the same as the last one; we need to backtrack to the earliest tuple that matches the previous outer tuple.</li></ul></li></ol><h4 id="when-is-sort-merge-join-useful"><a class="markdownIt-Anchor" href="#when-is-sort-merge-join-useful"></a> When is sort-merge join useful?</h4><ol><li>We can save some cost when one or both tables are sorted using the join key.</li><li>When output must be sorted on the join key, if the join output is larger, we might use sort-merge join to produce sorted output directly.<ul><li>If the output has a small amount, hash join might still be the better way.</li></ul></li></ol><h3 id="hash-join"><a class="markdownIt-Anchor" href="#hash-join"></a> Hash join</h3><h4 id="how-does-hash-join-work"><a class="markdownIt-Anchor" href="#how-does-hash-join-work"></a> How does hash join work?</h4><ol><li><p>The thought behind hash join is that:</p><ul><li>If tuple <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>r</mi><mo>∈</mo><mi>R</mi></mrow><annotation encoding="application/x-tex">r \in R</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5782em;vertical-align:-0.0391em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.00773em;">R</span></span></span></span> and a tuple<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>s</mi><mo>∈</mo><mi>S</mi></mrow><annotation encoding="application/x-tex">s \in S</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5782em;vertical-align:-0.0391em;"></span><span class="mord mathnormal">s</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.05764em;">S</span></span></span></span> satisfy the join condition; they have the same value for the join attributes.</li><li>If that value is hashed to some partition <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>i</mi></mrow><annotation encoding="application/x-tex">i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.65952em;vertical-align:0em;"></span><span class="mord mathnormal">i</span></span></span></span>, the <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>R</mi></mrow><annotation encoding="application/x-tex">R</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.00773em;">R</span></span></span></span> tuple must be in <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>r</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">r_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> and the <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>S</mi></mrow><annotation encoding="application/x-tex">S</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.05764em;">S</span></span></span></span> tuple in <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>s</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">s_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>.</li><li>Therefore, <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>R</mi></mrow><annotation encoding="application/x-tex">R</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.00773em;">R</span></span></span></span> tuples in <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>r</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">r_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> need only to be compared with <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>S</mi></mrow><annotation encoding="application/x-tex">S</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.05764em;">S</span></span></span></span> tuples in <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>s</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">s_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>.</li></ul></li><li><p>In the first phase (build), we scan the outer relation and populate a hash table using the hash function <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>h</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">h_1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.84444em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> on the join attributes.</p><p>In the second phase (probe), scan the inner relation and use <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>h</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">h_1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.84444em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> on each tuple, jump to a location in the hash table, and find a matching tuple.</p></li><li><p>The keys stored in the hash table are the attribute(s) on which the query is joining the tables. We always need the original key to verify that we have a correct match in case of hash collisions.</p><p>The values stored vary per implementation, which depends on what the operators above the join in the query plan expect as its input.</p></li><li><p>Assume that we have enough buffers, we need to read and write both tables with the cost of <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>2</mn><mo stretchy="false">(</mo><mi>M</mi><mo>+</mo><mi>N</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">2(M+N)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord">2</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.10903em;">M</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">N</span><span class="mclose">)</span></span></span></span> in the partitioning phase, and read both tables with the cost of <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>M</mi><mo>+</mo><mi>N</mi></mrow><annotation encoding="application/x-tex">M+N</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.76666em;vertical-align:-0.08333em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">M</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">N</span></span></span></span> in the probing phase.</p><ul><li>We can see that there is no constraint on the size of the inner table.</li></ul></li></ol><h4 id="how-big-of-a-table-can-we-hash-using-this-approach"><a class="markdownIt-Anchor" href="#how-big-of-a-table-can-we-hash-using-this-approach"></a> How big of a table can we hash using this approach?</h4><ol><li>In the first phase of building a hash table, we can use at most <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>B</mi><mo>−</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">B-1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.76666em;vertical-align:-0.08333em;"></span><span class="mord mathnormal" style="margin-right:0.05017em;">B</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">1</span></span></span></span> spill partitions, leaving one page as an input buffer. When one partition is full, we should write it out on the disk and clear it.</li><li>total number of both the outer and inner table of each partition should be no more than <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>B</mi></mrow><annotation encoding="application/x-tex">B</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.05017em;">B</span></span></span></span> blocks big so that in the second phase, we can store all tuples in the same partition in memory.</li><li>The total number of pages used is <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>B</mi><mo>⋅</mo><mo stretchy="false">(</mo><mi>B</mi><mo>−</mo><mn>1</mn><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">B\cdot (B-1)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.05017em;">B</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.05017em;">B</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord">1</span><span class="mclose">)</span></span></span></span>. A hash table of <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>N</mi></mrow><annotation encoding="application/x-tex">N</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">N</span></span></span></span> pages need about <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msqrt><mi>N</mi></msqrt></mrow><annotation encoding="application/x-tex">\sqrt{N}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.04em;vertical-align:-0.11333499999999996em;"></span><span class="mord sqrt"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.9266650000000001em;"><span class="svg-align" style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord" style="padding-left:0.833em;"><span class="mord mathnormal" style="margin-right:0.10903em;">N</span></span></span><span style="top:-2.886665em;"><span class="pstrut" style="height:3em;"></span><span class="hide-tail" style="min-width:0.853em;height:1.08em;"><svg width='400em' height='1.08em' viewBox='0 0 400000 1080' preserveAspectRatio='xMinYMin slice'><path d='M95,702c-2.7,0,-7.17,-2.7,-13.5,-8c-5.8,-5.3,-9.5,-10,-9.5,-14c0,-2,0.3,-3.3,1,-4c1.3,-2.7,23.83,-20.7,67.5,-54c44.2,-33.3,65.8,-50.3,66.5,-51c1.3,-1.3,3,-2,5,-2c4.7,0,8.7,3.3,12,10s173,378,173,378c0.7,0,35.3,-71,104,-213c68.7,-142,137.5,-285,206.5,-429c69,-144,104.5,-217.7,106.5,-221l0 -0c5.3,-9.3,12,-14,20,-14H400000v40H845.2724s-225.272,467,-225.272,467s-235,486,-235,486c-2.7,4.7,-9,7,-19,7c-6,0,-10,-1,-12,-3s-194,-422,-194,-422s-65,47,-65,47zM834 80h400000v40h-400000z'/></svg></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.11333499999999996em;"><span></span></span></span></span></span></span></span></span> buffers if the hash distribution is even.</li><li>When including the fudge factor <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>f</mi><mo>&gt;</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">f&gt;1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">&gt;</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">1</span></span></span></span> when the hash distribution is skewed, we need <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>B</mi><mo>⋅</mo><msqrt><mrow><mi>f</mi><mo>⋅</mo><mi>N</mi></mrow></msqrt></mrow><annotation encoding="application/x-tex">B\cdot\sqrt{f\cdot N}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.05017em;">B</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1.04em;vertical-align:-0.20500000000000007em;"></span><span class="mord sqrt"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.835em;"><span class="svg-align" style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord" style="padding-left:0.833em;"><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">N</span></span></span><span style="top:-2.795em;"><span class="pstrut" style="height:3em;"></span><span class="hide-tail" style="min-width:0.853em;height:1.08em;"><svg width='400em' height='1.08em' viewBox='0 0 400000 1080' preserveAspectRatio='xMinYMin slice'><path d='M95,702c-2.7,0,-7.17,-2.7,-13.5,-8c-5.8,-5.3,-9.5,-10,-9.5,-14c0,-2,0.3,-3.3,1,-4c1.3,-2.7,23.83,-20.7,67.5,-54c44.2,-33.3,65.8,-50.3,66.5,-51c1.3,-1.3,3,-2,5,-2c4.7,0,8.7,3.3,12,10s173,378,173,378c0.7,0,35.3,-71,104,-213c68.7,-142,137.5,-285,206.5,-429c69,-144,104.5,-217.7,106.5,-221l0 -0c5.3,-9.3,12,-14,20,-14H400000v40H845.2724s-225.272,467,-225.272,467s-235,486,-235,486c-2.7,4.7,-9,7,-19,7c-6,0,-10,-1,-12,-3s-194,-422,-194,-422s-65,47,-65,47zM834 80h400000v40h-400000z'/></svg></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.20500000000000007em;"><span></span></span></span></span></span></span></span></span>.</li></ol><h4 id="can-we-optimize-the-search-for-tuples-that-do-not-have-any-match"><a class="markdownIt-Anchor" href="#can-we-optimize-the-search-for-tuples-that-do-not-have-any-match"></a> Can we optimize the search for tuples that do not have any match?</h4><ol><li>We can create a Bloom filter during the build phase when the key will likely not exist in the hash table. This method is called Bloom filter or sideways information passing.</li><li>The Bloom filter is a probabilistic data structure (bitmap) that answers set membership queries.<ul><li>False negatives will never occur, while false positives can sometimes occur.</li><li>To insert a key into the filter, we use <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi></mrow><annotation encoding="application/x-tex">k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.03148em;">k</span></span></span></span> hash functions to set all <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi></mrow><annotation encoding="application/x-tex">k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.03148em;">k</span></span></span></span> bits to <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1</mn></mrow><annotation encoding="application/x-tex">1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">1</span></span></span></span>.</li><li>During the lookup of a key, the key may exist if all <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi></mrow><annotation encoding="application/x-tex">k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.03148em;">k</span></span></span></span> bits hashed by the same <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi></mrow><annotation encoding="application/x-tex">k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.03148em;">k</span></span></span></span> hash function are all <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1</mn></mrow><annotation encoding="application/x-tex">1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">1</span></span></span></span>. The key definitely does not exist if one of the <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi></mrow><annotation encoding="application/x-tex">k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.03148em;">k</span></span></span></span> bits is <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>0</mn></mrow><annotation encoding="application/x-tex">0</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">0</span></span></span></span>.</li></ul></li></ol><h4 id="what-if-we-lack-the-memory-to-fit-the-entire-hash-table"><a class="markdownIt-Anchor" href="#what-if-we-lack-the-memory-to-fit-the-entire-hash-table"></a> What if we lack the memory to fit the entire hash table?</h4><ol><li>We can use the recursive hash join (GRACE hash join).</li><li>Similar to the aforementioned algorithm, both tables should be hashed into the same number of buckets with the same hash function.</li><li>Perform regular hash join on each pair of matching buckets at the same level between two tables.</li><li>If the buckets do not fit in memory, use recursive partitioning to split the tables into chunks that will fit.<ul><li>Build another hash table for <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>b</mi><mi>u</mi><mi>c</mi><mi>k</mi><mi>e</mi><msub><mi>t</mi><mrow><mi>R</mi><mo separator="true">,</mo><mi>i</mi></mrow></msub></mrow><annotation encoding="application/x-tex">bucket_{R,i}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.980548em;vertical-align:-0.286108em;"></span><span class="mord mathnormal">b</span><span class="mord mathnormal">u</span><span class="mord mathnormal">c</span><span class="mord mathnormal" style="margin-right:0.03148em;">k</span><span class="mord mathnormal">e</span><span class="mord"><span class="mord mathnormal">t</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.328331em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.00773em;">R</span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight">i</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span></span></span></span> using hash function <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>h</mi><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">h_2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.84444em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> (with <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>h</mi><mn>2</mn></msub><mo mathvariant="normal">≠</mo><msub><mi>h</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">h_2≠h_1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord"><span class="mord mathnormal">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel"><span class="mrel"><span class="mord vbox"><span class="thinbox"><span class="rlap"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="inner"><span class="mrel"></span></span><span class="fix"></span></span></span></span></span><span class="mrel">=</span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.84444em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>).</li><li>Then, probe it for each tuple of the other table’s bucket at that level.</li></ul></li><li><strong>Hybrid hash join</strong>: If the keys are skewed, the DBMS keeps the hot partition in-memory and immediately performs the comparison instead of spilling it to disk.</li></ol>]]></content>
      
      
      <categories>
          
          <category> Open Courses </category>
          
          <category> CMU 15-445/645 Database System </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Database System </tag>
            
            <tag> External Algorithms </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Project #1: Buffer Pool</title>
      <link href="/2023/06/27/OpenSource/BusTub/Project-1-Buffer-Pool/"/>
      <url>/2023/06/27/OpenSource/BusTub/Project-1-Buffer-Pool/</url>
      
        <content type="html"><![CDATA[<p><ul class="markdownIt-TOC"><li><a href="#task-1-lru-k-replacement-policy">Task #1 - LRU-K Replacement Policy</a></li><li><a href="#task-2-buffer-pool-manager">Task #2 - Buffer Pool Manager</a><ul><li><a href="#basic">Basic</a></li><li><a href="#leaderboard-optimization">Leaderboard optimization</a></li></ul></li><li><a href="#task-3-readwrite-page-guards">Task #3 - Read/Write Page Guards</a></li></ul></p><h1 id="task-1-lru-k-replacement-policy"><a class="markdownIt-Anchor" href="#task-1-lru-k-replacement-policy"></a> Task #1 - LRU-K Replacement Policy</h1><ol><li><p>Evict rule:</p><ul><li>When all evictable frames have more than <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>K</mi></mrow><annotation encoding="application/x-tex">K</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.07153em;">K</span></span></span></span> access records, evict the one whose backward k-distance is maximum.</li><li>When some frames only have less than <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>K</mi></mrow><annotation encoding="application/x-tex">K</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.07153em;">K</span></span></span></span> access records, evict the one with the earliest first access record among those less than <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>K</mi></mrow><annotation encoding="application/x-tex">K</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.07153em;">K</span></span></span></span> frames.</li></ul></li><li><p>Comparison:</p><ul><li>When each frame is created or stored with a new page, push an access record of <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>0</mn></mrow><annotation encoding="application/x-tex">0</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">0</span></span></span></span> to its history to represent <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>+</mo><mi>inf</mi><mo>⁡</mo></mrow><annotation encoding="application/x-tex">+\inf</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.77777em;vertical-align:-0.08333em;"></span><span class="mord">+</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mop">in<span style="margin-right:0.07778em;">f</span></span></span></span></span>.</li><li>Each comparison uses the first two records in the list. If the first record (the earliest backward most k-distance) is the same, it must be <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>0</mn></mrow><annotation encoding="application/x-tex">0</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">0</span></span></span></span> causing a comparison of the second record, representing the true first access of that frame.</li><li>Remember to update the second comparison timestamp when the first time, find <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>0</mn></mrow><annotation encoding="application/x-tex">0</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">0</span></span></span></span> in the first timestamp.</li></ul><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">size_t</span> k_timestamp = frame.second.<span class="built_in">GetKTimestamp</span>();</span><br><span class="line"><span class="type">size_t</span> sec_timestamp = frame.second.<span class="built_in">GetSecondTimestamp</span>();</span><br><span class="line"><span class="keyword">if</span> (k_timestamp &lt; cmp_k_timestamp) &#123;</span><br><span class="line">victim = frame.first;</span><br><span class="line">cmp_k_timestamp = k_timestamp;</span><br><span class="line"><span class="keyword">if</span> (k_timestamp == <span class="number">0</span>) &#123;</span><br><span class="line">cmp_sec_timestamp = sec_timestamp;</span><br><span class="line">&#125;</span><br><span class="line">&#125; <span class="keyword">else</span> <span class="keyword">if</span> (k_timestamp == cmp_k_timestamp &amp;&amp; sec_timestamp &lt; cmp_sec_timestamp) &#123;</span><br><span class="line">victim = frame.first;</span><br><span class="line">cmp_sec_timestamp = sec_timestamp;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>After successfully choosing a victim, we need to clear its history (leaving the <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>0</mn></mrow><annotation encoding="application/x-tex">0</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">0</span></span></span></span> as sentinel), set it to non-evictable, and reduce the current size of the replacer.</p></li></ol><h1 id="task-2-buffer-pool-manager"><a class="markdownIt-Anchor" href="#task-2-buffer-pool-manager"></a> Task #2 - Buffer Pool Manager</h1><h2 id="basic"><a class="markdownIt-Anchor" href="#basic"></a> Basic</h2><ol><li><p>When the page that is asked to fetch is already in the buffer pool, we still need to do several things:</p><ul><li>Set it to non-evictable.</li><li>Record its access in the replacer.</li><li>Increase its pin count.</li></ul></li><li><p>When the page is not in the buffer pool or creating a new page:</p><ul><li>First, we need to acquire a free frame.<ul><li>Erase it from the page table when we are evicting one.</li><li>Write the content to disk when the old page is dirty.</li></ul></li><li>Then, similar to the other situation, we need to:<ul><li>Set it to non-evictable</li><li>Record its access in the replacer.</li><li>Put it in the page table.</li><li>Set its pin count to <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1</mn></mrow><annotation encoding="application/x-tex">1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">1</span></span></span></span></li><li>Set <code>is_dirty_</code> to <code>false</code></li><li>Set its page ID to frame.</li></ul></li><li>Even in <code>NewPage</code>, the <code>is_dirty_</code> is false because it can directly “write” empty to file by increasing offset, which is done when a larger page ID is written. There is no need actually to write empty content.</li></ul></li><li><p>When setting <code>is_dirty_</code> in <code>Unpin</code>, if the page is already dirty, we should not set it to clean, no matter what we are told.</p></li></ol><h2 id="leaderboard-optimization"><a class="markdownIt-Anchor" href="#leaderboard-optimization"></a> Leaderboard optimization</h2><ol><li>Fine-grain lock<ul><li>A coarse-grain lock is easier to program while sacrificing performance.</li><li>In fine-grain lock, a <code>core_latch_</code> is used to protect the core data of the buffer pool manager, i.e., <code>page_table_</code>, <code>free_list_</code>, <code>next_page_id_</code>). Each frame has its latch to protect its data, i.e., <code>pin_count_</code>, <code>is_dirty_</code>, <code>page_id_</code>.</li><li>Each function thread will, at most, grab the core_latch_ and one of the frame latches.</li><li>To avoid deadlock, each procedure is designed so that a thread will try to acquire a page latch only if it already has a <code>core_latch_</code> or it won’t want a core_latech later.</li><li>To obtain atomic when switching from <code>core_latch_</code> to a page latch, we must acquire the page latch before releasing the <code>core_latch_</code>.<ul><li>If we release core_latch_ first, some other thread may change the frame we want to use (e.g., evict the frame, modify its metadata) before acquiring the frame latch.</li></ul></li></ul></li><li>Delay write-out:<ul><li>Disk I/Os consume a large amount of time. So, we must avoid holding a lock while communicating with the disk.</li><li>When we need to write data into disk, instead of immediately calling the disk_manager_-&gt;WritePage, we create a temporary buffer in memory and copy data into the buffer. After all locks are released, we write that content in the buffer into a disk.</li><li>A similar thought is to delay reading data until all locks are released. However, <code>ReadData</code> is called in <code>FetchPage</code>, where we can only release the frame latch after the whole frame is ready for others to visit. Still, we can <code>ReadData</code> after <code>core_latch_</code> is released since the <code>core_latch_</code> could be the bottleneck of the manager.</li><li>However, there is a problem:<ul><li>When a page is evicted, and only a short time later, that exact page is fetched again. Since all latches are released before writing dirty data to disk, there is a chance that FetchPage reads stale data from disk before the up-to-date data is written to disk.</li><li>My other thought is maintaining a list of page IDs in the writing buffer. If the page ID of <code>FetchPage</code> is in the list, copy data from the writing buffer and erase that page from the writing buffer.</li><li>The problem is that we need to guarantee the atomic between getting the writing content and writing it to disk. Otherwise, tricky concurrent operations may cause the written content to be wrong.</li><li>Hence, we cannot unlock the latches until we are sure the content is written, which also makes fine-grained latches meaningless, given that disk I/O is the key problem of performance.</li></ul></li></ul></li><li>Pre-fetch<ul><li>To better suit the scan case, the buffer pool manager can pre-fetch several following pages when accessing three consecutive page IDs in a row.</li><li>Different from fetching pages through <code>FetchPage</code>, pre-fetched frames need to set <code>pin_count_</code> to <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>0</mn></mrow><annotation encoding="application/x-tex">0</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">0</span></span></span></span> and evictable.</li><li>Pre-fetch should not stall <code>FetchPage</code> from returning, so it must be run in a separate thread.</li><li>The problem is that pre-fetch must be an independent background thread. It won’t know whether the buffer pool manager is destroyed, which will cause a heap-use-after-free error.</li></ul></li></ol><h1 id="task-3-readwrite-page-guards"><a class="markdownIt-Anchor" href="#task-3-readwrite-page-guards"></a> Task #3 - Read/Write Page Guards</h1><ol><li>Any <code>PageGuard</code> will automatically unpin itself when it is deconstructed. But they don’t need to pin themselves since they are pinned before <code>PageGuard</code> is created when fetching or creating a page.</li><li>If a <code>Read/WritePageGuard</code> is acquired through <code>FetchPageRead</code> or <code>FetchPageWrite</code>, the latch is acquired inside these functions. However, the latch won’t be acquired automatically if a <code>PageGuard</code> is acquired through its construction function.</li><li>No matter how <code>Read/WritePageGuard</code> is acquired, the latch will always be released automatically when the <code>PageGuard</code> is deconstructed by a deconstructor or move operation.</li><li>In the move assignment, we must first drop the original page, copy from the right reference, and finally deconstruct the right reference.</li></ol>]]></content>
      
      
      <categories>
          
          <category> Open Source Code </category>
          
          <category> BusTub </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Database System </tag>
            
            <tag> Storage </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>05 Index Concurrency</title>
      <link href="/2023/06/25/Courses/15445/05-Index-Concurrency/"/>
      <url>/2023/06/25/Courses/15445/05-Index-Concurrency/</url>
      
        <content type="html"><![CDATA[<p><ul class="markdownIt-TOC"><li><a href="#concurrency-control">Concurrency control</a><ul><li><a href="#what-are-the-correctness-criteria-of-concurrency-control">What are the correctness criteria of concurrency control?</a></li><li><a href="#what-is-the-more-specific-difference-between-locks-and-latches">What is the more specific difference between locks and latches?</a></li><li><a href="#what-are-the-two-latch-modes">What are the two latch modes?</a></li><li><a href="#what-are-the-different-latch-implementations">What are the different latch implementations?</a></li></ul></li><li><a href="#latching-scheme">Latching scheme</a><ul><li><a href="#hash-table-latching">Hash table latching</a><ul><li><a href="#why-are-deadlocks-not-possible-in-the-hash-table">Why are deadlocks not possible in the hash table?</a></li><li><a href="#how-can-we-design-hash-table-latching">How can we design hash table latching?</a></li></ul></li><li><a href="#btree-latching">B+Tree latching</a><ul><li><a href="#what-should-we-use-latching-to-prevent">What should we use latching to prevent?</a></li><li><a href="#how-should-we-achieve-physical-correctness">How should we achieve physical correctness?</a></li><li><a href="#what-is-the-problem-with-the-aforementioned-strategy">What is the problem with the aforementioned strategy?</a></li><li><a href="#when-will-a-deadlock-occur">When will a deadlock occur?</a></li></ul></li></ul></li></ul></p><h1 id="concurrency-control"><a class="markdownIt-Anchor" href="#concurrency-control"></a> Concurrency control</h1><h2 id="what-are-the-correctness-criteria-of-concurrency-control"><a class="markdownIt-Anchor" href="#what-are-the-correctness-criteria-of-concurrency-control"></a> What are the correctness criteria of concurrency control?</h2><ol><li>Logical Correctness:<ul><li>Can a thread see the data that it is supposed to see? For example, correctly control data race.</li></ul></li><li>Physical Correctness:<ul><li>Is the internal representation of the object sound? For example, fetching a ptr will point to the correct address, and it won’t be freed between fetching and accessing.</li></ul></li></ol><h2 id="what-is-the-more-specific-difference-between-locks-and-latches"><a class="markdownIt-Anchor" href="#what-is-the-more-specific-difference-between-locks-and-latches"></a> What is the more specific difference between locks and latches?</h2><ol><li>What are they used to separate? What are they protecting? How long will they be held?<ul><li>Locks separate user transactions accessing the same tuples in database contents. Locks are held in the entire transaction.</li><li>Latches are used to separate threads accessing the same in-memory data structures. Latches are held in the critical section.</li></ul></li><li>How many modes do they have?<ul><li>Locks have four modes: shared, exclusive, update, and intention.</li><li>Latches only have two modes: read and write.</li></ul></li><li>How do they solve deadlock?<ul><li>Locks use detection and resolution by waits-for, timeout, or abort.</li><li>Latches can only avoid deadlock by code discipline.</li></ul></li><li>Where are they kept?<ul><li>Locks are kept in Lock Manager, while latches are kept in the protected data structure.</li></ul></li></ol><h2 id="what-are-the-two-latch-modes"><a class="markdownIt-Anchor" href="#what-are-the-two-latch-modes"></a> What are the two latch modes?</h2><ol><li><p>Read mode means that Multiple threads can read the same object simultaneously.</p><ul><li>A thread can acquire the read latch if another thread has it in read mode.</li></ul></li><li><p>Write mode only allows one thread to access the object.</p><ul><li>A thread cannot acquire a write latch if another thread has it in any mode.</li></ul></li><li><p>In the compatibility matrix, only two read mode access is allowed.</p></li></ol><h2 id="what-are-the-different-latch-implementations"><a class="markdownIt-Anchor" href="#what-are-the-different-latch-implementations"></a> What are the different latch implementations?</h2><ol><li>The first is blocking OS Mutex.<ul><li>It is simple to use.</li><li>It takes about <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>25</mn><mtext> </mtext><mi>n</mi><mi>s</mi></mrow><annotation encoding="application/x-tex">25\ ns</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">2</span><span class="mord">5</span><span class="mspace"> </span><span class="mord mathnormal">n</span><span class="mord mathnormal">s</span></span></span></span> per lock/unlock invocation, which means that it is non-scalable.<ul><li><code>std::mutex</code> is slower than <code>pthread_mutex,</code> and <code>futex</code> is faster than both.</li></ul></li><li><code>futex</code> stands for fast userspace mutex.<ul><li>It has a userspace spinlock and a heavy-weight OS latch.</li><li>Threads will first try to acquire the userspace lock. If success, then that is good.</li><li>But if failed, the thread will fall back to the OS latch. OS takes control of the thread and when to schedule it, and DBMS can do nothing with it. Also, <code>syscall</code> is expensive.</li></ul></li></ul></li><li>The second approach is reader-writer latches.<ul><li>It allows for concurrent readers. Must manage read/write queues to avoid starvation.</li><li>It can be implemented on top of spinlock.</li><li>Still, <code>std::shared_mutex</code> is slower than <code>pthread_rwlock</code>.</li></ul></li></ol><h1 id="latching-scheme"><a class="markdownIt-Anchor" href="#latching-scheme"></a> Latching scheme</h1><h2 id="hash-table-latching"><a class="markdownIt-Anchor" href="#hash-table-latching"></a> Hash table latching</h2><h3 id="why-are-deadlocks-not-possible-in-the-hash-table"><a class="markdownIt-Anchor" href="#why-are-deadlocks-not-possible-in-the-hash-table"></a> Why are deadlocks not possible in the hash table?</h3><ol><li>All threads move in the same direction and only access a single page/slot at a time.<ul><li>Hence, no loops are waiting in this scenario.</li></ul></li><li>To resize the table, take a global write latch on the entire table.</li></ol><h3 id="how-can-we-design-hash-table-latching"><a class="markdownIt-Anchor" href="#how-can-we-design-hash-table-latching"></a> How can we design hash table latching?</h3><ol><li>The coarser-grain approach is to use page latches.<ul><li>Each page has a reader-writer latch that protects its entire contents.</li></ul></li><li>The finer-grain approach is to use slot latches.<ul><li>Each slot has its latch.</li><li>It can use a single-mode latch to reduce meta-data and computational overhead.</li></ul></li></ol><h2 id="btree-latching"><a class="markdownIt-Anchor" href="#btree-latching"></a> B+Tree latching</h2><h3 id="what-should-we-use-latching-to-prevent"><a class="markdownIt-Anchor" href="#what-should-we-use-latching-to-prevent"></a> What should we use latching to prevent?</h3><ol><li>Threads are trying to modify the contents of a node at the same time. (This is logical correctness, i.e., data race)</li><li>One thread traverses the tree while another thread splits/merges nodes.<ul><li>This is physical correctness. Splitting/merging will cause free pointers, nodes, or in-node entries.</li><li>This will also cause a problem with logical correctness, i.e., false negative.<ul><li>If a thread gets the pointer of the node that possesses the key it wants, then before it accesses the node, the key is borrowed by a sibling, causing the thread to think the key does not exist.</li></ul></li></ul></li><li>When introducing sibling pointers, we may have a deadlock situation.</li></ol><h3 id="how-should-we-achieve-physical-correctness"><a class="markdownIt-Anchor" href="#how-should-we-achieve-physical-correctness"></a> How should we achieve physical correctness?</h3><ol><li>The most naive method is to hold all locks until the entire process is done. But its performance is a disaster.<ul><li>We must release some latches when we are sure they are safe.</li><li>According to our goal, a node is safe when we know that it won’t be changed (split, merged, or redistributed) when updated.</li><li>We can know a child is safe when its child is not full on insertion or more than half-full on deletion, i.e., any later operations can be isolated on or below its level.</li></ul></li><li>For find operation, there won’t be any updates. Hence, we can always unlatch the parent when we acquire an R latch on the child.</li><li>We need to obtain W latches as required for insert or delete operations. Once a child is latched, check if it is safe.<ul><li>If the child is safe, we can release all latches on ancestors. The latches should be released from top to bottom to perform better.</li></ul></li></ol><h3 id="what-is-the-problem-with-the-aforementioned-strategy"><a class="markdownIt-Anchor" href="#what-is-the-problem-with-the-aforementioned-strategy"></a> What is the problem with the aforementioned strategy?</h3><ol><li>Every insert/delete operation will take a write latch on the root, which makes the root a bottleneck with higher concurrency.</li><li>We can assume that most modifications to a B+Tree will not require a split or merge.</li><li>Hence, optimistically traverse the tree using read latches instead of assuming that there will be a split/merge as aforementioned. If the guess is wrong, repeat traversal with the pessimistic algorithm.</li><li>For insert/delete operations, set latches as if for search, get to leaf, and set W latch on leaf. If the leaf is unsafe, release all latches and restart the thread using the previous insert/delete protocol with write latches.</li></ol><h3 id="when-will-a-deadlock-occur"><a class="markdownIt-Anchor" href="#when-will-a-deadlock-occur"></a> When will a deadlock occur?</h3><ol><li>With sibling pointers, we may move from one leaf node to another where deadlock could occur.</li><li>Latches cannot detect deadlock, so the only solution is to kill one thread.</li><li>The leaf node sibling latch acquisition protocol must support a “no-wait” mode. The DBMS’s data structures must cope with failed latch acquisitions.</li><li>Though some scenarios do not have a deadlock, the waiting thread cannot know what the other thread is doing, which means it can only kill itself to avoid deadlock.</li></ol>]]></content>
      
      
      <categories>
          
          <category> Open Courses </category>
          
          <category> CMU 15-445/645 Database System </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Concurrency Control </tag>
            
            <tag> Database System </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>04 Data Organization</title>
      <link href="/2023/06/24/Courses/15445/04-Data-Organization/"/>
      <url>/2023/06/24/Courses/15445/04-Data-Organization/</url>
      
        <content type="html"><![CDATA[<p><ul class="markdownIt-TOC"><li><a href="#what-does-the-database-access-methods-layer-need-to-do">What does the database access methods layer need to do?</a></li><li><a href="#hash-table">Hash table</a><ul><li><a href="#how-is-the-naive-static-hash-table">How is the naive static hash table?</a></li><li><a href="#what-are-hash-functions">What are hash functions?</a></li><li><a href="#static-hashing-schemes">Static hashing schemes</a><ul><li><a href="#how-is-linear-probe-hashing">How is linear probe hashing?</a></li><li><a href="#how-to-solve-the-non-unique-keys-problem">How to solve the non-unique keys problem?</a></li><li><a href="#how-is-the-robin-hood-hashing">How is the Robin Hood hashing?</a></li><li><a href="#how-is-the-cuckoo-hashing">How is the cuckoo hashing?</a></li></ul></li><li><a href="#dynamic-hashing-schemes">Dynamic hashing schemes</a><ul><li><a href="#how-is-chained-hashing">How is chained hashing?</a></li><li><a href="#how-is-extendible-hashing">How is extendible hashing?</a></li><li><a href="#how-is-linear-hashing">How is linear hashing?</a></li></ul></li></ul></li><li><a href="#tree">Tree</a><ul><li><a href="#table-indexes">Table indexes</a><ul><li><a href="#what-do-table-indexes-do">What do table indexes do?</a></li><li><a href="#what-are-clustered-indexes">What are clustered indexes?</a></li></ul></li><li><a href="#basic-b-tree">Basic B+ Tree</a><ul><li><a href="#what-is-a-b-tree">What is a B+ Tree?</a></li><li><a href="#how-are-keyvalue-pairs-stored-in-each-node">How are key/value pairs stored in each node?</a></li><li><a href="#what-is-stored-in-the-leaf-node">What is stored in the leaf node?</a></li><li><a href="#what-are-the-pros-and-cons-of-b-tree-compared-with-btree">What are the pros and cons of B-Tree compared with B+Tree?</a></li><li><a href="#how-does-btree-insert-a-node">How does B+Tree insert a node?</a></li><li><a href="#how-does-btree-delete-a-node">How does B+Tree delete a node?</a></li></ul></li><li><a href="#btree-usage-and-design">B+Tree usage and design</a><ul><li><a href="#how-does-dbms-use-btree-in-the-selection-query">How does DBMS use B+Tree in the selection query?</a></li><li><a href="#how-to-handle-duplicate-keys">How to handle duplicate keys?</a></li><li><a href="#how-to-solve-redundant-page-jumps-when-sequential-access-leaf-nodes">How to solve redundant page jumps when sequential access leaf nodes?</a></li><li><a href="#how-to-choose-node-size">How to choose node size?</a></li><li><a href="#how-to-choose-a-merge-threshold">How to choose a merge threshold?</a></li><li><a href="#how-to-handle-variable-length-keys">How to handle variable length keys?</a></li><li><a href="#how-can-we-do-the-intra-node-search">How can we do the intra-node search?</a></li><li><a href="#how-can-we-optimize-space-usage">How can we optimize space usage?</a></li><li><a href="#how-can-we-optimize-consumed-time">How can we optimize consumed time?</a></li></ul></li></ul></li></ul></p><h1 id="what-does-the-database-access-methods-layer-need-to-do"><a class="markdownIt-Anchor" href="#what-does-the-database-access-methods-layer-need-to-do"></a> What does the database access methods layer need to do?</h1><ol><li><p>Data Organization</p><ul><li>How do we layout data structure in memory/pages, and what information should be stored to support efficient access?</li><li>This layer will organize all kinds of data inside the database, e.g., internal meta-data, core data storage, temporary data structures, and table indexes.</li></ul></li><li><p>Concurrency</p><ul><li>How can multiple threads be enabled to access the data structure simultaneously without causing problems?</li></ul></li><li><p>There are two types of data structures: hash tables and trees.</p></li></ol><h1 id="hash-table"><a class="markdownIt-Anchor" href="#hash-table"></a> Hash table</h1><h2 id="how-is-the-naive-static-hash-table"><a class="markdownIt-Anchor" href="#how-is-the-naive-static-hash-table"></a> How is the naive static hash table?</h2><ol><li><p>A hash table implements an unordered associative array that maps keys to values.</p></li><li><p>For any input key, hash functions return an integer representation.</p></li><li><p>The space complexity is <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>O</mi><mo stretchy="false">(</mo><mi>n</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">O(n)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">O</span><span class="mopen">(</span><span class="mord mathnormal">n</span><span class="mclose">)</span></span></span></span>, the average time complexity is <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>O</mi><mo stretchy="false">(</mo><mn>1</mn><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">O(1)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">O</span><span class="mopen">(</span><span class="mord">1</span><span class="mclose">)</span></span></span></span> and the worst time complexity is <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>O</mi><mo stretchy="false">(</mo><mi>n</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">O(n)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">O</span><span class="mopen">(</span><span class="mord mathnormal">n</span><span class="mclose">)</span></span></span></span>.</p><ul><li>Databases need to be about constants. For time complexity, smaller constants can save much time in billions of operations.</li><li>The space will be several times larger than the number of keys.</li></ul></li><li><p>The naive static hash table assumes:</p><ul><li>The number of elements is known ahead of time and fixed.</li><li>Each key is unique.</li><li>We have the perfect hash function where two keys must have different hash values.</li></ul></li><li><p>These assumptions are not always satisfied.</p><ul><li><p>We need a dynamic hashing scheme to suit when the first assumption fails.</p></li><li><p>To suit when the last two assumptions failed, we need to design a more delicate hash function to reduce the collision rate and hashing scheme to handle collisions after hashing.</p><ul><li><p>The trade-off of the hash function is between being fast and collision rate.</p></li><li><p>The trade-off of the hashing scheme is between allocating a larger hash table and additional instructions to get/put keys.</p></li></ul></li></ul></li></ol><h2 id="what-are-hash-functions"><a class="markdownIt-Anchor" href="#what-are-hash-functions"></a> What are hash functions?</h2><ol><li><p>We do not want to use a cryptographic hash function for DBMS hash tables, e.g., SHA-2.</p><ul><li>Because this hashing is only used internally, we will never worry about leaking keys.</li><li>We want something that is fast and has a low collision rate.</li></ul></li><li><p>The commonly used hash functions are:</p><ul><li>CRC-64: Used in networking for error detection.</li><li>MurmurHash: Designed as a fast, general-purpose hash function.</li><li>Google CityHash: Designed to be faster for short keys (&lt;64 bytes).</li><li>Facebook XXHash: From the creator of zstd compression, the state-of-the-art.</li><li>Google Farmhash: A newer version of CityHash with better collision rates.</li></ul></li><li><p>Their speed comparison is as follows:</p><img src="/imgs/15445/Organization/hash_func.png" width="75%"></li></ol><h2 id="static-hashing-schemes"><a class="markdownIt-Anchor" href="#static-hashing-schemes"></a> Static hashing schemes</h2><h3 id="how-is-linear-probe-hashing"><a class="markdownIt-Anchor" href="#how-is-linear-probe-hashing"></a> How is linear probe hashing?</h3><ol><li>A key-value pair is stored in the hashing table for all the schemes. The key is determining whether this is the key we want to find.</li><li>It resolves collisions by linearly searching for the next free slot in the table.</li><li>To determine whether an element is present, hash to a location in the index and scan for it. If an empty slot is found before the key, the element does not exist.</li><li>To delete an entry, there are two approaches:<ul><li><strong>Movement</strong>: Rehash the remaining keys until find the first empty slot. Nobody does this.</li><li><strong>Tombstone</strong>: Set a marker to indicate that the entry in the slot is logically deleted. The slot can be reused for new keys. This may still need periodic garbage collection.</li></ul></li></ol><h3 id="how-to-solve-the-non-unique-keys-problem"><a class="markdownIt-Anchor" href="#how-to-solve-the-non-unique-keys-problem"></a> How to solve the non-unique keys problem?</h3><ol><li>The first choice is to store values in separate storage areas for each key, and the value of the hash table points to the area.</li><li>The second choice is storing duplicate key entries in the hash table.<ul><li>Read would return the first key they found.</li><li>Deletes would remove all the keys or a specific key-value pair.</li></ul></li></ol><h3 id="how-is-the-robin-hood-hashing"><a class="markdownIt-Anchor" href="#how-is-the-robin-hood-hashing"></a> How is the Robin Hood hashing?</h3><ol><li>This variant of linear probe hashing steals slots from “rich” keys and gives them to “poor” keys.<ul><li>Each key tracks the number of positions they are from where its optimal position (original hash value) is in the table.</li><li>The keys farther away from their optimal position are poorer, while the keys closer are richer.</li><li>On insert, a key takes the slot of another key if the first key is “richer” than the second key. And the second key will keep searching linearly until it finds another “richer” key.</li></ul></li><li>Stealing increases the number of writing operations compared with the linear probing scheme while reducing the time of the worst case.</li><li>This could have cascading/flooding problems where one inserts causes multiple “stealing.” Also, it does not consider the possibility of having hotkeys.</li></ol><h3 id="how-is-the-cuckoo-hashing"><a class="markdownIt-Anchor" href="#how-is-the-cuckoo-hashing"></a> How is the cuckoo hashing?</h3><ol><li>Use multiple hash tables with different hash function seeds to ensure they won’t hash to the same value.<ul><li>On insert, check every table and pick anyone with a free slot.</li><li>If no table has a free slot, choose one victim, evict it, and then re-hash it to find a new location.</li></ul></li><li>Look-ups and deletions are always <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>O</mi><mo stretchy="false">(</mo><mn>1</mn><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">O(1)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">O</span><span class="mopen">(</span><span class="mord">1</span><span class="mclose">)</span></span></span></span> because only one location per hash table is checked.</li><li>There is a possibility of cascading. The worst case is an infinite cascading loop.<ul><li>We can use extra code to detect if replacing is going in a loop. If so, we must double the hash table size with new hash functions and re-insert all keys.</li></ul></li></ol><h2 id="dynamic-hashing-schemes"><a class="markdownIt-Anchor" href="#dynamic-hashing-schemes"></a> Dynamic hashing schemes</h2><h3 id="how-is-chained-hashing"><a class="markdownIt-Anchor" href="#how-is-chained-hashing"></a> How is chained hashing?</h3><ol><li>It maintains a linked list of buckets for each slot in the hash table.</li><li>Resolve collisions by placing all elements with the same hash key into the same bucket.<ul><li>To determine whether an element is present, hash to its bucket and scan for it.</li></ul></li><li>The problem is that the linked list can grow forever, causing the time spent on search to increase as the system runs.</li></ol><h3 id="how-is-extendible-hashing"><a class="markdownIt-Anchor" href="#how-is-extendible-hashing"></a> How is extendible hashing?</h3><ol><li>Multiple slot locations can point to the same bucket chain.</li><li>For the number of bits that need to be examined, there is a global and a local one.</li><li>It reshuffles bucket entries on split and increases the number of bits to examine when a list is full.<ul><li>If there is only one slot pointing to this list, i.e., the global examining bits are the same as the local one,<ul><li>The DBMS increases the global number, causing the size of the hashing table doubled.</li><li>Those lists with smaller local numbers will still set the pointers of corresponding new slots (with only the last global examining bit different) to themselves.</li><li>DBMS also increases the number of local examining bits on the fulled list. The keys in it will re-hash to their two new lists.</li></ul></li><li>If more than one slot is pointing to this list, i.e., the global examining bits are larger than the local one,<ul><li>The DBMS only increases the local examining bits of the full list and does the re-hashing.</li></ul></li></ul></li></ol><h3 id="how-is-linear-hashing"><a class="markdownIt-Anchor" href="#how-is-linear-hashing"></a> How is linear hashing?</h3><ol><li>It is similar to extensible hashing. But the hash table maintains a pointer that tracks the next bucket to split.</li><li>When any bucket overflows, split the bucket at the pointer location.<ul><li>When the split causes the number of slots in the hash table to double, it introduces a new hash function, taking modulo with the new hash table size.</li></ul></li><li>It uses multiple hashes to find the right bucket for a given key.<ul><li>It always first uses the old hash function with a smaller modulus.</li><li>If this hash value is smaller than the split pointer, which means that this slot has already been split, DBMS needs to use the new hash function to find the true hash value.</li><li>Otherwise, this slot is not split, and the old hash value works fine.</li></ul></li><li>Splitting buckets based on the split pointer will eventually get to all overflowed buckets.<ul><li>When the pointer reaches the last slot, delete the first hash function and return to the beginning.</li></ul></li><li>Deleting may cause the size of the hash table to shrink when it deletes the only entry in the second half of the hash table.<ul><li>DMBS shrinks the size of the hash table and deletes the new hash function.</li></ul></li></ol><h1 id="tree"><a class="markdownIt-Anchor" href="#tree"></a> Tree</h1><h2 id="table-indexes"><a class="markdownIt-Anchor" href="#table-indexes"></a> Table indexes</h2><h3 id="what-do-table-indexes-do"><a class="markdownIt-Anchor" href="#what-do-table-indexes-do"></a> What do table indexes do?</h3><ol><li>A table index is a replica of a subset of a table’s attributes organized and sorted for efficient access using those attributes.</li><li>It is used in queries to find tuples with attributes that match certain values.</li><li>The DBMS ensures that the contents of the table and the index are logically synchronized.</li><li>The DBMS’s job is to figure out the best index(es) to execute each query.</li><li>There is a trade-off regarding the number of indexes to create per database, i.e., the lookup speed and synchronization overhead.<ul><li>We need extra storage overhead to store the data structure and maintenance overhead to keep synchronization.</li></ul></li></ol><h3 id="what-are-clustered-indexes"><a class="markdownIt-Anchor" href="#what-are-clustered-indexes"></a> What are clustered indexes?</h3><ol><li>The table is stored in the sort order specified by the primary key.<ul><li>It can be either heap- or index-organized storage.</li></ul></li><li>Some DBMSs always use a clustered index. If a table does not contain a primary key, the DBMS will<br />automatically make a hidden primary key.</li><li>Other DBMSs cannot use them at all.</li></ol><h2 id="basic-b-tree"><a class="markdownIt-Anchor" href="#basic-b-tree"></a> Basic B+ Tree</h2><h3 id="what-is-a-b-tree"><a class="markdownIt-Anchor" href="#what-is-a-b-tree"></a> What is a B+ Tree?</h3><ol><li>A B+Tree is a self-balancing tree data structure that keeps data sorted and allows searches, sequential access, insertions, and deletions always in <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>O</mi><mo stretchy="false">(</mo><mi>log</mi><mo>⁡</mo><mi>n</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">O(\log n)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">O</span><span class="mopen">(</span><span class="mop">lo<span style="margin-right:0.01389em;">g</span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal">n</span><span class="mclose">)</span></span></span></span>.</li><li>A B+ tree is an M-way search tree.<ul><li>It is perfectly balanced, i.e., every leaf node is at the same depth in the tree.</li><li>Every node other than the root is at least half-full, i.e., <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>M</mi><mi mathvariant="normal">/</mi><mn>2</mn><mo>−</mo><mn>1</mn><mo>≤</mo><mi>n</mi><mi>u</mi><mi>m</mi><mi>b</mi><mi>e</mi><mi>r</mi><mtext> </mtext><mi>o</mi><mi>f</mi><mtext> </mtext><mi>k</mi><mi>e</mi><mi>y</mi><mi>s</mi><mo>≤</mo><mi>M</mi><mo>−</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">M/2-1 ≤ number\ of\ keys ≤ M-1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">M</span><span class="mord">/</span><span class="mord">2</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.78041em;vertical-align:-0.13597em;"></span><span class="mord">1</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">≤</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord mathnormal">n</span><span class="mord mathnormal">u</span><span class="mord mathnormal">m</span><span class="mord mathnormal">b</span><span class="mord mathnormal">e</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mspace"> </span><span class="mord mathnormal">o</span><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="mspace"> </span><span class="mord mathnormal" style="margin-right:0.03148em;">k</span><span class="mord mathnormal">e</span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="mord mathnormal">s</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">≤</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.76666em;vertical-align:-0.08333em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">M</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">1</span></span></span></span>.</li><li>Every inner node with <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi></mrow><annotation encoding="application/x-tex">k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.03148em;">k</span></span></span></span> keys has <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi><mo>+</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">k+1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.77777em;vertical-align:-0.08333em;"></span><span class="mord mathnormal" style="margin-right:0.03148em;">k</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">1</span></span></span></span> non-null children.</li></ul></li></ol><h3 id="how-are-keyvalue-pairs-stored-in-each-node"><a class="markdownIt-Anchor" href="#how-are-keyvalue-pairs-stored-in-each-node"></a> How are key/value pairs stored in each node?</h3><ol><li>Every B+Tree node is comprised of an array of key/value pairs.</li><li>The keys are derived from the attribute(s) on which the index is based.</li><li>The value stored in an inner node is a pointer to its corresponding children, while the value stored in a leaf node is its specific value.</li><li>There are two storage methods for the key-value pair.<ul><li>One is to store them consecutively, i.e., each value is stored immediately after its key.</li><li>The other is to store them in the same place in two arrays, i.e., each value has the same index as its key.</li></ul></li><li>The arrays are (usually) kept in sorted key order.</li></ol><h3 id="what-is-stored-in-the-leaf-node"><a class="markdownIt-Anchor" href="#what-is-stored-in-the-leaf-node"></a> What is stored in the leaf node?</h3><ol><li><p>Each leaf node also has pointers that point to its siblings.</p></li><li><p>There are two approaches to store the values:</p><ul><li>The first approach is to store them with record IDs, a pointer to the page ID, and an offset of the tuple to which the index entry corresponds.</li><li>The second approach is to store them with tuple data, specifically primary keys.</li></ul></li><li><p>The pros of the second approach are that we do not need to access another address to fetch the contents when primary keys are all we want.</p><p>However, secondary indexes must store the Record ID as their value. Hence, if we want secondary indexes in the second approach, we must look up other tables to find the Record ID with the same primary keys.</p></li></ol><h3 id="what-are-the-pros-and-cons-of-b-tree-compared-with-btree"><a class="markdownIt-Anchor" href="#what-are-the-pros-and-cons-of-b-tree-compared-with-btree"></a> What are the pros and cons of B-Tree compared with B+Tree?</h3><ol><li>The main difference is that  B-Tree stores keys and values in all nodes in the tree, while B+Tree only stores values in leaf nodes. Inner nodes only guide the search process.</li><li>B-Tree is more space-efficient since each key only appears once in the tree.</li><li>However, B-Tree needs to jump between pages when we want sequential access keys, causing much more I/O.</li></ol><h3 id="how-does-btree-insert-a-node"><a class="markdownIt-Anchor" href="#how-does-btree-insert-a-node"></a> How does B+Tree insert a node?</h3><ol><li>Find correct leaf node L. Insert data entry into L in sorted order.</li><li>If L has enough space, then it is done.</li><li>Otherwise, split L keys into L and a new node L2. Insert the index entry pointing to L2 into the parent of L.<ul><li>The parent of L may need to be rebalanced after this insertion.</li></ul></li></ol><h3 id="how-does-btree-delete-a-node"><a class="markdownIt-Anchor" href="#how-does-btree-delete-a-node"></a> How does B+Tree delete a node?</h3><ol><li>Start at the root and find leaf L, where the entry belongs. Remove the entry.</li><li>If L is at least half-full, then it is done.</li><li>If L has only M/2-1 entries,<ul><li>First, try to re-distribute, borrowing from siblings.</li><li>If re-distribution fails, merge L and sibling and delete the entry (pointing to L or sibling) from the parent of L.<ul><li>The parent of L may need a rebalance.</li></ul></li></ul></li></ol><h2 id="btree-usage-and-design"><a class="markdownIt-Anchor" href="#btree-usage-and-design"></a> B+Tree usage and design</h2><h3 id="how-does-dbms-use-btree-in-the-selection-query"><a class="markdownIt-Anchor" href="#how-does-dbms-use-btree-in-the-selection-query"></a> How does DBMS use B+Tree in the selection query?</h3><ol><li><p>When creating an index, a certain attribute order is specified to sort the tuple.</p><ul><li><p>When <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>A</mi><mn>1</mn></msub><mo separator="true">,</mo><mo>…</mo><mo separator="true">,</mo><msub><mi>A</mi><mi>n</mi></msub></mrow><annotation encoding="application/x-tex">A_1, \dots,A_n</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8777699999999999em;vertical-align:-0.19444em;"></span><span class="mord"><span class="mord mathnormal">A</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="minner">…</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathnormal">A</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">n</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> are specified, the B+Tree will store the corresponding <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi></mrow><annotation encoding="application/x-tex">n</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathnormal">n</span></span></span></span> values in as keys in each node.</p></li><li><p>When <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>a</mi><mn>1</mn></msub><mo separator="true">,</mo><mo>…</mo><mo separator="true">,</mo><msub><mi>a</mi><mi>n</mi></msub></mrow><annotation encoding="application/x-tex">a_1, \dots,a_n</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord"><span class="mord mathnormal">a</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="minner">…</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathnormal">a</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">n</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> are stored in one node, all nodes in its left sub-tree have <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>A</mi><mn>1</mn></msub><mo>≤</mo><msub><mi>a</mi><mn>1</mn></msub><mo separator="true">,</mo><mo>…</mo><mo separator="true">,</mo><msub><mi>A</mi><mi>n</mi></msub><mo>≤</mo><msub><mi>a</mi><mi>n</mi></msub></mrow><annotation encoding="application/x-tex">A_1≤a_1,\dots,A_n≤a_n</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">A</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">≤</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.8777699999999999em;vertical-align:-0.19444em;"></span><span class="mord"><span class="mord mathnormal">a</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="minner">…</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathnormal">A</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">n</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">≤</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">a</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">n</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> while all nodes in its right sub-tree are only guaranteed with <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>A</mi><mn>1</mn></msub><mo>&gt;</mo><msub><mi>a</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">A_1 &gt; a_1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">A</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">&gt;</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">a</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>, i.e., the B+Tree is maintained with <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>A</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">A_1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">A</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> as its primary sorting key.</p></li></ul></li><li><p>In a selection condition, we can easily select with certain conditions on <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>A</mi><mn>1</mn></msub><mo separator="true">,</mo><mo>…</mo><mo separator="true">,</mo><msub><mi>A</mi><mi>k</mi></msub><mtext> </mtext><mo stretchy="false">(</mo><mi>k</mi><mo>≤</mo><mi>n</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">A_1,\dots,A_k\ (k≤n)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathnormal">A</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="minner">…</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathnormal">A</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace"> </span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.03148em;">k</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">≤</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">n</span><span class="mclose">)</span></span></span></span>. Some DBMS also support conditions specified only on <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>A</mi><mi>k</mi></msub><mo separator="true">,</mo><mo>…</mo><mo separator="true">,</mo><msub><mi>A</mi><mi>n</mi></msub></mrow><annotation encoding="application/x-tex">A_k, \dots,A_n</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8777699999999999em;vertical-align:-0.19444em;"></span><span class="mord"><span class="mord mathnormal">A</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="minner">…</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathnormal">A</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">n</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>, which requires DBMS to access all leaf nodes sequentially.</p></li><li><p>Compared with the hash table, B+Tree can better support selection without knowing the attributes to look for.</p></li></ol><h3 id="how-to-handle-duplicate-keys"><a class="markdownIt-Anchor" href="#how-to-handle-duplicate-keys"></a> How to handle duplicate keys?</h3><ol><li>The first approach is to add the tuple’s unique Record ID as part of the key to ensure all keys are unique.<ul><li>The DBMS can still use partial keys to find tuples.</li></ul></li><li>The second approach is allowing leaf nodes to spill into overflow nodes containing duplicate keys.<ul><li>Only duplicate keys of existing keys can overflow.</li><li>Overflow nodes also need to split or merge when splitting or merging nodes.</li><li>This is more complex to maintain and modify.</li></ul></li></ol><h3 id="how-to-solve-redundant-page-jumps-when-sequential-access-leaf-nodes"><a class="markdownIt-Anchor" href="#how-to-solve-redundant-page-jumps-when-sequential-access-leaf-nodes"></a> How to solve redundant page jumps when sequential access leaf nodes?</h3><ol><li>In a clustered B+Tree, nodes on the same page are in consecutive order.<ul><li>We can traverse the left-most leaf page and retrieve tuples from all leaf pages.</li><li>This will always be better than sorting data for each query.</li></ul></li><li>In a non-clustered B+Tree, the DBMS can first figure out all the tuples it needs and then sort them based on their Page ID.</li></ol><h3 id="how-to-choose-node-size"><a class="markdownIt-Anchor" href="#how-to-choose-node-size"></a> How to choose node size?</h3><ol><li>The slower the storage device, the larger the optimal node size for a B+Tree.<ul><li>HDD takes <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1</mn><mtext> </mtext><mi>M</mi><mi>B</mi></mrow><annotation encoding="application/x-tex">1\ MB</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord">1</span><span class="mspace"> </span><span class="mord mathnormal" style="margin-right:0.10903em;">M</span><span class="mord mathnormal" style="margin-right:0.05017em;">B</span></span></span></span>, SSD usually takes <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>10</mn><mtext> </mtext><mi>K</mi><mi>B</mi></mrow><annotation encoding="application/x-tex">10\ KB</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord">1</span><span class="mord">0</span><span class="mspace"> </span><span class="mord mathnormal" style="margin-right:0.07153em;">K</span><span class="mord mathnormal" style="margin-right:0.05017em;">B</span></span></span></span>, in-memory nodes have <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>512</mn><mtext> </mtext><mi>B</mi></mrow><annotation encoding="application/x-tex">512\ B</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord">5</span><span class="mord">1</span><span class="mord">2</span><span class="mspace"> </span><span class="mord mathnormal" style="margin-right:0.05017em;">B</span></span></span></span>.</li></ul></li><li>Optimal sizes can vary depending on the workload. The trade-off is between leaf node scans and root-to-leaf traversals.<ul><li>With a larger size, we can have more sequential reads in leaf node scans, but we need to read more data in root-to-leaf traversals.</li></ul></li></ol><h3 id="how-to-choose-a-merge-threshold"><a class="markdownIt-Anchor" href="#how-to-choose-a-merge-threshold"></a> How to choose a merge threshold?</h3><ol><li>Some DBMSs do not always merge nodes when they are half full.</li><li>Delaying a merge operation may reduce the amount of reorganization. They assume that the missing part will be filled soon.</li><li>Having smaller nodes exist and periodically rebuilding the entire tree may also be better.</li></ol><h3 id="how-to-handle-variable-length-keys"><a class="markdownIt-Anchor" href="#how-to-handle-variable-length-keys"></a> How to handle variable length keys?</h3><ol><li>The first approach is to store the keys as pointers to the tuple’s attribute.</li><li>The second approach is to allow variable-length nodes. It requires careful memory management.</li><li>The third approach is always to pad the key to the max length of the key type.</li><li>The last approach is a key map or indirection. It is similar to the in-node dictionary.</li></ol><h3 id="how-can-we-do-the-intra-node-search"><a class="markdownIt-Anchor" href="#how-can-we-do-the-intra-node-search"></a> How can we do the intra-node search?</h3><ol><li>The naive method is linear search. We can use SIMD to vectorize the process.</li><li>The second method is binary search, given that keys in a node are already sorted.</li><li>The third method is interpolation search.<ul><li>This requires a known distribution of keys.</li><li>It jumps to the approximate location of the desired key based on known distribution.</li></ul></li></ol><h3 id="how-can-we-optimize-space-usage"><a class="markdownIt-Anchor" href="#how-can-we-optimize-space-usage"></a> How can we optimize space usage?</h3><ol><li>Prefix compression<ul><li>Sorted keys in the same leaf node will likely have the same prefix.</li><li>Extract common prefixes and store only a unique suffix for each key.</li></ul></li><li>Deduplication<ul><li>Non-unique indexes can end up storing multiple copies of the same key in leaf nodes.</li><li>Store the key once and then maintain a list of tuples with that key.</li></ul></li><li>Suffix truncation<ul><li>The keys in the inner nodes are only used to “direct traffic.” We don’t need the entire key.</li><li>Store a minimum prefix needed to route probes into the index correctly.</li></ul></li></ol><h3 id="how-can-we-optimize-consumed-time"><a class="markdownIt-Anchor" href="#how-can-we-optimize-consumed-time"></a> How can we optimize consumed time?</h3><ol><li>Pointer swizzling<ul><li>Nodes use page IDs to reference other nodes in the index. The DBMS must get the memory location from the page table during traversal.</li><li>If a page is pinned in the buffer pool, we can store raw pointers instead of page IDs. This avoids address lookups from the page table.</li></ul></li><li>Bulk insert<ul><li>The fastest way to build a new B+Tree for an existing table is first to sort the keys and then build the index from the bottom up.</li></ul></li></ol>]]></content>
      
      
      <categories>
          
          <category> Open Courses </category>
          
          <category> CMU 15-445/645 Database System </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Database System </tag>
            
            <tag> Data Structure </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>03 Buffer Pool Manage</title>
      <link href="/2023/06/24/Courses/15445/03-Buffer-Pool-Manage/"/>
      <url>/2023/06/24/Courses/15445/03-Buffer-Pool-Manage/</url>
      
        <content type="html"><![CDATA[<p><ul class="markdownIt-TOC"><li><a href="#buffer-pool-manage">Buffer pool manage</a><ul><li><a href="#what-does-the-databse-storage-need-to-control">What does the databse storage need to control?</a></li><li><a href="#how-is-the-buffer-pool-organized">How is the buffer pool organized?</a></li><li><a href="#clarification-what-are-the-locks-and-latches-referenced-in-the-database">Clarification: What are the locks and latches referenced in the database?</a></li><li><a href="#how-can-we-optimize-performance-with-multiple-buffer-pools">How can we optimize performance with multiple buffer pools?</a></li><li><a href="#how-can-we-optimize-performance-with-pre-fetching">How can we optimize performance with pre-fetching?</a></li><li><a href="#how-can-we-optimize-performance-with-scan-sharing">How can we optimize performance with scan sharing?</a></li><li><a href="#how-can-we-optimize-performance-with-buffer-pool-bypass">How can we optimize performance with buffer pool bypass?</a></li><li><a href="#should-we-use-the-os-page-cache">Should we use the OS page cache?</a></li></ul></li><li><a href="#buffer-replacement-policies">Buffer replacement policies</a><ul><li><a href="#what-is-the-lru-least-recently-used-policy-and-clock-policy">What is the LRU (Least-Recently Used) policy and clock policy?</a></li><li><a href="#what-is-the-problem-with-lru-and-the-clock-and-how-can-it-be-alleviated">What is the problem with LRU and the clock, and how can it be alleviated?</a></li><li><a href="#how-do-we-deal-with-evicted-pages">How do we deal with evicted pages?</a></li></ul></li></ul></p><h1 id="buffer-pool-manage"><a class="markdownIt-Anchor" href="#buffer-pool-manage"></a> Buffer pool manage</h1><h2 id="what-does-the-databse-storage-need-to-control"><a class="markdownIt-Anchor" href="#what-does-the-databse-storage-need-to-control"></a> What does the databse storage need to control?</h2><ol><li>Spatial Control: Where to write pages on disk.<ul><li>The goal is to keep pages that are used together often as physically close together as possible on disk.</li></ul></li><li>Temporal Control: When to read pages into memory and write them to disk.<ul><li>The goal is to minimize the number of stalls from having to read data from a disk.</li></ul></li></ol><h2 id="how-is-the-buffer-pool-organized"><a class="markdownIt-Anchor" href="#how-is-the-buffer-pool-organized"></a> How is the buffer pool organized?</h2><ol><li>The memory region is organized as an array of fixed-size pages. An array entry is called a <strong>frame</strong>.<ul><li>Pages are on disk, while frames are on memory.</li></ul></li><li>When the DBMS requests a page, an exact copy is placed into one of these frames.</li><li>The buffer pool manager needs to maintain a <strong>page table</strong> to track pages currently in memory.<ul><li>The page table maps from page IDs to a copy of the page in buffer pool frames.<ul><li>This in-memory data structure does not need to be stored on disk.</li></ul></li><li>The page directory maps from page IDs to page locations in the database files.<ul><li>All changes must be recorded on disk to allow the DBMS to find on restart.</li></ul></li></ul></li><li>Some additional meta-data per page also need to be maintained:<ul><li><strong>Dirty flag</strong>: Mark whether a page has been modified to show whether can safely evict this page.</li><li><strong>Pin/reference counter</strong>: Some queries use it to prevent the buffer pool manager from evicting this page. They unpinned this page after no longer using it.</li><li><strong>Latches</strong>: This can be used to pre-occupy an entry in the page table and release the latch after copying that page and updating the entry.</li><li>These meta-data can either be stored in a page or page table.</li></ul></li></ol><h2 id="clarification-what-are-the-locks-and-latches-referenced-in-the-database"><a class="markdownIt-Anchor" href="#clarification-what-are-the-locks-and-latches-referenced-in-the-database"></a> Clarification: What are the locks and latches referenced in the database?</h2><ol><li>Locks:<ul><li>It protects the database’s logical contents from other transactions.</li><li>It is held for transaction duration. Need to be able to rollback changes.</li><li>Locks can be taken on a tuple or table but not on a page.</li></ul></li><li>Latches:<ul><li>It protects the critical sections of the DBMS’s internal data structure from other threads.</li><li>It is held for operation duration. Do not need to be able to rollback changes.</li><li>This is similar to the mutex provided by OS.</li></ul></li></ol><h2 id="how-can-we-optimize-performance-with-multiple-buffer-pools"><a class="markdownIt-Anchor" href="#how-can-we-optimize-performance-with-multiple-buffer-pools"></a> How can we optimize performance with multiple buffer pools?</h2><ol><li>Advantages:<ul><li>The different pools can have different eviction policies to improve locality.</li><li>Each time accessing the meta-data of each buffer pool needs to take a latch. Multiple buffer pools can reduce latch contention.</li></ul></li><li>The manager can use a per-database buffer pool, per-page type buffer pool, or per-index type buffer pool.</li><li>Managers decide which pool to store pages in two approaches:<ul><li>The first is to embed an object identifier in record IDs and then maintain a mapping from objects to specific buffer pools.<ul><li>This can be used to specify certain pages must be stored in a specific pool.</li></ul></li><li>The other is to hash the page ID to select which buffer pool to access.</li></ul></li></ol><h2 id="how-can-we-optimize-performance-with-pre-fetching"><a class="markdownIt-Anchor" href="#how-can-we-optimize-performance-with-pre-fetching"></a> How can we optimize performance with pre-fetching?</h2><ol><li>Pre-fetching can be easily used in two situations: sequential scans and index scans.</li><li>In sequential scans, when the manager fetches the first few consecutive pages, it can be inferred that the following consecutive pages will be used soon and pre-fetched into memory.</li><li>The query may not access consecutive pages in index scans, but DBMS sees the B+ tree structure and thus knows where the following indices are.</li></ol><h2 id="how-can-we-optimize-performance-with-scan-sharing"><a class="markdownIt-Anchor" href="#how-can-we-optimize-performance-with-scan-sharing"></a> How can we optimize performance with scan sharing?</h2><ol><li>It allows multiple queries to attach to a single cursor that scans a table.<ul><li>The queries do not have to be the same.</li><li>They can also share intermediate results.</li></ul></li><li>If a query wants to scan a table and another query is already doing this, the DBMS will attach the second query’s cursor to the existing cursor.</li><li>After the earlier query is finished, the later query will return to read the pages the earlier one already read before the later one begins.</li><li>If the later query has a <code>LIMIT</code> clause without WHERE or ORDER BY clause, given that the relation is unordered, it may not need to read extra data if those scan-sharing data are enough to satisfy the <code>LIMIT</code> clause.</li></ol><h2 id="how-can-we-optimize-performance-with-buffer-pool-bypass"><a class="markdownIt-Anchor" href="#how-can-we-optimize-performance-with-buffer-pool-bypass"></a> How can we optimize performance with buffer pool bypass?</h2><ol><li>Sequential flooding: A query performs a sequential scan that reads every page.<ul><li>This pollutes the buffer pool with pages that are read once and never again.</li></ul></li><li>Buffer pool bypass will not store fetched pages in the buffer pool. Insteach, the manager has a private pool where those pages will be stored temporarily and deleted once finished.</li><li>It works well if the operator needs to read a large sequence of contiguous pages on disk. It can also be used for temporary data (sorting, joins).</li></ol><h2 id="should-we-use-the-os-page-cache"><a class="markdownIt-Anchor" href="#should-we-use-the-os-page-cache"></a> Should we use the OS page cache?</h2><ol><li>Most disk operations go through the OS API. Unless the DBMS tells it not to, the OS maintains its filesystem cache.</li><li>Most DBMSs bypass the OS’s cache by using direct I/O (O_DIRECT).</li><li>The OS page cache can cause redundant copies of pages. OS and DBMS have different eviction policies, causing DBMS to lose control over file I/O.</li></ol><h1 id="buffer-replacement-policies"><a class="markdownIt-Anchor" href="#buffer-replacement-policies"></a> Buffer replacement policies</h1><h2 id="what-is-the-lru-least-recently-used-policy-and-clock-policy"><a class="markdownIt-Anchor" href="#what-is-the-lru-least-recently-used-policy-and-clock-policy"></a> What is the LRU (Least-Recently Used) policy and clock policy?</h2><ol><li>Managers maintain a single timestamp of when each page was last accessed.</li><li>When the DBMS needs to evict a page, select the one with the oldest timestamp.<ul><li>It can keep the pages in sorted order to reduce the search time on eviction.</li></ul></li><li>An approximation of LRU that does not need a separate timestamp per page is the clock policy.<ul><li>Each page has a reference bit. When a page is accessed, set it to <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1</mn></mrow><annotation encoding="application/x-tex">1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">1</span></span></span></span>.</li><li>Organize the pages in a circular buffer with a “clock hand.”: Upon sweeping, check if a page’s bit is set<br />to 1. If yes, set it to zero. If no, then evict.</li></ul></li></ol><h2 id="what-is-the-problem-with-lru-and-the-clock-and-how-can-it-be-alleviated"><a class="markdownIt-Anchor" href="#what-is-the-problem-with-lru-and-the-clock-and-how-can-it-be-alleviated"></a> What is the problem with LRU and the clock, and how can it be alleviated?</h2><ol><li>LRU and CLOCK replacement policies are susceptible to sequential flooding. In some workloads, the most recently used page is the most unneeded.</li><li><strong>LRU-K</strong> policy can alleviate the problem.<ul><li>Track the history of the last K references to each page as timestamps and compute the average interval between subsequent accesses. And evict the one that will be accessed at the latest, according to the prediction.</li><li>In the implementation, the manager only needs to maintain a queue of size K. Pop out the oldest timestamp when a new timestamp arrives.</li></ul></li><li>Another policy is <strong>localization</strong>: The DBMS chooses which pages to evict on a per transaction/query basis, e.g., it allocates private frames to the query.</li><li><strong>Priority hints</strong>: The DBMS knows about the context of each page during query execution. It can provide hints to the buffer pool on whether a page is important.</li></ol><h2 id="how-do-we-deal-with-evicted-pages"><a class="markdownIt-Anchor" href="#how-do-we-deal-with-evicted-pages"></a> How do we deal with evicted pages?</h2><ol><li>Fast Path: If a page in the buffer pool is not dirty, the DBMS can drop it.</li><li>Slow Path: If a page is dirty, the DBMS must write back to disk to ensure its changes persist.<ul><li>The DBMS can periodically walk through the page table and write dirty pages to disk.</li><li>When a dirty page is safely written, the DBMS can either evict the page or just unset the dirty flag.</li><li>Need to be careful that the system doesn’t write dirty pages before their log records are written.</li></ul></li><li>The Trade-off is between fast evictions versus dirty writing pages that will not be read again.</li></ol>]]></content>
      
      
      <categories>
          
          <category> Open Courses </category>
          
          <category> CMU 15-445/645 Database System </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Database System </tag>
            
            <tag> Storage </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>02 Storage</title>
      <link href="/2023/06/24/Courses/15445/02-Storage/"/>
      <url>/2023/06/24/Courses/15445/02-Storage/</url>
      
        <content type="html"><![CDATA[<p><ul class="markdownIt-TOC"><li><a href="#disk-based-architecture">Disk-based architecture</a><ul><li><a href="#what-are-the-storage-devices">What are the storage devices?</a></li><li><a href="#what-is-disk-oriented-dmbs">What is disk-oriented DMBS?</a></li><li><a href="#why-not-use-the-os-memory-mapping-virtual-memory">Why not use the OS memory mapping (virtual memory)?</a></li></ul></li><li><a href="#page-oriented-architecture">Page-oriented architecture</a><ul><li><a href="#file-storage">File storage</a><ul><li><a href="#how-does-dbms-store-files">How does DBMS store files?</a></li><li><a href="#how-does-dbms-manage-pages-in-files-on-disk">How does DBMS manage pages in files on disk?</a></li></ul></li><li><a href="#page-layout">Page layout</a><ul><li><a href="#what-is-stored-on-each-page">What is stored on each page?</a></li><li><a href="#how-to-organize-tuple-oriented-data">How to organize tuple-oriented data?</a></li><li><a href="#how-do-we-find-the-tuple-we-need-on-a-page">How do we find the tuple we need on a page?</a></li></ul></li><li><a href="#tuple-layout">Tuple layout</a><ul><li><a href="#what-is-stored-in-a-tuple">What is stored in a tuple?</a></li><li><a href="#what-is-denormalized-data">What is denormalized data?</a></li></ul></li></ul></li><li><a href="#log-structured-storage">Log-structured storage</a><ul><li><a href="#what-is-stored-in-log-structured-storage">What is stored in log-structured storage?</a></li><li><a href="#how-to-read-in-a-log-structured-storage">How to read in a log-structured storage?</a></li><li><a href="#how-to-solve-that-the-log-will-become-larger-and-larger">How to solve that the log will become larger and larger?</a></li></ul></li><li><a href="#tuple-storage">Tuple storage</a><ul><li><a href="#how-to-store-data-in-a-tuple">How to store data in a tuple?</a></li><li><a href="#what-are-supported-data-types">What are supported data types?</a></li></ul></li><li><a href="#data-storage-models">Data storage models</a><ul><li><a href="#what-kind-of-database-workloads-are-there">What kind of database workloads are there?</a></li><li><a href="#how-does-dbms-store-tuples">How does DBMS store tuples?</a></li><li><a href="#database-compression">Database compression</a><ul><li><a href="#why-do-we-need-database-compression-and-what-is-the-trade-off">Why do we need database compression, and what is the trade-off?</a></li><li><a href="#why-can-we-compress-data">Why can we compress data?</a></li><li><a href="#what-are-the-goals-of-compression">What are the goals of compression?</a></li><li><a href="#what-are-the-compression-granularities">What are the compression granularities?</a></li><li><a href="#what-is-naive-compression">What is naive compression?</a></li><li><a href="#how-can-we-do-better-with-the-high-level-meaning-or-semantics-of-the-data">How can we do better with the high-level meaning or semantics of the data?</a></li></ul></li></ul></li></ul></p><h1 id="disk-based-architecture"><a class="markdownIt-Anchor" href="#disk-based-architecture"></a> Disk-based architecture</h1><h2 id="what-are-the-storage-devices"><a class="markdownIt-Anchor" href="#what-are-the-storage-devices"></a> What are the storage devices?</h2><ol><li>The first type is volatile memory: CPU registers, CPU caches, and DRAM.<ul><li>They provide random access, and they are byte-addressable.</li></ul></li><li>The second type is the non-volatile disks: SSD, HDD, and network storage.<ul><li>They only provide sequential access.<ul><li>Random access on non-volatile storage is almost always much slower than sequential access.</li><li>DBMS will want to maximize sequential access.</li></ul></li><li>They are block-addressable.</li></ul></li><li>The access times of each storage are as follows:<br /><img src="/imgs/15445/Storage/access_times.png" width="50%"></li></ol><h2 id="what-is-disk-oriented-dmbs"><a class="markdownIt-Anchor" href="#what-is-disk-oriented-dmbs"></a> What is disk-oriented DMBS?</h2><ol><li>The DBMS assumes that the primary storage location of the database is on a non-volatile disk.</li><li>DBMS manages a buffer pool in memory where directory and data pages are stored.</li><li>When the execution engine asks DBMS for a certain page:<ul><li>If that page is not in memory already, DBMS will look up the directory first (if also not in memory, load from disk) to find the disk position of that page.</li><li>Then, DBMS will load that page from the disk and return a pointer to the buffer pool to the execution engine.</li></ul></li></ol><h2 id="why-not-use-the-os-memory-mapping-virtual-memory"><a class="markdownIt-Anchor" href="#why-not-use-the-os-memory-mapping-virtual-memory"></a> Why not use the OS memory mapping (virtual memory)?</h2><ol><li>Transaction safety: OS can flush dirty pages at any time, causing dirty data to corrupt the database. OS doesn’t know anything about transactions. Hence, it doesn’t care whether writing a page to disk is safe.</li><li>IO stalls: When a page miss happens, the thread will be stalled, and DBMS can do nothing about it.<ul><li>Allowing multiple threads to access the <code>mmap</code> files to hide page fault stalls is good enough for read-only access. But it is complicated when there are multiple writers.</li></ul></li><li>Error handling: Any access can cause a <code>SIGBUS</code> that the DBMS must handle. However, DBMS may isolate and handle the error only in the storage layer.</li><li>Performance issues: Like OS data structure contention or TLB shootdowns.</li><li>In conclusion, DBMS always knows better than OS. Thus, DBMS almost always wants to control things and can do a better job than the OS.<ul><li>Like how to flush dirty pages to disk in the correct order, provide specialized prefetching, better buffer replacement policy, and thread/process scheduling.</li></ul></li></ol><h1 id="page-oriented-architecture"><a class="markdownIt-Anchor" href="#page-oriented-architecture"></a> Page-oriented architecture</h1><h2 id="file-storage"><a class="markdownIt-Anchor" href="#file-storage"></a> File storage</h2><h3 id="how-does-dbms-store-files"><a class="markdownIt-Anchor" href="#how-does-dbms-store-files"></a> How does DBMS store files?</h3><ol><li>The DBMS stores a database as one or more files on disk, typically in a proprietary format.</li><li>The storage manager is responsible for maintaining a database’s files.<ul><li>It organizes the files as a collection of pages.</li><li>It also tracks data read/written to pages and the available space.</li><li>Some do their scheduling for reads and writes to improve pages’ spatial and temporal locality.</li></ul></li><li>A database page is a fixed-size block of data.<ul><li>Most systems do not mix page types, i.e., data on a page belong to the same table.</li><li>Some systems require a page to be self-contained, i.e., all metadata we need to interpret the page has to be contained in the page.</li><li>Hardware pages and OS pages are usually <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>4</mn><mtext> </mtext><mi>K</mi><mi>B</mi></mrow><annotation encoding="application/x-tex">4\ KB</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord">4</span><span class="mspace"> </span><span class="mord mathnormal" style="margin-right:0.07153em;">K</span><span class="mord mathnormal" style="margin-right:0.05017em;">B</span></span></span></span>. But database pages may be <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>512</mn><mtext> </mtext><mi>B</mi><mo>−</mo><mn>16</mn><mtext> </mtext><mi>K</mi><mi>B</mi></mrow><annotation encoding="application/x-tex">512\ B-16\ KB</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.76666em;vertical-align:-0.08333em;"></span><span class="mord">5</span><span class="mord">1</span><span class="mord">2</span><span class="mspace"> </span><span class="mord mathnormal" style="margin-right:0.05017em;">B</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord">1</span><span class="mord">6</span><span class="mspace"> </span><span class="mord mathnormal" style="margin-right:0.07153em;">K</span><span class="mord mathnormal" style="margin-right:0.05017em;">B</span></span></span></span> depending on DBMS and configuration.<ul><li>A larger page size can increase sequential IO, issue fewer system calls, and have a smaller page table.</li><li>Smaller page sizes only need to maintain less memory when only a small amount of data is needed.</li></ul></li></ul></li></ol><h3 id="how-does-dbms-manage-pages-in-files-on-disk"><a class="markdownIt-Anchor" href="#how-does-dbms-manage-pages-in-files-on-disk"></a> How does DBMS manage pages in files on disk?</h3><ol><li>There are different ways to manage: Heap File Organization, Tree File Organization, Sequential / Sorted File Organization (ISAM), or Hashing File Organization.</li><li>A heap file is an unordered collection of pages with tuples stored in random order.</li><li>The DBMS maintains a directory in special pages that track the location of data pages in the database files.<ul><li>Ensure that the directory pages are in sync with the data pages.</li><li>The directory also records meta-data about available space: the number of free slots per page and the list of free/empty pages.</li></ul></li></ol><h2 id="page-layout"><a class="markdownIt-Anchor" href="#page-layout"></a> Page layout</h2><h3 id="what-is-stored-on-each-page"><a class="markdownIt-Anchor" href="#what-is-stored-on-each-page"></a> What is stored on each page?</h3><ol><li>Every page contains a header of meta-data about the page’s contents.<ul><li>Page Size</li><li>Checksum to check whether data is corrupted.</li><li>The DBMS version of the creator of this page is used to provide compatibility even when the DBMS update changes the page layout. With this, the data can be corrected and re-layout when the DBMS is updated.</li><li>Transaction Visibility</li><li>Compression Information</li></ul></li><li>The data in a page can be organized in tuple-oriented or log-structured.</li></ol><h3 id="how-to-organize-tuple-oriented-data"><a class="markdownIt-Anchor" href="#how-to-organize-tuple-oriented-data"></a> How to organize tuple-oriented data?</h3><ol><li>A naive strategy is to store the number of tuples in the header and append a new tuple to the end.<ul><li>What if we delete a tuple?<ul><li>How do we know there is available space?</li><li>What do we do to the following tuples? Do we move them forward, or leave them there?</li></ul></li><li>A more severe problem is what happens if we have a variable-length attribute.<ul><li>How can we know the beginning and end of a tuple?</li></ul></li></ul></li><li>We store a slot array at the header in the slotted pages scheme.<ul><li>The slot array maps “slots” to the tuples’ starting position offsets.</li><li>The header keeps track of the number of used slots and the offset of the starting location of the last slot used.</li><li>The space used to store tuples grows from tail to head, while the slot array grows from head to tail.</li><li>When a tuple is deleted, we must invalidate its value in a slot array where we can know available space.<ul><li>As for its following tuples, we can either leave them as-is or compact the space.</li><li>As modification goes in memory, and deleting usually holds a lock, compacting the space can be fast, and there is no need to inform the rest of the system.</li></ul></li><li><img src="/imgs/15445/Storage/slot-array.png" width="25%"></li></ul></li></ol><h3 id="how-do-we-find-the-tuple-we-need-on-a-page"><a class="markdownIt-Anchor" href="#how-do-we-find-the-tuple-we-need-on-a-page"></a> How do we find the tuple we need on a page?</h3><ol><li>Each tuple is assigned a unique record identifier.</li><li>The most commonly used is <code>page_id + offset/slot</code>.</li></ol><h2 id="tuple-layout"><a class="markdownIt-Anchor" href="#tuple-layout"></a> Tuple layout</h2><h3 id="what-is-stored-in-a-tuple"><a class="markdownIt-Anchor" href="#what-is-stored-in-a-tuple"></a> What is stored in a tuple?</h3><ol><li>A tuple is essentially a sequence of bytes. It’s the job of the DBMS to interpret those bytes into attribute types and values.</li><li>Each tuple is prefixed with a header containing meta-data, e.g., visibility info for concurrency control, Bit Map for NULL values.<ul><li>We do not need to store meta-data about the schema.</li></ul></li><li>Attributes are typically stored in the order you specify when creating the table.</li></ol><h3 id="what-is-denormalized-data"><a class="markdownIt-Anchor" href="#what-is-denormalized-data"></a> What is denormalized data?</h3><ol><li>DBMS can physically denormalize (pre-join) related tuples and store them together on the same page.<ul><li>For two tables, one table has an attribute referenced to another table, DBMS can store the tuples and their referenced tuples in the same slot.</li><li><img src="/imgs/15445/Storage/denorm_declare.png" width="25%"></li><li><img src="/imgs/15445/Storage/denorm_diagram.png" width="25%"></li></ul></li><li>This can potentially reduce the amount of I/O for common workload patterns and make updates more expensive.</li></ol><h1 id="log-structured-storage"><a class="markdownIt-Anchor" href="#log-structured-storage"></a> Log-structured storage</h1><h2 id="what-is-stored-in-log-structured-storage"><a class="markdownIt-Anchor" href="#what-is-stored-in-log-structured-storage"></a> What is stored in log-structured storage?</h2><ol><li>DBMS stores log records that contain changes to tuples (PUT, DELETE).<ul><li>Each log record must contain the tuple’s unique identifier. In this case, the identifier is not <code>page_id + offset/slot</code> mentioned above since the page doesn’t exist in this scheme.</li></ul></li><li>As the application changes the database, the DBMS appends log records to the end of the file without checking previous log records.</li><li>When the page gets full, the DBMS writes it out of the disk and fills the next page with records.<ul><li>All on-disk pages are immutable.</li><li>All disk writes are sequential.</li></ul></li></ol><h2 id="how-to-read-in-a-log-structured-storage"><a class="markdownIt-Anchor" href="#how-to-read-in-a-log-structured-storage"></a> How to read in a log-structured storage?</h2><ol><li>To read a tuple with a given ID, the DBMS finds the newest log record corresponding to that ID. It needs to scan the log from newest to oldest.<ul><li>DBMS can maintain an index that maps a tuple ID to the newest log record to optimize the linear scan.</li></ul></li><li>If the log record is in memory, just read it. If the log record is on a disk page, retrieve it.</li></ol><h2 id="how-to-solve-that-the-log-will-become-larger-and-larger"><a class="markdownIt-Anchor" href="#how-to-solve-that-the-log-will-become-larger-and-larger"></a> How to solve that the log will become larger and larger?</h2><ol><li>The DBMS can periodically compact pages to reduce wasted space.<ul><li>It can take two continuous pages and scan from newest to oldest, leaving one newest log for each tuple.</li></ul></li><li>The DBMS can sort the page based on ID order to improve future look-up efficiency.<ul><li>This sorted table is called a <strong>Sorted String Table</strong>, <strong>SSTable</strong>.</li><li>After a page is compacted, the DBMS does need to maintain the temporal ordering of records within the page since each tuple ID is guaranteed to appear at most once on the page.</li></ul></li><li>There are two strategies to choose which pages to compact:<ul><li>The Universal compaction chooses any two continuous pages.</li><li>The level compaction chooses two continuous pages on the same level and compacts them into the next level.</li></ul></li><li>The downside of compaction is write-amplification caused by duplicate writing to the newest record of a tuple, and compacting itself is expensive.</li></ol><h1 id="tuple-storage"><a class="markdownIt-Anchor" href="#tuple-storage"></a> Tuple storage</h1><h2 id="how-to-store-data-in-a-tuple"><a class="markdownIt-Anchor" href="#how-to-store-data-in-a-tuple"></a> How to store data in a tuple?</h2><ol><li>A tuple is essentially a sequence of bytes. It’s the job of the DBMS to interpret those bytes into attribute types and values.</li><li>The DBMS’s catalogs contain the schema information about tables that the system uses to figure out the tuple’s layout.<ul><li>A DBMS stores meta-data about databases in its internal catalogs.<ul><li>Tables, columns, indexes, views</li><li>Users, permissions</li><li>Internal statistics</li></ul></li></ul></li></ol><h2 id="what-are-supported-data-types"><a class="markdownIt-Anchor" href="#what-are-supported-data-types"></a> What are supported data types?</h2><ol><li>The basic types are supported: <code>INTEGER</code>/<code>BIGINT</code>/<code>SMALLINT</code>/<code>TINYINT</code>, <code>FLOAT</code>/<code>REAL</code>, <code>VARCHAR</code>/<code>VARBINARY</code>/<code>TEXT</code>/<code>BLOB</code>, <code>TIME</code>/<code>DATE</code>/<code>TIMESTAMP</code>.</li><li>Since IEEE 754 floating points may be inaccurate, fixed-point decimals are also supported as <code>NUMERIC</code>/<code>DECIMAL</code>. But their execution is way slower than floating points.</li><li>Most DBMSs don’t allow a tuple to exceed the size of a single page.<ul><li>The DBMS uses separate overflow storage pages to store values that are larger than a page.</li><li>Some systems allow you to store a large value in an external file. And treat the data as a BLOB type. Then, the DBMS cannot manipulate the contents of an external file.<ul><li>No durability protections. No transaction protections.</li><li>They are outside of DBMS. Hence, we cannot update it through DBMS either.</li></ul></li></ul></li></ol><h1 id="data-storage-models"><a class="markdownIt-Anchor" href="#data-storage-models"></a> Data storage models</h1><h2 id="what-kind-of-database-workloads-are-there"><a class="markdownIt-Anchor" href="#what-kind-of-database-workloads-are-there"></a> What kind of database workloads are there?</h2><ol><li>On-Line Transaction Processing (OLTP): In this situation, commands are fast operations that only read/update a small amount of data each time. The data accessed in a query is related to a single entity in the database.</li><li>On-Line Analytical Processing (OLAP): Here, commands are complex queries that read a lot of data to compute aggregates, i.e., they will execute complex writes and complex reads.</li><li>Hybrid Transaction + Analytical Processing: OLTP + OLAP together on the same database instance.</li></ol><h2 id="how-does-dbms-store-tuples"><a class="markdownIt-Anchor" href="#how-does-dbms-store-tuples"></a> How does DBMS store tuples?</h2><ol><li><strong>N-ary storage model</strong> (<strong>row storage</strong>): The DBMS contiguously stores all attributes for a single tuple on a page.<ul><li>This model is ideal for OLTP workloads where queries operate only on an individual entity and insert-heavy workloads.</li><li>The advantage is fast inserts, updates, and deletes. It is also suitable for queries that need the entire tuple.</li><li>However, it is not good for scanning large portions of the table and a subset of the attributes.</li></ul></li><li><strong>Decomposition storage model</strong> (<strong>DSM</strong>, <strong>Column storage</strong>): The DBMS stores the values of a single attribute for all tuples contiguously on a page.<ul><li>This model is ideal for OLAP workloads where read-only queries perform large scans over a subset of the table’s attributes.</li><li>DBMS can identify tuples in two choices:<ul><li>The first is using fixed-length offsets when each value is the same length for an attribute. It does not require each attribute to have the same length. This is the most used scheme.</li><li>The second is using embedded tuple IDs. Each value is stored in a column with its tuple ID.</li></ul></li><li>The advantage of DSM is that it reduces the amount wasted I/O because the DBMS only reads the data it needs and provides better query processing and data compression.</li><li>The disadvantage is that it is slow for point queries, inserts, updates, and deletes because of tuple splitting/stitching.</li></ul></li></ol><h2 id="database-compression"><a class="markdownIt-Anchor" href="#database-compression"></a> Database compression</h2><h3 id="why-do-we-need-database-compression-and-what-is-the-trade-off"><a class="markdownIt-Anchor" href="#why-do-we-need-database-compression-and-what-is-the-trade-off"></a> Why do we need database compression, and what is the trade-off?</h3><ol><li>I/O is the main bottleneck if the DBMS fetches data from the disk during query execution.</li><li>The DBMS can compress pages to increase the utility of the data moved per I/O operation.</li><li>The fundamental trade-off is between speed and compression ratio.<ul><li>Compressing and decompressing will take higher CPU costs to get a better compression ratio. But it can reduce DRAM requirements.</li><li>Some engines work with compressed data, which can reduce CPU costs.</li></ul></li></ol><h3 id="why-can-we-compress-data"><a class="markdownIt-Anchor" href="#why-can-we-compress-data"></a> Why can we compress data?</h3><ol><li>Data sets tend to have highly skewed distributions for attribute values.</li><li>Data sets tend to have a high correlation between attributes of the same tuple.</li></ol><h3 id="what-are-the-goals-of-compression"><a class="markdownIt-Anchor" href="#what-are-the-goals-of-compression"></a> What are the goals of compression?</h3><ol><li>It must produce fixed-length values. The only exception is var-length data stored in a separate pool.</li><li>Late materialization: Postpone decompression for as long as possible during query execution.</li><li>It must be a lossless scheme.<ul><li>When a DBMS uses compression, it is always lossless because people don’t like losing data.</li><li>Any lossy compression must be performed at the application level.</li></ul></li></ol><h3 id="what-are-the-compression-granularities"><a class="markdownIt-Anchor" href="#what-are-the-compression-granularities"></a> What are the compression granularities?</h3><ol><li>Block-level: Compression is performed on a block of tuples for the same table.</li><li>Tuple-level: Compression is performed on the contents of the entire tuple (NSM-only).</li><li>Attribute-level: Compression is performed on a single attribute within one tuple (overflow). It can target multiple attributes for the same tuple.</li><li>Column-level: Compression is performed on multiple values for one or more attributes stored for multiple tuples (DSM-only).</li></ol><h3 id="what-is-naive-compression"><a class="markdownIt-Anchor" href="#what-is-naive-compression"></a> What is naive compression?</h3><ol><li>Naive means that the data system does not understand the bits after compression.</li><li>We can compress data using a general-purpose algorithm. The scope of compression is only based on the data provided as input.</li><li>In disk, each page stores the compressed data and the modification log of this page.</li><li>When DBMS reads a page into the buffer pool<ul><li>It won’t decompress until queries need to return the whole tuple.</li><li>Every update will only append an entry in the mod log. Hence no need to decompress data when only updating tuples. The only thing we need to know in updating is which page this tuple is.</li><li>DBMS will decompress the page and apply changes when the mod log is full.</li></ul></li></ol><h3 id="how-can-we-do-better-with-the-high-level-meaning-or-semantics-of-the-data"><a class="markdownIt-Anchor" href="#how-can-we-do-better-with-the-high-level-meaning-or-semantics-of-the-data"></a> How can we do better with the high-level meaning or semantics of the data?</h3><ol><li>This is performed on the column level.</li><li>Run-length encoding:<ul><li>Compress runs of continuous same value in a single column into triplets <code>(value, offset, length) </code>.<ul><li><code>Value</code> is the value of the attribute.</li><li><code>Offset</code> is the start position in the column segment of the continuous save value run.</li><li><code>Length</code> is the number of elements in the run.</li></ul></li><li>It requires the columns to be sorted intelligently to maximize compression opportunities.</li></ul></li><li>Bit-packing encoding:<ul><li>When values for an attribute are always less than the value’s declared largest size, store them as a smaller data type.</li><li>Mostly, encoding uses a special marker to indicate when a value exceeds the largest size and maintains a look-up table to store them.</li></ul></li><li>Bitmap encoding:<ul><li>Store a separate bitmap for <strong>each unique value</strong> for an attribute where an offset in the vector corresponds to a tuple.</li><li>When reading, DBMS needs looks into the bits in the tuple to find which bit is <code>1</code> to know which value is stored in this attribute of this tuple.</li><li>We need to store the value for each bitmap. So, the total space required is the total length of possible values, and the number of bits is the same as the number of tuples for each value.</li></ul></li><li>Delta encoding:<ul><li>Recording the difference between this tuple and its last tuple.</li><li>Store base value in-line or in a separate look-up table.</li><li>Combine with RLE to get even better compression ratios.</li></ul></li><li>Incremental encoding:<ul><li>Delta encoding is for numbers, while incremental encoding is for strings.</li><li>It stores the length of common prefixes between this tuple and its last tuple and the extra suffixes of this tuple.</li><li>When there is no common prefix, the length is <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>0</mn></mrow><annotation encoding="application/x-tex">0</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">0</span></span></span></span>. It performed better when we sorted tuples according to the strings.</li></ul></li><li>Dictionary compression (most widely used):<ul><li>Build a data structure that maps variable-length values to a smaller integer identifier. And replace those values with their corresponding identifier in the dictionary data structure.</li><li>A dictionary is required to support fast encoding, decoding, and a range of queries.</li><li>The hash function can not be used due to key confliction, and decoding cannot be provided.</li><li>When the dictionary encodes values in a certain order (e.g., alphabetic order), the execution engine can be optimized to do some queries only access the dictionary, especially for those <code>DISTINCT</code> queries.</li></ul></li></ol>]]></content>
      
      
      <categories>
          
          <category> Open Courses </category>
          
          <category> CMU 15-445/645 Database System </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Database System </tag>
            
            <tag> Storage </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>01 Relational Model</title>
      <link href="/2023/06/24/Courses/15445/01-Relational-Model/"/>
      <url>/2023/06/24/Courses/15445/01-Relational-Model/</url>
      
        <content type="html"><![CDATA[<p><ul class="markdownIt-TOC"><li><a href="#database">Database</a><ul><li><a href="#why-shouldnt-we-store-the-database-in-a-flat-file-like-csv-which-we-manage-ourselves-in-our-application-code">Why shouldn’t we store the database in a flat file like CSV, which we manage ourselves in our application code?</a></li><li><a href="#what-do-dbms-and-data-models-do">What do DBMS and data models do?</a></li><li><a href="#what-kinds-of-data-models-are-there">What kinds of data models are there?</a></li><li><a href="#how-does-the-document-data-model-store-data">How does the document data model store data?</a></li></ul></li><li><a href="#relational-model">Relational model</a><ul><li><a href="#how-are-data-stored">How are data stored?</a></li><li><a href="#what-are-primary-keys-and-foreign-keys">What are primary keys and foreign keys?</a></li><li><a href="#what-is-supported-in-relational-algebra">What is supported in relational algebra?</a></li></ul></li><li><a href="#morden-sql">Morden SQL</a><ul><li><a href="#what-is-provided-in-a-relational-language">What is provided in a relational language?</a></li><li><a href="#aggregations-and-group-by">Aggregations and Group By</a><ul><li><a href="#what-are-aggregations">What are aggregations?</a></li><li><a href="#how-to-output-other-columns-with-aggregations">How to output other columns with aggregations?</a></li></ul></li><li><a href="#what-string-operations-are-supported">What string operations are supported?</a></li><li><a href="#output">Output</a><ul><li><a href="#where-can-we-redirect-outputs">Where can we redirect outputs?</a></li><li><a href="#how-can-we-control-the-outputs">How can we control the outputs?</a></li></ul></li><li><a href="#what-if-we-need-a-temporary-relation-in-a-query">What if we need a temporary relation in a query?</a></li><li><a href="#how-do-window-functions-work">How do window functions work?</a></li></ul></li></ul></p><h1 id="database"><a class="markdownIt-Anchor" href="#database"></a> Database</h1><h2 id="why-shouldnt-we-store-the-database-in-a-flat-file-like-csv-which-we-manage-ourselves-in-our-application-code"><a class="markdownIt-Anchor" href="#why-shouldnt-we-store-the-database-in-a-flat-file-like-csv-which-we-manage-ourselves-in-our-application-code"></a> Why shouldn’t we store the database in a flat file like CSV, which we manage ourselves in our application code?</h2><ol><li>The first concern is data integrity:<ul><li>How to ensure that the data makes sense to the design schema?</li><li>How to prevent invalid data and malicious attacks?</li><li>The management of deleting some entries causing deleting entries in other databases is a pain.</li></ul></li><li>Another problem is implementation:<ul><li>How to find a record?</li><li>How to share a database between applications?</li><li>How to handle concurrent writes?</li></ul></li><li>Also concerned about durability:<ul><li>What if the machine crashed?</li><li>How to replicate the database?</li></ul></li></ol><h2 id="what-do-dbms-and-data-models-do"><a class="markdownIt-Anchor" href="#what-do-dbms-and-data-models-do"></a> What do DBMS and data models do?</h2><ol><li>DBMS supports the definition, creation, querying, update, and administration of databases in accordance with some data model.<ul><li>The physical storage is left up to the DBMS implementation.</li><li>Programmers access data through high-level language, and DBMS figures out the best execution strategy.</li></ul></li><li>A data model is a collection of concepts describing the data in a database.<ul><li>A schema describes a particular collection of data using a given data model.</li></ul></li></ol><h2 id="what-kinds-of-data-models-are-there"><a class="markdownIt-Anchor" href="#what-kinds-of-data-models-are-there"></a> What kinds of data models are there?</h2><ol><li>The most used is the Relational model.</li><li>One class called NoSQL:<ul><li>Key/Value</li><li>Graph</li><li>Document / Object</li><li>Wide-Column / Column-family</li></ul></li><li>For machine learning, there are Array / Matrix / Vectors.</li><li>The obsolete or legacy ones are:<ul><li>Hierarchical</li><li>Network</li><li>Multi-Value</li></ul></li></ol><h2 id="how-does-the-document-data-model-store-data"><a class="markdownIt-Anchor" href="#how-does-the-document-data-model-store-data"></a> How does the document data model store data?</h2><ol><li>It embeds data hierarchy into a single object like JSON, XML, etc.</li><li>The problem is similar to the aforementioned store database in a flat file like CSV.</li></ol><h1 id="relational-model"><a class="markdownIt-Anchor" href="#relational-model"></a> Relational model</h1><h2 id="how-are-data-stored"><a class="markdownIt-Anchor" href="#how-are-data-stored"></a> How are data stored?</h2><ol><li>Data are stored in simple data structures called relations.</li><li>A relation is an <strong>unordered set</strong> that contains the relationship of attributes that represent entities.<ul><li>A n-ary relation is a table with n columns.</li></ul></li><li>A tuple is a set of attribute values (domain) in the relation.<ul><li>NULL is a member of every domain if allowed.</li></ul></li></ol><h2 id="what-are-primary-keys-and-foreign-keys"><a class="markdownIt-Anchor" href="#what-are-primary-keys-and-foreign-keys"></a> What are primary keys and foreign keys?</h2><ol><li>A relation’s primary key uniquely identifies a single tuple.<ul><li>In defining a relation, primary keys are usually marked with an underline.</li></ul></li><li>A foreign key specifies that an attribute from one relation must map to a tuple in another.<ul><li>Normally, foreign keys must be primary keys in another relation.</li></ul></li></ol><h2 id="what-is-supported-in-relational-algebra"><a class="markdownIt-Anchor" href="#what-is-supported-in-relational-algebra"></a> What is supported in relational algebra?</h2><ol><li>Select: <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>σ</mi><mrow><mi>p</mi><mi>r</mi><mi>e</mi><mi>d</mi><mi>i</mi><mi>c</mi><mi>a</mi><mi>t</mi><mi>e</mi></mrow></msub><mo stretchy="false">(</mo><mi>R</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\sigma_{predicate}(R)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.036108em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">σ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361079999999999em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">p</span><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span><span class="mord mathnormal mtight">e</span><span class="mord mathnormal mtight">d</span><span class="mord mathnormal mtight">i</span><span class="mord mathnormal mtight">c</span><span class="mord mathnormal mtight">a</span><span class="mord mathnormal mtight">t</span><span class="mord mathnormal mtight">e</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="mclose">)</span></span></span></span><ul><li>Choose a subset of the tuples from a relation that satisfies the selection predicate.<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> R</span><br><span class="line"> <span class="keyword">WHERE</span> predicate;</span><br></pre></td></tr></table></figure></li></ul></li><li>Projection: <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="normal">Π</mi><mrow><msub><mi>A</mi><mn>1</mn></msub><mo separator="true">,</mo><msub><mi>A</mi><mn>2</mn></msub><mo separator="true">,</mo><mo>…</mo><mo separator="true">,</mo><msub><mi>A</mi><mi>n</mi></msub></mrow></msub><mo stretchy="false">(</mo><mi>R</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\Pi_{A_1,A_2,\dots,A_n}(R)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.036108em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord">Π</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.328331em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight">A</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31731428571428577em;"><span style="top:-2.357em;margin-left:0em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em;"><span></span></span></span></span></span></span><span class="mpunct mtight">,</span><span class="mord mtight"><span class="mord mathnormal mtight">A</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31731428571428577em;"><span style="top:-2.357em;margin-left:0em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em;"><span></span></span></span></span></span></span><span class="mpunct mtight">,</span><span class="minner mtight">…</span><span class="mpunct mtight">,</span><span class="mord mtight"><span class="mord mathnormal mtight">A</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.16454285714285719em;"><span style="top:-2.357em;margin-left:0em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight">n</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em;"><span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="mclose">)</span></span></span></span><ul><li>Generate a relation with tuples that contain only the specified attributes.</li><li>It can be used to rearrange attributes’ ordering and manipulate the values.<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> A1, A2, ..., An <span class="keyword">FROM</span> R;</span><br></pre></td></tr></table></figure></li></ul></li><li>Union: <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>R</mi><mo>∪</mo><mi>S</mi></mrow><annotation encoding="application/x-tex">R\cup S</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">∪</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.05764em;">S</span></span></span></span><ul><li>Two relations must have identical attributes.</li><li>The result may be duplicated if some tuples appear in both relations.<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">(<span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> R) <span class="keyword">UNION</span> <span class="keyword">ALL</span> (<span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> S);</span><br></pre></td></tr></table></figure></li></ul></li><li>Intersection: <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>R</mi><mo>∩</mo><mi>S</mi></mrow><annotation encoding="application/x-tex">R\cap S</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">∩</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.05764em;">S</span></span></span></span><ul><li>Two relations must have the same attributes.<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">(<span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> R) <span class="keyword">INTERSECT</span> (<span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> S);</span><br></pre></td></tr></table></figure></li></ul></li><li>Difference: <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>R</mi><mo>−</mo><mi>S</mi></mrow><annotation encoding="application/x-tex">R-S</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.76666em;vertical-align:-0.08333em;"></span><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.05764em;">S</span></span></span></span><ul><li>Two relations must have identical attributes.<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">(<span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> R) <span class="keyword">EXCEPT</span> (<span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> S);</span><br></pre></td></tr></table></figure></li></ul></li><li>Product: <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>R</mi><mo>×</mo><mi>S</mi></mrow><annotation encoding="application/x-tex">R\times S</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.76666em;vertical-align:-0.08333em;"></span><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.05764em;">S</span></span></span></span><ul><li>Generate a relation that contains all possible combinations of tuples from the input relations, i.e., Cartesian product.<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> R <span class="keyword">CROSS</span> <span class="keyword">JOIN</span> S;</span><br><span class="line"># <span class="keyword">Or</span></span><br><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> R, S;</span><br></pre></td></tr></table></figure></li></ul></li><li>Join: <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>R</mi><mo>⋈</mo><mi>S</mi></mrow><annotation encoding="application/x-tex">R\bowtie S</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68833em;vertical-align:-0.005em;"></span><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">⋈</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.05764em;">S</span></span></span></span><ul><li>The difference between join and intersection is that join can match attributes’ names automatically, while intersection requires that two relations have the same attribute order.</li><li>It does product first, then compare attributes.<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> R <span class="keyword">NATURAL</span> <span class="keyword">JOIN</span> S;</span><br><span class="line"># <span class="keyword">Or</span></span><br><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> R <span class="keyword">JOIN</span> S <span class="keyword">USING</span> (A1, A2, ..., An);</span><br></pre></td></tr></table></figure></li><li>In the broad sense, join can have a predicate <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>R</mi><msub><mo>⋈</mo><mrow><mi>p</mi><mi>r</mi><mi>e</mi><mi>d</mi><mi>i</mi><mi>c</mi><mi>a</mi><mi>t</mi><mi>e</mi></mrow></msub><mi>S</mi></mrow><annotation encoding="application/x-tex">R\bowtie_{predicate}S</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.969438em;vertical-align:-0.286108em;"></span><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel"><span class="mrel">⋈</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361079999999999em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">p</span><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span><span class="mord mathnormal mtight">e</span><span class="mord mathnormal mtight">d</span><span class="mord mathnormal mtight">i</span><span class="mord mathnormal mtight">c</span><span class="mord mathnormal mtight">a</span><span class="mord mathnormal mtight">t</span><span class="mord mathnormal mtight">e</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.05764em;">S</span></span></span></span> which is the same as <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>σ</mi><mrow><mi>p</mi><mi>r</mi><mi>e</mi><mi>d</mi><mi>i</mi><mi>c</mi><mi>a</mi><mi>t</mi><mi>e</mi></mrow></msub><mo stretchy="false">(</mo><mi>R</mi><mo>×</mo><mi>S</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\sigma_{predicate}(R\times S)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.036108em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">σ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361079999999999em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">p</span><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span><span class="mord mathnormal mtight">e</span><span class="mord mathnormal mtight">d</span><span class="mord mathnormal mtight">i</span><span class="mord mathnormal mtight">c</span><span class="mord mathnormal mtight">a</span><span class="mord mathnormal mtight">t</span><span class="mord mathnormal mtight">e</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.05764em;">S</span><span class="mclose">)</span></span></span></span>.</li></ul></li><li>Different orders of steps can have the same result with varying amounts of computation.<ul><li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>R</mi><mo>⋈</mo><mo stretchy="false">(</mo><msub><mi>σ</mi><mrow><mi>p</mi><mi>r</mi><mi>e</mi><mi>d</mi><mi>i</mi><mi>c</mi><mi>a</mi><mi>t</mi><mi>e</mi></mrow></msub><mo stretchy="false">(</mo><mi>S</mi><mo stretchy="false">)</mo><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">R\bowtie(\sigma_{predicate}(S))</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68833em;vertical-align:-0.005em;"></span><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">⋈</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.036108em;vertical-align:-0.286108em;"></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">σ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361079999999999em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">p</span><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span><span class="mord mathnormal mtight">e</span><span class="mord mathnormal mtight">d</span><span class="mord mathnormal mtight">i</span><span class="mord mathnormal mtight">c</span><span class="mord mathnormal mtight">a</span><span class="mord mathnormal mtight">t</span><span class="mord mathnormal mtight">e</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.05764em;">S</span><span class="mclose">)</span><span class="mclose">)</span></span></span></span> is much more efficient than <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>σ</mi><mrow><mi>p</mi><mi>r</mi><mi>e</mi><mi>d</mi><mi>i</mi><mi>c</mi><mi>a</mi><mi>t</mi><mi>e</mi></mrow></msub><mo stretchy="false">(</mo><mi>R</mi><mo>⋈</mo><mi>S</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\sigma_{predicate}(R\bowtie S)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.036108em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">σ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361079999999999em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">p</span><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span><span class="mord mathnormal mtight">e</span><span class="mord mathnormal mtight">d</span><span class="mord mathnormal mtight">i</span><span class="mord mathnormal mtight">c</span><span class="mord mathnormal mtight">a</span><span class="mord mathnormal mtight">t</span><span class="mord mathnormal mtight">e</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">⋈</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.05764em;">S</span><span class="mclose">)</span></span></span></span>.</li></ul></li></ol><h1 id="morden-sql"><a class="markdownIt-Anchor" href="#morden-sql"></a> Morden SQL</h1><h2 id="what-is-provided-in-a-relational-language"><a class="markdownIt-Anchor" href="#what-is-provided-in-a-relational-language"></a> What is provided in a relational language?</h2><ol><li>Data Manipulation Language (DML)</li><li>Data Definition Language (DDL)</li><li>Data Control Language (DCL)</li><li>Also, view definition, integrity, and referential constraints, transactions.</li></ol><h2 id="aggregations-and-group-by"><a class="markdownIt-Anchor" href="#aggregations-and-group-by"></a> Aggregations and Group By</h2><h3 id="what-are-aggregations"><a class="markdownIt-Anchor" href="#what-are-aggregations"></a> What are aggregations?</h3><ol><li>They are functions that return a single value from a bag of tuples.</li><li><code>AVG(col)</code>, <code>MIN(col)</code>, <code>MAX(col)</code>, <code>SUM(col)</code>, <code>COUNT(col)</code><ul><li>For <code>COUNT</code>, the passed argument does not matter since it only returns the number of rows.</li></ul></li><li>Aggregate functions can almost only be used in the <code>SELECT</code> output list.</li><li><code>COUNT</code>, <code>SUM</code>, and <code>AVG</code> support <code>DISTINCT</code>.<ul><li>In this case, the columns passed to <code>COUNT</code> matters.</li></ul></li><li>The output of other columns outside of an aggregate is undefined.<ul><li>Aggregations create a new relation with a different number of tuples.</li><li>If we directly ask for other columns, the number of tuples won’t match the output of aggregations.</li><li>We don’t know the relation between the output of aggregations and values from other columns (some languages may allow this but with chaotic order).</li></ul></li><li>We also cannot filter output tuples based on aggregation column names.<ul><li>Since <code>SELECT</code> happens at last, when <code>WHERE</code> or <code>HAVING </code> is calculated, the aggregation columns haven’t been calculated yet.</li></ul></li></ol><h3 id="how-to-output-other-columns-with-aggregations"><a class="markdownIt-Anchor" href="#how-to-output-other-columns-with-aggregations"></a> How to output other columns with aggregations?</h3><ol><li><code>GROUP BY</code> projects tuples into subsets and calculates aggregates against each subset.</li><li>Non-aggregated values in the SELECT output clause must appear in the <code>GROUP BY</code> clause.</li><li>With group-by, each aggregation output has the same values in those grouped columns. So <code>SELECT</code> knows their relation.</li><li><code>HAVING</code> like a <code>WHERE</code> clause for a <code>GROUP BY</code>.<ul><li>It can filter results based on aggregation computation. But it also shouldn’t use the column names of aggregation in <code>SELECT</code>.</li><li>Instead, it should directly use the aggregation function. Although the execution engine knows these two are the same and doesn’t do the repeat calculation.</li></ul></li></ol><h2 id="what-string-operations-are-supported"><a class="markdownIt-Anchor" href="#what-string-operations-are-supported"></a> What string operations are supported?</h2><ol><li>Predicate of string matching can be done with <code>=</code><ul><li>Some DBMSs are case-sensitive, while others are not.</li><li>We can also use <code>LIKE</code> to match with string-match operators.<ul><li><code>%</code> matches any substring (including empty strings)</li><li><code>_</code> match any one character.</li></ul></li></ul></li><li>Other string functions are provided:<ul><li><code>UPPER</code> and <code>LOWER</code></li><li><code>SUBSTRING(str, start_index, end_index)</code></li></ul></li><li>Different languages have different ways to concatenate strings: <code>str1 || str2</code>, <code>str1 + str2</code> or <code>CONCAT(str1, str2)</code>.</li></ol><h2 id="output"><a class="markdownIt-Anchor" href="#output"></a> Output</h2><h3 id="where-can-we-redirect-outputs"><a class="markdownIt-Anchor" href="#where-can-we-redirect-outputs"></a> Where can we redirect outputs?</h3><ol><li>We can store query results in another table.<ul><li>That table must not already be defined.</li><li>It will have the same number of columns and types as the input.</li></ul></li><li>We can also insert tuples from a query into another table.<ul><li>The inner select must generate the same columns as the target table.</li><li>DMBSs have different options/syntax on what to do with integrity violations.</li></ul></li></ol><h3 id="how-can-we-control-the-outputs"><a class="markdownIt-Anchor" href="#how-can-we-control-the-outputs"></a> How can we control the outputs?</h3><ol><li>We can order the output tuples by the values in one or more of their columns with <code>ORDER BY &lt;column*&gt; [ASC|DESC]</code>.</li><li>We can also limit the number of tuples returned in output with <code>LIMIT &lt;count&gt; [OFFSET &lt;count2&gt;]</code>.<ul><li>Although this limits the number of outputs, its execution may still need to compute the whole relation, e.g., to output the top-10 largest numbers, it still needs to sort all numbers.</li></ul></li></ol><h2 id="what-if-we-need-a-temporary-relation-in-a-query"><a class="markdownIt-Anchor" href="#what-if-we-need-a-temporary-relation-in-a-query"></a> What if we need a temporary relation in a query?</h2><ol><li>The first solution is nested queries.<ul><li>Inner queries can appear almost anywhere in a query.</li><li>In the WHERE clause, we can perform a predicate between the tuples from the current relation and the result of the subqueries.<ul><li><code>ALL</code> must satisfy expressions for all rows in the subquery.</li><li><code>ANY</code> must satisfy the expression for at least one row in the subquery.</li><li><code>IN</code> is equivalent to <code>=ANY()</code>.</li><li><code>EXISTS</code> returns true if the relation is not empty.</li><li><code>NOT</code></li></ul></li></ul></li><li>Another choice is a common table expression using <code>WITH cteName AS (query)</code>.<ul><li>It also supports bind/alias output columns to names <code>WITH cteName (col1, ..., coln) AS (query)</code></li><li>In the next query, we can reference this temporary relation with <code>cteName</code>.</li><li>We can enable recursive calculation using <code>WITH RECURSIVE</code>.</li></ul></li></ol><h2 id="how-do-window-functions-work"><a class="markdownIt-Anchor" href="#how-do-window-functions-work"></a> How do window functions work?</h2><ol><li>Window functions perform a sliding calculation across a set of related tuples.</li><li>Like an aggregation, they only appear in the <code>SELECT</code> clause. However, tuples are not grouped into a single output tuples. Instead, the number of rows of the output is the same as the input.</li><li>In the SELECT clause, the syntax of the window functions is <code>FUNC-NAME(...) OVER(...)</code>.<ul><li>The <code>FUNC-NAME</code> can be aggregation functions or special functions (<code>ROW_NUMBER</code> and <code>RANK</code>)<ul><li><code>ROW_NUMBER</code> assigns the number of the current rows in a certain order.</li><li><code>RANK</code> assigns the order position of the current row.</li><li>When two rows tie, <code>RANK</code> will assign the same number to them and skip the next number, while ROW_NUMBER will assign a different number.</li></ul></li><li>The <code>OVER</code> parameter controls how to slice up data.<ul><li>It controls how to group tuples when computing the window function with <code>PARTITION BY</code>.</li><li>It also controls the computing order with <code>ORDER BY ... [ASC|DESC]</code>.</li></ul></li></ul></li></ol>]]></content>
      
      
      <categories>
          
          <category> Open Courses </category>
          
          <category> CMU 15-445/645 Database System </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Database System </tag>
            
            <tag> Relational Model </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Lab 4: ShardKV</title>
      <link href="/2023/03/27/OpenSource/6.824/Lab-4-ShardKV/"/>
      <url>/2023/03/27/OpenSource/6.824/Lab-4-ShardKV/</url>
      
        <content type="html"><![CDATA[<p><ul class="markdownIt-TOC"><li><a href="#how-to-shard-key-value-pairs">How to shard key-value pairs?</a></li><li><a href="#how-to-install-a-new-configuration">How to install a new configuration?</a></li><li><a href="#how-to-reduce-the-pauses-for-clients-when-installing-new-configurations">How to reduce the pauses for clients when installing new configurations?</a></li><li><a href="#how-does-garbage-collect-past-configurations">How does garbage collect past configurations?</a></li></ul></p><h1 id="how-to-shard-key-value-pairs"><a class="markdownIt-Anchor" href="#how-to-shard-key-value-pairs"></a> How to shard key-value pairs?</h1><ol><li>The total number of shards is fixed to be <code>NShards</code>. The keys are mapped into shards by a hash function mod by <code>NShards</code>.</li><li>Each KV group in the cluster needs to be responsible for some shards. An additional Raft group named Shard Controller is responsible for the cluster configurations.<ul><li>Each KV group would acquire the latest configuration from the Shard Controller.</li><li>When a new configuration is found, it will be proposed to the Raft group. It is installed until it has been committed.</li></ul></li><li>Administrators can modify the configuration of the Raft groups in the cluster by giving commands to the Shard Controllers. <code>Leave</code>, <code>Join</code>, and <code>Move</code> are provided.<ul><li>When a command comes from administrators, a Raft entry is proposed. A new configuration will only be created when that entry is committed.</li><li>When creating new configurations, <code>Leave</code> and <code>Join</code> will try to rebalance the distribution of shards as evenly as possible or move as few shards as possible.</li></ul></li></ol><h1 id="how-to-install-a-new-configuration"><a class="markdownIt-Anchor" href="#how-to-install-a-new-configuration"></a> How to install a new configuration?</h1><ol><li>For the shards in the last config, not in the new config, we cannot simply discard them. When we give up a shard, some other group must be responsible for it, and they do not have it now. Therefore, we need to transmit the data to them.<ul><li>One way is to push the data to the new owner of the shards. However, they may not be online now; they are partitioned from this node, or they may not have installed this new configuration, causing waste RPC flows.</li><li>Another way is to keep all data from past configurations and separate them from the current configuration data, waiting for other nodes to pull the shards they want.</li></ul></li><li>We must acquire the shards in the new configuration and not in the last configuration from somewhere.<ul><li>As aforementioned, when a new configuration is installed, this peer will issue an RPC to pull the missing shards from other groups.</li><li>To avoid that the target host of missing shards only executes part of commands of the last config causing missing values, a host is allowed to transmit shards only if it has installed the next configuration of the requested configuration.</li></ul></li><li>The executed index records also need to be separated between configurations to prevent lagged groups from rejecting to execute commands from clients.</li><li>When installing a new configuration from a snapshot, remember to initiate the goroutines to fetch the missing shards from the snapshot.</li></ol><h1 id="how-to-reduce-the-pauses-for-clients-when-installing-new-configurations"><a class="markdownIt-Anchor" href="#how-to-reduce-the-pauses-for-clients-when-installing-new-configurations"></a> How to reduce the pauses for clients when installing new configurations?</h1><ol><li>In the naive schema, we must wait until all shards are received before executing any client commands. However, receiving all shards could take a long time.</li><li>Executing the commands that only need the received shards is reasonable, even if some shards remain missing.</li><li>We can add a data structure to record the state of each shard in a configuration. If the state is received, we can execute the commands on that shard.</li><li>To execute the commands in commit order, we will still be stalled by the commands requesting missing shards.</li><li>Nevertheless, this schema can push the process forward as much as possible and parallel executing commands of received shards and waiting for missing shards.</li></ol><h1 id="how-does-garbage-collect-past-configurations"><a class="markdownIt-Anchor" href="#how-does-garbage-collect-past-configurations"></a> How does garbage collect past configurations?</h1><ol><li>In the naive schema, the redundant data would grow larger and larger since we cannot delete data from past configurations.</li><li>We can notice that a shard in the past configuration can be deleted when it is received by the group that needs to request it.<ul><li>A peer can ask the corresponding peers whether they have received the shards. Similar to why we do not push shards, it will waste a lot of RPC flows.</li><li>When a peer receives a shard, whether requesting from another group or installing a snapshot, it will inform the groups that host shards from the previous configuration.</li><li>The shard can be deleted from the host of the last configuration when all peers who host a shard in the next configuration have received it.</li></ul></li><li>A garbage collection goroutine is initiated when the next configuration is installed.</li><li>A snapshot must persist before informing other groups of receiving shards to prevent recovery from a snapshot without shards while the host has already deleted due to received acknowledgment.</li><li>When a shard can be deleted, snapshot installation becomes more tricky.<ul><li>We should not copy the deleted shards and deleted configurations from the snapshot. We can also delete the shads that are deleted in the snapshot.</li><li>When a new configuration is created from a snapshot, a garbage collection of the former configuration needs to be started.</li></ul></li></ol>]]></content>
      
      
      <categories>
          
          <category> Open Source Code </category>
          
          <category> 6.824 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Distributed System </tag>
            
            <tag> Distributed Storage </tag>
            
            <tag> Consensus Algorithm </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Lab 3: Fault-tolerant Key/Value Service</title>
      <link href="/2023/03/27/OpenSource/6.824/Lab-3-Fault-tolerant-Key-Value-Service/"/>
      <url>/2023/03/27/OpenSource/6.824/Lab-3-Fault-tolerant-Key-Value-Service/</url>
      
        <content type="html"><![CDATA[<p><ul class="markdownIt-TOC"><li><a href="#how-does-the-keyvalue-server-execute-a-command-from-the-clerk">How does the Key/Value server execute a command from the clerk?</a><ul><li><a href="#how-can-we-take-advantage-of-follower-nodes">How can we take advantage of follower nodes?</a></li></ul></li><li><a href="#how-can-we-prevent-re-execution-of-an-executed-command">How can we prevent re-execution of an executed command?</a></li><li><a href="#how-many-kinds-of-errors-could-occur-when-a-client-issues-a-command">How many kinds of errors could occur when a client issues a command?</a></li><li><a href="#what-should-be-stored-in-a-snapshot">What should be stored in a snapshot?</a></li><li><a href="#what-needs-to-be-done-to-recover-the-state-after-a-crash">What needs to be done to recover the state after a crash?</a></li><li><a href="#execution-speed-of-get-operation">Execution speed of Get operation:</a></li><li><a href="#execution-speed-of-putappend-operation">Execution speed of PutAppend operation:</a></li></ul></p><h1 id="how-does-the-keyvalue-server-execute-a-command-from-the-clerk"><a class="markdownIt-Anchor" href="#how-does-the-keyvalue-server-execute-a-command-from-the-clerk"></a> How does the Key/Value server execute a command from the clerk?</h1><ol><li>It will call the <code>Start()</code> function of its associated Raft server. It can safely execute the command until the Raft server commits that command.</li><li>Only the KV server associated with the leader Raft server can successfully use Start() to append commands to logs.</li><li>However, there could be a situation in which the network is partitioned, and the clerk connects to a partition leader whose log entry can never be successfully committed. So, we need to set a timeout for each command. The clerk should be informed to find another server if it cannot be committed in time.</li></ol><h2 id="how-can-we-take-advantage-of-follower-nodes"><a class="markdownIt-Anchor" href="#how-can-we-take-advantage-of-follower-nodes"></a> How can we take advantage of follower nodes?</h2><ol><li><p>To achieve linearizability, there is no chance for the follower to improve the performance of the Put/Append operation. However, we can allow them to handle read-only requests to enhance the cluster’s throughput.</p></li><li><p>The key idea is to make the follower know it is up-to-date to handle the read. To confirm that, we must consult the leader of the current commit index.</p></li><li><p>A case is a partitioned follower and leader when another true leader connects to the majority.</p><ul><li>The solution is that the leader must check whether it is a legitimate leader before authorizing the followers to execute the read.</li></ul></li><li><p>The whole process is as follows:</p><ul><li>When a follower received a read from the client, it would consult the leader for a <code>readIndex</code>.</li><li>The leader then needs to send heartbeats to all peers in the group to ensure it is still the leader.</li><li>When the leader receives from the majority, the current commit index can be returned to the follower as <code>readIndex</code>.</li><li>The follower can execute the read request if it has at least applied up to <code>readIndex</code>.</li></ul></li><li><p>In the Raft protocol, a leader can only commit the entries appended in its term. Similarly, a leader can only grant <code>ReadIndex</code>, pointing to an entry in its term. Or the result of the reading may become unlinearizable.</p><ul><li><p>Consider that a leader committed an index of <em>x</em> and granted a ReadIndex of <em>x</em> to its associated KV server. So, the KV server returned the result up to index <em>x</em>.</p></li><li><p>But it crashed before sending a commit message to other followers. Then, a new leader is elected who receives a request for ReadIndex. It does not know anything about committing entry <em>x</em>, thus granting a ReadIndex lower than <em>x</em>.</p></li><li><p>Hence, the read will return a result unseeing the execution result of the entry of index x, which violates the linearizability scheme.</p></li><li><p>So, the solution is to append an empty entry to the log if the leader hasn’t appended any entry in its term.</p></li></ul></li></ol><h1 id="how-can-we-prevent-re-execution-of-an-executed-command"><a class="markdownIt-Anchor" href="#how-can-we-prevent-re-execution-of-an-executed-command"></a> How can we prevent re-execution of an executed command?</h1><ol><li>Each clerk needs to maintain a monotonically increasing index to mark the command it issued.</li><li>Each Key/Value server needs to track the highest index executed for each clerk.</li><li>When a Key/Value server receives a new command, it compares the new command’s index with that clerk’s highest executed index. If the command’s index is lower, it can know that this is an executed command and return the result directly.</li></ol><h1 id="how-many-kinds-of-errors-could-occur-when-a-client-issues-a-command"><a class="markdownIt-Anchor" href="#how-many-kinds-of-errors-could-occur-when-a-client-issues-a-command"></a> How many kinds of errors could occur when a client issues a command?</h1><ol><li>For read-only operations, there could be a key error.</li><li>Except for the read-only operation with follower read, the client may connect to a follower who cannot append a command.</li><li>The client may connect to a server in a minority partition of servers.<ul><li>The PutAppend command is appended to the log but cannot commit.</li><li>For the read-only operation with follower read, it connects to its leader, but its leader cannot receive a majority response. Hence, it cannot acquire a ReadIndex.</li></ul></li><li>For read-only operations with follower read,<ul><li>The KV Server is associated with a leader, and its leader sets a higher commit index when communicating with the majority. But the Raft leader crashed before committing that entry, leaving the KV server waiting to apply as up-to-date as the ReadIndex.</li><li>The client may connect to a partition without a leader and, hence, cannot acquire ReadIndex.</li></ul></li></ol><h1 id="what-should-be-stored-in-a-snapshot"><a class="markdownIt-Anchor" href="#what-should-be-stored-in-a-snapshot"></a> What should be stored in a snapshot?</h1><ol><li>Of course, we need to store the state of all key-value pairs.</li><li>We must also store the last index executed for each client so far to recognize duplicated commands even after a crash.</li><li>The index of the last applied entry is also stored to prevent the first command after recovery is a read-only operation.</li></ol><h1 id="what-needs-to-be-done-to-recover-the-state-after-a-crash"><a class="markdownIt-Anchor" href="#what-needs-to-be-done-to-recover-the-state-after-a-crash"></a> What needs to be done to recover the state after a crash?</h1><ol><li>First, we need to install the latest snapshot persisted.</li><li>But that is not enough if only the KV server crashes while the associated Raft server is still running since there might still be some committed entries not included in the snapshot yet applied before the crash. The KV server needs to acquire those committed entries to truly bring itself back to the state right before the crash.</li></ol><h1 id="execution-speed-of-get-operation"><a class="markdownIt-Anchor" href="#execution-speed-of-get-operation"></a> Execution speed of Get operation:</h1><ol><li>When running the test without enabling snapshot:<ul><li>The time spent for each operation of the un-optimized implementation will become slower as the number of operations grows. This is because each Raft server’s log becomes larger and slower to persist.</li><li>When executing the Get operation, the log of optimized implementation won’t increase. Hence, it won’t slow down the execution.</li><li>When executing <em>3000</em> Get operations, the un-optimized implementation needs about <em>50 ms/op</em>, while the optimized implementation only needs <em>1.7 ms/op</em>, about 29 times the speedup.</li></ul></li><li>When running the test enabling snapshot:<ul><li>The time spent on the un-optimized implementation has become stable since the log size has become stable. However, when only executing the Get operation, the optimized implementation does not need the benefit of trimming logs.</li><li>When executing <em>3000</em> Get operations, the un-optimized implementation needs about <em>14.7 ms/op</em>, while the optimized implementation is still <em>1.7 ms/op</em>, about <em>8.6</em> times speedup.</li><li>I think that the speedup of the optimized read-only scheme comes from two parts: follower concurrency that increased the total bandwidth between clients and servers and the persisting time saved by eliminating Get operation entries from logs.</li></ul></li></ol><h1 id="execution-speed-of-putappend-operation"><a class="markdownIt-Anchor" href="#execution-speed-of-putappend-operation"></a> Execution speed of PutAppend operation:</h1><ol><li>When executing <em>1000</em> Put operations without enabling snapshots, both implementations need about <em>29.5 ms/op</em>. Executing Append operations needs about the same amount of time.</li><li>When executing <em>1000</em> Put operations enabling snapshot, both implementations need about <em>13.9 ms/op</em>. Executing Append operations needs about the same amount of time.</li><li>Thus, with snapshot enabled, it can achieve about <em>2.1</em> times speedup. I think the speedup mainly comes from the persisting time saved by shrinking the log.</li></ol>]]></content>
      
      
      <categories>
          
          <category> Open Source Code </category>
          
          <category> 6.824 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Distributed System </tag>
            
            <tag> Distributed Storage </tag>
            
            <tag> Consensus Algorithm </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Lab 2: Raft</title>
      <link href="/2023/03/26/OpenSource/6.824/Lab-2-Raft/"/>
      <url>/2023/03/26/OpenSource/6.824/Lab-2-Raft/</url>
      
        <content type="html"><![CDATA[<p><ul class="markdownIt-TOC"><li><a href="#leader-election">Leader election</a><ul><li><a href="#how-to-count-the-votes-a-candidate-gets">How to count the votes a candidate gets?</a></li><li><a href="#how-does-each-server-initial-an-election">How does each server initial an election?</a></li><li><a href="#how-can-we-prevent-partitioned-followers-from-ending-up-in-a-high-term">How can we prevent partitioned followers from ending up in a high term?</a></li></ul></li><li><a href="#log-replication">Log Replication</a><ul><li><a href="#how-does-the-leader-send-log-entries-to-followers">How does the leader send log entries to followers?</a></li><li><a href="#how-to-optimize-the-consistency-check-protocol">How to optimize the consistency check protocol?</a></li><li><a href="#how-should-a-follower-accept-log-entries-after-passing-all-consistency-checks">How should a follower accept log entries after passing all consistency checks?</a></li><li><a href="#how-will-each-server-commit-an-index">How will each server commit an index?</a></li><li><a href="#how-does-the-leader-check-which-entries-can-be-committed">How does the leader check which entries can be committed?</a></li><li><a href="#what-is-the-constraint-of-committing-uncommitted-entries-of-earlier-terms">What is the constraint of committing uncommitted entries of earlier terms?</a></li></ul></li><li><a href="#persistence">Persistence</a><ul><li><a href="#when-a-server-restarts-what-information-should-it-restore">When a server restarts, what information should it restore?**</a></li><li><a href="#when-will-invoke-persist">When will invoke persist()?</a></li></ul></li><li><a href="#log-compaction">Log compaction</a><ul><li><a href="#how-to-deal-with-those-deleted-entries-when-a-server-restarts">How to deal with those deleted entries when a server restarts?</a></li><li><a href="#how-to-take-a-snapshot">How to take a snapshot?</a></li><li><a href="#how-to-install-a-snapshot">How to install a snapshot?</a></li></ul></li></ul></p><h1 id="leader-election"><a class="markdownIt-Anchor" href="#leader-election"></a> Leader election</h1><h2 id="how-to-count-the-votes-a-candidate-gets"><a class="markdownIt-Anchor" href="#how-to-count-the-votes-a-candidate-gets"></a> How to count the votes a candidate gets?</h2><ol><li>The candidate begins a new goroutine to request votes from each server.</li><li>Use a shared variable to track how many votes the candidate has gotten. After this vote, each goroutine monitors that the candidate has gotten enough votes to become a leader independently.</li><li>When each goroutine receives a reply from other peers, it needs to check whether the reply is still in the same term as the term where it is now and whether it is still a candidate.<ul><li>Only checking its state is insufficient. The check of the term is in case delayed replies arrive in the future election initialed by this server.</li></ul></li><li>My initial thought<ul><li>The election goroutine will monitor the process of votes instead of the request goroutines.</li><li>Then the check loop in the election goroutine needs to sleep after each time it fails. Or the election would be hard to converge.</li><li>I GUESS that the reason is the for-loop never ends and takes too many resources, causing the CPU to not schedule the RequestVote goroutine and later election goroutines in time.</li></ul></li></ol><h2 id="how-does-each-server-initial-an-election"><a class="markdownIt-Anchor" href="#how-does-each-server-initial-an-election"></a> How does each server initial an election?</h2><ol><li>A timestamp records the last time heard from a leader or candidate. And <code>electionTimeout</code> is set randomly at the startup and beginning of the election.<ul><li>Each time the server wants to change its state into a follower, it must reset the timestamp before switching, or it may trigger a new election due to the stale timestamp.</li><li>When the replied term is larger than the term of sending <code>AppendEntries</code>, the leader should know that itself is out-of-date. But before any further settings, it should check whether the replied term is larger than the term where it is now to prevent this being a stale reply processed with a stale term, causing currectTerm to decrease.</li></ul></li><li><code>ticker()</code> will check periodically whether the time since the timestamp is larger than the <code>electionTimeout</code> and if so, a new election is initiated.<ul><li>When the checking is failed, this goroutine should sleep for a short time. However, it cannot simply sleep as long as <code>electionTimeout</code> because the next sleep may be shorter than <code>electionTimeout</code>.</li></ul></li><li>Another way is to set the <code>electionTimeout </code> when checking the condition instead of fixing the electionTimeout`` between two elections.<ul><li>But this will cause multiple peers to initiate an election in a short gap. In addition to the unreliable network and the burden of scheduling goroutines, the <code>RequestVote()</code> may not be executed by others immediately, causing severe brain split and re-elections.</li><li>The reason, I GUESS, is that it only needs one short sleep time to kick off the election. And with a new random sleep time every <code>CHECKTIMEOUT</code> ms, there is a greater probability that one sleep time is short, which shortens the <code>electionTimeout</code> I want.</li></ul></li></ol><h2 id="how-can-we-prevent-partitioned-followers-from-ending-up-in-a-high-term"><a class="markdownIt-Anchor" href="#how-can-we-prevent-partitioned-followers-from-ending-up-in-a-high-term"></a> How can we prevent partitioned followers from ending up in a high term?</h2><ol><li>The problem is that when a follower is partitioned, it cannot receive from the leader. It will try to be elected to be the leader. Yet, because it cannot connect to the majority of its peers, it can never succeed, causing it to keep increasing its term.</li><li>To solve the problem, we need to make a peer realize that it has no chance to be elected to be the leader and gives up increasing their term.<ul><li>Before truly increasing its term, we can ask it to simulate the election, i.e., pre-vote.</li><li>During the pre-vote, the candidate will send the same data as the true election, and other peers will reply whether they will vote for a candidate.</li><li>An actual election is initiated until a peer has received a pre-vote from the majority.</li></ul></li><li>The difference between a pre-vote and an actual election:<ul><li>The pre-vote can grant votes to different peers in the same term.</li><li>The pre-vote will not cause voters to increase the term and become followers.</li><li>The pre-vote happens before increasing the term.</li></ul></li><li>The disadvantage of the pre-vote is that it requires an extra round of RPC for an election.<ul><li>This cost is significantly unacceptable when the network is too unreliable, causing many elections.</li><li>When the network is more stable, the elections are rare, and it can prevent partitioned followers from interrupting the current term.</li></ul></li></ol><h1 id="log-replication"><a class="markdownIt-Anchor" href="#log-replication"></a> Log Replication</h1><h2 id="how-does-the-leader-send-log-entries-to-followers"><a class="markdownIt-Anchor" href="#how-does-the-leader-send-log-entries-to-followers"></a> How does the leader send log entries to followers?</h2><ol><li><code>nextIndex</code> is the lowest index of entries missed by each peer known by the leader.</li><li>There are two situations for sending log entries: the first is when there are some un-replicated entries for some followers, and the second is the heartbeat message.<ul><li><code>SyncLogWithFollower(x int)</code> is implemented to check whether server x has some missing entries.</li><li><code>Heartbeat()</code> is implemented to send a heartbeat message.</li><li><code>SendEntriesOnceTo(x int)</code> is implemented actually to send log entries to server x.</li><li>The <code>SyncLogWIthFollower()</code> goroutine for each server and the <code>Heartbeat()</code> goroutine is initiated when the server is elected leader.</li></ul></li><li>The difference between <code>SyncLogWithFollower()</code> and <code>Heartbeat()</code><ul><li><code>SyncLogWithFollower()</code> sends entries only when there are missing entries in server x. But <code>Heartbeat()</code> always sends entries even when there are no missing entries, in which case an empty log is sent.</li><li>The check cycle in <code>SyncLogWithFollower()</code> is way shorter than the sending cycle in <code>Heartbeat()</code> to ensure the missing entries can be replicated as soon as possible.</li></ul></li><li>When <code>SyncLogWithFollower()</code> calls <code>SendEntriesOnceTo()</code>, it cannot create a goroutine.<ul><li>Because the check cycle in <code>SyncLogWithFollower()</code> is quite short, if the <code>SyncLogWithFollower()</code> goroutine keeps being scheduled, the <code>SendEntriesOnceTo()</code> cannot send entries to the follower. Thus, the <code>SyncLogWithFollower()</code> goroutine keeps creating too many <code>SendEntriesOnceTo()</code> goroutine.</li></ul></li><li>My initial thought<ul><li>Start a <code>SendEntriesOnceTo()</code> goroutine for every follower after <code>Start()</code> has added a new log entry to the leader’s logs instead of using <code>SyncLogWithFollower()</code> goroutine.</li><li>But concurrent Start() may cause multiple <code>SendEntriesOnceTo()</code> goroutines to send the same RPC to the same follower.</li></ul></li></ol><h2 id="how-to-optimize-the-consistency-check-protocol"><a class="markdownIt-Anchor" href="#how-to-optimize-the-consistency-check-protocol"></a> How to optimize the consistency check protocol?</h2><ol><li>Additional AppenEntries RPC results for fast rollback:<ul><li><code>Xterm</code>: the term of the conflicting entry.</li><li><code>Xindex</code>: the first index in <code>Xterm</code>.</li><li><code>Xlen</code>: the length of the log</li></ul></li><li>Fast rollback implementation:<ul><li>If the leader doesn’t have <code>Xterm</code>, then every entry of Xterm in the follower’s log will cause conflict. Hence, the <code>nextIndex</code> can back up to <code>Xindex</code>.</li><li>If the leader has <code>Xterm</code>, the matching entry in the leader’s log must have a term no larger than <code>Xterm</code>. Hence, the <code>nextIndex</code> should go back to the next entry of the last Xterm in the leader’s log.</li><li>If the follower’s conflict is due to empty in <code>prevLogTerm</code>, then <code>Xterm</code> is set to <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>−</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">-1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.72777em;vertical-align:-0.08333em;"></span><span class="mord">−</span><span class="mord">1</span></span></span></span>, and the leader should back up to <code>Xlen</code>.</li></ul></li></ol><h2 id="how-should-a-follower-accept-log-entries-after-passing-all-consistency-checks"><a class="markdownIt-Anchor" href="#how-should-a-follower-accept-log-entries-after-passing-all-consistency-checks"></a> How should a follower accept log entries after passing all consistency checks?</h2><ol><li>The <code>nextIndex</code> and <code>logs</code> of the leader can be updated by different goroutines of <code>SendEntriesOnce()</code> and <code>Start()</code>. So it is possible that <code>args.Entries</code> are chosen through a stale <code>nextIndex</code> and an up-to-date <code>log</code> or even a stale <code>nextIndex</code> and a stale <code>log</code>.</li><li>If the <code>nextIndex</code> is stale while the <code>log</code> is up-to-date, i.e., there are some entries after the nextIndex is already replicated by the follower.<ul><li>Then we need to drop those replicated entries, but not all, since there could still be some new entries.</li><li>We need to drop those entries with the same index and the same term according to the Log Matching property and append only those different entries.</li><li>I didn’t consider the case of <code>nextIndex</code> being larger than the follower’s replicated indices. Transmission won’t succeed, and a fast backup will be triggered.</li></ul></li><li>If both the <code>nextIndex</code> and <code>logs</code> are stale, it is similar to the former situation since the only additional problem is that it cannot be brought up-to-date by one <code>AppendEntries</code>.</li></ol><h2 id="how-will-each-server-commit-an-index"><a class="markdownIt-Anchor" href="#how-will-each-server-commit-an-index"></a> How will each server commit an index?</h2><ol><li><code>commitIndex</code> is the highest index of entries that can commit now. This is included in the <code>AppendEntries</code> arguments from leader to followers.</li><li><code>lastApplied</code> is the highest index of committed entries. If <code>lastApplied</code> is no larger than <code>commitIndex</code>, a server can commit the entry next to <code>lastApplied</code>.</li><li>Followers cannot modify <code>commitIndex</code> before the logs are synchronized since there may be some entries that need to be wiped out by the leader.</li></ol><h2 id="how-does-the-leader-check-which-entries-can-be-committed"><a class="markdownIt-Anchor" href="#how-does-the-leader-check-which-entries-can-be-committed"></a> How does the leader check which entries can be committed?</h2><ol><li>My solution<ul><li><code>matchIndex</code> tracks the highest indices of entries replicated by each peer.</li><li>When a group of entries that ends with index <code>i</code> is accepted by one peer, the leader first sets the corresponding <code>matchIndex</code> to <code>i</code>.</li><li>Then, check whether a majority of <code>matchIndex</code> is larger than <code>i</code>. If so, the leader can commit at least until <code>i</code>, or it won’t commit any entry.</li></ul></li><li>Improvement<ul><li>When a lagged peer replicated a lot of entries, it may be insufficient to commit the last entry it replicated. It could be sufficient to commit some earlier entries.</li><li>We only need to commit the k-th largest index in <code>matchIndex</code>.</li></ul></li><li>My initial thought<ul><li>Track the replication state of each entry instead of each peer.</li><li>However, the entries are a lot more than peers, causing higher time complexity to maintain when a lot of entries are by peers.</li></ul></li></ol><h2 id="what-is-the-constraint-of-committing-uncommitted-entries-of-earlier-terms"><a class="markdownIt-Anchor" href="#what-is-the-constraint-of-committing-uncommitted-entries-of-earlier-terms"></a> What is the constraint of committing uncommitted entries of earlier terms?</h2><ol><li>A constraint on commit entries is that each leader can only commit entries added to the term. And by committing such entries, they also commit all entries before it. Hence, the entries of earlier terms are committed indirectly.</li><li>But there is a corner case where a leader doesn’t receive any entry at the beginning of its term, causing those uncommitted entries of earlier terms not to be committed.</li><li>My solution is that when a server becomes the leader, it will add an empty entry, and by this empty entry, those uncommitted entries can be committed.</li><li>However, the test system of 6.824 didn’t consider this case. This implementation will cause all tests to fail.</li></ol><h1 id="persistence"><a class="markdownIt-Anchor" href="#persistence"></a> Persistence</h1><h2 id="when-a-server-restarts-what-information-should-it-restore"><a class="markdownIt-Anchor" href="#when-a-server-restarts-what-information-should-it-restore"></a> When a server restarts, what information should it restore?**</h2><ol><li>Naturally, it must restore its <code>currentTerm</code>, <code>votedFor</code>, and <code>logs</code> from the persisted state.</li><li>Then, it needs to set its <code>lastLogIndex</code> and <code>lastLogTerm</code> appropriately.</li><li>The <code>lastApplied</code>, <code>commitIndex</code>, and <code>lastIncludedIndex</code> will be set to the index of the sentinel entry.<ul><li>Because the current state is the same state executed until the sentinel entry.</li><li>In the future, if the server finds that other peers have committed later entries, it needs to re-execute those entries to achieve the same state.</li></ul></li><li>It should update its <code>lastApplied</code> to the last committed entry according to the commit state in each log entry.</li></ol><h2 id="when-will-invoke-persist"><a class="markdownIt-Anchor" href="#when-will-invoke-persist"></a> When will invoke persist()?</h2><ol><li><code>persist()</code> is called only when <code>rf.currentTerm</code>, <code>rf.votedFor</code>, or <code>rf.logs</code> is changed.</li><li>When they’re changed, the <code>rf.mu</code> lock must be held by the caller of <code>persist()</code>. I won’t release the lock until the <code>persist()</code> is finished to store the states as soon as possible.</li><li>Modifying the three variables several times before communicating with outside or releasing the lock is possible. In that case, we use a variable to mark whether persist is needed instead of really calling <code>persist()</code> each time. And only call the <code>persist()</code> at the end.</li></ol><h1 id="log-compaction"><a class="markdownIt-Anchor" href="#log-compaction"></a> Log compaction</h1><h2 id="how-to-deal-with-those-deleted-entries-when-a-server-restarts"><a class="markdownIt-Anchor" href="#how-to-deal-with-those-deleted-entries-when-a-server-restarts"></a> How to deal with those deleted entries when a server restarts?</h2><ol><li>When a server restores its state from <code>readPersist()</code>, we want it to re-execute those persisted logs.</li><li>But we don’t need to re-execute those deleted entries since we can get to the state of the last deleted log by restoring the snapshot without execution.</li><li>The effect is the same as we have committed those missing entries. So, we also need to modify the <code>lastApplied</code> and <code>commitIndex</code> to the last deleted log index before re-executing.</li></ol><h2 id="how-to-take-a-snapshot"><a class="markdownIt-Anchor" href="#how-to-take-a-snapshot"></a> How to take a snapshot?</h2><ol><li>In this lab, the snapshot is naive. It simply stores all the log entries.</li><li>Hence, the server must set <code>lastIncludedIndex</code> and <code>lastIncludedTerm</code> appropriately, and all the snapshotted entries must be removed.</li><li>Also, if the log is empty after removal, we need to insert the sentinel entry back into the entry. Its command is still unimportant.</li></ol><h2 id="how-to-install-a-snapshot"><a class="markdownIt-Anchor" href="#how-to-install-a-snapshot"></a> How to install a snapshot?</h2><ol><li>The snapshot data only contains commands in log entries, so we need to recover the log entries with the snapshot.<ul><li>Their indices and commands are easy to understand.</li><li>We only know the <code>lastIncludedterm</code>. Also, the leader has already committed to these entries. Thus, no matter what happens, these entries will not be overwritten, and no <code>AppendEntry</code> will need to compare with these entries except for the last one. Hence, for convenience, I set all their terms to the <code>LastIncludedTerm</code>.</li><li>As aforementioned, these entries are already reflected in the snapshot. Thus, there is no need to re-commit them again.</li></ul></li><li>Then, we need to determine whether the snapshot contains new information.<ul><li><code>FirstUncover</code> indicates the first entry in <code>logs</code> that is more up-to-date than the last entry in the snapshot.<ul><li>If the snapshot contains new information not already in the recipient’s log, then <code>firstUncover == len(rf.logs)</code>.</li><li>If the snapshot describes a prefix of its log, then <code>firstUncover &lt; len(rf.logs)</code>, we only need to delete the former entries.</li></ul></li><li>I thought that maybe I needed to compare the <code>lastLogIndex</code> in the server and the <code>LastIncludedIndex</code> in the snapshot, but this is insufficient.<ul><li>Some servers need to discard the last few entries from earlier leaders, yet they are not in the current leader’s logs.</li><li>We need to remove the entries whose term is smaller than the <code>LastIncludedTerm</code> of the snapshot and whose index is larger than the <code>LastIncludedIndex</code>.</li></ul></li></ul></li><li>If the snapshot contains new information<ul><li>We will discard all log entries and insert a new sentinel entry with an index equal to <code>LastIncludedIndex</code> and a term equal to <code>LastIncludedTerm</code>.</li><li>Then <code>commitIndex</code> and <code>lastApplied</code> need to be updated to <code>LastIncludedIndex</code> since we won’t re-execute those new entries in the snapshot.</li><li>It needs to be persisted.</li></ul></li><li>If the snapshot describes only a prefix of logs, then discard the covered entries. But don’t discard those covered yet uncommitted entries, and leave one entry as a dummy entry.</li><li>If PrevLog is already trimmed, we should find the entry with the same index as the sentinel. Make it the new <code>PrevLog</code>, and only accept the entries following it.</li></ol>]]></content>
      
      
      <categories>
          
          <category> Open Source Code </category>
          
          <category> 6.824 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Distributed System </tag>
            
            <tag> Distributed Storage </tag>
            
            <tag> Consensus Algorithm </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>16. Heterogeneous Parallelism and Hardware Specialization</title>
      <link href="/2022/07/24/Courses/CS149/16-Heterogeneous-Parallelism-and-Hardware-Specialization/"/>
      <url>/2022/07/24/Courses/CS149/16-Heterogeneous-Parallelism-and-Hardware-Specialization/</url>
      
        <content type="html"><![CDATA[<ol><li>Amdahl’s law in terms of resource limits: <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>s</mi><mi>p</mi><mi>e</mi><mi>e</mi><mi>d</mi><mi>u</mi><mi>p</mi><mo stretchy="false">(</mo><mi>f</mi><mo separator="true">,</mo><mi>n</mi><mo separator="true">,</mo><mi>r</mi><mo stretchy="false">)</mo><mo>=</mo><mfrac><mn>1</mn><mrow><mfrac><mrow><mn>1</mn><mo>−</mo><mi>f</mi></mrow><mrow><mi>p</mi><mi>e</mi><mi>r</mi><mi>f</mi><mo stretchy="false">(</mo><mi>r</mi><mo stretchy="false">)</mo></mrow></mfrac><mo>+</mo><mfrac><mi>f</mi><mrow><mi>p</mi><mi>e</mi><mi>r</mi><mi>f</mi><mo stretchy="false">(</mo><mi>r</mi><mo stretchy="false">)</mo><mo>⋅</mo><mfrac><mi>n</mi><mi>r</mi></mfrac></mrow></mfrac></mrow></mfrac></mrow><annotation encoding="application/x-tex">speedup(f, n, r)=\frac{1}{\frac{1-f}{perf(r)}+\frac{f}{perf(r)\cdot\frac{n}{r}}}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">s</span><span class="mord mathnormal">p</span><span class="mord mathnormal">e</span><span class="mord mathnormal">e</span><span class="mord mathnormal">d</span><span class="mord mathnormal">u</span><span class="mord mathnormal">p</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal">n</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.877228em;vertical-align:-1.03212em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.845108em;"><span style="top:-2.51911em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mopen nulldelimiter sizing reset-size3 size6"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.9584142857142857em;"><span style="top:-2.640785714285714em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">p</span><span class="mord mathnormal mtight">e</span><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span><span class="mord mathnormal mtight" style="margin-right:0.10764em;">f</span><span class="mopen mtight">(</span><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span><span class="mclose mtight">)</span></span></span></span><span style="top:-3.2255000000000003em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line mtight" style="border-bottom-width:0.049em;"></span></span><span style="top:-3.4623857142857144em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight">1</span><span class="mbin mtight">−</span><span class="mord mathnormal mtight" style="margin-right:0.10764em;">f</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.5377857142857143em;"><span></span></span></span></span></span><span class="mclose nulldelimiter sizing reset-size3 size6"></span></span><span class="mbin mtight">+</span><span class="mord mtight"><span class="mopen nulldelimiter sizing reset-size3 size6"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.9584142857142857em;"><span style="top:-2.5925285714285713em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">p</span><span class="mord mathnormal mtight">e</span><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span><span class="mord mathnormal mtight" style="margin-right:0.10764em;">f</span><span class="mopen mtight">(</span><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span><span class="mclose mtight">)</span><span class="mbin mtight">⋅</span><span class="mord mtight"><span class="mopen nulldelimiter sizing reset-size1 size6"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8175600000000001em;"><span style="top:-2.468em;"><span class="pstrut" style="height:3em;"></span><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span></span></span><span style="top:-3.2255000000000003em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line mtight" style="border-bottom-width:0.049em;"></span></span><span style="top:-3.387em;"><span class="pstrut" style="height:3em;"></span><span class="mord mtight"><span class="mord mathnormal mtight">n</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.532em;"><span></span></span></span></span></span><span class="mclose nulldelimiter sizing reset-size1 size6"></span></span></span></span></span><span style="top:-3.2255000000000003em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line mtight" style="border-bottom-width:0.049em;"></span></span><span style="top:-3.4623857142857144em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.10764em;">f</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.7874714285714286em;"><span></span></span></span></span></span><span class="mclose nulldelimiter sizing reset-size3 size6"></span></span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.03212em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span>. Here, <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>f</mi><mo>=</mo></mrow><annotation encoding="application/x-tex">f =</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span></span></span></span> fraction of a program that is parallelizable, <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi><mo>=</mo></mrow><annotation encoding="application/x-tex">n =</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathnormal">n</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span></span></span></span> total processing resources, <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>r</mi><mo>=</mo></mrow><annotation encoding="application/x-tex">r =</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span></span></span></span> resources dedicated to each processing core, each of the <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mi>n</mi><mi>r</mi></mfrac></mrow><annotation encoding="application/x-tex">\frac{n}{r}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.040392em;vertical-align:-0.345em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.695392em;"><span style="top:-2.6550000000000002em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">n</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.345em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span> cores have sequential performance <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi><mi>e</mi><mi>r</mi><mi>f</mi><mo stretchy="false">(</mo><mi>r</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">perf(r)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">p</span><span class="mord mathnormal">e</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mclose">)</span></span></span></span>.</li><li>If a processor has one <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi><mi>e</mi><mi>r</mi><mi>f</mi><mo stretchy="false">(</mo><mi>r</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">perf(r)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">p</span><span class="mord mathnormal">e</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mclose">)</span></span></span></span> core and <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi><mo>−</mo><mi>r</mi></mrow><annotation encoding="application/x-tex">n-r</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.66666em;vertical-align:-0.08333em;"></span><span class="mord mathnormal">n</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span></span></span></span> <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi><mi>e</mi><mi>r</mi><mi>f</mi><mo stretchy="false">(</mo><mn>1</mn><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">perf(1)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">p</span><span class="mord mathnormal">e</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="mopen">(</span><span class="mord">1</span><span class="mclose">)</span></span></span></span> cores, its <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>s</mi><mi>p</mi><mi>e</mi><mi>e</mi><mi>d</mi><mi>u</mi><mi>p</mi><mo stretchy="false">(</mo><mi>f</mi><mo separator="true">,</mo><mi>n</mi><mo separator="true">,</mo><mi>r</mi><mo stretchy="false">)</mo><mo>=</mo><mfrac><mn>1</mn><mrow><mfrac><mrow><mn>1</mn><mo>−</mo><mi>f</mi></mrow><mrow><mi>p</mi><mi>e</mi><mi>r</mi><mi>f</mi><mo stretchy="false">(</mo><mi>r</mi><mo stretchy="false">)</mo></mrow></mfrac><mo>+</mo><mfrac><mi>f</mi><mrow><mi>p</mi><mi>e</mi><mi>r</mi><mi>f</mi><mo stretchy="false">(</mo><mi>r</mi><mo stretchy="false">)</mo><mo>+</mo><mo stretchy="false">(</mo><mi>n</mi><mo>−</mo><mi>r</mi><mo stretchy="false">)</mo><mi>p</mi><mi>e</mi><mi>r</mi><mi>f</mi><mo stretchy="false">(</mo><mn>1</mn><mo stretchy="false">)</mo></mrow></mfrac></mrow></mfrac></mrow><annotation encoding="application/x-tex">speedup(f, n, r)=\frac{1}{\frac{1-f}{perf(r)}+\frac{f}{perf(r)+(n-r)perf(1)}}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">s</span><span class="mord mathnormal">p</span><span class="mord mathnormal">e</span><span class="mord mathnormal">e</span><span class="mord mathnormal">d</span><span class="mord mathnormal">u</span><span class="mord mathnormal">p</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal">n</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.702448em;vertical-align:-0.8573399999999999em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.845108em;"><span style="top:-2.5191100000000004em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mopen nulldelimiter sizing reset-size3 size6"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.9584142857142857em;"><span style="top:-2.640785714285714em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">p</span><span class="mord mathnormal mtight">e</span><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span><span class="mord mathnormal mtight" style="margin-right:0.10764em;">f</span><span class="mopen mtight">(</span><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span><span class="mclose mtight">)</span></span></span></span><span style="top:-3.2255000000000003em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line mtight" style="border-bottom-width:0.049em;"></span></span><span style="top:-3.4623857142857144em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight">1</span><span class="mbin mtight">−</span><span class="mord mathnormal mtight" style="margin-right:0.10764em;">f</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.5377857142857143em;"><span></span></span></span></span></span><span class="mclose nulldelimiter sizing reset-size3 size6"></span></span><span class="mbin mtight">+</span><span class="mord mtight"><span class="mopen nulldelimiter sizing reset-size3 size6"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.9584142857142857em;"><span style="top:-2.640785714285714em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">p</span><span class="mord mathnormal mtight">e</span><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span><span class="mord mathnormal mtight" style="margin-right:0.10764em;">f</span><span class="mopen mtight">(</span><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span><span class="mclose mtight">)</span><span class="mbin mtight">+</span><span class="mopen mtight">(</span><span class="mord mathnormal mtight">n</span><span class="mbin mtight">−</span><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span><span class="mclose mtight">)</span><span class="mord mathnormal mtight">p</span><span class="mord mathnormal mtight">e</span><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span><span class="mord mathnormal mtight" style="margin-right:0.10764em;">f</span><span class="mopen mtight">(</span><span class="mord mtight">1</span><span class="mclose mtight">)</span></span></span></span><span style="top:-3.2255000000000003em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line mtight" style="border-bottom-width:0.049em;"></span></span><span style="top:-3.4623857142857144em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.10764em;">f</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.5377857142857143em;"><span></span></span></span></span></span><span class="mclose nulldelimiter sizing reset-size3 size6"></span></span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.8573399999999999em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span>.</li><li>Most “real world” applications have complex workload characteristics. The most efficient processor is a heterogeneous mixture of resources, namely use the most efficient tool for the job.</li><li>Supercomputers are energy constrained due to shear scale and overall cost to operate (power for machine and cooling)<br />Datacenters are energy-constrained to reduce cooling costs and physical space requirements.<br />Mobile devices are energy constrained due to limited battery life and heat dissipation.</li><li>The challenge of heterogeneous for system designers: what is the right mixture of resources to meet performance, cost, and energy goals?<br />Too few throughput-oriented resources would lower peak throughput for parallel workloads. Too few sequential processing resources limit the overall system by sequential part of the workload. How much chip area should be dedicated to a specific function? (these resources are taken away from general-purpose processing) Work balance must be anticipated at chip design time</li><li>The challenge to software developers: how to map programs onto a heterogeneous collection of resources?<br />Wish to design algorithms that decompose well into components that each map well to different processing components of the machine. The scheduling problem is more complex in a heterogeneous system. An available mixture of resources can dictate the choice of algorithm: software portability and maintenance nightmare.</li><li>Reducing energy consumption should use specialized processing and moving less data.</li></ol>]]></content>
      
      
      <categories>
          
          <category> Open Courses </category>
          
          <category> CMU 15-418 / Stanford CS149 Parallel Computing </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Parallelism </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>15. Transactional Memory</title>
      <link href="/2022/07/21/Courses/CS149/15-Transactional-Memory/"/>
      <url>/2022/07/21/Courses/CS149/15-Transactional-Memory/</url>
      
        <content type="html"><![CDATA[<h1 id="transactional-memory"><a class="markdownIt-Anchor" href="#transactional-memory"></a> Transactional memory</h1><ol><li><p>Declarative programming is when the programmer states what to do, not how to do it. The system implements synchronization as necessary to ensure atomicity.</p></li><li><p>In transaction memory, the atomic construct is declarative, which means that the programmer states what to do, not how to do it. The system implements synchronization as necessary to ensure atomicity.<br />The system could implement <code>atomic&#123;&#125;</code> using a lock. However, the programmer has no explicit use or management of locks.</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Traditional method</span></span><br><span class="line"><span class="built_in">lock</span>(mutex);</span><br><span class="line"><span class="comment">//critical code</span></span><br><span class="line"><span class="built_in">unlock</span>(mutex);</span><br><span class="line"></span><br><span class="line"><span class="comment">// Transaction memory</span></span><br><span class="line">atomic &#123;</span><br><span class="line">  <span class="comment">// critical code</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>Memory transaction is an atomic and isolated sequence of memory accesses inspired by database transactions.<br />Atomicity requires that upon transaction commit, all memory writes in the transaction take effect at once, and on transaction abort, none of the writes appear to take effect as if the transaction never happened.<br />Isolation means that no other processor can observe writes before committing the transaction.<br />Serializability is that transactions appear to commit in a single serial order, but transaction semantics does not guarantee the exact order of commits.</p></li><li><p>Load-linked, store conditional (LL/SC) is a light version of transactional memory. It has a pair of corresponding instructions (not a single atomic instruction)<br /><code>load_linked(x)</code>: load value from address<br /><code>store_conditional(x, value)</code>: store value to x, if x hasn’t been written to since<br />corresponding LL</p></li><li><p>Two read operations won’t cause true contention. In TM, we can allow the parallelism between two read operations. However, serialization must be ensured when at least one write operation occurs.</p></li><li><p>The transactional memory system is also responsible for processing exceptions, decreasing the complexity of manually using try-catch statements to catch exceptions.<br />When an exception inside the atomic block occurs, the transaction is aborted, and memory updates are undone.</p></li><li><p>A transactional memory system needs composable locks.<br />Composing lock-based code can be tricky, requiring system-wide policies to get correct, and can break software modularity.<br />The following code can end up in a deadlock. TM system should be able to compose the two synchronizations together to avoid the possible deadlock. A programmer can use an <code>atomic&#123;&#125;</code> to correctly represent the two <code>synchronized &#123;&#125;</code> structures.</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">void</span> <span class="title">function</span><span class="params">(A, B)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">  <span class="built_in">synchronized</span>(A)</span><br><span class="line">  &#123;</span><br><span class="line">    <span class="built_in">synchronized</span>(B)</span><br><span class="line">    &#123;</span><br><span class="line">      <span class="comment">// critical code</span></span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// thread 0</span></span><br><span class="line"><span class="built_in">function</span>(x, y);</span><br><span class="line"></span><br><span class="line"><span class="comment">//thread 1</span></span><br><span class="line"><span class="built_in">function</span>(y, x);</span><br></pre></td></tr></table></figure></li><li><p><code>Atomic&#123;&#125;</code> is not the same as <code>lock()/unlock()</code>. Atomic is a high-level declaration of atomicity, which does not specify the implementation of atomicity. The lock is a low-level blocking primitive that does not provide atomicity or isolation on its own.<br />Locks can be used to implement an atomic block. Also, locks can be used for purposes beyond atomicity. Namely, we cannot replace all uses of locks with atomic regions.<br />Atomic eliminates many data races, but programming with atomic blocks can still suffer from atomicity violations.</p></li><li><p>Atomicity violation due to programmer error: Logically, the atomic code sequence is erroneously separated into two atomic blocks.</p></li></ol><h1 id="implementing-transactional-memory"><a class="markdownIt-Anchor" href="#implementing-transactional-memory"></a> Implementing transactional memory</h1><h2 id="data-versioning"><a class="markdownIt-Anchor" href="#data-versioning"></a> Data versioning</h2><ol><li>Data versioning manages uncommitted (new) and previously committed (old) versions of data for concurrent transactions. This is used to allow transaction abort.</li><li>Eager versioning updates memory immediately and maintains “undo log” in case of abort.<br />When a write happens, the old value is pushed into the undo log, and the new value is to memory.<br />When a transaction is aborted, we can search the undo log to recover the corresponding state.<br />When the transaction is committed, we can discard the undo log of those committed contents.</li><li>Lazy versioning is a deferred update. Namely, it logs memory updates in the transaction write buffer and flushes the buffer on commit.<br />When a write happens, the new value is pushed into the write buffer, and we don’t write the new value in memory.<br />When a transaction is aborted, we discard the write buffer, and there is no need to modify the memory since we haven’t written anything to it yet.<br />When a transaction is committed, we write the data in the write buffer to memory and discard the write buffer.</li><li>Eager versioning is faster in commit since data is already in memory. But it is slower in aborts and has fault tolerance issues (crashes in the middle of a transaction). It writes to memory immediately, hoping the transaction won’t abort, but deals with aborts when necessary.</li><li>Lazy versioning is faster in abort, clears the log, and has no fault tolerance issues. But it is slower in commits. It only writes to memory when you have to.</li></ol><h2 id="conflict-detection-and-resolution"><a class="markdownIt-Anchor" href="#conflict-detection-and-resolution"></a> Conflict detection and resolution</h2><ol><li>This is to decide when to abort. It must detect and handle transaction conflicts, including read-write and write-write conflicts. The system must track a transaction’s read set and write set.</li><li>Pessimistic detection checks for conflicts during loads or stores. A hardware implementation will check for conflicts through coherent actions.<br />The philosophy is, &quot;I suspect conflicts might happen, so let’s always check to see if one has occurred after each memory operation… if I’m going to have to roll back, might as well do it now to avoid wasted work.”</li><li>The contention manager decides to stall or abort the transaction when a conflict is detected. A conflict can be stalled when detected before executing (early detection). When a conflict is detected after execution, then it can only restart.<br />When two writes cause the conflict, it may raise a livelock if both threads restart before the other one has finished.</li><li>Optimistic detection detects conflicts when a transaction attempts to commit. Hardware validates the write set using coherence actions and gets exclusive access to cache lines in the write set.<br />The intuition is, “Let’s hope for the best and sort out all the conflicts only when the transaction tries to commit.”<br />In a conflict, it gives priority to committing the transactions. Other transactions may be aborted later on. In conflicts between committing transactions, use the contention manager to decide priorities. Optimistic detection won’t cause livelock.</li><li>We can use optimistic and pessimistic schemes together. Several STM systems use optimistic for reads and pessimistic for writes.</li><li>Pessimistic conflict detection (“eager”) can detect conflicts early and thus undo less work, turning some aborts into stalls. It has no forward progress guarantees, and there are more aborts in some cases. Also, fine-grained communication is required to check on each load/store.<br />Bad: detection on the critical path</li><li>Optimistic conflict detection (“lazy” or “commit”) has forward progress guarantees. It requires bulk communication and conflict detection. It detects conflicts late and can still have fairness problems.</li><li>Conflict detection granularity<br />Object granularity is a software-based technique. It reduces time and space overhead and is close to the programmer’s reasoning. But there might be false sharing on large objects.<br />Machine word granularity can minimize false sharing but increases the overhead of time and space.<br />Cache-line granularity is a compromise between an object and a word.</li></ol><h2 id="hardware-transactional-memory"><a class="markdownIt-Anchor" href="#hardware-transactional-memory"></a> Hardware transactional memory</h2><ol><li>Data versioning is implemented in caches. Cache the write buffer or the undo log. And add new cache line metadata to track transaction read and write sets.<br />Conflict detection is implemented through cache coherence protocol. Coherence lookups detect conflicts between transactions. It works with snooping and directory coherence.</li><li>Register checkpoint must also be taken at the transaction begins to restore the execution context state on abort.</li><li>Cache lines need extra bits to track the read set and write set.<br /><strong>R bit</strong> indicates data read by transaction and is set on loads, while <strong>W bit</strong> indicates data written by transaction and is set on stores. R/W bits gang-cleared on transaction commit or abort.<br />R/W bits can be a work or cache-line granularity.<br />We need a 2nd cache write for the undo log for eager versioning.</li><li>Coherence requests check R/W bits to detect conflicts.<br />Observing shared requests to W-word is a read-write conflict.<br />Observing exclusive (intent to write) requests to R-word is a write-read conflict.<br />Observing exclusive (intent to write) requests to W-word is a write-write conflict.</li><li>Fast two-phase commit<br />Validate: request RdX access to write set lines (if needed)<br />Commit: gang-reset R and W bits, turns to write set data to valid (dirty) data.</li><li>Fast conflict detection and abort<br />Check: lookup exclusive requests in the read set and write set<br />Abort: invalidate write set, gang-reset R and W bits, restore to register checkpoint</li></ol>]]></content>
      
      
      <categories>
          
          <category> Open Courses </category>
          
          <category> CMU 15-418 / Stanford CS149 Parallel Computing </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Parallelism </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>14. Fine-grained Synchronization and Lock-free Programming</title>
      <link href="/2022/07/17/Courses/CS149/14-Fine-grained-Synchronization-and-Lock-free-Programming/"/>
      <url>/2022/07/17/Courses/CS149/14-Fine-grained-Synchronization-and-Lock-free-Programming/</url>
      
        <content type="html"><![CDATA[<h1 id="fine-grained-synchronization-and-fine-grained-lock"><a class="markdownIt-Anchor" href="#fine-grained-synchronization-and-fine-grained-lock"></a> Fine-grained synchronization and fine-grained lock</h1><ol><li>Data structures are often larger than a single memory location. One solution is to protect the structure with a single lock.<br />It is relatively simple to implement correct mutual exclusion for data structure operations. However, the operations on the data structure are serialized, which may limit parallel application performance.</li><li>Another solution is “hand-over-hand” locking. We set a lock for each element in the data structure. Each thread only keeps as little as the lock they need, and every time a thread moves forward, it unlocks the locks they don’t need anymore and locks the locks they need now.</li><li>Fine-grained lock aims to enable parallelism in data structure operations by Reducing contention for global data structure lock.<br />It is tricky to ensure correctness (how to determine when mutual exclusion is required, how to avoid deadlock or livelock).</li><li>It has an overhead of taking a lock on each traversal step. There are extra instructions, and traversal now involves memory writes. Also, it has extra storage costs, namely a lock per node.</li><li>C++11 has an <code>atomic&lt;T&gt;</code>. It provides atomic read, write, read-modify-write of entire objects. Atomicity may be implemented by mutex or efficiently by processor-supported atomic instructions if <code>T</code> is a basic type.<br />It also provides memory ordering semantics for operations before and after atomic operations.</li></ol><h1 id="lock-free-programming"><a class="markdownIt-Anchor" href="#lock-free-programming"></a> Lock-free programming</h1><ol><li><p>Single reader, single writer bounded queue: Only two threads (one producer, one consumer) accessing the queue simultaneously.</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">struct</span> <span class="title class_">Queue</span> &#123;</span><br><span class="line">  <span class="type">int</span> data[N];</span><br><span class="line">  <span class="type">unsigned</span> head; <span class="comment">// head of queue</span></span><br><span class="line">  <span class="type">unsigned</span> tail; <span class="comment">// next free element</span></span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">init</span><span class="params">(Queue* q)</span> </span>&#123;</span><br><span class="line">  q-&gt;head = q-&gt;tail = <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// return false if queue is full</span></span><br><span class="line"><span class="function"><span class="type">bool</span> <span class="title">push</span><span class="params">(Queue* q, <span class="type">int</span> value)</span> </span>&#123;</span><br><span class="line">  <span class="comment">// queue is full if tail is element before head</span></span><br><span class="line">  <span class="keyword">if</span> (q-&gt;tail == <span class="built_in">MOD_N</span>(q-&gt;head - <span class="number">1</span>))</span><br><span class="line">    <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">  q.data[q-&gt;tail] = value;</span><br><span class="line">  q-&gt;tail = <span class="built_in">MOD_N</span>(q-&gt;tail + <span class="number">1</span>);</span><br><span class="line">  <span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// returns false if queue is empty</span></span><br><span class="line"><span class="function"><span class="type">bool</span> <span class="title">pop</span><span class="params">(Queue* q, <span class="type">int</span>* value)</span> </span>&#123;</span><br><span class="line">  <span class="comment">// if not empty</span></span><br><span class="line">  <span class="keyword">if</span> (q-&gt;head != q-&gt;tail) &#123;</span><br><span class="line">    *value = q-&gt;data[q-&gt;head];</span><br><span class="line">    q-&gt;head = <span class="built_in">MOD_N</span>(q-&gt;head + <span class="number">1</span>);</span><br><span class="line">    <span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>Single reader, single writer unbounded queue: Only push modifies <code>tail</code> and <code>reclaim</code>; only pop modifies <code>head</code>.</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">struct</span> <span class="title class_">Node</span> &#123;</span><br><span class="line">  Node* next;</span><br><span class="line">  <span class="type">int</span> value;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="keyword">struct</span> <span class="title class_">Queue</span> &#123;</span><br><span class="line">  Node* head;    <span class="comment">// the element before head of queue</span></span><br><span class="line">  Node* tail;    <span class="comment">// the last element added</span></span><br><span class="line">  Node* reclaim; <span class="comment">// the head of undeleted nodes</span></span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">init</span><span class="params">(Queue* q)</span> </span>&#123;</span><br><span class="line">  q-&gt;head = q-&gt;tail = q-&gt;reclaim = <span class="keyword">new</span> Node;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">push</span><span class="params">(Queue* q, <span class="type">int</span> value)</span> </span>&#123;</span><br><span class="line">  Node* n = <span class="keyword">new</span> Node;</span><br><span class="line">  n-&gt;next = <span class="literal">NULL</span>;</span><br><span class="line">  n-&gt;value = value;</span><br><span class="line">  q-&gt;tail-&gt;next = n;</span><br><span class="line">  q-&gt;tail = q-&gt;tail-&gt;next;</span><br><span class="line">  <span class="comment">// delete all nodes between reclaim and head</span></span><br><span class="line">  <span class="keyword">while</span> (q-&gt;reclaim != q-&gt;head) &#123;</span><br><span class="line">    Node* tmp = q-&gt;reclaim;</span><br><span class="line">    q-&gt;reclaim = q-&gt;reclaim-&gt;next;</span><br><span class="line">    <span class="keyword">delete</span> tmp;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// returns false if queue is empty</span></span><br><span class="line"><span class="function"><span class="type">bool</span> <span class="title">pop</span><span class="params">(Queue* q, <span class="type">int</span>* value)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">if</span> (q-&gt;head != q-&gt;tail) &#123;</span><br><span class="line">    *value = q-&gt;head-&gt;next-&gt;value;</span><br><span class="line">    q-&gt;head = q-&gt;head-&gt;next;</span><br><span class="line">    <span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>Lock-free stack: the main idea is that a thread’s modification can proceed as long as no other thread has modified the stack. The <code>compare_and_swap</code> operation is atomic, but doesn’t need to hold any other lock on data structure.</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">struct</span> <span class="title class_">Node</span> &#123;</span><br><span class="line">  Node* next;</span><br><span class="line">  <span class="type">int</span> value;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="keyword">struct</span> <span class="title class_">Stack</span> &#123;</span><br><span class="line">  Node* top;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">init</span><span class="params">(Stack* s)</span> </span>&#123;</span><br><span class="line">  s-&gt;top = <span class="literal">NULL</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">push</span><span class="params">(Stack* s, Node* n)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">while</span> (<span class="number">1</span>) &#123;</span><br><span class="line">    Node* old_top = s-&gt;top;</span><br><span class="line">    n-&gt;next = old_top;</span><br><span class="line">    <span class="comment">// Check whether the current top is the old top, </span></span><br><span class="line">    <span class="comment">// if true, set the current top to n; or get a new top</span></span><br><span class="line">    <span class="keyword">if</span> (<span class="built_in">compare_and_swap</span>(&amp;s-&gt;top, old_top, n) == old_top)</span><br><span class="line">      <span class="keyword">return</span>;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function">Node* <span class="title">pop</span><span class="params">(Stack* s)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">while</span> (<span class="number">1</span>) &#123;</span><br><span class="line">    Node* old_top = s-&gt;top;</span><br><span class="line">    <span class="keyword">if</span> (old_top == <span class="literal">NULL</span>)</span><br><span class="line">      <span class="keyword">return</span> <span class="literal">NULL</span>;</span><br><span class="line">    Node* new_top = old_top-&gt;next;</span><br><span class="line">    <span class="comment">// if the top is still the old top, return old top and set to new top</span></span><br><span class="line">    <span class="comment">// or get a new top</span></span><br><span class="line">    <span class="keyword">if</span> (<span class="built_in">compare_and_swap</span>(&amp;s-&gt;top, old_top, new_top) == old_top)</span><br><span class="line">      <span class="keyword">return</span> old_top;  <span class="comment">// Assume that consumer then recycles old_top</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>The above push operation is fine, but the pop operation may have some error.<br />After thread0 stores the old_top, if thread1 pops the old_top out, modifies the stack, and pushes the old_top into the stack again, then the <code>compare_and_swap</code> operation of thread0 will pass. Namely, thread0 cannot realize that the stack has already been modified.</p></li><li><p>One solution is adding a <code>pop_counter</code> to check whether other pop operations happened.</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">struct</span> <span class="title class_">Node</span> &#123;</span><br><span class="line">  Node* next;</span><br><span class="line">  <span class="type">int</span> value;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="keyword">struct</span> <span class="title class_">Stack</span> &#123;</span><br><span class="line">  Node* top;</span><br><span class="line">  <span class="type">int</span> pop_count;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">init</span><span class="params">(Stack* s)</span> </span>&#123;</span><br><span class="line">  s-&gt;top = <span class="literal">NULL</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">push</span><span class="params">(Stack* s, Node* n)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">while</span> (<span class="number">1</span>) &#123;</span><br><span class="line">    Node* old_top = s-&gt;top;</span><br><span class="line">    n-&gt;next = old_top;</span><br><span class="line">    <span class="keyword">if</span> (<span class="built_in">compare_and_swap</span>(&amp;s-&gt;top, old_top, n) == old_top)</span><br><span class="line">      <span class="keyword">return</span>;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function">Node* <span class="title">pop</span><span class="params">(Stack* s)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">while</span> (<span class="number">1</span>) &#123;</span><br><span class="line">    <span class="type">int</span> pop_count = s-&gt;pop_count;</span><br><span class="line">    Node* top = s-&gt;top;</span><br><span class="line">    <span class="keyword">if</span> (top == <span class="literal">NULL</span>)</span><br><span class="line">      <span class="keyword">return</span> <span class="literal">NULL</span>;</span><br><span class="line">    Node* new_top = top-&gt;next;</span><br><span class="line">    <span class="keyword">if</span> (<span class="built_in">double_compare_and_swap</span>(&amp;s-&gt;top, top, new_top,</span><br><span class="line">                                &amp;s-&gt;pop_count, pop_count, pop_count+<span class="number">1</span>))</span><br><span class="line">    &#123;</span><br><span class="line">      <span class="keyword">return</span> top;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure></li><li><p>Another solution to the ABA problem is hazard pointers. The reuse of the <code>old_top</code> causes the ABA problem. We can use the hazard pointers to track all <code>old_top</code>s, and they cannot be recycled or reused if they match any hazard pointers.</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">struct</span> <span class="title class_">Node</span> &#123;</span><br><span class="line">  Node* next;</span><br><span class="line">  <span class="type">int</span> value;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="keyword">struct</span> <span class="title class_">Stack</span> &#123;</span><br><span class="line">  Node* top;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line">Node *hazard[NUM_THREADS];</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">init</span><span class="params">(Stack* s)</span> </span>&#123;</span><br><span class="line">  s-&gt;top = <span class="literal">NULL</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">push</span><span class="params">(Stack* s, Node* n)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">while</span> (<span class="number">1</span>) &#123;</span><br><span class="line">    Node* old_top = s-&gt;top;</span><br><span class="line">    n-&gt;next = old_top;</span><br><span class="line">    <span class="keyword">if</span> (<span class="built_in">compare_and_swap</span>(&amp;s-&gt;top, old_top, n) == old_top)</span><br><span class="line">      <span class="keyword">return</span>;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function">Node* <span class="title">pop</span><span class="params">(Stack* s)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">while</span> (<span class="number">1</span>) &#123;</span><br><span class="line">    hazard[t] = s-&gt;top;</span><br><span class="line">    Node* top = hazard[t];</span><br><span class="line">    <span class="keyword">if</span> (top == <span class="literal">NULL</span>)</span><br><span class="line">      <span class="keyword">return</span> <span class="literal">NULL</span>;</span><br><span class="line">    Node* new_top = top-&gt;next;</span><br><span class="line">    <span class="keyword">if</span> (<span class="built_in">compare_and_swap</span>(&amp;s-&gt;top, top, new_top))</span><br><span class="line">      <span class="keyword">return</span> top;  <span class="comment">// Caller must clear hazard[t] when it’s done with top</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>Lock-free linked list insertion assumes the only operation on the list is inserting. Supporting lock-free deletion significantly complicates data structure.</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">struct</span> <span class="title class_">Node</span> &#123;</span><br><span class="line">  <span class="type">int</span> value;</span><br><span class="line">  Node* next;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="keyword">struct</span> <span class="title class_">List</span> &#123;</span><br><span class="line">  Node* head;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="comment">// insert new node after specified node</span></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">insert_after</span><span class="params">(List* list, Node* after, <span class="type">int</span> value)</span> </span>&#123;</span><br><span class="line">  Node* n = <span class="keyword">new</span> Node;</span><br><span class="line">  n-&gt;value = value;</span><br><span class="line">  <span class="comment">// assume case of insert into empty list handled</span></span><br><span class="line">  <span class="comment">// here (keep code on slide simple for class discussion)</span></span><br><span class="line">  Node* prev = list-&gt;head;</span><br><span class="line">  <span class="keyword">while</span> (prev-&gt;next) &#123;</span><br><span class="line">    <span class="keyword">if</span> (prev == after) &#123;</span><br><span class="line">      <span class="keyword">while</span> (<span class="number">1</span>) &#123;</span><br><span class="line">        Node* old_next = prev-&gt;next;</span><br><span class="line">        n-&gt;next = old_next;</span><br><span class="line">        <span class="keyword">if</span> (<span class="built_in">compare_and_swap</span>(&amp;prev-&gt;next, old_next, n) == old_next)</span><br><span class="line">          <span class="keyword">return</span>;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    prev = prev-&gt;next;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>If your program only uses the machine, well-written code with locks can be as fast (or faster) than lock-free code.<br />However, there are situations where code with locks can suffer from tricky performance problems. Like multi-programmed situations where page faults, pre-emption, etc., can occur while the thread is in a critical section</p></li></ol>]]></content>
      
      
      <categories>
          
          <category> Open Courses </category>
          
          <category> CMU 15-418 / Stanford CS149 Parallel Computing </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Parallelism </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>13. Implementing Synchronization</title>
      <link href="/2022/07/16/Courses/CS149/13-Implementing-Synchronization/"/>
      <url>/2022/07/16/Courses/CS149/13-Implementing-Synchronization/</url>
      
        <content type="html"><![CDATA[<h1 id="implementing-locks"><a class="markdownIt-Anchor" href="#implementing-locks"></a> Implementing locks</h1><ol><li>Three phases of a synchronization event：<br />Acquire method: How does a thread attempt to access protected resources?<br />Waiting algorithm: How does a thread wait for access shared resources?<br />Release method: How does a thread enable other threads to gain resources when its work in the synchronized region is complete?</li><li>Busy waiting (spinning): <code>while (condition X not true) ;</code></li><li>Blocking synchronization: <code>if (condition X not true) block until true;</code><br />If progress cannot be made because a resource cannot be acquired, it is desirable to free up execution resources for another thread and preempt the running thread.</li><li>Busy waiting can be preferable to blocking if scheduling overhead is larger than the expected wait time or the processor’s resources are not needed for other tasks.<br />The latter situation is often the case in a parallel program since we usually don’t oversubscribe a system when running a performance-critical parallel app.</li><li>Desirable lock performance characteristics:<br /><strong>Low latency</strong>: If the lock is free and no other processors are trying to acquire it, a processor should be able to acquire the lock quickly<br /><strong>Low interconnect traffic</strong>: If all processors are trying to acquire the lock at once, they should acquire the lock in succession with as little traffic as possible<br /><strong>Scalability</strong>: Latency/traffic should scale reasonably with the number of processors<br /><strong>Low storage cost</strong><br /><strong>Fairness</strong>: Avoid starvation or substantial unfairness. One idea is that processors should acquire the lock in the order they request access to it.</li></ol><h2 id="test-and-set-lock"><a class="markdownIt-Anchor" href="#test-and-set-lock"></a> Test-and-set lock</h2><h3 id="simple-test-and-set-lock"><a class="markdownIt-Anchor" href="#simple-test-and-set-lock"></a> Simple test-and-set lock</h3><ol><li>The following spin lock has data race because LOAD-TEST-STORE is not atomic.<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">// Lock</span><br><span class="line">ld   R0, mem[addr]  // load word into R0</span><br><span class="line">cmp  R0, #0          // compare R0 to 0</span><br><span class="line">bnz  lock            // if nonzero jump to top</span><br><span class="line">st   mem[addr], #1  // set lock to 1</span><br><span class="line"></span><br><span class="line">// Unlock</span><br><span class="line">st   mem[addr], #0  // set lock to 0</span><br></pre></td></tr></table></figure></li><li>So, we need an atomic test-and-set instruction<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">ts R0, mem[addr]  // load mem[addr] into R0</span><br><span class="line">                  // if mem[addr] is 0, set mem[addr] to 1</span><br><span class="line">                  </span><br><span class="line">// Lock</span><br><span class="line">ts   R0, mem[addr]  // load word into R0</span><br><span class="line">bnz  R0, lock        // if nonzero jump to top</span><br><span class="line"></span><br><span class="line">// Unlock</span><br><span class="line">st   mem[addr], #0  // store 0 to address</span><br></pre></td></tr></table></figure></li><li>Every time a processor executes the ts instruction, it will send a BusRdX signal and invalidate the lock in all other processors’ caches. The coherence traffic may be heavy when many processors try to execute on the same lock.<br />This lock generates one invalidation per waiting processor per test.</li><li>Bus contention increases the time to transfer the lock since the lock holder must wait to acquire the bus to release. Bus contention also slows down the execution of critical sections.</li><li>In x86, we can do the atomic compare and exchange by <code>lock cmpxchg src, dst</code> instruction. The <code>lock</code> prefix makes the operation atomic. The logic of the instruction is as follows:<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> (dst == %eax)  <span class="comment">// eax is the x86 accumulator register</span></span><br><span class="line">  ZF = <span class="number">1</span>          <span class="comment">// ZF is a flag registor</span></span><br><span class="line">dst = src <span class="keyword">else</span></span><br><span class="line">  ZF = <span class="number">0</span></span><br><span class="line">  %eax = dst</span><br></pre></td></tr></table></figure></li><li>Simple test-and-set lock has low latency (under low contention), high traffic, poor scaling, low storage cost (one int), and no provisions for fairness.</li></ol><h3 id="test-and-set-lock-with-back-off"><a class="markdownIt-Anchor" href="#test-and-set-lock-with-back-off"></a> Test-and-set lock with back off</h3><ol><li><p>Upon failure to acquire the lock, delay for a while before retrying.</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">void</span> <span class="title">Lock</span><span class="params">(<span class="keyword">volatile</span> <span class="type">int</span>* lock)</span> </span>&#123;</span><br><span class="line">  <span class="type">int</span> amount = <span class="number">1</span>;</span><br><span class="line">  <span class="keyword">while</span> (<span class="number">1</span>) &#123;</span><br><span class="line">    <span class="keyword">if</span> (<span class="built_in">test_and_set</span>(lock) == <span class="number">0</span>)</span><br><span class="line">      <span class="keyword">return</span>;</span><br><span class="line">    <span class="built_in">delay</span>(amount);</span><br><span class="line">    amount *= <span class="number">2</span>;</span><br><span class="line">  &#125; </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>It has the same uncontended latency as test-and-set but potentially higher latency under contention because the waiting processor may still delay even when the lock is available.</p></li><li><p>It generates less traffic than test-and-set since it does not continually attempt to acquire a lock. It improves scalability due to less traffic.</p></li><li><p>Storage cost unchanged (still one int for lock)</p></li><li><p>Exponential back-off can cause severe unfairness. Newer requesters back off for shorter intervals</p></li></ol><h3 id="test-and-test-and-set-lock"><a class="markdownIt-Anchor" href="#test-and-test-and-set-lock"></a> Test-and-test-and-set lock</h3><ol><li><p>To prevent the coherence traffic problem, we can test first and do the test-and-set only if the earlier test has passed.</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">void</span> <span class="title">Lock</span><span class="params">(<span class="keyword">volatile</span> <span class="type">int</span>* lock)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">while</span> (<span class="number">1</span>) &#123;</span><br><span class="line">    <span class="keyword">while</span> (*lock != <span class="number">0</span>) ;</span><br><span class="line">    <span class="keyword">if</span> (<span class="built_in">test_and_set</span>(lock) == <span class="number">0</span>)</span><br><span class="line">      <span class="keyword">return</span>;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">Unlock</span><span class="params">(<span class="keyword">volatile</span> <span class="type">int</span>* lock)</span> </span>&#123;</span><br><span class="line">  *lock = <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>This lock has slightly higher latency than test-and-set in uncontended cases but generates much less interconnect traffic. Only One invalidation is generated per waiting processor per lock release.<br />Namely, only <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>O</mi><mo stretchy="false">(</mo><mi>P</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">O(P)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">O</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="mclose">)</span></span></span></span> invalidation and <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>O</mi><mo stretchy="false">(</mo><msup><mi>P</mi><mn>2</mn></msup><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">O(P^2)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.064108em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">O</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141079999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span> interconnect traffic.</p></li><li><p>It is more scalable due to less traffic, storage cost unchanged (still one int), and no fairness provisions.</p></li></ol><h2 id="ticket-lock"><a class="markdownIt-Anchor" href="#ticket-lock"></a> Ticket lock</h2><ol><li>The test-and-set style locks cannot provide for fairness because all waiting processors attempt to acquire a lock using test-and-set upon release.</li><li>We can assign each thread a number when they try to acquire the lock. We give the lock to the waiting thread with the smallest number every time.<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">struct</span> <span class="title class_">lock</span> &#123;</span><br><span class="line">  <span class="keyword">volatile</span> <span class="type">int</span> next_ticket;</span><br><span class="line">  <span class="keyword">volatile</span> <span class="type">int</span> now_serving;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">Lock</span><span class="params">(lock* lock)</span> </span>&#123;</span><br><span class="line">  <span class="type">int</span> my_ticket = <span class="built_in">atomic_increment</span>(&amp;lock-&gt;next_ticket);  <span class="comment">// take a “ticket”</span></span><br><span class="line">  <span class="keyword">while</span> (my_ticket != lock-&gt;now_serving);                <span class="comment">//wait for number</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">unlock</span><span class="params">(lock* lock)</span> </span>&#123;</span><br><span class="line">  lock-&gt;now_serving++;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li>No atomic operation is needed to acquire the lock. Only a read is necessary when acquiring the lock, and write only happens when the lock is released. So, only one invalidation is generated per lock release, namely <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>O</mi><mo stretchy="false">(</mo><mi>P</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">O(P)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">O</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="mclose">)</span></span></span></span> interconnect traffic.</li></ol><h2 id="array-based-lock"><a class="markdownIt-Anchor" href="#array-based-lock"></a> Array-based lock</h2><ol><li><p>Each processor spins on a different memory address. It also utilizes atomic operations to assign an address to acquire it.<br />If there are two barriers, after some threads pass the first barrier, they might set the flag to 0 even if some other threads haven’t passed the first barrier yet, causing those slower threads to wait.</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">struct</span> <span class="title class_">lock</span> &#123;</span><br><span class="line">  <span class="keyword">volatile</span> padded_int status[P];  <span class="comment">// padded to keep off same cache line</span></span><br><span class="line">  <span class="keyword">volatile</span> <span class="type">int</span> head;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="type">int</span> my_element;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">Lock</span><span class="params">(lock* lock)</span> </span>&#123;</span><br><span class="line">  my_element = <span class="built_in">atomic_circ_increment</span>(&amp;lock-&gt;head);  <span class="comment">// assume modular increment </span></span><br><span class="line">  <span class="keyword">while</span> (lock-&gt;status[my_element] == <span class="number">1</span>);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">unlock</span><span class="params">(lock* lock)</span> </span>&#123;</span><br><span class="line">  lock-&gt;status[my_element] = <span class="number">1</span>;</span><br><span class="line">  lock-&gt;status[<span class="built_in">circ_next</span>(my_element)] = <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>The lock only requires <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>O</mi><mo stretchy="false">(</mo><mn>1</mn><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">O(1)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">O</span><span class="mopen">(</span><span class="mord">1</span><span class="mclose">)</span></span></span></span> interconnect traffic per release but requires linear space in <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>O</mi><mo stretchy="false">(</mo><mi>P</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">O(P)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">O</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="mclose">)</span></span></span></span>.</p></li><li><p>The atomic circular increment is a more complex operation. So, the lock has a higher overhead.</p></li><li><p>Queue-based Lock (MCS lock): Create a queue of waiters. Each thread allocates a local space on which to wait.</p></li></ol><h1 id="implementing-barrier"><a class="markdownIt-Anchor" href="#implementing-barrier"></a> Implementing barrier</h1><ol><li>The following code uses a <code>counter</code> to count how many threads have hit the barrier. The last thread hit the barrier and will release all of them.<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">struct</span> <span class="title class_">Barrier_t</span> &#123;</span><br><span class="line">   LOCK lock;</span><br><span class="line">  <span class="type">int</span> counter;  <span class="comment">// initialize to 0</span></span><br><span class="line">  <span class="type">int</span> flag;      <span class="comment">// the flag field should probably be padded to </span></span><br><span class="line">                <span class="comment">// sit on its own cache line. </span></span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="comment">// barrier for p processors</span></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">Barrier</span><span class="params">(Barrier_t* b, <span class="type">int</span> p)</span> </span>&#123;</span><br><span class="line">  <span class="built_in">lock</span>(b-&gt;lock);</span><br><span class="line">  <span class="keyword">if</span> (b-&gt;counter == <span class="number">0</span>) &#123;</span><br><span class="line">    b-&gt;flag = <span class="number">0</span>; <span class="comment">// first thread arriving at barrier clears flag </span></span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="type">int</span> num_arrived = ++(b-&gt;counter);</span><br><span class="line">  <span class="built_in">unlock</span>(b-&gt;lock);</span><br><span class="line"></span><br><span class="line">  <span class="keyword">if</span> (num_arrived == p) &#123; <span class="comment">// last arriver sets flag b-&gt;counter = 0;</span></span><br><span class="line">    b-&gt;flag = <span class="number">1</span>;</span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    <span class="keyword">while</span> (b-&gt;flag == <span class="number">0</span>); <span class="comment">// wait for flag</span></span><br><span class="line">  &#125; </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li>To solve the problem, we should wait for all processes to leave the first barrier, before clearing the flag for entry into the second.<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Centralized barrier</span></span><br><span class="line"> </span><br><span class="line"><span class="keyword">struct</span> <span class="title class_">Barrier_t</span> &#123;</span><br><span class="line">  LOCK lock;</span><br><span class="line">  <span class="type">int</span> arrive_counter;  <span class="comment">// initialize to 0 (number of threads that have arrived)</span></span><br><span class="line">  <span class="type">int</span> leave_counter;  <span class="comment">// initialize to P (number of threads that have left barrier)</span></span><br><span class="line">  <span class="type">int</span> flag;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="comment">// barrier for p processors</span></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">Barrier</span><span class="params">(Barrier_t* b, <span class="type">int</span> p)</span> </span>&#123;</span><br><span class="line">  <span class="built_in">lock</span>(b-&gt;lock);</span><br><span class="line">  <span class="keyword">if</span> (b-&gt;arrive_counter == <span class="number">0</span>) &#123;   <span class="comment">// if first to arrive...</span></span><br><span class="line">    <span class="keyword">if</span> (b-&gt;leave_counter == P) &#123;  <span class="comment">// check to make sure no other threads “still in barrier”</span></span><br><span class="line">      b-&gt;flag = <span class="number">0</span>;               <span class="comment">// first arriving thread clears flag</span></span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">      <span class="built_in">unlock</span>(lock);</span><br><span class="line">      <span class="keyword">while</span> (b-&gt;leave_counter != P);  <span class="comment">// wait for all threads to leave before clearing</span></span><br><span class="line">      <span class="built_in">lock</span>(lock);</span><br><span class="line">      b-&gt;flag = <span class="number">0</span>;                <span class="comment">// first arriving thread clears flag</span></span><br><span class="line">    &#125; </span><br><span class="line">  &#125;</span><br><span class="line">  <span class="type">int</span> num_arrived = ++(b-&gt;arrive_counter);</span><br><span class="line">  <span class="built_in">unlock</span>(b-&gt;lock);</span><br><span class="line">  <span class="keyword">if</span> (num_arrived == p) &#123;  <span class="comment">// last arriver sets flag</span></span><br><span class="line">    b-&gt;arrive_counter = <span class="number">0</span>;</span><br><span class="line">    b-&gt;leave_counter = <span class="number">1</span>;</span><br><span class="line">    b-&gt;flag = <span class="number">1</span>;</span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    <span class="keyword">while</span> (b-&gt;flag == <span class="number">0</span>);  <span class="comment">// wait for flag</span></span><br><span class="line">    <span class="built_in">lock</span>(b-&gt;lock);</span><br><span class="line">    b-&gt;leave_counter++;</span><br><span class="line">    <span class="built_in">unlock</span>(b-&gt;lock);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li>We can save one variable by sense reversal. Processors wait for the flag to be equal to the local sense.<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">struct</span> <span class="title class_">Barrier_t</span> &#123;</span><br><span class="line">  LOCK lock;</span><br><span class="line">  <span class="type">int</span> counter; <span class="comment">// initialize to 0</span></span><br><span class="line">  <span class="type">int</span> flag; <span class="comment">// initialize to 0</span></span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="type">int</span> local_sense = <span class="number">0</span>;  <span class="comment">// private per processor</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// barrier for p processors</span></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">Barrier</span><span class="params">(Barrier_t* b, <span class="type">int</span> p)</span> </span>&#123;</span><br><span class="line">  local_sense = (local_sense == <span class="number">0</span>) ? <span class="number">1</span> : <span class="number">0</span>; <span class="built_in">lock</span>(b-&gt;lock);</span><br><span class="line">  <span class="type">int</span> num_arrived = ++(b-&gt;counter);</span><br><span class="line">  <span class="keyword">if</span> (b-&gt;counter == p) &#123; <span class="comment">// last arriver sets flag</span></span><br><span class="line">    <span class="built_in">unlock</span>(b-&gt;lock);</span><br><span class="line">    b-&gt;counter = <span class="number">0</span>;</span><br><span class="line">    b-&gt;flag = local_sense;</span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    <span class="built_in">unlock</span>(b-&gt;lock);</span><br><span class="line">    <span class="keyword">while</span> (b-&gt;flag != local_sense); <span class="comment">// wait for flag</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li>There are <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>O</mi><mo stretchy="false">(</mo><mi>P</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">O(P)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">O</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="mclose">)</span></span></span></span> traffic on interconnects per barrier.<br />All threads have <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>2</mn><mi>P</mi></mrow><annotation encoding="application/x-tex">2P</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord">2</span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span></span></span></span> write transactions to obtain barrier lock and update the counter. <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>O</mi><mo stretchy="false">(</mo><mi>P</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">O(P)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">O</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="mclose">)</span></span></span></span> traffic assuming lock acquisition is implemented in <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>O</mi><mo stretchy="false">(</mo><mn>1</mn><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">O(1)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">O</span><span class="mopen">(</span><span class="mord">1</span><span class="mclose">)</span></span></span></span> manner<br />Last thread has <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>2</mn></mrow><annotation encoding="application/x-tex">2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">2</span></span></span></span> write transactions to write to the flag and reset the counter. <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>O</mi><mo stretchy="false">(</mo><mi>P</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">O(P)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">O</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="mclose">)</span></span></span></span> traffic since there are many sharers of the flag<br /><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>P</mi><mo>−</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">P-1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.76666em;vertical-align:-0.08333em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">1</span></span></span></span> transactions to read updated flag</li><li>In a centralized barrier, all threads share a single barrier lock and counter, which causes high contention.</li><li>Combining trees makes better use of parallelism in interconnect topologies, which has <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>l</mi><mi>o</mi><mi>g</mi><mi>P</mi></mrow><annotation encoding="application/x-tex">logP</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord mathnormal" style="margin-right:0.01968em;">l</span><span class="mord mathnormal">o</span><span class="mord mathnormal" style="margin-right:0.03588em;">g</span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span></span></span></span> span (latency). This strategy makes less sense on a bus where all traffic is still serialized on a shared bus.<br />Barrier acquire: when the processor arrives at the barrier, performs increment of parent counter. Process recurses to root.<br />Barrier release: beginning from the root, notify children of the release.</li></ol><h1 id="locks-in-cuda-assignment-3"><a class="markdownIt-Anchor" href="#locks-in-cuda-assignment-3"></a> Locks in CUDA (Assignment 3)</h1><ol><li><p>CUDA has provided <code>atomicCAS</code> and <code>atomicExch</code>. But if we use the following code to implement the mutex, threads will end up in a dead loop.<br />All warps in a block need to execute the same instructions. However, only one thread can have the lock; at most, one thread in a block can leave the loop, and hence, the whole block, including the one with the lock, will keep executing the <code>atomicCAS</code>. The thread with a loop cannot execute anything in a critical area and unlock the lock, which causes all threads to end up in the dead loop of the <code>lock</code>.</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">__share__ <span class="type">int</span> mutex;</span><br><span class="line"></span><br><span class="line"><span class="function">__device__ <span class="type">void</span> <span class="title">lock</span><span class="params">(<span class="type">int</span>* mutex)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">  <span class="keyword">while</span>(<span class="built_in">atomicCAS</span>(mutex, <span class="number">0</span>, <span class="number">1</span>)) ;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function">__device__ <span class="type">void</span> <span class="title">unlock</span><span class="params">(<span class="type">int</span>* mutex)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">  <span class="built_in">atomicExch</span>(mutex, <span class="number">0</span>);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function">__global__ <span class="type">void</span> <span class="title">kernel</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">  <span class="built_in">lock</span>(&amp;mutex);</span><br><span class="line">  <span class="comment">// critical code</span></span><br><span class="line">  <span class="built_in">unlock</span>(&amp;mutex);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>The method to solve the problem must also consider the special execution mode of condition instruction in CUDA. A loop is necessary, but we want to execute the instruction inside a condition body so that when one thread grabs the lock, it can execute and unlock the lock before the next iteration.<br />So, we can have an <code>if</code> condition inside the loop, such as the following code.</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">__share__ <span class="type">int</span> mutex;</span><br><span class="line"></span><br><span class="line"><span class="function">__kernel__ <span class="type">void</span> <span class="title">kernel</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">  <span class="type">bool</span> leaveLoop = <span class="literal">false</span>;</span><br><span class="line">  <span class="keyword">while</span> (!leaveLoop)</span><br><span class="line">  &#123;</span><br><span class="line">    <span class="keyword">if</span> (<span class="built_in">atomicExch</span>(&amp;mutex, <span class="number">1</span>))</span><br><span class="line">    &#123;</span><br><span class="line">      <span class="comment">// critical cade</span></span><br><span class="line">      leaveLoop = <span class="literal">true</span>;      <span class="comment">// this thread can leave the loop, but it need to </span></span><br><span class="line">                             <span class="comment">// wait for other threads in its block</span></span><br><span class="line">      <span class="built_in">atomicExch</span>(&amp;mutex, <span class="number">0</span>); <span class="comment">// unlock the lock, so that in next iteration, </span></span><br><span class="line">                             <span class="comment">// some other threads can have the lock and finish</span></span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li></ol>]]></content>
      
      
      <categories>
          
          <category> Open Courses </category>
          
          <category> CMU 15-418 / Stanford CS149 Parallel Computing </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Parallelism </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>12. Interconnection Network</title>
      <link href="/2022/07/13/Courses/CS149/12-Interconnection-Network/"/>
      <url>/2022/07/13/Courses/CS149/12-Interconnection-Network/</url>
      
        <content type="html"><![CDATA[<h1 id="interconnection"><a class="markdownIt-Anchor" href="#interconnection"></a> Interconnection</h1><ol><li>All parallel processors are connected and form an interconnection network.</li><li>The interconnection network connects processor cores with other cores, processors and memories, processor cores, and caches, caches, caches, and I/O devices.</li><li>The design of the interconnection network has an important impact on system scalability (How large of a system can be built? How easy is it to add more nodes?), system performance, and energy efficiency (How fast can cores, caches, and memory communicate? How long is latency to memory? How much energy is spent on communication?)</li></ol><h2 id="terminology"><a class="markdownIt-Anchor" href="#terminology"></a> Terminology</h2><ol><li><strong>Network node</strong>: a network endpoint connected to a router/switch, like the processor, the cache controller, or the memory controller</li><li><strong>Network interface</strong>: Connects nodes to the network</li><li><strong>Switch/router</strong>: Connects a fixed number of input links to a fixed number of output links</li><li><strong>Link</strong>: A bundle of wires carrying a signal<br /><img src="/imgs/CS149/12/1.png" width="40%"></li></ol><h2 id="design-issues"><a class="markdownIt-Anchor" href="#design-issues"></a> Design issues</h2><ol><li><strong>Topology</strong>: How switches are connected via links. Affects routing, throughput, latency, and complexity/cost of implementation.</li><li><strong>Routing</strong>: How a message gets from its source to its destination in the network. Can be static (messages take a predetermined path) or adaptive based on load.</li><li><strong>Buffering and flow control</strong>: What data are stored in the network? Packets, partial packets? Etc. How does the network manage buffer space?</li></ol><h2 id="properties-of-interconnect-topology"><a class="markdownIt-Anchor" href="#properties-of-interconnect-topology"></a> Properties of interconnect topology</h2><ol><li><strong>Routing distance</strong>: Number of links (“hops”) along a route between two nodes</li><li><strong>Diameter</strong>: the maximum routing distance</li><li><strong>Average distance</strong>: average routing distance over all valid routes</li><li><strong>Direct network</strong>: The switches and nodes are one in the same. The logic of the switch is built into the node itself.</li><li><strong>Indirect network</strong>: The switches are distinct from the nodes, forming a chain from one node to another.</li><li><strong>Blocking or non-blocking</strong>: The network is non-blocking if connecting any pairing of nodes simultaneously won’t cause conflict (using the same link or switch, assuming that one switch can only handle one message simultaneously). Otherwise, it is blocking.</li><li><strong>Bisection bandwidth</strong>: A measure of how much connectivity is in the network. If we cut the network in half, it is the connection between those two halves, namely the sum bandwidth of all severed links.<br />The low bisection bandwidth will be the choke point of the network.</li><li>Latency increases with load (throughput).<br />The topology, routing algorithm, and flow control have their minimum latency. The zero load or idle latency is the sum of the three min latencies.<br />Also, the topology, routing algorithm, and flow control have their throughput limit. The overall throughput limit is the min of the three limits.</li></ol><h1 id="interconnect-topologies"><a class="markdownIt-Anchor" href="#interconnect-topologies"></a> Interconnect topologies</h1><h2 id="bus"><a class="markdownIt-Anchor" href="#bus"></a> Bus</h2><ol><li><p>Physically, a bus is a wire. But from a graph point of view, a bus is a switch.</p></li><li><p>It is simple to design. It is cost-effective for a small number of nodes. It is easy to implement coherence via snooping.</p></li><li><p>Contention: all nodes contend for shared bus</p></li><li><p>Limited bandwidth: all nodes communicate over the same wires, and only one communication is allowed simultaneously.</p></li><li><p>There is a scalability problem. It is expensive to drive wires across the whole chips. There is quite a lot of power in driving signals on the bus.</p><img src="/imgs/CS149/12/2.png" width="40%"></li></ol><h2 id="crossbar"><a class="markdownIt-Anchor" href="#crossbar"></a> Crossbar</h2><ol><li><p>Every node is connected to every other node by a direct connection. The network is non-blocking and indirect (the network is indirect, but the nodes are connected directly).</p></li><li><p>It has <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>O</mi><mo stretchy="false">(</mo><mn>1</mn><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">O(1)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">O</span><span class="mopen">(</span><span class="mord">1</span><span class="mclose">)</span></span></span></span> latency and high bandwidth.</p></li><li><p>It also has a scalability problem since <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>O</mi><mo stretchy="false">(</mo><msup><mi>N</mi><mn>2</mn></msup><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">O(N^2)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.064108em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">O</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.10903em;">N</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141079999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span> switches are required. Also, it is expensive and difficult to arbitrate at scale.</p></li><li><p>Crossbars have been used in Oracle’s recent multi-core processing. The crossbar (CCX) occupies about the same chip area as a core in a multi-core chip.</p><img src="/imgs/CS149/12/3.png" width="40%"></li></ol><h2 id="ring"><a class="markdownIt-Anchor" href="#ring"></a> Ring</h2><ol><li><p>It lets the message to circle.</p></li><li><p>It is simple enough and relatively cheap, with only <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>O</mi><mo stretchy="false">(</mo><mi>N</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">O(N)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">O</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.10903em;">N</span><span class="mclose">)</span></span></span></span> cost.</p></li><li><p>But the latency is <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>O</mi><mo stretchy="false">(</mo><mi>N</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">O(N)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">O</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.10903em;">N</span><span class="mclose">)</span></span></span></span>, which is very high. The bisection bandwidth remains constant as nodes are added, which will cause the scalability problem.</p></li><li><p>It is used in recent Intel architectures, Core i7, and IBM CELL Broadband Engine. This is usually used on the ring scale of 4 or 8 elements.</p></li><li><p>Intel’s ring interconnect has four rings (request, snoop, ack, 32 bytes of data) and six interconnect nodes (four “slices” of L3 cache, system agent, and graphics). Each bank of L3 connected to the ring bus twice.</p><img src="/imgs/CS149/12/4.png" width="40%"></li></ol><h2 id="mesh"><a class="markdownIt-Anchor" href="#mesh"></a> Mesh</h2><ol><li><p>This is a direct network. It echoes locality in grid-based applications.</p></li><li><p>The cost is <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>O</mi><mo stretchy="false">(</mo><mi>N</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">O(N)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">O</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.10903em;">N</span><span class="mclose">)</span></span></span></span>, and the average latency is <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>O</mi><mo stretchy="false">(</mo><msqrt><mi>N</mi></msqrt><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">O(\sqrt{N})</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.176665em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">O</span><span class="mopen">(</span><span class="mord sqrt"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.9266650000000001em;"><span class="svg-align" style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord" style="padding-left:0.833em;"><span class="mord mathnormal" style="margin-right:0.10903em;">N</span></span></span><span style="top:-2.886665em;"><span class="pstrut" style="height:3em;"></span><span class="hide-tail" style="min-width:0.853em;height:1.08em;"><svg width='400em' height='1.08em' viewBox='0 0 400000 1080' preserveAspectRatio='xMinYMin slice'><path d='M95,702c-2.7,0,-7.17,-2.7,-13.5,-8c-5.8,-5.3,-9.5,-10,-9.5,-14c0,-2,0.3,-3.3,1,-4c1.3,-2.7,23.83,-20.7,67.5,-54c44.2,-33.3,65.8,-50.3,66.5,-51c1.3,-1.3,3,-2,5,-2c4.7,0,8.7,3.3,12,10s173,378,173,378c0.7,0,35.3,-71,104,-213c68.7,-142,137.5,-285,206.5,-429c69,-144,104.5,-217.7,106.5,-221l0 -0c5.3,-9.3,12,-14,20,-14H400000v40H845.2724s-225.272,467,-225.272,467s-235,486,-235,486c-2.7,4.7,-9,7,-19,7c-6,0,-10,-1,-12,-3s-194,-422,-194,-422s-65,47,-65,47zM834 80h400000v40h-400000z'/></svg></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.11333499999999996em;"><span></span></span></span></span></span><span class="mclose">)</span></span></span></span>.</p></li><li><p>It is easy to lay out on a chip since all links have a fixed length.</p></li><li><p>Path diversity: many ways for the message to travel from one node to another</p><img src="/imgs/CS149/12/5.png" width="40%"></li></ol><h2 id="torus"><a class="markdownIt-Anchor" href="#torus"></a> Torus</h2><ol><li><p>Characteristics of nodes in mesh topology are different based on whether the node is near the edge or middle of the network. Torus topology introduces new links to avoid this problem.</p></li><li><p>In torus topology, each row or column forms a ring by adding a new link to connect the two nodes on the edge.</p></li><li><p>Its cost is still <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>O</mi><mo stretchy="false">(</mo><mi>N</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">O(N)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">O</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.10903em;">N</span><span class="mclose">)</span></span></span></span>, but higher than 2D mesh. It also has higher path diversity and bisection bandwidth than mesh.</p></li><li><p>However, it has higher complexity and is difficult to layout on a chip because of its unequal link lengths.</p></li><li><p>Folded torus interleaving rows and columns to eliminate the need for long connections. All connections are doubled in length.</p><img src="/imgs/CS149/12/6.png" width="40%"></li></ol><h2 id="tree"><a class="markdownIt-Anchor" href="#tree"></a> Tree</h2><ol><li><p>This is a planar, hierarchical topology. Like mesh/torus, it performs well when traffic has a locality.</p></li><li><p>The latency is <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>O</mi><mo stretchy="false">(</mo><mi>l</mi><mi>o</mi><mi>g</mi><mi>N</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">O(logN)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">O</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.01968em;">l</span><span class="mord mathnormal">o</span><span class="mord mathnormal" style="margin-right:0.03588em;">g</span><span class="mord mathnormal" style="margin-right:0.10903em;">N</span><span class="mclose">)</span></span></span></span></p></li><li><p>If the signal needs to go upward in tree routing, there is only one option. If the signal needs to go downward, we can use <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>0</mn></mrow><annotation encoding="application/x-tex">0</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">0</span></span></span></span> to mark go left while <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1</mn></mrow><annotation encoding="application/x-tex">1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">1</span></span></span></span> to mark go right.<br />Every time, the signal will go upward first until having a common ancestor; then, it will go downward.<br />If the tree is complete and we assign numbers to the nodes according to their inorder traversal starting from zero, then the way to each node from the root node is the binary code of the number.</p></li><li><p>A fat tree increases bandwidth between nodes as it moves upward. It can alleviate root bandwidth problems with higher bandwidth links near the root.</p></li><li><p>The number of wires is the same as the height of the subtree. So, the bisection bandwidth of the fat tree is <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>O</mi><mo stretchy="false">(</mo><mi>N</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">O(N)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">O</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.10903em;">N</span><span class="mclose">)</span></span></span></span>.</p></li><li><p>The fat tree routing is similar to tree routing but randomly chooses when multiple links are possible.</p></li><li><p>Constant-width fat tree (folded clos network): All nodes have fixed degrees, which makes the hardware design simpler. This is used in Infiniband networks.</p><p><img src="/imgs/CS149/12/7.png" width="30%"><img src="/imgs/CS149/12/8.png" width="30%"><img src="/imgs/CS149/12/9.png" width="30%"></p></li></ol><h2 id="hypercube"><a class="markdownIt-Anchor" href="#hypercube"></a> Hypercube</h2><ol><li><p>It has a low latency of <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>O</mi><mo stretchy="false">(</mo><mi>l</mi><mi>o</mi><mi>g</mi><mi>N</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">O(logN)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">O</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.01968em;">l</span><span class="mord mathnormal">o</span><span class="mord mathnormal" style="margin-right:0.03588em;">g</span><span class="mord mathnormal" style="margin-right:0.10903em;">N</span><span class="mclose">)</span></span></span></span>. Its number of links is <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>O</mi><mo stretchy="false">(</mo><mi>N</mi><mi>l</mi><mi>o</mi><mi>g</mi><mi>N</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">O(NlogN)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">O</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.10903em;">N</span><span class="mord mathnormal" style="margin-right:0.01968em;">l</span><span class="mord mathnormal">o</span><span class="mord mathnormal" style="margin-right:0.03588em;">g</span><span class="mord mathnormal" style="margin-right:0.10903em;">N</span><span class="mclose">)</span></span></span></span>.</p></li><li><p>6D hypercube used in 64-core Cosmic Cube computer developed at Caltech in the 80s.</p></li><li><p>If the address of two nodes only differs by one bit, then a link connects them.<br />So, if we want to go from address A to address B, we do it one bit at a time.</p></li><li><p>The problem is that we cannot pack more dimensions into 3D that exists. We need to put enough wires in to make it work to implement a higher-dimension cube. But as we scale up more and more, the wires become so much that they don’t layout well.</p><img src="/imgs/CS149/12/10.png" width="40%"></li></ol><h2 id="multi-stage-logarithmic"><a class="markdownIt-Anchor" href="#multi-stage-logarithmic"></a> Multi-stage logarithmic</h2><ol><li><p>It is an indirect network with multiple switches between terminals.</p></li><li><p>The cost is <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>O</mi><mo stretchy="false">(</mo><mi>N</mi><mi>l</mi><mi>o</mi><mi>g</mi><mi>N</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">O(NlogN)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">O</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.10903em;">N</span><span class="mord mathnormal" style="margin-right:0.01968em;">l</span><span class="mord mathnormal">o</span><span class="mord mathnormal" style="margin-right:0.03588em;">g</span><span class="mord mathnormal" style="margin-right:0.10903em;">N</span><span class="mclose">)</span></span></span></span> while the latency is <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>O</mi><mo stretchy="false">(</mo><mi>l</mi><mi>o</mi><mi>g</mi><mi>N</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">O(logN)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">O</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.01968em;">l</span><span class="mord mathnormal">o</span><span class="mord mathnormal" style="margin-right:0.03588em;">g</span><span class="mord mathnormal" style="margin-right:0.10903em;">N</span><span class="mclose">)</span></span></span></span>.</p></li><li><p>It has many variations: Omega, butterfly, Clos networks, etc.</p></li><li><p>In the topology shown below, each switch has two output wires. In the routing, if 0 stands for up and 1 for down, we can also route according to the binary code of the number of targeting nodes.<br />Here, up means we will take the upper wire, and down means we will take the lower wire. They don’t always mean going up or going down.</p><img src="/imgs/CS149/12/11.png" width="40%"></li></ol><h1 id="buffering-and-flow-control"><a class="markdownIt-Anchor" href="#buffering-and-flow-control"></a> Buffering and flow control</h1><ol><li>Circuit switching sets up a full path (acquires all resources) between sender and receiver before sending a message. It has higher bandwidth transmission.<br />It has no per-packet link management overhead but does incur overhead to set up/tear down the path. Reserving links can result in low utilization.</li><li>Packet switching makes routing decisions per packet. It can use a link for a packet whenever a link is idle.<br />It has overhead due to dynamic switching logic during transmission but no setup/tear-down overhead.</li><li>The communication granularity from larger to miner is message, packet, and flit.<br />A message is the transfer unit between network clients and can be transmitted using many packets.<br />The packet is the unit of transfer for the network and can be transmitted using multiple flits.<br />Flit (flow control digit) is a network flow control unit. Packets broken into flits.</li><li>A packet consists of a header, payload/body, and tail.<br />The header contains routing and control information; at the start of the packet, the router can start forwarding early.<br />The payload/body contains the data to be sent.<br />The tail contains control information, like an error code, and is generally located at the end of the packet so it can be generated “on the way out.”</li><li>When two packets need to be routed onto the same outbound link simultaneously, contention occurs. There are three options: buffer one packet and send it over the link later, drop one packet, or reroute one packet (deflection).</li></ol><h2 id="circuit-switched-routing"><a class="markdownIt-Anchor" href="#circuit-switched-routing"></a> Circuit-switched routing</h2><ol><li>Main idea: pre-allocate all resources (links across multiple switches) along the entire network path for a message (“setup a flow”)</li><li>Costs:<br />Needs a setup phase (“probe”) to set up the path (and to tear it down and release the resources when the message is complete)<br />Lower link utilization. Transmission of two messages cannot share the same link (even if some resources on a preallocated path are no longer utilized during a transmission)</li><li>Benefits:<br />No contention during transmission due to preallocation, so no need for buffering<br />Arbitrary message sizes (once the path is set up, send data until done)</li></ol><h2 id="packet-based-flow-control"><a class="markdownIt-Anchor" href="#packet-based-flow-control"></a> Packet-based flow control</h2><ol><li>Store-and-forward: Packet copied entirely into network switch before moving to next node, which requires buffering for the entire packet in each router</li><li>The flow control unit is an entire packet. Different packets from the same message can take different routes, but all data in a packet is transmitted over the same route.</li><li>Store-and-forward has high per-packet latency. Its latency <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>=</mo></mrow><annotation encoding="application/x-tex">=</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.36687em;vertical-align:0em;"></span><span class="mrel">=</span></span></span></span> packet transmission time on the link <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>×</mo></mrow><annotation encoding="application/x-tex">\times</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.66666em;vertical-align:-0.08333em;"></span><span class="mord">×</span></span></span></span> network distance)</li><li>Cut-through flow control: The switch starts forwarding data to the next link as soon as the packet header is received since the header determines how much link bandwidth the packet requires and where to route.</li><li>Cut-through flow control reduces transmission latency and reduces store-and-forward under high contention.</li><li>The latency of cut-through flow control is header transmission time. <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>×</mo></mrow><annotation encoding="application/x-tex">\times</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.66666em;vertical-align:-0.08333em;"></span><span class="mord">×</span></span></span></span> network distance <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>+</mo></mrow><annotation encoding="application/x-tex">+</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.66666em;vertical-align:-0.08333em;"></span><span class="mord">+</span></span></span></span> rest packet transmission time on one link <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>≃</mo></mrow><annotation encoding="application/x-tex">\simeq</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.46375em;vertical-align:0em;"></span><span class="mrel">≃</span></span></span></span> network distance <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>+</mo></mrow><annotation encoding="application/x-tex">+</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.66666em;vertical-align:-0.08333em;"></span><span class="mord">+</span></span></span></span> number of packets.</li><li>The difference between store-and-forward and cut-through is whether we parallel the header transmission and the rest of the packet.</li><li>In cut-through flow control, if the output link is blocked (cannot transmit head), the transmission of the tail can continue. So, the switch needs to store more data before transmitting and deleting them, which requires switches to have buffering for the entire packet, just like store-and-forward.<br />The worst case is that the entire message is absorbed into a buffer in a switch, namely cut-through flow control degenerates to store-and-forward in this case.</li></ol><h2 id="wormhole-flow-control"><a class="markdownIt-Anchor" href="#wormhole-flow-control"></a> Wormhole flow control</h2><ol><li>Routing information is only in the head flit; body flits follow the head, and tail flit flows through the body. All flits move to their next switch simultaneously. If the head flit blocks, the rest of the packet stops.</li><li>Its latency <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>=</mo></mrow><annotation encoding="application/x-tex">=</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.36687em;vertical-align:0em;"></span><span class="mrel">=</span></span></span></span> header transmission time <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>×</mo></mrow><annotation encoding="application/x-tex">\times</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.66666em;vertical-align:-0.08333em;"></span><span class="mord">×</span></span></span></span></li><li>Head-of-line blocking problem: The route of the head flit of one packet is free but blocked behind the flit of another packet in the buffer while that packet is blocked, waiting for a busy link.</li><li>Virtual channel flow control: Multiplex multiple operations over a single physical channel and divide the switch’s input buffer into multiple buffers sharing a single physical channel.</li><li>Virtual channel reduces head-of-line blocking.<br />It can break the cyclic dependency of resources by ensuring requests and responses use different virtual channels to avoid deadlock.<br />Also, it provided quality-of-service guarantees. Some virtual channels have higher priority than others.</li><li>“Escape” virtual channels: retain at least one virtual channel that uses deadlock-free routing.</li></ol>]]></content>
      
      
      <categories>
          
          <category> Open Courses </category>
          
          <category> CMU 15-418 / Stanford CS149 Parallel Computing </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Parallelism </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>11. Memory Consistency</title>
      <link href="/2022/07/10/Courses/CS149/11-Memory-Consistency/"/>
      <url>/2022/07/10/Courses/CS149/11-Memory-Consistency/</url>
      
        <content type="html"><![CDATA[<h1 id="consistency"><a class="markdownIt-Anchor" href="#consistency"></a> Consistency</h1><h2 id="definition"><a class="markdownIt-Anchor" href="#definition"></a> Definition</h2><ol><li>In a correctly behaved parallel memory hierarchy, reading a location should return the latest value written by any thread.<br />Side-effects of writes are only observable when reads occur so that we will focus on the values returned by reads.</li><li>Within a thread, “latest” can be defined by program order. But when it comes across threads, we don’t want it to be physical time because there is no way that the hardware can pull that off. If it takes &gt;10 cycles to communicate between processors, there is no way that processor 0 can know what processor 1 did 2 clock ticks ago.</li><li>Writes from any particular thread must be consistent with program order. Writes across threads must be consistent with valid interleaving of threads.<br />We define the memory model as one in which each thread proceeds in program order, and memory accesses interleaved (one at a time) to a single-ported memory while the rate of progress of each thread is unpredictable.<br />“Latest” means consistent with some interleaving that matches this model.</li></ol><h2 id="hide-memory-latency"><a class="markdownIt-Anchor" href="#hide-memory-latency"></a> Hide memory latency</h2><ol><li>Idea: overlap memory accesses with other accesses and computation</li><li>“Out of order” pipelining: When an instruction is stuck, perhaps subsequent instructions can be executed.</li><li>We don’t need to wait for a conditional branch to be resolved before proceeding. Just predict the branch outcome and continue executing speculatively. If the prediction is wrong, squash any side effects and restart down the correct path.</li><li>Modern processors fetch and graduate instructions in order but issue out-of-order. So, intra-thread dependencies are preserved, but memory accesses get reordered.</li><li>Hiding write latency is simple in uniprocessors, adding a write buffer. But this affects correctness in multiprocessors.<br />In a multiprocessor, a write buffer or write-back cache might cause later writes to write earlier to memory, and accesses issued in order may be observed out of order by other processors.</li></ol><h1 id="sequential-consistency-sc-model"><a class="markdownIt-Anchor" href="#sequential-consistency-sc-model"></a> Sequential consistency (SC) model</h1><ol><li>Each processor’s access is in program order, and all accesses appear in sequential order. Any order implicitly assumed by the programmer is maintained. Any order implicitly assumed by the programmer is maintained.</li><li>How to implement sequential consistency:<br />Implement cache coherence: writes to the same location are observed in the same order by all processors<br />For each processor, delay the start of memory access until the previous one is complete. Namely, each processor has only one outstanding memory access at a time.</li><li>A read completes when its return value is bound.<br />A write completes when the new value is “visible” to other processors. “Visible” does not mean that other processors have necessarily seen the value yet. The new value is committed to the hypothetical serializable order (HSO).</li><li>The strict requirements of the SC model severely restrict common hardware and compiler optimizations.<br />Processor issues access one at a time and stalls for completion, which results in Low processor utilization even with caching.</li><li>Total store ordering (TSO) model: Compared to the SC model, a read operation doesn’t need to stall to wait for an earlier write operation. This is similar to the architecture with a FIFO write buffer.</li><li>Partial store ordering (PSO) model: Compared to the TSO model, even a write operation doesn’t need to stall to wait for an earlier write operation. This architecture has a write buffer that doesn’t have to be FIFO.</li></ol><h1 id="optimization"><a class="markdownIt-Anchor" href="#optimization"></a> Optimization</h1><ol><li>Most programs don’t require strict ordering (all of the time) for correctness. Here, correctness means the same results as sequential consistency.</li><li>Two accesses conflict if they access the same location; at least one is a write.</li><li>We can order accesses by program order (PO) and dependence order (DO). Operation2 is dependent on operation1 if operation2 reads operation1.</li><li>Data Race is two conflicting accesses on different processors, not ordered by intervening accesses.</li><li>Properly synchronized programs are where all synchronizations are explicitly identified, and all data accesses are ordered through synchronization.</li><li>Many parallel programs have mixtures of “private” and “public” parts.  The “private” parts must be protected by synchronization,  like locks and unlocks.<br />Between synchronization operations, we can allow memory operations to be reordered as long as intra-thread dependencies are preserved.<br />Just before and just after synchronization operations, the thread must wait for all prior operations to complete</li><li>MFENCE does not begin until all prior reads &amp; writes from that thread have completed, and no subsequent read or write from that thread can start until after it finishes. Xchg does this implicitly.<br />MFENCE operation does not push values out to other threads. It simply stalls the thread that performs the MFENCE until the write buffer is empty.<br />MFENCE operations create partial orderings that are observable across threads.</li><li>In the weak ordering model, we put MFENCEs before the lock operation and after the unlock operation.</li><li>Lock operation: only gains (“acquires”) permission to access data. Unlock operation: only gives away (“releases”) permission to access data.<br />The Release Consistency (RC) model ensures that writes before the lock or in the critical section are completed before the exit critical section and that reads/writes in the critical section or after the exit critical section doesn’t access the shared state until the lock is acquired.</li><li>LFENCE serializes only with respect to load operations, and SFENCE serializes only with respect to store operations. In practice, MFENCE and xchg are the most likely used ones.</li><li>Like Peterson’s algorithm, don’t use only normal memory operations for synchronization. Do use either explicit synchronization operations, like xchg (atomic), or fences.</li></ol>]]></content>
      
      
      <categories>
          
          <category> Open Courses </category>
          
          <category> CMU 15-418 / Stanford CS149 Parallel Computing </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Parallelism </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>10. Snooping Implementation</title>
      <link href="/2022/07/07/Courses/CS149/10-Snooping-Implementation/"/>
      <url>/2022/07/07/Courses/CS149/10-Snooping-Implementation/</url>
      
        <content type="html"><![CDATA[<h1 id="building-with-an-atomic-bus"><a class="markdownIt-Anchor" href="#building-with-an-atomic-bus"></a> Building with an atomic bus</h1><h2 id="transaction"><a class="markdownIt-Anchor" href="#transaction"></a> Transaction</h2><ol><li>There is a bus controller to do arbitration. If a processor wants to communicate on the bus, it has to make a request. If there are simultaneous requests from multiple processors, the arbiter will only grant one of them.</li><li>A transaction on an atomic bus generally needs four steps.<br />The client is granted bus access (the result of arbitration). The client places command on the bus (may also place data on the bus).<br />Response to command by another bus client placed on the bus. Next, the client obtains bus access (arbitration)</li><li>In a multi-processor with an atomic bus scenario, no other bus transactions are allowed between issuing addresses and receiving data when one processor wants to read. Also, when flush occurs, address and data are sent simultaneously and received by memory before any other transaction is allowed.</li><li>Both requests from the processor and bus require to look the tag on the cache.<br />If the bus receives priority during the bus transaction, the processor is locked out of its cache.<br />If the processor receives priority during processor cache accesses, the cache cannot respond with its snoop result. So, it delays other processors even if no sharing of any form is present.</li><li>We can alleviate contention to allow simultaneous access by processor-side and snoop controllers through cache duplicate tags or multi-ported tag memory. In either case, the additional performance cost is additional hardware resources.<br />Tags must stay in sync for correctness, so tag updates by one controller will still need to block the other controller, but modifying tags is infrequent compared to checking them.</li></ol><h2 id="read-miss"><a class="markdownIt-Anchor" href="#read-miss"></a> Read miss</h2><ol><li>Memory needs to know what to do when a cache read miss occurs. If the line is dirty, memory should not respond. And the loading cache needs to know what to do. If the line is shared, the cache should load into the S state, not E.</li><li>If one cache controller finds that the line is shared in its cache, it will send a message through the “shared” wire on the bus. If that line is dirty, the controller will send a message through the “dirty” wire on the bus.<br />Every time a processor responds to a snoop, the value in the “snoop-pending” wire will be lower and <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>0</mn></mrow><annotation encoding="application/x-tex">0</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">0</span></span></span></span> value indicates that all processors have reacted.</li><li>The memory controller could immediately start accessing DRAM but not respond (squelch response). If a snoop result from another cache indicates it has a copy of the most recent data, then the cache should provide data, not memory. The memory could assume one of the caches will service request until the snoop results are valid. If snoop indicates no cache has data, then memory must respond.</li></ol><h2 id="write-back"><a class="markdownIt-Anchor" href="#write-back"></a> Write back</h2><ol><li>Write-backs involve two bus transactions: incoming line (line requested by the processor) and outgoing line (evicted dirty line in the cache that must be flushed).<br />Ideally, we would like the processor to continue as soon as possible; it shouldn’t have to wait for the flush to complete.</li><li>The solution is a write-back buffer.<br />The stick line is to be flushed in a write-back buffer. Immediately load the requested line to allow the processor to continue. Flush contents of the write-back buffer at a later time.</li><li>If a request from another processor for the data address in the write-back buffer appears on the bus, the snoop controller must check the write-back buffer addresses and cache tags.<br />If there is a write-back buffer match, the controller will respond with data from the write-back buffer rather than cache and cancel the outstanding bus access requests.</li><li>A write commits when a read-exclusive transaction appears on the bus and is acknowledged by all other caches. All future reads will reflect the value of this write, even if data from P has not yet been written to P’s dirty cache line or memory.<br />The order of transactions on the bus defines the global order of writes in the parallel program.</li><li>“Commit” is not “complete”. A write completes when the updated value is in the cache line.</li></ol><h2 id="race-conditions"><a class="markdownIt-Anchor" href="#race-conditions"></a> Race conditions</h2><ol><li>Coherence protocol state transition diagrams assumed that transitions between states were atomic. However, in practice, state transitions are not atomic.</li><li>We’ve assumed the bus transaction itself is atomic, but all the operations the system performs as a result of a memory operation are not.</li><li>The processor, cache, and bus are all resources operating in parallel. They often contend for shared resources: processor and bus contend for cache, while caches contend for bus access.</li><li>The cache must be able to handle requests while waiting to acquire the bus AND be able to modify its outstanding requests.</li><li>To avoid deadlock, the processor must be able to service incoming transactions while waiting to issue requests.</li><li>To avoid livelock, a write that obtains exclusive ownership must be allowed to complete before exclusive ownership is relinquished.</li><li>Multiple processors competing for bus access must be careful to avoid (or minimize the likelihood of) starvation.</li><li>Performance optimization often entails splitting operations into several smaller transactions. Splitting costs in more hardware is needed to exploit additional parallelism, and care is needed to ensure abstractions still hold.</li></ol><h1 id="building-with-non-atomic-bus"><a class="markdownIt-Anchor" href="#building-with-non-atomic-bus"></a> Building with non-atomic bus</h1><ol><li>Problem with atomic bus: the bus is idle while the response is pending, which decreases effective bus bandwidth. The interconnect is a limited, shared resource in a multi-processor system. So it is important to use it as efficiently as possible.</li><li>Bus transactions are split into two transactions: the request and the response. Other transactions can intervene between a transaction’s request and response.</li><li>Basic design:<br />Up to eight outstanding requests at a time (system-wide)<br />Responses need not occur in the same order as requests. However, the request order establishes the total order for the system.<br />Flow control via negative acknowledgments (NACKs). The client can NACK a transaction when a buffer is full, causing a retry.</li><li>We can think of a split-transaction bus as two separate buses, a request bus, and a response bus.<br />The request bus has lines for command and address. The response bus has lines for data and response tags. Response tag has 3 bits to represent 8 requests.</li></ol><h2 id="read-miss-2"><a class="markdownIt-Anchor" href="#read-miss-2"></a> Read miss</h2><h3 id="phase-1"><a class="markdownIt-Anchor" href="#phase-1"></a> Phase 1</h3><ol><li>Request arbitration: cache controllers present a request for address to bus (many caches may be doing so in the same cycle)</li><li>Request resolution: address bus arbiter grants access to one of the requestors. Request table entry allocated for the request. Special arbitration lines indicate the tag assigned to the request.</li><li>The bus “winner” places the command/address on the bus.</li><li>Caches perform snoop: look up tags, update cache state, etc. Memory operation commits here. (no bus traffic)</li><li>Caches acknowledge this snoop result is ready or signal they could not complete it in time here.</li></ol><h3 id="phase-2"><a class="markdownIt-Anchor" href="#phase-2"></a> Phase 2</h3><ol><li>Data response arbitration: responder presents intent to respond to request with tag T. (many caches or memory may be doing so in the same cycle)</li><li>Data bus arbiter grants one responder bus access.</li><li>The original requestor signals readiness to receive a response (or lack thereof: the requestor may be busy at this time)</li><li>Then, in phase 3, the Responder places response data on the data bus. Caches present snoop results for requests with the data. The request table entry is freed. Those 3 actions can happen in parallel.</li></ol><h2 id="pipelined-transactions"><a class="markdownIt-Anchor" href="#pipelined-transactions"></a> Pipelined transactions</h2><ol><li>The request bus and response bus can run parallel. So, the response to the last transaction and the request for the next transaction can happen simultaneously. Pipelining may cause out-of-order completion.</li><li>Write-backs and BusUpg transactions do not have a response component. Write-backs acquire access to the request address and data bus as part of the “request” phase. BusUpg does not need any acknowledgment or data.</li><li>Avoid conflicting requests by disallowing them. Each cache has a copy of the request table. Caches do not make requests that conflict with requests in the request table.</li><li>Caches/memory have buffers for receiving data off the bus. If the buffer fills, the client NACKs relevant requests or responses.</li><li>In a parallel system, we use queues to accommodate variable (unpredictable) production and consumption rates. As long as workers, on average, produce and consume at the same rate, all workers can run at full rate. Otherwise, some will stall, waiting for others to accept or produce new input.</li><li>We have queues to track requests and responses between the L1 and L2 caches and between the L2 cache and bus. One queue is for requests and responses from closer (to processor) to farther (L1 to L2 or L2 to bus), and the other is from farther to closer (L2 to L1 or bus to L2).</li><li>This may cause deadlock due to a full queue. Outgoing read requests (initiated by the processor) and incoming read requests (due to another cache) both requests generate responses that require space in the other queue (circular dependency)</li><li>Sizing all buffers to accommodate the maximum number of outstanding requests on the bus is one solution to avoiding deadlock. But a costly one.</li><li>Avoid buffer deadlock with separate request/response queues. Namely, we distinguish whether it is a request or a response.<br />Responses can be completed without generating further transactions. Requests increase queue length, But responses reduce queue length. While attempting to send a stalled request, the cache must be able to service responses. Responses will make progress, eventually freeing up resources for requests.</li></ol>]]></content>
      
      
      <categories>
          
          <category> Open Courses </category>
          
          <category> CMU 15-418 / Stanford CS149 Parallel Computing </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Parallelism </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>09. Directory-Based Cache Coherence</title>
      <link href="/2022/07/06/Courses/CS149/09-Directory-Based-Cache-Cohurence/"/>
      <url>/2022/07/06/Courses/CS149/09-Directory-Based-Cache-Cohurence/</url>
      
        <content type="html"><![CDATA[<h1 id="problems-to-solve"><a class="markdownIt-Anchor" href="#problems-to-solve"></a> Problems to solve</h1><ol><li>The snooping cache coherence protocols relied on broadcasting coherence information to all processors over the chip interconnect. Whenever a cache miss occurs, the triggering cache communicates with all other caches, so the interconnect has heavy traffic.</li><li>The efficiency of the NUMA system does little good if the coherence protocol can’t also be scaled. The processor accesses nearby memory, but it must still broadcast to all other processors to ensure coherence.</li><li>One possible solution is hierarchical snooping, which arranges nodes in a tree and uses snooping coherence at each level. The interconnects involved in communication are as low as possible and kept as local as possible.</li><li>The structure of hierarchical snooping is relatively simple to build.<br />It uses a tree to reduce the conjunction at the center part, but if the workload is not nicely partitioned, then the root of the network can become a bottleneck.<br />It also has larger latencies than direct communication and does not apply to more general network topologies (meshes, cubes)</li></ol><h1 id="directory"><a class="markdownIt-Anchor" href="#directory"></a> Directory</h1><ol><li>Snooping schemes broadcast coherence messages to determine the state of a line in the other caches. The alternative idea is to avoid broadcasting by storing information about the line’s status in one place, namely a “directory.”</li><li>A line is a region of memory that would be cached as a single block. One directory entry corresponds to one line of memory.<br />In a directory entry, there is a dirty bit that indicates the line is dirty in one of the processors’ caches and P presence bits that indicate whether processor P has a line in its cache.</li><li>The NUMA system uses the directory; each processor has a “local” memory and a directory.<br />The home node of a line is the node with memory holding the corresponding data for the line.<br />The requesting node is the node containing the processor requesting line.</li></ol><h2 id="read-and-write"><a class="markdownIt-Anchor" href="#read-and-write"></a> Read and write</h2><ol><li>When a read miss happens:<br />The requesting node will send a read miss message to the home node of the requested line. Then, the home directory checks the entry for the line.<br />If the dirty bit for the cache line is OFF, the home node will respond with contents from memory and set the presence bit of the requesting node to true to indicate that the line is cached by the requesting processor.<br />If the dirty bit for the cache line is ON, the home node will respond with a message providing the identity of the line owner. The requesting node requests data from the owner, and the owner changes the state in the cache to SHARED (read-only) and responds to the requesting node. The owner also responds to the home node, which will clear the dirty bit, update presence bits (both the requesting node and owner cache line), and update memory.</li><li>When a write miss happens:<br />The requesting node will send a write miss message to the home node of the requested line.<br />The home node will respond to the sharer IDs and data to the requesting node.<br />The requesting node will send an invalidation signal to all sharers. After receiving invalidation acks from all sharers, the requesting node can perform write.<br />The home node will update the presence bits (the line is cached by only the requesting node) and dirty bits.</li><li>On reads, the directory tells the requesting node exactly where to get the line from, either from the node (if the line is clean) or the owning node (if the line is dirty). Either way, retrieving data involves only point-to-point communication.</li><li>On writes, the advantage of directories depends on the number of sharers. In the limit, if all caches are sharing data, all caches must be communicated with, just like broadcast in a snooping protocol.</li><li>In general, only a few processors share the line; only a few processors must be told of writes.  The expected number of sharers typically increases slowly with P.</li></ol><h2 id="reduce-storage-overhead"><a class="markdownIt-Anchor" href="#reduce-storage-overhead"></a> Reduce storage overhead</h2><ol><li>Full bit vector directory storage is proportional to <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>P</mi><mo>×</mo><mi>M</mi></mrow><annotation encoding="application/x-tex">P\times M</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.76666em;vertical-align:-0.08333em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">M</span></span></span></span> where <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>P</mi></mrow><annotation encoding="application/x-tex">P</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span></span></span></span> is the number of nodes and <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>M</mi></mrow><annotation encoding="application/x-tex">M</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">M</span></span></span></span> is the number of lines in memory. The storage overhead of the directory is too much, and we do not want it to be DRAM since we need it to run fast.</li><li>One way to reduce storage overhead is to optimize the full-bit vector.<br />Increase cache line size to reduce <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>M</mi></mrow><annotation encoding="application/x-tex">M</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">M</span></span></span></span> term.<br />Group multiple processors into a single directory node to reduce <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>P</mi></mrow><annotation encoding="application/x-tex">P</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span></span></span></span> term. We could use a snooping protocol to maintain coherence among processors in a node or directory across nodes.</li><li>Another way is to limit the sharer pointer. Since data is expected to only be in a few caches simultaneously, storage for a limited number of pointers per directory entry should be sufficient. Only need a list of the nodes holding a valid copy of the line.</li><li>When an overflow in limited pointer schemes occurs, we can revert to broadcast if the broadcast mechanism exists. If no broadcast mechanism is present on the machine, the newest sharer replaces an existing one (must invalidate line in the old sharer’s cache)</li><li>One more way is through the sparse directory.<br />The majority of memory is not resident in the cache. To carry out the coherence protocol, the system only needs to share information for lines currently in some cache. So, most directory entries are empty most of the time.<br />We can add a tag for each directory line to indicate the memory in some cache. The overhead is now <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>P</mi><mo>×</mo><mi>C</mi></mrow><annotation encoding="application/x-tex">P\times C</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.76666em;vertical-align:-0.08333em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.07153em;">C</span></span></span></span> where <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>C</mi></mrow><annotation encoding="application/x-tex">C</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.07153em;">C</span></span></span></span> is the number of lines in each cache.</li></ol><h2 id="reduce-the-number-of-messages-sent"><a class="markdownIt-Anchor" href="#reduce-the-number-of-messages-sent"></a> Reduce the number of messages sent</h2><ol><li>In a read miss to the dirty line, there are five network transactions in total. However, only four of the transactions are on the critical path.</li><li>In intervention forward, the home node requests data from the owner node (intervention read). After the owner has responded, the home node updates the directory and responds to the requesting node with data.<br />Four network transactions in total (less traffic). But all four of the transactions are on the critical path.</li><li>In request forwarding, the home node requests the owner to send data to the requesting node. Then, the owner will simultaneously send data to the requesting node and home node.<br />Four network transactions in total, with only three of the transactions, are on the critical path.</li></ol>]]></content>
      
      
      <categories>
          
          <category> Open Courses </category>
          
          <category> CMU 15-418 / Stanford CS149 Parallel Computing </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Parallelism </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>08. Snooping-based Cache Coherence</title>
      <link href="/2022/06/19/Courses/CS149/08-Snooping-based-Cache-Coherence/"/>
      <url>/2022/06/19/Courses/CS149/08-Snooping-based-Cache-Coherence/</url>
      
        <content type="html"><![CDATA[<h1 id="the-cache-coherence-problem"><a class="markdownIt-Anchor" href="#the-cache-coherence-problem"></a> The cache coherence problem</h1><ol><li>This problem happens in a shared memory multi-processor system. Reading a value at address X should return the last value written to address X by any processor.</li><li>This problem is created by replicating the data stored at address X in local caches (a hardware implementation detail) and cannot be fixed by adding locks.</li><li>Memory coherence problems exist because global storage (main memory) and per-processor local storage (processor caches) implement the abstraction of a single shared address space.</li><li>In a cache hierarchy,<br />L1 and L2 caches are private per core, while cores share the L3 cache in the same chip.<br />L3 cache is split into sectors or banks. Each bank is physically associated with a core but managed hardware-wise as a single coherent unit.<br />L2 and L3 cache communicate through a ring interconnect where most inter-processor actions happen.</li></ol><h2 id="uniprocessor-case"><a class="markdownIt-Anchor" href="#uniprocessor-case"></a> Uniprocessor case</h2><ol><li>Providing coherence is fairly simple on a uniprocessor since writes typically come from one client: the processor. Load operation must examine all pending stores in the store buffer and select the last sequence.</li><li>One exception on a uniprocessor is device I/O via direct memory access (DMA).</li><li>One solution to DMA is that the CPU writes to shared buffers using uncached stores.<br />Another way OS supports this is by marking virtual memory pages containing shared buffers as not-cachable and explicitly flushing pages from the cache when I/O is completed.</li><li>In practice, DMA transfers are infrequent compared to CPU loads and stores (so these heavyweight software solutions are acceptable)</li></ol><h2 id="coherence-definition"><a class="markdownIt-Anchor" href="#coherence-definition"></a> Coherence definition</h2><ol><li>Obeys program order as expected of a uniprocessor system: A read by processor P to address X that follows a write by P to address X should return the value of the write by P (assuming no other processor wrote to X in between)</li><li>Write propagation: A read by processor P1 to address X that follows a write by processor P2 to X returns the written value if the read and write are “sufficiently separated&quot; in time (assuming no other write to X occurs in between)</li><li>Write serialization: Writes to the same address are serialized: two writes to address X by any two processors are observed in the same order by all processors.</li><li>Write propagation means that notification of a write must eventually get to the other processors. Note that precisely when information about the write is propagated is not specified in the definition of coherence.</li></ol><h1 id="implementing-coherence"><a class="markdownIt-Anchor" href="#implementing-coherence"></a> Implementing coherence</h1><ol><li>Software-based solution: OS uses a page-fault mechanism to propagate writes. It can be used to implement memory coherence over clusters of workstations.</li><li>Hardware-based solutions: “snooping&quot;-based coherence implementations and directory-based coherence implementations</li><li>Most modern multi-core CPUs implement cache coherence<br />Discrete GPUs do not implement cache coherence. Overhead of coherence deemed not worth it for graphics and scientific computing applications (NVIDIA GPUs provide single shared L2 + atomic memory operations)<br />But the latest Intel Integrated GPUs do implement cache coherence</li></ol><h2 id="shared-caches"><a class="markdownIt-Anchor" href="#shared-caches"></a> Shared caches</h2><ol><li>One single cache shared by all processors eliminates the problem of replicating the state in multiple caches and makes coherence easy.</li><li>This has obvious scalability problems since the point of a cache is to be local and fast. It also causes interference and contention due to many clients.</li><li>Facilitates fine-grained sharing (overlapping working sets). Loads/stores by one processor might pre-fetch lines for another processor.</li></ol><h2 id="snooping-cache-coherence-schemes"><a class="markdownIt-Anchor" href="#snooping-cache-coherence-schemes"></a> Snooping cache-coherence schemes</h2><ol><li>Main idea: all coherence-related activity is broadcast to all processors</li><li>Cache controllers monitor (“they snoop&quot;) memory operations and react accordingly to maintain memory coherence.</li><li>The cache controller must respond to actions from both ends:<br />It must respond to the Load/Store requests from its local processor<br />It also must respond to coherence-related activity broadcast over the chip’s interconnect.</li><li>The interconnect is between memory and caches possessed by each processor. There is not only memory-cache information but also cache-cache information, limiting the system’s scalability.</li></ol><h3 id="write-through-caches"><a class="markdownIt-Anchor" href="#write-through-caches"></a> Write-through caches</h3><ol><li>For the invalidation-based protocol, when one processor writes into an address, the cache controller broadcasts an invalidation message for other caches to mark that line to invalidation.<br />The next read from other processors will trigger a cache miss.</li><li>Other caches will update their local copies as the information is sent for the update-based protocol.</li><li>States: Valid (V) or Invalid (I)<br />A local processor read (PrRd) always ends at valid. If the operation starts from an invalid state, a message will be sent (BusRd). If it starts from a valid state, no message will be sent.<br />A local processor write (PrWr) always ends in the same state as before the operation (assumes write no-allocate policy) and always sends a message (BusWr).<br />When a write message from another processor is received (BusWr), It always ends in an invalid state.<br /><img src="/imgs/CS149/08/1.jpeg" width="20%"></li><li>Requirements of the interconnect:<br />All write transactions are visible to all cache controllers.<br />All write transactions are visible to all cache controllers in the same order.</li><li>Simplifying assumptions here:<br />Interconnect and memory transactions are atomic<br />The processor waits until previous memory operations are complete before issuing the next memory operation<br />Invalidation applied immediately as part of receiving an invalidation broadcast</li></ol><h1 id="write-back-caches-invalidation-based"><a class="markdownIt-Anchor" href="#write-back-caches-invalidation-based"></a> Write-back caches (Invalidation-based)</h1><ol><li>The dirty state of the cache line now indicates exclusive ownership</li><li>Exclusive: cache is only cache with a valid copy of line (it can safely be written to)<br />Owner: cache is responsible for supplying the line to other processors when they attempt to load it from memory (otherwise, a load from another processor will get stale data from memory)</li><li>A line in the “exclusive&quot; state can be modified without notifying<br />the other caches<br />The processor can only write to lines in the exclusive state. So, they need a way to tell other caches they want exclusive access to the line. They will do this by sending all the other cache messages.<br />When the cache controller snoops a request for exclusive access to the line it contains, it must invalidate the line in its cache.</li></ol><h2 id="msi-write-back-invalidation-protocol"><a class="markdownIt-Anchor" href="#msi-write-back-invalidation-protocol"></a> MSI write-back invalidation protocol</h2><ol><li>Three cache line states:<br />Invalid (I): same as meaning of invalid in uniprocessor cache<br />Shared (S): line valid in one or more caches<br />Modified (M): line valid in exactly one cache (a.k.a. “dirty&quot; or “exclusive&quot; state)</li><li>The local processors have the same operations as a write-through case.<br />The coherence-related bus transactions from remote caches have three kinds:<br />BusRd: obtain a copy of the line with no intent to modify<br />BusRdX: obtain a copy of the line with the intent to modify<br />flush: write dirty line out to memory<br /><img src="/imgs/CS149/08/2.png" width="50%"></li><li>When try to write an invalid line without reading it, the content of the current modified state line will be sent to the new writer.</li><li>Write propagation is achieved via a combination of invalidation on BusRdX and flush from M-state on subsequent BusRd/BusRdX from another processor.</li><li>Write serialization<br />Writes that appear on interconnect are ordered by the order they appear on interconnect (BusRdX)<br />Reads that appear on interconnect are ordered by the order they appear on interconnect (BusRd)<br />Writes that don’t appear on the interconnect (PrWr to line already in M state):<ul><li>The sequence of writes to the line comes between two interconnect transactions for the line</li><li>All writes in sequence are performed by the same processor, P (that processor certainly observes them in correct sequential order)</li><li>All other processors observe notification of these writes only after an interconnect transaction for the line.</li><li>So, all processors see writes in the same order.</li></ul></li></ol><h2 id="mesi-invalidation-protocol"><a class="markdownIt-Anchor" href="#mesi-invalidation-protocol"></a> MESI invalidation protocol</h2><ol><li>MSI requires two interconnect transactions for the common case of reading an address and then writing to it<ul><li>Transaction 1: BusRd to move from I to S state</li><li>Transaction 2: BusRdX to move from S to M state</li></ul></li><li>Solution: add additional state E (“exclusive clean&quot;) to mark the line that has not been modified, but only this cache has a copy of the line<br />This state decouples exclusivity from line ownership (the line is not dirty, so the copy in memory is a valid copy of data)<br />Upgrade from E to M does not require an interconnect transaction.</li><li><img src="/imgs/CS149/08/3.jpeg" width="50%"></li></ol><h2 id="5-stage-invalidation-based-protocol"><a class="markdownIt-Anchor" href="#5-stage-invalidation-based-protocol"></a> 5-stage invalidation-based protocol</h2><ol><li>Who should supply data on a cache miss when the line is in the E or S state of another cache? <br />Can get cache line data from memory, or can get data from another cache? If the source is another cache, which one should provide it?</li><li>Cache-to-cache transfers add complexity but are commonly used to reduce the latency of data access and the memory bandwidth required by the application.</li><li>MESIF: Like MESI, but one cache holds a shared line in the F state rather than S (F=“forward”). Cache with a line in F state services miss<br />Simplifies decision of which cache should service miss (basic MESI: all caches respond)<br />Used by Intel processors</li><li>MOESI: Transition from M to O (O=“owned, but not exclusive”) and do not flush to memory (In MESI protocol, transition from M to S requires flush to memory).<br />Other processors maintain a shared line in the S state, while one maintains a line in the O state. Data in memory is stale, so cache with a line in O state must service cache misses.<br />Used in AMD Opteron</li></ol><h1 id="invalidation-based-vs-update-based"><a class="markdownIt-Anchor" href="#invalidation-based-vs-update-based"></a> Invalidation-based vs. Update-based</h1><ol><li>Invalidation-based protocol: The cache must obtain exclusive access to write to a line. All other caches must invalidate their copies.</li><li>Update-based protocol: Can write to shared copy by broadcasting update to all other copies</li><li>Intuitively, the update would seem preferable if other processors<br />sharing data, continue to access it after a write occurs<br />But updates are overhead if data sits in caches (and is never reread by another processor) or the application performs many writes before the next read</li><li>The update can reduce the cache miss rate since all shared copies remain valid.<br />The update can suffer from high traffic due to multiple writes before the next read by another processor.</li></ol><h1 id="snoop-for-a-cache-hierarchy"><a class="markdownIt-Anchor" href="#snoop-for-a-cache-hierarchy"></a> Snoop for a cache hierarchy</h1><ol><li>Challenge: changes made to data at the L1 cache may not be visible to the L2 cache controller, then snoops the interconnect.</li><li>Inclusion property:<br />All lines closer to the processor cache are also in farther caches. Thus, all transactions relevant to L1 are also relevant to L2, so it is sufficient for only the L2 to snoop the interconnect.<br />If the line is in the owned state (M in MSI/MESI) in L1, it must also be in an owned state in L2. Allows L2 to determine if a bus transaction requests a modified cache line in L1 without requiring information from L1.</li><li>Even if L2 is larger than L1, the inclusion cannot be maintained automatically. L1 and L2 might evict different lines because the access histories differ.</li><li>When line X is invalidated in the L2 cache due to BusRdX from another cache. Must also invalidate line X in L1<br />Solution: Each L2 line contains an additional state bit indicating if the line also exists in L1. This bit tells the L2 invalidations of the cache line due to coherence traffic need to be propagated to L1.</li><li>When the L1 write is hit, the corresponding line in the L2 cache is in the modified state in the coherence protocol, but the L2 data is stale.<br />When the coherence protocol requires X to be flushed from L2, the L2 cache must request the data from L1.<br />Add another bit for “modified-but-stale&quot; (flushing a “modified-but-stale&quot; L2 line requires getting the real data from L1 first.)</li></ol><h1 id="false-sharing"><a class="markdownIt-Anchor" href="#false-sharing"></a> False sharing</h1><ol><li>False sharing is when two processors write to different addresses, but those addresses map to the same cache line. The cache line keeps invalidating and requesting data from another processor, generating significant communication due to the coherence protocol.</li><li>We can split the line into two parts; each processor only writes one part.</li><li>One way is to insert some paddings to make the data written by one processor take up a whole cache line. This can easily implemented at the software level. But it causes memory waste.</li><li>Another way is mapping addresses handled by the same processor to the same cache line. This causes no waste but breaks the successiveness of memory address within a cache line. Also, it needs to know the addresses each processor will write and is harder to implement.</li></ol>]]></content>
      
      
      <categories>
          
          <category> Open Courses </category>
          
          <category> CMU 15-418 / Stanford CS149 Parallel Computing </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Parallelism </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>07. Workload-driven Performance Evaluation</title>
      <link href="/2022/06/11/Courses/CS149/07-Workload-driven-Perfromance-Evaluation/"/>
      <url>/2022/06/11/Courses/CS149/07-Workload-driven-Perfromance-Evaluation/</url>
      
        <content type="html"><![CDATA[<p>We should compare parallel program speedup to the best sequential program instead of parallel algorithm running on one core.<br />The reason is that to allow for parallelism, we might change the algorithm and make it slower when executed sequentially.</p><h1 id="scaling"><a class="markdownIt-Anchor" href="#scaling"></a> Scaling</h1><h2 id="why-consider-scaling"><a class="markdownIt-Anchor" href="#why-consider-scaling"></a> Why consider scaling?</h2><ol><li><p>Both problem size and the processors’ number determine arithmetic intensity. Small problem sizes or large processor numbers yield low arithmetic intensity.</p></li><li><p>If the problem is too small, it might execute fast enough on a single core. Scaling the performance of small problems may not be all that important.<br />Parallelism overheads dominate parallelism benefits and may even result in slowdowns.</p></li><li><p>If the problem size is too large for a single machine, the working set may not fit in memory, causing thrashing to disk. With enough processors, the key working set fits in the per-processor cache.<br />This may get a super-linear speedup and make speedup on a bigger parallel machine with more memory look amazing.</p></li><li><p>Another situation in which we might get a super-linear speedup is when we try to search for a solution. With parallelism, we are trying more different variances of search and are more likely to find the solution earlier.</p></li><li><p>So, we shouldn’t only consider a fixed problem size. Instead, it is desirable to scale problem size as machine sizes grow.</p></li><li><p>In architecture, scaling up considers how performance scales with increasing core count, and will the design scale to the high end?<br />Scaling down considers how performance scales with decreasing core count, and will the design scale to the low end?</p></li></ol><h2 id="different-scalings"><a class="markdownIt-Anchor" href="#different-scalings"></a> Different scalings</h2><ol><li><p>Strong scaling: scaling processors with a fixed problem size. Consider the ratio between the runtime of the problem <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>X</mi></mrow><annotation encoding="application/x-tex">X</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.07847em;">X</span></span></span></span> on <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>P</mi></mrow><annotation encoding="application/x-tex">P</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span></span></span></span> processors and the runtime <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>X</mi></mrow><annotation encoding="application/x-tex">X</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.07847em;">X</span></span></span></span> on <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1</mn></mrow><annotation encoding="application/x-tex">1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">1</span></span></span></span> processor.</p></li><li><p>The goal ratio is <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>P</mi></mrow><annotation encoding="application/x-tex">P</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span></span></span></span>. This scaling tells us whether having more processors gets the job done faster.</p></li><li><p>Weak scaling: scaling problem size and processors proportionally. Consider the ratio of the runtime of the problem. <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>P</mi><mo>×</mo><mi>X</mi></mrow><annotation encoding="application/x-tex">P\times X</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.76666em;vertical-align:-0.08333em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.07847em;">X</span></span></span></span> on <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>P</mi></mrow><annotation encoding="application/x-tex">P</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span></span></span></span> processors and the runtime of the problem <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>X</mi></mrow><annotation encoding="application/x-tex">X</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.07847em;">X</span></span></span></span> on <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1</mn></mrow><annotation encoding="application/x-tex">1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">1</span></span></span></span> processor.</p></li><li><p>The goal ratio is <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1</mn></mrow><annotation encoding="application/x-tex">1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">1</span></span></span></span>. This scaling tells us whether having more processors allows me to do bigger jobs.</p></li><li><p>Problem size is often determined by more than one parameter. So, in weak scaling, we need to consider how the parameter should be changed.</p></li></ol><h2 id="scaling-constraints"><a class="markdownIt-Anchor" href="#scaling-constraints"></a> Scaling constraints</h2><ol><li><p>When scaling a problem, we should first ask that, in my situation, under what constraints should the problem be scaled?</p></li><li><p>Problem-constrained scaling uses a parallel computer to solve the same problem faster.<br />Speedup <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>=</mo><mfrac><mrow><mi>t</mi><mi>i</mi><mi>m</mi><mi>e</mi><mtext> </mtext><mn>1</mn><mtext> </mtext><mi>p</mi><mi>r</mi><mi>o</mi><mi>c</mi><mi>e</mi><mi>s</mi><mi>s</mi><mi>o</mi><mi>r</mi></mrow><mrow><mi>t</mi><mi>i</mi><mi>m</mi><mi>e</mi><mtext> </mtext><mi>P</mi><mtext> </mtext><mi>p</mi><mi>r</mi><mi>o</mi><mi>c</mi><mi>e</mi><mi>s</mi><mi>s</mi><mi>o</mi><mi>r</mi><mi>s</mi></mrow></mfrac></mrow><annotation encoding="application/x-tex">=\frac{time\ 1\ processor}{time\ P\ processors}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.36687em;vertical-align:0em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.38888em;vertical-align:-0.481108em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.907772em;"><span style="top:-2.6550000000000002em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span><span class="mord mathnormal mtight">i</span><span class="mord mathnormal mtight">m</span><span class="mord mathnormal mtight">e</span><span class="mspace mtight"><span class="mtight"> </span></span><span class="mord mathnormal mtight" style="margin-right:0.13889em;">P</span><span class="mspace mtight"><span class="mtight"> </span></span><span class="mord mathnormal mtight">p</span><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span><span class="mord mathnormal mtight">o</span><span class="mord mathnormal mtight">c</span><span class="mord mathnormal mtight">e</span><span class="mord mathnormal mtight">s</span><span class="mord mathnormal mtight">s</span><span class="mord mathnormal mtight">o</span><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span><span class="mord mathnormal mtight">s</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.446108em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span><span class="mord mathnormal mtight">i</span><span class="mord mathnormal mtight">m</span><span class="mord mathnormal mtight">e</span><span class="mspace mtight"><span class="mtight"> </span></span><span class="mord mtight">1</span><span class="mspace mtight"><span class="mtight"> </span></span><span class="mord mathnormal mtight">p</span><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span><span class="mord mathnormal mtight">o</span><span class="mord mathnormal mtight">c</span><span class="mord mathnormal mtight">e</span><span class="mord mathnormal mtight">s</span><span class="mord mathnormal mtight">s</span><span class="mord mathnormal mtight">o</span><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.481108em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></p></li><li><p>Time-constrained scaling focuses on completing more work in a fixed amount of time.<br />Speedup $ = \frac{work\ done\ by\ P\ processors}{work\ done\ by\ 1\ processor}$</p></li><li><p>“Work done” may not be a linear function of problem inputs. One approach to defining “work done” is by execution time of the same computation on a single processor (but consider the effects of thrashing if the problem is too big)</p></li><li><p>Ideally, a measure of work is simple to understand and scales linearly with sequential run time (So ideal speedup remains linear in <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>P</mi></mrow><annotation encoding="application/x-tex">P</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span></span></span></span>)</p></li><li><p>Memory-constrained scaling (weak scaling) focuses on running the largest problem possible without overflowing main memory. Neither work nor execution times are held constant.<br />Speedup <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>=</mo><mfrac><mrow><mi>w</mi><mi>o</mi><mi>r</mi><mi>k</mi><mtext> </mtext><mo stretchy="false">(</mo><mi>P</mi><mtext> </mtext><mi>p</mi><mi>r</mi><mi>o</mi><mi>c</mi><mi>e</mi><mi>s</mi><mi>s</mi><mi>o</mi><mi>r</mi><mi>s</mi><mo stretchy="false">)</mo></mrow><mrow><mi>t</mi><mi>i</mi><mi>m</mi><mi>e</mi><mtext> </mtext><mo stretchy="false">(</mo><mi>P</mi><mtext> </mtext><mi>p</mi><mi>r</mi><mi>o</mi><mi>c</mi><mi>e</mi><mi>s</mi><mi>s</mi><mi>o</mi><mi>r</mi><mi>s</mi><mo stretchy="false">)</mo></mrow></mfrac><mi mathvariant="normal">/</mi><mfrac><mrow><mi>w</mi><mi>o</mi><mi>r</mi><mi>k</mi><mtext> </mtext><mo stretchy="false">(</mo><mn>1</mn><mtext> </mtext><mi>p</mi><mi>r</mi><mi>o</mi><mi>c</mi><mi>e</mi><mi>s</mi><mi>s</mi><mi>o</mi><mi>r</mi><mo stretchy="false">)</mo></mrow><mrow><mi>t</mi><mi>i</mi><mi>m</mi><mi>e</mi><mtext> </mtext><mo stretchy="false">(</mo><mn>1</mn><mtext> </mtext><mi>p</mi><mi>r</mi><mi>o</mi><mi>c</mi><mi>e</mi><mi>s</mi><mi>s</mi><mi>o</mi><mi>r</mi><mo stretchy="false">)</mo></mrow></mfrac><mo>=</mo><mfrac><mrow><mi>w</mi><mi>o</mi><mi>r</mi><mi>k</mi><mtext> </mtext><mi>p</mi><mi>e</mi><mi>r</mi><mtext> </mtext><mi>u</mi><mi>n</mi><mi>i</mi><mi>t</mi><mtext> </mtext><mi>t</mi><mi>i</mi><mi>m</mi><mi>e</mi><mtext> </mtext><mi>o</mi><mi>n</mi><mtext> </mtext><mi>P</mi><mtext> </mtext><mi>p</mi><mi>r</mi><mi>o</mi><mi>c</mi><mi>e</mi><mi>s</mi><mi>s</mi><mi>o</mi><mi>r</mi><mi>s</mi></mrow><mrow><mi>w</mi><mi>o</mi><mi>r</mi><mi>k</mi><mtext> </mtext><mi>p</mi><mi>e</mi><mi>r</mi><mtext> </mtext><mi>u</mi><mi>n</mi><mi>i</mi><mi>t</mi><mtext> </mtext><mi>t</mi><mi>i</mi><mi>m</mi><mi>e</mi><mtext> </mtext><mi>o</mi><mi>n</mi><mtext> </mtext><mn>1</mn><mtext> </mtext><mi>p</mi><mi>r</mi><mi>o</mi><mi>c</mi><mi>e</mi><mi>s</mi><mi>s</mi><mi>o</mi><mi>r</mi></mrow></mfrac></mrow><annotation encoding="application/x-tex">= \frac{work\ (P\ processors)}{time\ (P\ processors)}/\frac{work\ (1\ processor)}{time\ (1\ processor)}=\frac{work\ per\ unit\ time\ on\ P\ processors}{work\ per\ unit\ time\ on\ 1\ processor}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.36687em;vertical-align:0em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.53em;vertical-align:-0.52em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.01em;"><span style="top:-2.655em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span><span class="mord mathnormal mtight">i</span><span class="mord mathnormal mtight">m</span><span class="mord mathnormal mtight">e</span><span class="mspace mtight"><span class="mtight"> </span></span><span class="mopen mtight">(</span><span class="mord mathnormal mtight" style="margin-right:0.13889em;">P</span><span class="mspace mtight"><span class="mtight"> </span></span><span class="mord mathnormal mtight">p</span><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span><span class="mord mathnormal mtight">o</span><span class="mord mathnormal mtight">c</span><span class="mord mathnormal mtight">e</span><span class="mord mathnormal mtight">s</span><span class="mord mathnormal mtight">s</span><span class="mord mathnormal mtight">o</span><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span><span class="mord mathnormal mtight">s</span><span class="mclose mtight">)</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.485em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.02691em;">w</span><span class="mord mathnormal mtight">o</span><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span><span class="mspace mtight"><span class="mtight"> </span></span><span class="mopen mtight">(</span><span class="mord mathnormal mtight" style="margin-right:0.13889em;">P</span><span class="mspace mtight"><span class="mtight"> </span></span><span class="mord mathnormal mtight">p</span><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span><span class="mord mathnormal mtight">o</span><span class="mord mathnormal mtight">c</span><span class="mord mathnormal mtight">e</span><span class="mord mathnormal mtight">s</span><span class="mord mathnormal mtight">s</span><span class="mord mathnormal mtight">o</span><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span><span class="mord mathnormal mtight">s</span><span class="mclose mtight">)</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.52em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mord">/</span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.01em;"><span style="top:-2.655em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span><span class="mord mathnormal mtight">i</span><span class="mord mathnormal mtight">m</span><span class="mord mathnormal mtight">e</span><span class="mspace mtight"><span class="mtight"> </span></span><span class="mopen mtight">(</span><span class="mord mtight">1</span><span class="mspace mtight"><span class="mtight"> </span></span><span class="mord mathnormal mtight">p</span><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span><span class="mord mathnormal mtight">o</span><span class="mord mathnormal mtight">c</span><span class="mord mathnormal mtight">e</span><span class="mord mathnormal mtight">s</span><span class="mord mathnormal mtight">s</span><span class="mord mathnormal mtight">o</span><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span><span class="mclose mtight">)</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.485em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.02691em;">w</span><span class="mord mathnormal mtight">o</span><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span><span class="mspace mtight"><span class="mtight"> </span></span><span class="mopen mtight">(</span><span class="mord mtight">1</span><span class="mspace mtight"><span class="mtight"> </span></span><span class="mord mathnormal mtight">p</span><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span><span class="mord mathnormal mtight">o</span><span class="mord mathnormal mtight">c</span><span class="mord mathnormal mtight">e</span><span class="mord mathnormal mtight">s</span><span class="mord mathnormal mtight">s</span><span class="mord mathnormal mtight">o</span><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span><span class="mclose mtight">)</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.52em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.4133239999999998em;vertical-align:-0.481108em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.9322159999999999em;"><span style="top:-2.6550000000000002em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.02691em;">w</span><span class="mord mathnormal mtight">o</span><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span><span class="mspace mtight"><span class="mtight"> </span></span><span class="mord mathnormal mtight">p</span><span class="mord mathnormal mtight">e</span><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span><span class="mspace mtight"><span class="mtight"> </span></span><span class="mord mathnormal mtight">u</span><span class="mord mathnormal mtight">n</span><span class="mord mathnormal mtight">i</span><span class="mord mathnormal mtight">t</span><span class="mspace mtight"><span class="mtight"> </span></span><span class="mord mathnormal mtight">t</span><span class="mord mathnormal mtight">i</span><span class="mord mathnormal mtight">m</span><span class="mord mathnormal mtight">e</span><span class="mspace mtight"><span class="mtight"> </span></span><span class="mord mathnormal mtight">o</span><span class="mord mathnormal mtight">n</span><span class="mspace mtight"><span class="mtight"> </span></span><span class="mord mtight">1</span><span class="mspace mtight"><span class="mtight"> </span></span><span class="mord mathnormal mtight">p</span><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span><span class="mord mathnormal mtight">o</span><span class="mord mathnormal mtight">c</span><span class="mord mathnormal mtight">e</span><span class="mord mathnormal mtight">s</span><span class="mord mathnormal mtight">s</span><span class="mord mathnormal mtight">o</span><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.446108em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.02691em;">w</span><span class="mord mathnormal mtight">o</span><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span><span class="mspace mtight"><span class="mtight"> </span></span><span class="mord mathnormal mtight">p</span><span class="mord mathnormal mtight">e</span><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span><span class="mspace mtight"><span class="mtight"> </span></span><span class="mord mathnormal mtight">u</span><span class="mord mathnormal mtight">n</span><span class="mord mathnormal mtight">i</span><span class="mord mathnormal mtight">t</span><span class="mspace mtight"><span class="mtight"> </span></span><span class="mord mathnormal mtight">t</span><span class="mord mathnormal mtight">i</span><span class="mord mathnormal mtight">m</span><span class="mord mathnormal mtight">e</span><span class="mspace mtight"><span class="mtight"> </span></span><span class="mord mathnormal mtight">o</span><span class="mord mathnormal mtight">n</span><span class="mspace mtight"><span class="mtight"> </span></span><span class="mord mathnormal mtight" style="margin-right:0.13889em;">P</span><span class="mspace mtight"><span class="mtight"> </span></span><span class="mord mathnormal mtight">p</span><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span><span class="mord mathnormal mtight">o</span><span class="mord mathnormal mtight">c</span><span class="mord mathnormal mtight">e</span><span class="mord mathnormal mtight">s</span><span class="mord mathnormal mtight">s</span><span class="mord mathnormal mtight">o</span><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span><span class="mord mathnormal mtight">s</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.481108em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span>There are two assumptions: memory resources scale with processor count, and spilling to disk is infeasible behavior.</p></li></ol><h2 id="challenges-of-scaling-down-or-up"><a class="markdownIt-Anchor" href="#challenges-of-scaling-down-or-up"></a> Challenges of scaling down or up</h2><ol><li><p>Preserve the ratio of time spent in different program phases.</p></li><li><p>Preserve important behavioral characteristics.</p></li><li><p>Preserve contention and communication patterns. It is tough to preserve contention since contention is a function of timing and ratios.</p></li><li><p>Preserve scaling relationships between problem parameters.</p></li></ol><h1 id="simulation"><a class="markdownIt-Anchor" href="#simulation"></a> Simulation</h1><ol><li><p>Architects evaluate architectural decisions quantitatively using hardware performance simulators.</p></li><li><p>Before comparing simulated performance, the architect runs simulations with new features and simulations without new features. Or simulate against a wide collection of benchmarks.</p></li><li><p>You can design a detailed simulator to test new architectural features. It would be costly to simulate a parallel machine in full detail.<br />Often, it cannot simulate full machine configurations or realistic problem sizes (must scale down workloads significantly). Architects need to be confident in the scaled-down simulated results to predict reality.</p></li><li><p>In the trace-driven simulator, we instrument real code running on a real machine to record a trace of all memory accesses. Then, play back the trace on the simulator.<br />It may lead to overfitting your trace instead of having a better generalization.</p></li><li><p>In the execution-driven simulator, we execute the simulated program in software. Simulated processors generate memory references, which the simulated memory hierarchy processes.<br />The simulator’s performance is typically inversely proportional to the level of simulated detail.</p></li><li><p>When dealing with large parameter space of machines (number of processors, cache sizes, cache line sizes, memory bandwidths, etc. ), we can use the architectural simulation state space.</p></li></ol><h1 id="understanding-the-performance"><a class="markdownIt-Anchor" href="#understanding-the-performance"></a> Understanding the performance</h1><ol><li><p>Always, always, always try the simplest parallel solution first, then measure performance to see where you stand.</p></li><li><p>Determine if your performance is limited by computation, memory bandwidth (or latency), or synchronization.<br />Try to establish “high watermarks”. What’s the best you can do in practice? How close is your implementation to a best-case scenario?</p></li><li><p>Roofline model: Use microbenchmarks to compute the peak performance of a machine as a function of the arithmetic intensity of the application. Then, compare the application’s performance to known peak values.</p></li><li><p>The x-axis means operational intensity (like Flops/Byte), and the y-axis means attenable GFlops/s.<br />In the diagonal region, the y grows with x, which limits memory bandwidth. In the horizontal region, the y stays the same as x grows, which means the compute is limited.</p></li><li><p>We can use ILP, SIMD, or balance floating-point when computing is limited.<br />When memory bandwidth is limited, we can limit accesses to unit stride accesses only, develop memory affinity, or use software prefetching.</p></li></ol><h2 id="establish-high-watermarks"><a class="markdownIt-Anchor" href="#establish-high-watermarks"></a> Establish high watermarks</h2><ol><li><p>Add “math” (non-memory instructions).<br />Does execution time increase linearly with operation count as math is added? If so, this is evidence that the code is instruction-rate limited.</p></li><li><p>Remove almost all math, but load the same data.<br />How much does execution time decrease? If not much, suspect memory bottleneck</p></li><li><p>The first two ways need to avoid compiler optimization.</p></li><li><p>Change all array accesses to A[0].<br />How much faster does your code get?<br />This establishes an upper bound for improving the locality of data access.</p></li><li><p>Remove all atomic operations or locks.<br />How much faster does your code get? (provided it still does approximately the same amount of work)<br />This establishes an upper bound on the benefit of reducing sync overhead.</p></li></ol><h2 id="profilersperformance-monitoring-tools"><a class="markdownIt-Anchor" href="#profilersperformance-monitoring-tools"></a> Profilers/performance monitoring tools</h2><ol><li><p>All modern processors have low-level event “performance counters,” which are registers that count important details such as instructions completed, clock ticks, L2/L3 cache hits/misses, bytes read from the memory controller, etc.</p></li><li><p>Intel’s Performance Counter Monitor Tool provides a C++ API for accessing these registers.</p></li><li><p>It can use <code>getIPC(begin, end)</code>, <code>getL3CacheHitRatio(begin, end)</code>, <code>getBytesReadFromMC(begin, end)</code>, etc. to get values of that information.</p></li><li><p>The <code>begin</code> and <code>end</code> are <code>SystemCountState</code> instances acquired by <code>getSystemCounterState()</code> at the beginning and end of the code to analyze.</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">PCM *m = PCM::<span class="built_in">getInstance</span>();</span><br><span class="line">SystemCounterState begin = <span class="built_in">getSystemCounterState</span>();</span><br><span class="line"></span><br><span class="line"><span class="comment">// code to analyze goes here</span></span><br><span class="line"></span><br><span class="line">SystemCounterState end = <span class="built_in">getSystemCounterState</span>();</span><br><span class="line"></span><br><span class="line"><span class="built_in">printf</span>(“Instructions per clock: %f\n”, <span class="built_in">getIPC</span>(begin, end));</span><br><span class="line"><span class="built_in">printf</span>(“L3 cache hit ratio: %f\n”, <span class="built_in">getL3CacheHitRatio</span>(begin, end));</span><br><span class="line"><span class="built_in">printf</span>(“Bytes read: %d\n”, <span class="built_in">getBytesReadFromMC</span>(begin, end));</span><br></pre></td></tr></table></figure></li></ol>]]></content>
      
      
      <categories>
          
          <category> Open Courses </category>
          
          <category> CMU 15-418 / Stanford CS149 Parallel Computing </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Parallelism </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>06. Locality, Communication, and Contention</title>
      <link href="/2022/05/21/Courses/CS149/06-Locality-Communication-and-Contention/"/>
      <url>/2022/05/21/Courses/CS149/06-Locality-Communication-and-Contention/</url>
      
        <content type="html"><![CDATA[<h1 id="communication"><a class="markdownIt-Anchor" href="#communication"></a> Communication</h1><h2 id="reduce-communication-time"><a class="markdownIt-Anchor" href="#reduce-communication-time"></a> Reduce communication time</h2><ol><li><p>Total communication time = overhead + occupancy + network delay.</p></li><li><p>Overhead is the time spent on communication by a processor, occupancy is the time for data to pass through the slowest component of the system, and network delay is everything else.</p></li><li><p>Reduce overhead of communication to sender/receiver:<br />Reassign tasks in a better way that needs to send fewer messages.<br />Make messages larger to amortize overhead.<br />Coalesce many small messages into large ones</p></li><li><p>Reduce delay:<br />Application writers can restructure code to exploit locality.<br />Hardware implementors can improve communication architecture.</p></li></ol><h2 id="reduce-communication-cost"><a class="markdownIt-Anchor" href="#reduce-communication-cost"></a> Reduce communication cost</h2><ol><li><p>Total communication cost = communication time - overlap</p></li><li><p>Overlap: portion of communication performed concurrently with other work (“other work” can be computation or other communication)</p></li><li><p>Cost is the part you cannot overcome by changing the protocol. The communication time is necessary, and we can hide the overlap part by pipelining.</p></li><li><p>Increase communication/computation overlap:<br />Application writers can use asynchronous communication (e.g., async messages)<br />Hardware implementors can use pipelining, multi-threading, pre-fetching, out-of-order execution<br />Requires additional concurrency in the application (more concurrency than the number of execution units)</p></li><li><p>Instruction pipeline: Break the execution of each instruction down into several smaller steps.<br />Enables higher clock frequency; only a simple, short operation is done by each part of the pipeline in each clock</p></li><li><p>Non-pipelined communication: <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>T</mi><mo stretchy="false">(</mo><mi>n</mi><mo stretchy="false">)</mo><mo>=</mo><msub><mi>T</mi><mn>0</mn></msub><mo>+</mo><mfrac><mi>n</mi><mi>B</mi></mfrac></mrow><annotation encoding="application/x-tex">T(n)=T_0+\frac{n}{B}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="mopen">(</span><span class="mord mathnormal">n</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1.040392em;vertical-align:-0.345em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.695392em;"><span style="top:-2.6550000000000002em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.05017em;">B</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">n</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.345em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span> (<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>T</mi><mn>0</mn></msub></mrow><annotation encoding="application/x-tex">T_0</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> is the start-up latency, n is bytes transferred in operation, and B is the transfer rate or bandwidth)<br />Efficient bandwidth <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>=</mo><mfrac><mi>n</mi><mrow><mi>T</mi><mo stretchy="false">(</mo><mi>n</mi><mo stretchy="false">)</mo></mrow></mfrac></mrow><annotation encoding="application/x-tex">=\frac{n}{T(n)}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.36687em;vertical-align:0em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.215392em;vertical-align:-0.52em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.695392em;"><span style="top:-2.655em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em;">T</span><span class="mopen mtight">(</span><span class="mord mathnormal mtight">n</span><span class="mclose mtight">)</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">n</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.52em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></p></li></ol><h2 id="improve-arithmetic-intensity"><a class="markdownIt-Anchor" href="#improve-arithmetic-intensity"></a> Improve arithmetic intensity</h2><ol><li><p>Communication-to-computation ratio = amount of communication/amount of computation<br />The units can be different. If the denominator is the execution time of computation, the ratio gives the average bandwidth requirement.</p></li><li><p>Arithmetic intensity = 1 / communication-to-computation ratio</p></li><li><p>Change the traversal order to reduce the time between accesses to the same data. We want to do all the calculations related to accessing data now.<br />This way, we can improve the cache utilization by preventing those data from getting flushed out when we try to reaccess them.</p></li><li><p>Fuse loops to reduce the frequency of store operation.</p></li><li><p>Improve arithmetic intensity by sharing data. Co-locate tasks that operate on the same data.  Schedule threads to work on the same data structure and on the same processor at the same time. Reduces inherent communication</p></li></ol><h2 id="reduce-artifactual-communication"><a class="markdownIt-Anchor" href="#reduce-artifactual-communication"></a> Reduce artifactual communication</h2><ol><li><p>Inherent communication: Communication that must occur in a parallel algorithm. The communication is fundamental to the algorithm.<br />Artifactual communication: all other communication happens because we want to use resources efficiently.</p></li><li><p>The granularity of communication can be important because it may introduce artifactual communication.<br />Assume that communication granularity is a cache line.</p></li><li><p>If we see data as a row-major layout, when the data required is in the column, each communication only provides one needed data.</p></li><li><p>When Threads access their assigned elements (no inherent communication exists), real machine triggers (artifactual) communication due to the cache line being written to by both processors.</p></li><li><p>Reduce artifactual communications by blocking data layout. Each communication only involves the data in the same block. If communication granularity is larger than a block row, each communication will transfer multiple rows.</p></li></ol><h1 id="contention"><a class="markdownIt-Anchor" href="#contention"></a> Contention</h1><ol><li><p>Contention occurs when many requests for a resource are made within a small window of time. The resource is a hot spot.<br />Contention of shared resources results in longer overall operation times.</p></li><li><p>Distributed work queues serve to reduce contention (contention in access to a single shared work queue)</p></li><li><p>One way to reduce contention is to use finer-granularity locks. Instead of locking the whole data structure, we can only lock a part of that structure.</p></li><li><p>Another way is that each CUDA block computes partial results and merges them afterward. However, this requires extra work for merging, and each CUDA block needs to store a partial result instead of all using the same result.</p></li><li><p>The best way is to stagger access to contended resources. For example, instead of calculating the final result directly, we can calculate several temporal results with no contention and get the final result from them.</p></li></ol><h1 id="understanding-the-performance"><a class="markdownIt-Anchor" href="#understanding-the-performance"></a> Understanding the performance</h1><ol><li><p>Always, always, always try the simplest parallel solution first, then measure performance to see where you stand.</p></li><li><p>We should compare parallel program speedup to the best sequential program instead of parallel algorithm running on one core.<br />The reason is that to allow for parallelism, we might change the algorithm and make it slower when executed sequentially.</p></li><li><p>Determine if your performance is limited by computation, memory bandwidth (or latency), or synchronization.<br />Try to establish “high watermarks”. What’s the best you can do in practice? How close is your implementation to a best-case scenario?</p></li><li><p>Roofline model: Use microbenchmarks to compute the peak performance of a machine as a function of the arithmetic intensity of the application. Then, compare the application’s performance to known peak values.</p></li></ol><h2 id="establish-high-watermarks"><a class="markdownIt-Anchor" href="#establish-high-watermarks"></a> Establish high watermarks</h2><ol><li><p>Add “math” (non-memory instructions).<br />Does execution time increase linearly with operation count as math is added?<br />If so, this is evidence that the code is instruction-rate limited.</p></li><li><p>Remove almost all math, but load the same data.<br />How much does execution time decrease?<br />If not much, suspect memory bottleneck</p></li><li><p>Change all array accesses to A[0].<br />How much faster does your code get?<br />This establishes an upper bound for improving the locality of data access.</p></li><li><p>Remove all atomic operations or locks.<br />How much faster does your code get? (provided it still does approximately the same amount of work)<br />This establishes an upper bound on the benefit of reducing sync overhead.</p></li></ol><h2 id="scaling"><a class="markdownIt-Anchor" href="#scaling"></a> Scaling</h2><ol><li><p>Both problem size and the processor’s number determine arithmetic intensity. Small problem sizes or large processor numbers yield low arithmetic intensity.</p></li><li><p>If the problem is too small, it might execute fast enough on a single core. Scaling the performance of small problems may not be all that important.</p></li><li><p>If the problem size is too large for a single machine, the working set may not fit in memory, causing thrashing to disk. With enough processors, the key working set fits in the per-processor cache.<br />This may get a super-linear speedup and make speedup on a bigger parallel machine with more memory look amazing.</p></li><li><p>Desire to scale problem size as machine sizes grow (buy a bigger machine to compute more, rather than compute the same problem faster)</p></li><li><p>Problem-constrained scaling uses a parallel computer to solve the same problem faster.<br /><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>S</mi><mi>p</mi><mi>e</mi><mi>e</mi><mi>d</mi><mi>u</mi><mi>p</mi><mo>=</mo><mfrac><mrow><mi>t</mi><mi>i</mi><mi>m</mi><mi>e</mi><mtext> </mtext><mn>1</mn><mtext> </mtext><mi>p</mi><mi>r</mi><mi>o</mi><mi>c</mi><mi>e</mi><mi>s</mi><mi>s</mi><mi>o</mi><mi>r</mi></mrow><mrow><mi>t</mi><mi>i</mi><mi>m</mi><mi>e</mi><mtext> </mtext><mi>P</mi><mtext> </mtext><mi>p</mi><mi>r</mi><mi>o</mi><mi>c</mi><mi>e</mi><mi>s</mi><mi>s</mi><mi>o</mi><mi>r</mi><mi>s</mi></mrow></mfrac></mrow><annotation encoding="application/x-tex">Speedup=\frac{time\ 1\ processor}{time\ P\ processors}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord mathnormal" style="margin-right:0.05764em;">S</span><span class="mord mathnormal">p</span><span class="mord mathnormal">e</span><span class="mord mathnormal">e</span><span class="mord mathnormal">d</span><span class="mord mathnormal">u</span><span class="mord mathnormal">p</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.38888em;vertical-align:-0.481108em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.907772em;"><span style="top:-2.6550000000000002em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span><span class="mord mathnormal mtight">i</span><span class="mord mathnormal mtight">m</span><span class="mord mathnormal mtight">e</span><span class="mspace mtight"><span class="mtight"> </span></span><span class="mord mathnormal mtight" style="margin-right:0.13889em;">P</span><span class="mspace mtight"><span class="mtight"> </span></span><span class="mord mathnormal mtight">p</span><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span><span class="mord mathnormal mtight">o</span><span class="mord mathnormal mtight">c</span><span class="mord mathnormal mtight">e</span><span class="mord mathnormal mtight">s</span><span class="mord mathnormal mtight">s</span><span class="mord mathnormal mtight">o</span><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span><span class="mord mathnormal mtight">s</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.446108em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span><span class="mord mathnormal mtight">i</span><span class="mord mathnormal mtight">m</span><span class="mord mathnormal mtight">e</span><span class="mspace mtight"><span class="mtight"> </span></span><span class="mord mtight">1</span><span class="mspace mtight"><span class="mtight"> </span></span><span class="mord mathnormal mtight">p</span><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span><span class="mord mathnormal mtight">o</span><span class="mord mathnormal mtight">c</span><span class="mord mathnormal mtight">e</span><span class="mord mathnormal mtight">s</span><span class="mord mathnormal mtight">s</span><span class="mord mathnormal mtight">o</span><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.481108em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></p></li><li><p>Time-constrained scaling focuses on completing more work in a fixed amount of time.<br /><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>S</mi><mi>p</mi><mi>e</mi><mi>e</mi><mi>d</mi><mi>u</mi><mi>p</mi><mo>=</mo><mfrac><mrow><mi>w</mi><mi>o</mi><mi>r</mi><mi>k</mi><mtext> </mtext><mi>d</mi><mi>o</mi><mi>n</mi><mi>e</mi><mtext> </mtext><mi>b</mi><mi>y</mi><mtext> </mtext><mi>P</mi><mtext> </mtext><mi>p</mi><mi>r</mi><mi>o</mi><mi>c</mi><mi>e</mi><mi>s</mi><mi>s</mi><mi>o</mi><mi>r</mi><mi>s</mi></mrow><mrow><mi>w</mi><mi>o</mi><mi>r</mi><mi>k</mi><mtext> </mtext><mi>d</mi><mi>o</mi><mi>n</mi><mi>e</mi><mtext> </mtext><mi>b</mi><mi>y</mi><mtext> </mtext><mn>1</mn><mtext> </mtext><mi>p</mi><mi>r</mi><mi>o</mi><mi>c</mi><mi>e</mi><mi>s</mi><mi>s</mi><mi>o</mi><mi>r</mi></mrow></mfrac></mrow><annotation encoding="application/x-tex">Speedup = \frac{work\ done\ by\ P\ processors}{work\ done\ by\ 1\ processor}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord mathnormal" style="margin-right:0.05764em;">S</span><span class="mord mathnormal">p</span><span class="mord mathnormal">e</span><span class="mord mathnormal">e</span><span class="mord mathnormal">d</span><span class="mord mathnormal">u</span><span class="mord mathnormal">p</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.4133239999999998em;vertical-align:-0.481108em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.9322159999999999em;"><span style="top:-2.6550000000000002em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.02691em;">w</span><span class="mord mathnormal mtight">o</span><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span><span class="mspace mtight"><span class="mtight"> </span></span><span class="mord mathnormal mtight">d</span><span class="mord mathnormal mtight">o</span><span class="mord mathnormal mtight">n</span><span class="mord mathnormal mtight">e</span><span class="mspace mtight"><span class="mtight"> </span></span><span class="mord mathnormal mtight">b</span><span class="mord mathnormal mtight" style="margin-right:0.03588em;">y</span><span class="mspace mtight"><span class="mtight"> </span></span><span class="mord mtight">1</span><span class="mspace mtight"><span class="mtight"> </span></span><span class="mord mathnormal mtight">p</span><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span><span class="mord mathnormal mtight">o</span><span class="mord mathnormal mtight">c</span><span class="mord mathnormal mtight">e</span><span class="mord mathnormal mtight">s</span><span class="mord mathnormal mtight">s</span><span class="mord mathnormal mtight">o</span><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.446108em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.02691em;">w</span><span class="mord mathnormal mtight">o</span><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span><span class="mspace mtight"><span class="mtight"> </span></span><span class="mord mathnormal mtight">d</span><span class="mord mathnormal mtight">o</span><span class="mord mathnormal mtight">n</span><span class="mord mathnormal mtight">e</span><span class="mspace mtight"><span class="mtight"> </span></span><span class="mord mathnormal mtight">b</span><span class="mord mathnormal mtight" style="margin-right:0.03588em;">y</span><span class="mspace mtight"><span class="mtight"> </span></span><span class="mord mathnormal mtight" style="margin-right:0.13889em;">P</span><span class="mspace mtight"><span class="mtight"> </span></span><span class="mord mathnormal mtight">p</span><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span><span class="mord mathnormal mtight">o</span><span class="mord mathnormal mtight">c</span><span class="mord mathnormal mtight">e</span><span class="mord mathnormal mtight">s</span><span class="mord mathnormal mtight">s</span><span class="mord mathnormal mtight">o</span><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span><span class="mord mathnormal mtight">s</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.481108em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span><br />“Work done” may not be a linear function of problem inputs. One approach to defining “work done” is by execution time of exact computation on a single processor (but consider the effects of thrashing if the problem is too big)</p></li><li><p>Memory-constrained scaling (weak scaling) focuses on running the largest problem possible without overflowing main memory. Neither work nor execution times are held constant.<br /><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>S</mi><mi>p</mi><mi>e</mi><mi>e</mi><mi>d</mi><mi>u</mi><mi>p</mi><mo>=</mo><mfrac><mrow><mi>w</mi><mi>o</mi><mi>r</mi><mi>k</mi><mtext> </mtext><mo stretchy="false">(</mo><mi>P</mi><mtext> </mtext><mi>p</mi><mi>r</mi><mi>o</mi><mi>c</mi><mi>e</mi><mi>s</mi><mi>s</mi><mi>o</mi><mi>r</mi><mi>s</mi><mo stretchy="false">)</mo></mrow><mrow><mi>t</mi><mi>i</mi><mi>m</mi><mi>e</mi><mtext> </mtext><mo stretchy="false">(</mo><mi>P</mi><mtext> </mtext><mi>p</mi><mi>r</mi><mi>o</mi><mi>c</mi><mi>e</mi><mi>s</mi><mi>s</mi><mi>o</mi><mi>r</mi><mi>s</mi><mo stretchy="false">)</mo></mrow></mfrac><mi mathvariant="normal">/</mi><mfrac><mrow><mi>w</mi><mi>o</mi><mi>r</mi><mi>k</mi><mtext> </mtext><mo stretchy="false">(</mo><mn>1</mn><mtext> </mtext><mi>p</mi><mi>r</mi><mi>o</mi><mi>c</mi><mi>e</mi><mi>s</mi><mi>s</mi><mi>o</mi><mi>r</mi><mo stretchy="false">)</mo></mrow><mrow><mi>t</mi><mi>i</mi><mi>m</mi><mi>e</mi><mtext> </mtext><mo stretchy="false">(</mo><mn>1</mn><mtext> </mtext><mi>p</mi><mi>r</mi><mi>o</mi><mi>c</mi><mi>e</mi><mi>s</mi><mi>s</mi><mi>o</mi><mi>r</mi><mo stretchy="false">)</mo></mrow></mfrac><mo>=</mo><mfrac><mrow><mi>w</mi><mi>o</mi><mi>r</mi><mi>k</mi><mtext> </mtext><mi>p</mi><mi>e</mi><mi>r</mi><mtext> </mtext><mi>u</mi><mi>n</mi><mi>i</mi><mi>t</mi><mtext> </mtext><mi>t</mi><mi>i</mi><mi>m</mi><mi>e</mi><mtext> </mtext><mi>o</mi><mi>n</mi><mtext> </mtext><mi>P</mi><mtext> </mtext><mi>p</mi><mi>r</mi><mi>o</mi><mi>c</mi><mi>e</mi><mi>s</mi><mi>s</mi><mi>o</mi><mi>r</mi><mi>s</mi></mrow><mrow><mi>w</mi><mi>o</mi><mi>r</mi><mi>k</mi><mtext> </mtext><mi>p</mi><mi>e</mi><mi>r</mi><mtext> </mtext><mi>u</mi><mi>n</mi><mi>i</mi><mi>t</mi><mtext> </mtext><mi>t</mi><mi>i</mi><mi>m</mi><mi>e</mi><mtext> </mtext><mi>o</mi><mi>n</mi><mtext> </mtext><mn>1</mn><mtext> </mtext><mi>p</mi><mi>r</mi><mi>o</mi><mi>c</mi><mi>e</mi><mi>s</mi><mi>s</mi><mi>o</mi><mi>r</mi></mrow></mfrac></mrow><annotation encoding="application/x-tex">Speedup = \frac{work\ (P\ processors)}{time\ (P\ processors)}/\frac{work\ (1\ processor)}{time\ (1\ processor)}=\frac{work\ per\ unit\ time\ on\ P\ processors}{work\ per\ unit\ time\ on\ 1\ processor}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord mathnormal" style="margin-right:0.05764em;">S</span><span class="mord mathnormal">p</span><span class="mord mathnormal">e</span><span class="mord mathnormal">e</span><span class="mord mathnormal">d</span><span class="mord mathnormal">u</span><span class="mord mathnormal">p</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.53em;vertical-align:-0.52em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.01em;"><span style="top:-2.655em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span><span class="mord mathnormal mtight">i</span><span class="mord mathnormal mtight">m</span><span class="mord mathnormal mtight">e</span><span class="mspace mtight"><span class="mtight"> </span></span><span class="mopen mtight">(</span><span class="mord mathnormal mtight" style="margin-right:0.13889em;">P</span><span class="mspace mtight"><span class="mtight"> </span></span><span class="mord mathnormal mtight">p</span><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span><span class="mord mathnormal mtight">o</span><span class="mord mathnormal mtight">c</span><span class="mord mathnormal mtight">e</span><span class="mord mathnormal mtight">s</span><span class="mord mathnormal mtight">s</span><span class="mord mathnormal mtight">o</span><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span><span class="mord mathnormal mtight">s</span><span class="mclose mtight">)</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.485em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.02691em;">w</span><span class="mord mathnormal mtight">o</span><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span><span class="mspace mtight"><span class="mtight"> </span></span><span class="mopen mtight">(</span><span class="mord mathnormal mtight" style="margin-right:0.13889em;">P</span><span class="mspace mtight"><span class="mtight"> </span></span><span class="mord mathnormal mtight">p</span><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span><span class="mord mathnormal mtight">o</span><span class="mord mathnormal mtight">c</span><span class="mord mathnormal mtight">e</span><span class="mord mathnormal mtight">s</span><span class="mord mathnormal mtight">s</span><span class="mord mathnormal mtight">o</span><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span><span class="mord mathnormal mtight">s</span><span class="mclose mtight">)</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.52em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mord">/</span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.01em;"><span style="top:-2.655em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span><span class="mord mathnormal mtight">i</span><span class="mord mathnormal mtight">m</span><span class="mord mathnormal mtight">e</span><span class="mspace mtight"><span class="mtight"> </span></span><span class="mopen mtight">(</span><span class="mord mtight">1</span><span class="mspace mtight"><span class="mtight"> </span></span><span class="mord mathnormal mtight">p</span><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span><span class="mord mathnormal mtight">o</span><span class="mord mathnormal mtight">c</span><span class="mord mathnormal mtight">e</span><span class="mord mathnormal mtight">s</span><span class="mord mathnormal mtight">s</span><span class="mord mathnormal mtight">o</span><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span><span class="mclose mtight">)</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.485em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.02691em;">w</span><span class="mord mathnormal mtight">o</span><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span><span class="mspace mtight"><span class="mtight"> </span></span><span class="mopen mtight">(</span><span class="mord mtight">1</span><span class="mspace mtight"><span class="mtight"> </span></span><span class="mord mathnormal mtight">p</span><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span><span class="mord mathnormal mtight">o</span><span class="mord mathnormal mtight">c</span><span class="mord mathnormal mtight">e</span><span class="mord mathnormal mtight">s</span><span class="mord mathnormal mtight">s</span><span class="mord mathnormal mtight">o</span><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span><span class="mclose mtight">)</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.52em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.4133239999999998em;vertical-align:-0.481108em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.9322159999999999em;"><span style="top:-2.6550000000000002em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.02691em;">w</span><span class="mord mathnormal mtight">o</span><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span><span class="mspace mtight"><span class="mtight"> </span></span><span class="mord mathnormal mtight">p</span><span class="mord mathnormal mtight">e</span><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span><span class="mspace mtight"><span class="mtight"> </span></span><span class="mord mathnormal mtight">u</span><span class="mord mathnormal mtight">n</span><span class="mord mathnormal mtight">i</span><span class="mord mathnormal mtight">t</span><span class="mspace mtight"><span class="mtight"> </span></span><span class="mord mathnormal mtight">t</span><span class="mord mathnormal mtight">i</span><span class="mord mathnormal mtight">m</span><span class="mord mathnormal mtight">e</span><span class="mspace mtight"><span class="mtight"> </span></span><span class="mord mathnormal mtight">o</span><span class="mord mathnormal mtight">n</span><span class="mspace mtight"><span class="mtight"> </span></span><span class="mord mtight">1</span><span class="mspace mtight"><span class="mtight"> </span></span><span class="mord mathnormal mtight">p</span><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span><span class="mord mathnormal mtight">o</span><span class="mord mathnormal mtight">c</span><span class="mord mathnormal mtight">e</span><span class="mord mathnormal mtight">s</span><span class="mord mathnormal mtight">s</span><span class="mord mathnormal mtight">o</span><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.446108em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.02691em;">w</span><span class="mord mathnormal mtight">o</span><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span><span class="mspace mtight"><span class="mtight"> </span></span><span class="mord mathnormal mtight">p</span><span class="mord mathnormal mtight">e</span><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span><span class="mspace mtight"><span class="mtight"> </span></span><span class="mord mathnormal mtight">u</span><span class="mord mathnormal mtight">n</span><span class="mord mathnormal mtight">i</span><span class="mord mathnormal mtight">t</span><span class="mspace mtight"><span class="mtight"> </span></span><span class="mord mathnormal mtight">t</span><span class="mord mathnormal mtight">i</span><span class="mord mathnormal mtight">m</span><span class="mord mathnormal mtight">e</span><span class="mspace mtight"><span class="mtight"> </span></span><span class="mord mathnormal mtight">o</span><span class="mord mathnormal mtight">n</span><span class="mspace mtight"><span class="mtight"> </span></span><span class="mord mathnormal mtight" style="margin-right:0.13889em;">P</span><span class="mspace mtight"><span class="mtight"> </span></span><span class="mord mathnormal mtight">p</span><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span><span class="mord mathnormal mtight">o</span><span class="mord mathnormal mtight">c</span><span class="mord mathnormal mtight">e</span><span class="mord mathnormal mtight">s</span><span class="mord mathnormal mtight">s</span><span class="mord mathnormal mtight">o</span><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span><span class="mord mathnormal mtight">s</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.481108em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></p></li></ol>]]></content>
      
      
      <categories>
          
          <category> Open Courses </category>
          
          <category> CMU 15-418 / Stanford CS149 Parallel Computing </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Parallelism </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>05. Graphic processing units and CUDA</title>
      <link href="/2022/05/19/Courses/CS149/05-Graphic-processing-units-and-CUDA/"/>
      <url>/2022/05/19/Courses/CS149/05-Graphic-processing-units-and-CUDA/</url>
      
        <content type="html"><![CDATA[<h1 id="graphics"><a class="markdownIt-Anchor" href="#graphics"></a> Graphics</h1><ol><li>The first step to drawing a graphic on the screen is to describe the manipulated things (key entities), whose surface is represented as a 3D triangle mesh.<br />So, the input of the calculating system is a list of vertices in 3D space and their connectivity to primitives.</li><li>The operations of the system are as follows:<br />Given a scene camera position, compute where the vertices lie on the screen<br />Group vertices into primitives<br />Generate one fragment for each pixel a primitive overlaps<br />Compute the color of the primitive for each fragment based on scene lighting and primitive material properties<br />Put the color of the “closest fragment” to the camera in the output image</li><li>We can Abstract the process of rendering a picture as a sequence of operations on vertices, primitives, fragments, and pixels.<br />GPUs are very fast processors for performing the same computation (shader programs) on large collections of data (streams of vertices, fragments, and pixels), which sounds like data-parallelism.</li><li>To do GPU-based scientific computation, we need to set the OpenGL output image size to the output array size and render two triangles that exactly cover the screen.</li></ol><h1 id="cuda"><a class="markdownIt-Anchor" href="#cuda"></a> CUDA</h1><h2 id="grid-block-and-thread"><a class="markdownIt-Anchor" href="#grid-block-and-thread"></a> Grid, Block, and Thread</h2><ol><li>CUDA thread IDs can be up to 3-dimensional. Multiple threads make up a block, and multiple blocks make up a grid.<br />Each kernel has a grid. All the blocks in a grid form a 3D matrix, and all the threads in a block also form a 3D matrix.<br />We can get information about the shape of threads in a block matrix or block in a grid matrix in a block with <code>block_dim</code> and <code>grid_dim</code></li><li>When launching the CUDA threads, we need to specify the size of blocks and threads with <code>kernel_function&lt;&lt;&lt;block_dim, thread_dim&gt;&gt;&gt;(parameters)</code>.<br />Here, block_dim and thread_dim can be either a dim3 value or a number of the total number of blocks and threads per block to make the CUDA compiler figure out how to arrange blocks and threads.</li><li>So, the coordinates for declaring or locating a block in a grid or a thread in a block are in 3D. In the CUDA code, we can get information about the current block or thread with <code>blockIdx</code> and <code>threadIdx</code> and their properties <code>x</code>, <code>y</code>, and <code>z</code>.</li><li>The calculation object of CUDA is usually matrices. So, we prefer to cut matrices into blocks. Each CUDA block calculates one block in matrices, and each thread calculates one element in matrices.</li><li>In <code>pthread</code>, there is stack space for the thread, and we need to allocate a control block so OS can schedule the thread.<br />Unlike <code>pthread</code>, CUDA controls those instances by thread blocks. If controlled by threads, there will be too many to control.</li><li>Major CUDA assumption: thread block execution can be carried out in any order (no dependencies between blocks)</li></ol><h2 id="kernel-function"><a class="markdownIt-Anchor" href="#kernel-function"></a> Kernel function</h2><ol><li>“Host” code: serial execution runs as part of normal C/C++ application on CPU<br />“CUDA device” code: a kernel function runs on GPU, denoted by <code>__global__</code> before the definition of the kernel function.<br />Device function: SPMD execution on GPU, denoted by <code>__device__</code>. Kernels call these functions and don’t generate new threads.<br />Kernels and device functions only reference device memory. Host code can only reference host memory but can have pointers to device memory.</li><li>In the kernel function, we need to get the indices of the element a thread is calculating. For a 2D matrix, we usually take <code>x</code> as the column direction and y as the row direction.<br />So to access <code>A[i][j]</code>, <code>i = blockIdx.y * blockDim * y + threadIdx.y</code> and <code>j = blockIdx.x * blockDim.x + threadIdx.x</code>.</li><li>The data collection size does not determine the number of kernel invocations. So, normally, we want to do a test before accessing the vector values (array values). The overhead of the test can be ignored, although it does cause some threads not to be used.</li><li><code>__syncthreads()</code> is a barrier that waits for all threads in the block to arrive at this point.<br />Atomic operations on global memory and shared memory variables are also provided, but they are costly and should only be used as a last resort.<br />There is an implicit barrier across all threads at the return of the kernel.</li><li>A compiled CUDA device binary includes program text (instructions) and information about required resources (how many threads per block, how much space per thread, how much shared-space per thread block)</li></ol><h2 id="memory-model"><a class="markdownIt-Anchor" href="#memory-model"></a> Memory Model</h2><ol><li>The host and device have distinct address spaces, so we need to copy data into CUDA memory before executing.<br /><code>cudaMalloc(ptr, size)</code> can allocate CUDA memory, and <code>cudaFree(ptr)</code> can free CUDA memory. The pointer in <code>cudaMalloc</code> can be a host variable, but the pointer in <code>cudaFree</code> must be allocated by <code>cudaMalloc</code>.<br /><code>cudaMemcpy(dest, src, size, kind)</code> can copy those data into CUDA memory. The kind of direction of copy can be <code>cudaMemcpyHostToDevice</code> or <code>curdaMemcpyDeviceToHost</code>.</li><li>Three distinct types of memory visible to kernels are per-thread private, per-block shared, and device global memory.</li><li><code>cudaMalloc</code>, <code>cudaMemcpy</code>, and cudaFree operate on the device’s global memory, and those local variables in the kernel function are in per-thread private memory.<br />We can declare variables in per-block shared memory with <code>__share__</code>.</li><li>If multiple threads in a block need to access a common memory, they will all read it once. And if that memory is in the global memory, it would be really slow.</li><li>We can copy the common memory into the per-block shared memory to avoid such an efficient decrease. So we only need to access global memory once, and later accesses only in per-block shared memory.<br />We need to declare a <code>__share__</code> array and assign it to values in global memory.</li><li>All threads copy data from global memory to per-block shared memory asynchronous, so we better ass a <code>_syncthread()</code> to make sure later operations only start when all data have been copied.</li></ol><h2 id="hardware-implementation"><a class="markdownIt-Anchor" href="#hardware-implementation"></a> Hardware implementation</h2><ol><li>Those synchronizations within a warp and scheduling are done by hardware, and programmers don’t need to worry about these things.</li><li>GPU implementation maps thread blocks (“work”) to cores using a dynamic scheduling policy that respects resource requirements.</li><li>In GPU implementation (not a CUDA abstraction), each SM has multiple groups of warps. However, the number of warp execution contexts is far more than the number of warps.<br />There is a warp selector for each warp to choose the instruction to be executed by that warp. Each warp selector usually has two (or more) Fectch/Decoder units.</li><li>Shared per-block memory and L1-cache are inside each SM, but L2-cache is shared by all SMs.<br />The device-global memory (GPU memory) only communicates with blocks through the L2 cache.</li><li>For each clock, an SM will choose several warp contexts to fill all warps to use thread-level parallelism, and a warp will choose several instructions to fill all Fetch/Decoder units to use instruction-level parallelism.</li><li>When running a CUDA program, the GPU work scheduler will map one block to multiple warps in the same SM core. CUDA threads are numbered within a block in row-major order.<br />Inside a single thread block is SPMD shared address space programming.</li><li>When a single warp accesses consecutive memory locations, do block read or write. When single warp accesses separated memory locations, it requires gather (read) or scatter(write)</li><li>One SM core may have multiple blocks, so an SMM core can concurrently execute multiple CUDA thread blocks.<br />When all threads in the block are complete, block resources (shared memory allocations, warp execution contexts) become available for the next block.</li><li>The CUDA program is not compiled into SIMD instructions like ISPC gangs. GPU hardware dynamically checks whether 32 independent CUDA threads share an instruction. If true, it executes all 32 threads in a SIMD manner, or performance can suffer due to divergent execution.</li></ol>]]></content>
      
      
      <categories>
          
          <category> Open Courses </category>
          
          <category> CMU 15-418 / Stanford CS149 Parallel Computing </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Parallelism </tag>
            
            <tag> CUDA </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>04. Work Distribution and Scheduling</title>
      <link href="/2022/05/17/Courses/CS149/04-Work-Distribution-and-Scheduling/"/>
      <url>/2022/05/17/Courses/CS149/04-Work-Distribution-and-Scheduling/</url>
      
        <content type="html"><![CDATA[<h1 id="balancing-the-workload"><a class="markdownIt-Anchor" href="#balancing-the-workload"></a> Balancing the workload</h1><p>Always implement the simplest solution first, then measure performance to determine if you need to do better.</p><h2 id="static-assignment"><a class="markdownIt-Anchor" href="#static-assignment"></a> Static assignment</h2><ol><li>The assignment of work to threads is pre-determined. But it is not necessarily determined at compile-time; it may depend on runtime parameters.</li><li>Benefit: simple, essentially zero runtime overhead</li><li>Applicable situation: When the cost (execution time) of work and the amount of work is predictable. The following are some of the most common situations:<br />When it is known upfront that all work has the same cost<br />When work is predictable, but not all jobs have the same cost<br />When statistics about execution time are known</li><li>Semi-static assignment: When the work cost is predictable for the near-term future, we can periodically profile itself and re-adjust the assignment.<br />The assignment is “static” for the interval between re-adjustments</li></ol><h2 id="dynamic-assignment"><a class="markdownIt-Anchor" href="#dynamic-assignment"></a> Dynamic assignment</h2><ol><li><p>The program determines assignment dynamically at runtime to ensure a well-distributed load. They are often used when the execution time or the total number of tasks is unpredictable.</p></li><li><p>The ISPC task is implemented dynamically.</p></li></ol><h3 id="with-one-queue"><a class="markdownIt-Anchor" href="#with-one-queue"></a> With one queue</h3><ol><li><p>The programmers divide the whole problem into sub-problems (or “tasks”, “work”). A queue shared by all threads is a collection of work to do. A thread will grab another task from the queue whenever it finishes its task.</p></li><li><p>Fine granularity partitioning: each task is small.<br />This is likely to have a good workload balance, but there is potential for high synchronization costs.</p></li><li><p>Coarse granularity partitioning: each task is larger.<br />This will decrease synchronization cost and the overhead but may have a worse workload balance.</p></li><li><p>Long tasks should be scheduled first. Thread performing long tasks performs fewer overall tasks but approximately the same amount of work as the other threads. This requires some knowledge of the workload.</p></li></ol><h3 id="with-a-set-of-queues"><a class="markdownIt-Anchor" href="#with-a-set-of-queues"></a> With a set of queues</h3><ol><li><p>When assigned to one queue, all threads have to communicate with each other about the queue.</p></li><li><p>Each thread has its queue, and it only executes tasks in its queue. So, there is no need to communicate with other threads.</p></li><li><p>Initially, the programmer pushes tasks into queues arbitrarily (a bit like a static assignment).<br />The dynamic is that when a queue is empty, that thread can steal from other still-working threads.<br />It will steal from a random thread. Every time, it will steal a proportion of the tasks in the target queue, not all of them, and usually more than one task.<br />A thread is terminated when there is no thread for it to steal; when a steal fails, it will try to steal from other threads until it has tried all of them.</p></li><li><p>Stealing involves communication but at a lower frequency than one queue method. In this way, the local queue access is fast.</p></li><li><p>Sometimes, it is hard to have fully independent tasks, but work in task queues need not be independent.<br />A task is not removed from the queue and assigned to the worker thread until all task dependencies are satisfied. Workers can submit new tasks (with optional, explicit dependencies) to the task system.</p></li></ol><h1 id="scheduling"><a class="markdownIt-Anchor" href="#scheduling"></a> Scheduling</h1><p>In a divide-and-conquer algorithm, there are both dependencies and independencies. Like in quick-sort, both divides depend on the partition, and those two divides are independent.<br />With Cilk Plus, we can express divide-and-conquer easier.</p><h2 id="cilk_spawn"><a class="markdownIt-Anchor" href="#cilk_spawn"></a> cilk_spawn</h2><ol><li><p><code>cilk_spawn</code> is labeled before a function call so that the called function can run concurrently with the code after the call.<br />The call labeled <code>cilk_spawn</code> is the spawned child, and the rest of the code is the continuation.</p></li><li><p>In divide-and-conquer, there is always a time when the problem size is small enough that the overhead of spawn trumps the benefits of<br />potential parallelization. Then, we will solve those problems sequentially.</p></li><li><p>The main idea is to expose independent work (potential parallelism) to the system using <code>cilk_spawn</code>.</p></li><li><p><code>cilk_spawn</code> is a bit like <code>pthread_create</code>, and <code>cilk_sync</code> is similar to <code>pthread_join</code>. But the <code>pthread</code> has some problems when too many threads are spawned.<br />The first is the heavyweight spawn operation. Many more concurrently running threads than cores will cause context-switching overhead, a larger working set than necessary, and less cache locality.</p></li><li><p>The Cilk Plus runtime maintains a pool of worker threads. All threads are created at the application launch.  The machine has exactly as many worker threads as in execution contexts.<br />If we labeled everything <code>cilk_spawn</code>, the main thread has nothing to do.</p></li><li><p>Each thread in the pool will maintain a work queue to store what word needs to be done.<br />When a thread goes idle, it will look in the busy thread’s queue for work and move work from the busy thread’s queue to its queue.</p></li><li><p>If the caller thread runs the continuation first, the queue should record the child for later execution, and the child is made available for stealing by other threads.<br />The caller thread will spawn as many children as possible using this method, like BFS. If there is no stealing, the execution order is very different than<br />that of program withcilk_spawnremoved.</p></li><li><p>If the caller thread runs the child first, the queue should record continuation for later execution, and continuation is made available for stealing by other threads.<br />In this method, the caller thread will only create one item to steal.<br />If no stealing occurs, the thread continually pops continuation from the work queue and enqueues new continuation (like DFS). The execution order is the same as for the program with spawn removed.<br />If continuation is stolen, the stealing thread spawns the next child.</p></li><li><p>If the continuation is run first, there will be more items to steal; thus, it will be a better advantage of multi-thread.<br />But if the continuation is run first, the work queue storage for a system with T threads is no more than T times that of stack storage for single-threaded execution and thus saves more space.</p></li><li><p>The work queue is implemented as a dequeue (double-ended queue).<br />Local thread pushes/pops from the “tail” (bottom), while remote threads steal from the “head” (top).<br />Reduces contention with local thread: local thread does not access the same part of dequeue as stealing threads.<br />Do larger work first: in divide-and-conquer, the top of the queue is usually at the beginning of the call tree and is a larger piece of work.<br />Maximizes locality: in conjunction with the run-child-first policy, the local thread works on the local part of the call tree</p></li></ol><h2 id="cilk_sync"><a class="markdownIt-Anchor" href="#cilk_sync"></a> cilk_sync</h2><ol><li><p><code>cilk_sync</code> is used after those <code>cilk_spawn</code> call code. It will return when all calls spawned by the current function have been completed.</p></li><li><p>There is an implicit <code>cilk_sync</code> at the end of every function containing a cilk_spawn, so when a Cilk function returns, all work associated with that function is complete.</p></li><li><p>If no work has been stolen by other threads, then there’s nothing to do at the sync point, <code>cilk_sync</code> is a no-op. But this is not a common situation.</p></li><li><p>One way to implement sync is with a stalling joint.<br />The thread that initiates the fork must perform the sync. Therefore, it waits for all spawned work to be complete.<br />The descriptor for block A was created.<br />When stealing from the initial thread happens, a descriptor for that stolen work is created to track the number of outstanding spawns for the block and the number of those that have completed.<br />When all the child spawned for the block is done, this block is considered done, and the descriptor is free. When all the blocks are done, sync is fulfilled.</p></li><li><p>Another way to implement sync is the greedy policy.<br />When the thread that initiates the fork goes idle, it can look to steal new work.  The last thread to reach the join point continues execution after sync. This will also create a descriptor for those stolen works.<br />The worker thread that initiated spawn may not be the thread that executes logic after <code>cilk_sync</code>.</p></li><li><p>In greed policy, All threads always attempt to steal if there is nothing to do, and the thread only goes idle if no work to steal is present in the system. But in stalling policy, the initial thread doesn’t steal and only waits until its work is done.</p></li><li><p>The overhead of bookkeeping steals and managing sync points only occurs when steals occur. If large pieces of work are stolen, this should occur infrequently. Most of the time, threads push/pop local work from their local queue.</p></li><li><p>Cilk uses greedy join scheduling.</p></li></ol>]]></content>
      
      
      <categories>
          
          <category> Open Courses </category>
          
          <category> CMU 15-418 / Stanford CS149 Parallel Computing </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Parallelism </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>03. Parallel Programming Basics</title>
      <link href="/2022/04/20/Courses/CS149/03-Parallel-Programming-Basics/"/>
      <url>/2022/04/20/Courses/CS149/03-Parallel-Programming-Basics/</url>
      
        <content type="html"><![CDATA[<h1 id="decomposition"><a class="markdownIt-Anchor" href="#decomposition"></a> Decomposition</h1><ol><li><p>Decomposition: The problem to solve is usually a chunk of work. So the first step we need to do is to decomposite them into subproblems (a.k.a tasks, work to do)</p></li><li><p>We usually want the number of subproblems to be at least as many as processors.</p></li><li><p>The key aspect of decomposition is to identify dependencies. We want subproblems to be independent so that they can be paralleled.</p></li><li><p>Amdahl’s Law: dependencies limit maximum speedup due to parallelism<br />Let S = the fraction of sequential execution that is inherently sequential (dependencies prevent parallel execution). The maximum speedup due to parallel execution ≤ 1/S.</p><p class='katex-block'><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>s</mi><mi>p</mi><mi>e</mi><mi>e</mi><mi>d</mi><mi>u</mi><mi>p</mi><mo>≤</mo><mfrac><mi>t</mi><mrow><mi>s</mi><mi>t</mi><mo>+</mo><mfrac><mrow><mo stretchy="false">(</mo><mn>1</mn><mo>−</mo><mi>s</mi><mo stretchy="false">)</mo><mi>t</mi></mrow><mi>p</mi></mfrac></mrow></mfrac><mo>=</mo><mfrac><mn>1</mn><mrow><mi>s</mi><mo>+</mo><mfrac><mrow><mn>1</mn><mo>−</mo><mi>s</mi></mrow><mi>p</mi></mfrac></mrow></mfrac></mrow><annotation encoding="application/x-tex">speedup \le\frac{t}{st+\frac{(1-s)t}{p}}=\frac1{s+\frac{1-s}{p}} </annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord mathnormal">s</span><span class="mord mathnormal">p</span><span class="mord mathnormal">e</span><span class="mord mathnormal">e</span><span class="mord mathnormal">d</span><span class="mord mathnormal">u</span><span class="mord mathnormal">p</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">≤</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:2.6731879999999997em;vertical-align:-1.381108em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.29208em;"><span style="top:-2.11em;"><span class="pstrut" style="height:3.01em;"></span><span class="mord"><span class="mord mathnormal">s</span><span class="mord mathnormal">t</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.01em;"><span style="top:-2.6550000000000002em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">p</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.485em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mtight">1</span><span class="mbin mtight">−</span><span class="mord mathnormal mtight">s</span><span class="mclose mtight">)</span><span class="mord mathnormal mtight">t</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.481108em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span><span style="top:-3.2399999999999998em;"><span class="pstrut" style="height:3.01em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.687em;"><span class="pstrut" style="height:3.01em;"></span><span class="mord"><span class="mord mathnormal">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.381108em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:2.537656em;vertical-align:-1.216216em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.32144em;"><span style="top:-2.264892em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathnormal">s</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.845108em;"><span style="top:-2.6550000000000002em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">p</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span><span class="mbin mtight">−</span><span class="mord mathnormal mtight">s</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.481108em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord">1</span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.216216em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></span></p></li><li><p>In most cases, the programmer is responsible for performing decomposition.</p></li><li><p>When doing the decomposition, it is better to think of partitioning computation instead of data.</p></li></ol><h1 id="assignment"><a class="markdownIt-Anchor" href="#assignment"></a> Assignment</h1><ol><li><p>Assignment: When the subproblems are more than processors, we will group them to form a larger chunk of work and assign the grouped tasks to parallel threads.</p></li><li><p>One goal is to balance the workload so that each processor finishes their work almost simultaneously.<br />Another goal is to reduce communication costs. Getting data from another processor is nontrivial expensive, either cache miss or waiting for a message.<br />These two goals are at odds with each other.</p></li><li><p>This step can be performed statically or dynamically during the execution<br />Static way: Before the processors begin the work, we have already decided how to divide things.<br />Dynamic way: We work out how to divide on the way as processing.</p></li><li><p>We can choose the static way with the programCount and programIndex assignment or pthread</p></li><li><p>We can choose the dynamic way with foreach if the system chooses the dynamic way or the queue.<br />In the queue way, we arrange all tasks in a queue, and when a processor has done its job, it will grab another task from the queue. This is an excellent way to balance the workload, but maintaining the queue and acquiring tasks from it might cost some performance.</p></li></ol><h1 id="orchestration"><a class="markdownIt-Anchor" href="#orchestration"></a> Orchestration</h1><ol><li><p>Orchestration: When parallel threads are running, they may need to cooperate. So, we need to let them communicate correctly.</p></li><li><p>We will worry about things like structure communication, synchronization, organizing data structure in memory, and scheduling tasks.</p></li><li><p>The goal is to reduce the costs of communication/sync, preserve the locality of data reference, reduce the overhead of synchronization or communication, etc.</p></li><li><p>In the shared address space model, lock/unlock is commonly used for preserving atomicity, and barriers can divide computation into phases. When threads execute to barriers, they will stop and wait. Until enough threads hit the barrier, those stalled threads can execute rest codes.</p></li><li><p>A commonly used optimization strategy is fewer locks/unlocks and barriers.<br />Every time we operate a shared variable, we must use the lock/unlock to keep atomicity. We could operate on partial variables locally and then merge the partial results.<br />When we use a barrier to keep a shared variable valid when it might be changed at the next phase, we can use different shared variables in successive phases. This is to trade off footprint for removing dependencies.</p></li></ol><h1 id="mapping"><a class="markdownIt-Anchor" href="#mapping"></a> Mapping</h1><ol><li><p>Mapping: Finally, we need to map each thread to physical hardware.</p></li><li><p>When we map pthreads to hardware execution context on a CPU core, this is done by the operating system.<br />When we map ISPC program instances to vector instruction lanes, this is done by the compiler.<br />When we map CUDA thread blocks to GPU cores, this is done by the hardware.</p></li><li><p>Place related threads (cooperating threads) on the same processor to maximize locality data sharing and minimize costs of comm/sync.<br />Place unrelated threads on the same processor (one might be bandwidth-limited, and another might be compute-limited) to use the machine more efficiently.</p></li><li><p>Normally, we just let the OS do the mapping as it wants. But sometimes we still want to control the way of mapping.</p></li></ol>]]></content>
      
      
      <categories>
          
          <category> Open Courses </category>
          
          <category> CMU 15-418 / Stanford CS149 Parallel Computing </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Parallelism </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>02. Parallel programming models</title>
      <link href="/2022/04/18/Courses/CS149/02-Parallel-programming-models/"/>
      <url>/2022/04/18/Courses/CS149/02-Parallel-programming-models/</url>
      
        <content type="html"><![CDATA[<h1 id="ispc-intel-spmd-program-compiler"><a class="markdownIt-Anchor" href="#ispc-intel-spmd-program-compiler"></a> ISPC (Intel SPMD Program Compiler)</h1><h2 id="format-of-ispc"><a class="markdownIt-Anchor" href="#format-of-ispc"></a> Format of ISPC</h2><ol><li><p>ISPC is an SPMD compiler, not an SIMD.</p></li><li><p>The code that needs to be paralleled will be written in a file with the suffix “.ispc” as a function. And we will call that function in the main.cpp.<br />Call to the ISPC function spawns a gang of ISPC program instances. All instances run ISPC code concurrently. The ISPC function will return when all instances have been completed.<br />All code in main.cpp will be executed sequentially.</p></li><li><p><code>programCount</code>: the number of simultaneously executing instances in the gang. It is the same for all instances, thus called “uniform value.” This is not set by the programmer but by the run-time system. Programmers can only read it but don’t set that.</p></li><li><p><code>programIndex</code>: the ID of the current instance in the gang. It is a non-uniform value, namely varying.<br />This is used to assign work to each instance. If we don’t use the programIndex to control the work to be done by each instance, they will all do all the work. Thus, there will be redundancy and no performance improvement.</p></li><li><p><code>uniform</code>: a type modifier. All instances have a copy of the same value for this variable. Its use is purely an optimization. Not needed for correctness.<br />We cannot directly add a non-uniform value to a uniform value, which will cause a compile-time type error. To do so, we need a reduce_add function from the ISPC library.</p></li><li><p>Those ISPC program instances are not separate threads. The ISPC compiler generates a SIMD thread. So, the <code>programCount</code> is the vector width of the machine.<br />So, it can only run on one core. And “task” is used to achieve multi-core execution.</p></li></ol><h2 id="ways-of-assignment"><a class="markdownIt-Anchor" href="#ways-of-assignment"></a> Ways of assignment</h2><ol><li><p>Interleaved assignment: the data processed by each instance is discontinuous. Namely, the subscript is:</p><p class='katex-block'><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>p</mi><mi>r</mi><mi>o</mi><mi>g</mi><mi>r</mi><mi>a</mi><mi>m</mi><mi>I</mi><mi>n</mi><mi>d</mi><mi>e</mi><mi>x</mi><mo>+</mo><mi>i</mi><mo>×</mo><mi>p</mi><mi>r</mi><mi>o</mi><mi>g</mi><mi>r</mi><mi>a</mi><mi>m</mi><mi>C</mi><mi>o</mi><mi>u</mi><mi>n</mi><mi>t</mi><mo separator="true">,</mo><mi>i</mi><mo>∈</mo><mo stretchy="false">[</mo><mn>0</mn><mo separator="true">,</mo><mfrac><mrow><mi>N</mi><mo>−</mo><mi>p</mi><mi>r</mi><mi>o</mi><mi>g</mi><mi>r</mi><mi>a</mi><mi>m</mi><mi>I</mi><mi>n</mi><mi>d</mi><mi>e</mi><mi>x</mi></mrow><mrow><mi>p</mi><mi>r</mi><mi>o</mi><mi>g</mi><mi>r</mi><mi>a</mi><mi>m</mi><mi>C</mi><mi>o</mi><mi>u</mi><mi>n</mi><mi>t</mi></mrow></mfrac><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">programIndex+i\times programCount,i\in[0,\frac{N-programIndex}{programCount}) </annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord mathnormal">p</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mord mathnormal">o</span><span class="mord mathnormal" style="margin-right:0.03588em;">g</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mord mathnormal">a</span><span class="mord mathnormal">m</span><span class="mord mathnormal" style="margin-right:0.07847em;">I</span><span class="mord mathnormal">n</span><span class="mord mathnormal">d</span><span class="mord mathnormal">e</span><span class="mord mathnormal">x</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.74285em;vertical-align:-0.08333em;"></span><span class="mord mathnormal">i</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.8777699999999999em;vertical-align:-0.19444em;"></span><span class="mord mathnormal">p</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mord mathnormal">o</span><span class="mord mathnormal" style="margin-right:0.03588em;">g</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mord mathnormal">a</span><span class="mord mathnormal">m</span><span class="mord mathnormal" style="margin-right:0.07153em;">C</span><span class="mord mathnormal">o</span><span class="mord mathnormal">u</span><span class="mord mathnormal">n</span><span class="mord mathnormal">t</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal">i</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:2.25188em;vertical-align:-0.8804400000000001em;"></span><span class="mopen">[</span><span class="mord">0</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.3714399999999998em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathnormal">p</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mord mathnormal">o</span><span class="mord mathnormal" style="margin-right:0.03588em;">g</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mord mathnormal">a</span><span class="mord mathnormal">m</span><span class="mord mathnormal" style="margin-right:0.07153em;">C</span><span class="mord mathnormal">o</span><span class="mord mathnormal">u</span><span class="mord mathnormal">n</span><span class="mord mathnormal">t</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.10903em;">N</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mord mathnormal">p</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mord mathnormal">o</span><span class="mord mathnormal" style="margin-right:0.03588em;">g</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mord mathnormal">a</span><span class="mord mathnormal">m</span><span class="mord mathnormal" style="margin-right:0.07847em;">I</span><span class="mord mathnormal">n</span><span class="mord mathnormal">d</span><span class="mord mathnormal">e</span><span class="mord mathnormal">x</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.8804400000000001em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mclose">)</span></span></span></span></span></p></li><li><p>Block assignment: the data is split into several chunks, and each instance processes one chunk. So, the data is continuous. Namely, the subscript is:</p><p class='katex-block'><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>p</mi><mi>r</mi><mi>o</mi><mi>g</mi><mi>r</mi><mi>a</mi><mi>m</mi><mi>I</mi><mi>n</mi><mi>d</mi><mi>e</mi><mi>x</mi><mo>×</mo><mi>c</mi><mi>o</mi><mi>u</mi><mi>n</mi><mi>t</mi><mo>+</mo><mi>i</mi><mo separator="true">,</mo><mi>i</mi><mo>∈</mo><mo stretchy="false">[</mo><mn>0</mn><mo separator="true">,</mo><mi>c</mi><mi>o</mi><mi>u</mi><mi>n</mi><mi>t</mi><mo stretchy="false">)</mo><mo separator="true">,</mo><mi>c</mi><mi>o</mi><mi>u</mi><mi>n</mi><mi>t</mi><mo>=</mo><mfrac><mi>N</mi><mrow><mi>p</mi><mi>r</mi><mi>o</mi><mi>g</mi><mi>r</mi><mi>a</mi><mi>m</mi><mi>C</mi><mi>o</mi><mi>u</mi><mi>n</mi><mi>t</mi></mrow></mfrac></mrow><annotation encoding="application/x-tex">programIndex\times count+i, i\in[0,count),count=\frac{N}{programCount}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord mathnormal">p</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mord mathnormal">o</span><span class="mord mathnormal" style="margin-right:0.03588em;">g</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mord mathnormal">a</span><span class="mord mathnormal">m</span><span class="mord mathnormal" style="margin-right:0.07847em;">I</span><span class="mord mathnormal">n</span><span class="mord mathnormal">d</span><span class="mord mathnormal">e</span><span class="mord mathnormal">x</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.69841em;vertical-align:-0.08333em;"></span><span class="mord mathnormal">c</span><span class="mord mathnormal">o</span><span class="mord mathnormal">u</span><span class="mord mathnormal">n</span><span class="mord mathnormal">t</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.85396em;vertical-align:-0.19444em;"></span><span class="mord mathnormal">i</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal">i</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">[</span><span class="mord">0</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal">c</span><span class="mord mathnormal">o</span><span class="mord mathnormal">u</span><span class="mord mathnormal">n</span><span class="mord mathnormal">t</span><span class="mclose">)</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal">c</span><span class="mord mathnormal">o</span><span class="mord mathnormal">u</span><span class="mord mathnormal">n</span><span class="mord mathnormal">t</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:2.2407700000000004em;vertical-align:-0.8804400000000001em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.36033em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathnormal">p</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mord mathnormal">o</span><span class="mord mathnormal" style="margin-right:0.03588em;">g</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mord mathnormal">a</span><span class="mord mathnormal">m</span><span class="mord mathnormal" style="margin-right:0.07153em;">C</span><span class="mord mathnormal">o</span><span class="mord mathnormal">u</span><span class="mord mathnormal">n</span><span class="mord mathnormal">t</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.10903em;">N</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.8804400000000001em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></span></p></li><li><p>When using the block assignment, there are some situations when the cost of processing later data is more expensive than processing former data, making the assignment uneven. So, the interleaved assignment is less risky.</p></li><li><p>Since ISPC only generates one thread, continuous access to data in block assignments is less cache-friendly than discontinuous access in interleaved assignments.<br />If there are several threads, the block assignment might be more cache-friendly.</p></li><li><p>The data requested by all instances at the same time is a vector. In interleaved assignment, the data in a vector is memory continuous, while it is not in block assignment. So, in memory access, interleaved assignment is faster.</p></li><li><p><code>foreach (i = 0 ... N)</code> says that these loop iterations can be paralleled, and ISPC implementation assigns iterations to program instances in a gang. The current ISPC implementation will perform a static interleaved assignment.</p></li></ol><h2 id="system-layers"><a class="markdownIt-Anchor" href="#system-layers"></a> System layers</h2><ol><li><p>The layers from up to down are parallel applications, compilers and parallel runtime, operating system, Micro-architecture (hardware implementation)</p></li><li><p>Different parallel models can have various combinations of concerned layers.</p></li><li><p>If we express parallelism with pthread, it goes through all layers. First the parallel application calls <code>pthread_create()</code> to access the pthread library implementation. Then, the pthread library uses System call API to ask for OS support: kernel thread management. Finally, the OS uses <code>x86-64</code> to control modern multi-core CPU.</p></li><li><p>If we express parallelism with ISPC without “task,” it doesn’t need the support of OS. The parallel application uses ISPC language to ask for the service of the ISPC compiler. The compiler will produce machine language of x86-64, including <code>AVX vector instruction</code> to control a single-core CPU.</p></li></ol><h1 id="communication"><a class="markdownIt-Anchor" href="#communication"></a> Communication</h1><h2 id="shared-address-space"><a class="markdownIt-Anchor" href="#shared-address-space"></a> Shared Address Space</h2><ol><li><p>The whole machine has a shared space address. When threads aren’t working together, they access their memory space. They can communicate with each other by reading or writing the same data and manipulating synchronization primitives (like locks)</p></li><li><p>This model requires hardware support to implement efficiently. In hardware implementation, any processor can directly reference any memory location.</p></li><li><p>Symmetric (shared-memory) multi-processor (SMP): all processors have uniform memory access time. Namely, accessing an uncached memory address costs the same for all processors.<br />This is unscalable since the access latency will increase fast with more and more processors and memory chips.<br />The cores can share memory through a shared L3 cache or a crossbar switch with a die area of one core.</p></li><li><p>Non-uniform memory access (NUMA): All processors can access any memory location, but the cost of memory access (latency and bandwidth) differs for different processors. Each processor has a memory chip that is close to it.<br />This is more scalable because of the low latency and high bandwidth to local memory.<br />Cost is the increased programmer effort for performance tuning. Finding and exploiting locality is important to performance (want most memory accesses to be to local memories)</p></li></ol><h2 id="message-passing"><a class="markdownIt-Anchor" href="#message-passing"></a> Message Passing</h2><ol><li><p>Threads operate within their private address spaces and communicate by sending/receiving messages.</p></li><li><p>send: specifies recipient, buffer to be transmitted, and optional message identifier (“tag”)<br />receive: sender, specifies the buffer to store data, and optional message identifier</p></li><li><p>With this model, we can easily build large-scale parallel machines by interconnecting them. Hardware need not implement system-wide loads and stores to execute message-passing programs; need only be able to communicate messages.<br />However, the interconnect speed can be the system’s bottleneck.</p></li><li><p>We can implement the message-passing model with shared memory space.<br />Sending a message is copying memory from message library buffers while receiving the message is copying data from message library buffers.</p></li><li><p>Using less efficient software solutions, we can implement shared address space abstraction on machines without hardware support.<br />Mark all pages with shared variables as invalid at first, and the page-fault handler issues appropriate network requests</p></li><li><p>Synchronous (blocking) send and receive<br />Send(): Call returns when the sender receives an acknowledgment that the message data resides in the receiver’s address space.<br />Recv(): Call returns when data from the received message is copied into the receiver’s address space and acknowledgment sent back to the sender.<br />So, when using the message-passing model, we must be careful with the order of send() and recv() in each thread because it may easily raise a deadlock.<br />If the first call of all threads is send(), then no one is receiving, and all are waiting for someone to receive what they have sent.<br />One common way to program is to arrange one thread to send first and the receiver of that send to receive first.</p></li><li><p>Non-blocking asynchronous send/recv<br />Send() call returns immediately, while recv() posts intent to receive in the future and returns immediately.<br />We can use checksend() and checkrecv() to determine the actual status of the send/receipt.<br />The buffer provided to send() cannot be modified by calling the thread since message processing occurs concurrently with thread execution.</p></li></ol><h2 id="data-parallel"><a class="markdownIt-Anchor" href="#data-parallel"></a> Data Parallel</h2><ol><li><p>Data parallel has a very rigid computation structure. If it works well, it will work very well. But sometimes it just won’t work.</p></li><li><p>Nowadays, data-parallel usually takes the form of SPMD instead of SIMD. Programs perform the same function on different data elements in a collection<br /><code>map(function, collection)</code>: Synchronization is implicit at the end of the map. Map returns when the function has been applied to all elements of the collection</p></li><li><p>When the function is too complicated, the result might be non-deterministic.<br />Data-parallel model (foreach) provides no specification of the order in which iterations occur and no primitives for fine-grained mutual exclusion/synchronization.</p></li><li><p>Streams: collections of elements. Elements can be processed independently.<br />Kernels: side-effect-free functions. Operate element-wise on collections.</p></li><li><p>A stream can be claimed by <code>stream&lt;ElemType&gt; name(N)</code><br />When defining the kernel function, its parameters are single elements instead of a whole collection. But when we call the kernel function, we pass the streams into the function directly.</p></li><li><p>Benefits of stream programming:<br />Functions are side-effect-free (cannot write a non-deterministic program)<br />The compiler knows program data flow: Inputs and outputs of each invocation are known in advance, and thus, prefetching can be employed to hide latency.<br />When there are multiple kernels, and the output of the last kernel is the input of the next kernel, producer-consumer locality is known in advance.<br />Implementation can be structured so the second kernel immediately processes the outputs of the first kernel. The values are stored in on-chip buffers/caches and never written to memory, which saves bandwidth.<br />These optimizations are the responsibility of the stream program compiler. Requires global program analysis.</p></li><li><p>The drawback of stream programming is the need for a library of operators to describe complex data flows so that it might go wrong.</p></li><li><p><code>stream_gather(input, indices, tmp_input)</code>: Put elements in input to tmp_input according to indices. This is called before the kernel function, and the kernel function will deal with the gathered stream.<br /><code>stream_scatter(tmp_output, indices, output)</code>: Similar to stream_gather, but it is called after the kernel function, which will deal with the original stream.<br />The parameters of both functions are all stream.</p></li></ol><h2 id="synchronization-and-communication"><a class="markdownIt-Anchor" href="#synchronization-and-communication"></a> Synchronization and Communication</h2><ol><li><p>In shared address space, mutual exclusion is required for shared variables, and barriers are used to express dependencies between computation phases.<br />They can communicate through implicit loads/stores to shared variables.</p></li><li><p>In the message-passing model, the synchronizations and communications are performed by sending and receiving messages.</p></li><li><p>In the data parallel model, a single logical thread is in control, but the system may parallelize iterations of the forall loop. There is an implicit barrier at the end of the forall loop body.<br />They can also communicate through implicit loads and stores, like shared address space. There are also some special built-in primitives for more complex communication patterns, e.g., reduce</p></li></ol><h2 id="modern-practice"><a class="markdownIt-Anchor" href="#modern-practice"></a> Modern practice</h2><ol><li><p>Use shared address space programming within a multi-core chip of a cluster and use message passing between chips.<br />Use the convenience of shared address space where it can be implemented efficiently (within a chip) and require explicit communication elsewhere.</p></li><li><p>Data-parallel-ish programming models support shared-memory style synchronization primitives in kernels. This could permit limited forms of inter-iteration communication.</p></li></ol>]]></content>
      
      
      <categories>
          
          <category> Open Courses </category>
          
          <category> CMU 15-418 / Stanford CS149 Parallel Computing </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Parallelism </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>01. Modern Multicore Processors</title>
      <link href="/2022/04/13/Courses/CS149/01-Modern-Multicore-Processors/"/>
      <url>/2022/04/13/Courses/CS149/01-Modern-Multicore-Processors/</url>
      
        <content type="html"><![CDATA[<h1 id="speedup"><a class="markdownIt-Anchor" href="#speedup"></a> Speedup</h1><ol><li>Speedup (using P processors) = execution time (using 1 processor) / execution time (using P processors)</li><li>We can only get a speedup of less than P times when using P processors.<br />One reason is that although cores are in the same chip when they want to communicate with each other, they have to transmit information through wires, which takes some time.<br />Another reason is the imbalance in work assignments, which caused one core to have too heavy assignments while others had nothing to do but wait.<br />Communication costs can dominate a parallel computation, severely limiting speedup. Especially when you assign tasks to too many cores, each core gets little computation.</li></ol><h1 id="parallelism"><a class="markdownIt-Anchor" href="#parallelism"></a> Parallelism</h1><p>Why parallelism?<br />Before 2004, the performance of single-processors grew exponentially. However, in 2004, Intel hit the Power Density Wall. It goes too hot if you get over 100 watts in a chip and will melt. And the battery won’t hold long.</p><h2 id="ilp"><a class="markdownIt-Anchor" href="#ilp"></a> ILP</h2><ol><li>Instruction-Level Parallelism. Extract several instructions from the same instruction stream, and multiple ALUs perform multiple operations parallel (within a core). This has to be done in the semantics of a program.</li><li>Superscalar processor: exploit ILP within an instruction stream. Parallelism is automatically and dynamically discovered by the hardware during execution (not programmer visible)</li><li>Example: Pentium 4<br />Its instruction decoder will yank a whole bunch of instructions out of the instruction stream and map them to a new kind of computation called data flow computation that will track which value is generated and feed which instruction there.<br />Decoders map them to independent processing units that can each perform a subset of the whole operations.<br />Control logics try to predict what’s going on and deal with it when it predicts incorrectly. The Branch Target Buffer records all the control flow instructions to predict where they will go again. If it predicts wrong, it will back out and doesn’t commit to those results generated, flushing them away.<br />Meltdown inspector: This logic leaks information about what other processors are doing.</li><li>Most available ILP is exploited by a processor capable of issuing four instructions per clock, and only little performance benefits from building a processor that can issue more.</li></ol><h2 id="multi-core"><a class="markdownIt-Anchor" href="#multi-core"></a> Multi-Core</h2><p>Before the multi-core era, the Majority of chip transistors were used to perform operations that helped a single instruction stream run fast.<br />More transistors mean a larger cache, smarter out-of-order logic, smarter branch predictor, etc. Also, more transistors get smaller transistors and, thus, higher clock frequencies.</p><h3 id="simpler-cores"><a class="markdownIt-Anchor" href="#simpler-cores"></a> Simpler cores</h3><ol><li>It uses increasing transistor count to add more cores to the processor rather than using transistors to increase the sophistication of processor logic that accelerates a single instruction stream (e.g., out-of-order and speculative operations)</li><li>Each core runs a single instruction stream slower than our original large core, but the sum performance is faster. With a smaller core, the communication cost inside of a chip will be cheaper.</li><li>However, the original programs express no parallelism and run as one thread on one of the processor cores.</li><li>One way to express parallelism is by using pthreads. It will create threads to deal with the tasks we assigned.</li><li>Another way is called data-parallel expression. The programmer declares loop iterations independent, and a compiler might automatically generate parallel threaded code.</li></ol><h3 id="simd-processing"><a class="markdownIt-Anchor" href="#simd-processing"></a> SIMD processing</h3><ol><li>Amortize the cost/complexity of managing an instruction stream across many ALUs. The same instruction is broadcast to all ALUs, executed in parallel on all ALUs</li><li>Each core has an independent vector register set that is different from the regular register set. Each core has multiple ALUs to execute the same instructions for different data.</li><li>Only a very structural, carefully written code can be automatically vectorized by compilers.</li><li>When conditional executions occur, the condition will run first and create a mask according to the result, which disables the ALUs that should not execute current instructions. Those active ALUs will execute the instructions and create a new mask. This procession will continue until all ALUs have executed all conditional instructions they should execute, and then they can execute the remaining unconditional codes together again.<br />When a core can handle n elements at the same time, the performance in the worst case is 1 / n of the peak performance.</li><li>Instruction stream coherence (“coherent execution”): Same instruction sequence applies to all elements operated upon simultaneously.<br />“Divergent” execution: A lack of instruction stream coherence</li><li>Coherent execution is necessary for efficient use of SIMD processing resources. However, coherent execution is unnecessary for efficient parallelization across cores since each core can fetch/decode a different instruction stream.</li></ol><h4 id="simd-on-modern-cpus"><a class="markdownIt-Anchor" href="#simd-on-modern-cpus"></a> SIMD on modern CPUs</h4><ol><li>SSE instructions: 128-bit operations: 4x32 bits or 2x64 bits (4-wide float vectors)<br />AVX instructions: 256-bit operations: 8x32 bits or 4x64 bits (8-wide float vectors)<br />AVX512 instructions: 512 bit operations: 16x32 bits or 8x64 bits (8-wide float vectors)</li><li>Instructions are generated by the compiler. Parallelism is explicitly requested by a programmer using intrinsics and conveyed using parallel language semantics. Finally, it is inferred by dependency analysis of loops by “auto-vectorizing” compiler.</li><li>Explicit SIMD: SIMD parallelization is performed at compile time. We can inspect the program binary and see SIMD instructions.</li></ol><h4 id="simd-on-modern-gpus"><a class="markdownIt-Anchor" href="#simd-on-modern-gpus"></a> SIMD on modern GPUs</h4><ol><li>It is usually SPMD (Single Program Multiple Data) in GPUs, and SIMD is used to implement much of the logic.</li><li>Implicit SIMD: Compiler generates a scalar binary (scalar instructions). But N instances of the program are <em>always run</em> together on the processor. In other words, the interface to the hardware itself is data-parallel.</li><li>Hardware (not compiler) is responsible for simultaneously executing the same instruction from multiple instances on different data on SIMD ALUs</li><li>SIMD width of most modern GPUs ranges from 8 to 32</li></ol><h1 id="access-memory"><a class="markdownIt-Anchor" href="#access-memory"></a> Access Memory</h1><ol><li>Memory latency: The time for a memory request (e.g., load, store) from a processor to be serviced by the memory system. Memory “access time” is a measure of latency.</li><li>Memory bandwidth: The rate at which the memory system can provide data to a processor</li><li>Stall: A processor “stalls” when it cannot run the next instruction in an instruction stream because of a dependency on a previous instruction. Accessing memory is a major source of stalls.</li><li>One way to reduce stall is by reducing latency.<br />One strategy is cache, which provides high bandwidth data transfer to the CPU.</li><li>Another way is hiding latency; namely, the latency of the memory operation is not changed; it just no longer causes reduced processor utilization.<br />One common strategy is the prefetch. All modern CPUs have logic for prefetching data into caches. Prefetching can also reduce performance if the guess is wrong (hogs bandwidth, pollutes caches)<br />The other is using multi-threading. The idea is to interleave the processing of multiple threads on the same core to hide stalls.</li></ol><h2 id="multi-threading"><a class="markdownIt-Anchor" href="#multi-threading"></a> Multi-threading</h2><ol><li>The key idea of throughput-oriented systems is that they potentially increase the time to complete work by any one thread to improve overall system throughput when running multiple threads.<br />Sometimes, one thread is runnable, but the processor does not execute it since the core is running some other thread.</li><li>With more storing execution contexts in the cache, the working set per thread is smaller, and the latency hiding ability is higher.<br />Since the cache space per thread is smaller, it may go to memory more often. Thus, it relies heavily on memory bandwidth.<br />When the thread is enough to achieve 100% utilization of the core, additional threads yield no benefit.</li><li>The instruction decoder will choose instructions from multiple threads and fire them to the execution units where the threads are shared. The memory interface unit will detect dependencies automatically.</li><li>Interleaved multi-threading (a.k.a. temporal multi-threading): For each clock, the core chooses a thread and runs an instruction from the thread on the ALUs</li><li>Simultaneous multi-threading (SMT): The core chooses instructions from multiple threads to run on ALUs for each clock. It is an extension of the superscalar CPU design.</li><li>The operating system maps your pthreads to the processor’s thread execution contexts.</li></ol><h2 id="cpus-and-gpus"><a class="markdownIt-Anchor" href="#cpus-and-gpus"></a> CPUs and GPUs</h2><ol><li>CPU has big caches, few threads, modest memory BW, and relies mainly on caches and prefetching.<br />GPU has small caches, many threads, huge memory BW, and relies mainly on multi-threading.</li><li>The bandwidth of GPUs is a lot faster than CPUs.</li><li>In GPUs, ALUs run twice the clock rate of the rest of the chip. So, each decoded instruction runs on 32 pieces of data on the 16 ALUs over two ALU clocks. (but to the programmer, it behaves like a 32-wide SIMD operation)<br />Warp: An instruction operating on a whole vector of data at a time.<br />SM: Streaming Multi-processor. Each SM has multiple warp selectors. Each selector has multiple ALUs with different functions. The selectors in the same SM have shared the memory and L1 cache. And all selectors can run parallel.</li><li>A core can have multiple scalar ALUs and multiple vector ALUs. Each vector ALU can perform either MUL and ADD or ADD only.<br />The number of execution contexts determines the maximum number of threads activated in a core.</li></ol><h2 id="bandwidth"><a class="markdownIt-Anchor" href="#bandwidth"></a> Bandwidth</h2><ol><li>If processors request data at a too high rate, the memory system cannot keep up. No amount of latency hiding helps this.</li><li>Organize computation to fetch data from memory less often.<br />Reuse data previously loaded by the same thread (traditional intra-thread temporal locality optimizations). <br />Share data across threads (inter-thread cooperation)</li><li>Request data less often (instead, do more arithmetic: it’s “free”).<br />Arithmetic intensity: Ratio of math operations to data access operations in an instruction stream.<br />The main point is that programs must have high arithmetic intensity to utilize modern processors efficiently.<br />If the data needed can be recalculated in ALUs, then don’t access memory; do the calculation.</li></ol>]]></content>
      
      
      <categories>
          
          <category> Open Courses </category>
          
          <category> CMU 15-418 / Stanford CS149 Parallel Computing </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Parallelism </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>

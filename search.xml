<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>00. Trade-offs summary</title>
      <link href="/2024/02/22/Courses/15445/00-Trade-offs-summary/"/>
      <url>/2024/02/22/Courses/15445/00-Trade-offs-summary/</url>
      
        <content type="html"><![CDATA[<p></p><ol><li><strong>Database</strong> v.s. <strong>CSV files</strong>:<ul><li>Database provided a better encapsulation representation that provides ensurence of data integrety, necessary operations and durability. Only SQL is exposed to the users.</li><li>CSV files requires used to write all operations, e.g. searching and writing, by themselves. It is enough for small amount of data.</li><li>Database can be easily used to manage complex or enormously large data which can be difficult for CSV files.</li></ul></li><li><strong>Disk-oriented DBMS</strong> v.s. <strong>OS memory mapping</strong>:<ul><li>The basic idea is that DBMS always knows better than OS.</li><li>Transaction safety: OS can flush dirty pages at any time causing dirty data corrupt database.</li><li>Error handling: DBMS may isolate the error and handle it only in the storage layer.</li></ul></li><li></li></ol>]]></content>
      
      
      <categories>
          
          <category> Open Courses </category>
          
          <category> CMU 15-445/645 Database System </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Database System </tag>
            
            <tag> Trade off </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Single Raft</title>
      <link href="/2023/12/09/OpenSource/TinyKV/Single-Raft/"/>
      <url>/2023/12/09/OpenSource/TinyKV/Single-Raft/</url>
      
        <content type="html"><![CDATA[<p><ul class="markdownIt-TOC"><li><a href="#execution-of-client-commands">Execution of client commands</a></li><li><a href="#tick-control">Tick control</a><ul><li><a href="#snapshot-generation-and-application">Snapshot generation and application</a></li></ul></li></ul></p><h1 id="execution-of-client-commands"><a class="markdownIt-Anchor" href="#execution-of-client-commands"></a> Execution of client commands</h1><img src="/imgs/TiKV/exec.png"><h1 id="tick-control"><a class="markdownIt-Anchor" href="#tick-control"></a> Tick control</h1><ol><li>When the <code>tickerDrive</code> of <code>RaftStore</code> sends a <code>MsgTypeTick</code> to <code>RaftWorker</code>, the <code>peerMsgHandler</code> would check several schedules.</li><li>When <code>PeerTickRaft</code> is up, the Raft node ticker is moved forward.</li><li>When <code>PeerTickRaftLogGC</code> is up and existing applied entries are more then the limit, it will propose a Raft command with administrator request to compact Raft log to the applied index when this request is made.<ul><li>The compaction is only executed when this request is committed.</li><li>The Raft node and peer storage modify their state according to the compact index and term. Then a garbage collection task is sent to the <code>raftLogGCWorker</code> which will remove compacted entries from <code>RaftDB</code>.</li></ul></li><li>When <code>PeerTickSchedulerHeartbeat</code> is up, a <code>SchedulerRegionHeartbeatTask</code> is sent to <code>schedulerWorker</code>.</li></ol><h2 id="snapshot-generation-and-application"><a class="markdownIt-Anchor" href="#snapshot-generation-and-application"></a> Snapshot generation and application</h2><img src="/imgs/TiKV/Snapshot.png">]]></content>
      
      
      <categories>
          
          <category> Open Source Code </category>
          
          <category> TiKV/TinyKV </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Storage </tag>
            
            <tag> TinyKV </tag>
            
            <tag> Raft </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Storage: Write and Read</title>
      <link href="/2023/11/24/OpenSource/TinyKV/Storage-Write-and-Read/"/>
      <url>/2023/11/24/OpenSource/TinyKV/Storage-Write-and-Read/</url>
      
        <content type="html"><![CDATA[<p><ul class="markdownIt-TOC"><li><a href="#key-value-storage-storagestorage">Key-Value Storage (storage.Storage)</a><ul><li><a href="#interface">Interface</a></li><li><a href="#simple-example-project1-standalonekv">Simple example: Project1 StandaloneKV</a></li><li><a href="#raftstorage">RaftStorage</a></li></ul></li><li><a href="#raft-storage-raftstorage">Raft storage (raft.Storage)</a><ul><li><a href="#interface-2">Interface</a></li><li><a href="#simple-example-memstorage">Simple example: MemStorage</a></li><li><a href="#project-2b-peerstorage">Project 2B: PeerStorage</a></li></ul></li></ul></p><h1 id="key-value-storage-storagestorage"><a class="markdownIt-Anchor" href="#key-value-storage-storagestorage"></a> Key-Value Storage (storage.Storage)</h1><ol><li>Each <code>Server</code> uses the KV storage interfaces <code>Write</code> and <code>Reader</code> to implement RPC interfaces like <code>RawGet</code>, <code>RawPut</code>, <code>RawDelete</code> and <code>RawScan</code> (in <code>kv/storage/server/raw_api.go</code>) provided to clients for corresponding functions.</li><li>This is the higher level abstract storage interface that hides lower-level storage implementation from the servers and clients. How do we implement the interface changes in different scenarios.<ul><li>In <code>kv/storage/mem_storage.go</code>, it is implemented as an in-memory standalone storage.</li><li>In <code>kv/storage/standalone_storage/standalone_storage.go</code>, it is implemented as BadgerDB.</li><li>In <code>kv/storage/raft_storage/raft_server.go</code>, it is implemented as a distributed storage based on Raft.</li></ul></li></ol><h2 id="interface"><a class="markdownIt-Anchor" href="#interface"></a> Interface</h2><ol><li><p>The storage interface must implement <code>Write</code> and <code>Reader</code>.</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// kv/storage/storage.go</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">type</span> Storage <span class="keyword">interface</span> &#123;</span><br><span class="line">Write(ctx *kvrpcpb.Context, batch []Modify) <span class="type">error</span></span><br><span class="line">Reader(ctx *kvrpcpb.Context) (StorageReader, <span class="type">error</span>)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p><code>Write</code> receives a batch of modification requests. Each request can be either a put request with a key-value pair or a delete request with only a key field.</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// kv/storage/modify.go</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">type</span> Modify <span class="keyword">struct</span> &#123;</span><br><span class="line">Data <span class="keyword">interface</span>&#123;&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">type</span> Put <span class="keyword">struct</span> &#123;</span><br><span class="line">Key   []<span class="type">byte</span></span><br><span class="line">Value []<span class="type">byte</span></span><br><span class="line">Cf    <span class="type">string</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">type</span> Delete <span class="keyword">struct</span> &#123;</span><br><span class="line">Key []<span class="type">byte</span></span><br><span class="line">Cf  <span class="type">string</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p><code>Reader</code> returns an API to get the value of a certain key or iterate over a column family.</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// kv/storage/storage.go</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">type</span> StorageReader <span class="keyword">interface</span> &#123;</span><br><span class="line"><span class="comment">// When the key doesn&#x27;t exist, return nil for the value</span></span><br><span class="line">GetCF(cf <span class="type">string</span>, key []<span class="type">byte</span>) ([]<span class="type">byte</span>, <span class="type">error</span>)</span><br><span class="line">IterCF(cf <span class="type">string</span>) engine_util.DBIterator</span><br><span class="line">Close()</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>The <code>DBIterator</code> is another interface that provides APIs to iterate over database.</p><ul><li><code>Item()</code> returns pointer to the current key-value pair.</li><li><code>Valid()</code> returns false when iteration is done.</li><li><code>Next()</code> would advance the iterator by one.</li><li><code>Seek([]byte)</code> would seek to the provided key if present. If absent, it would seek to the next smallest key greater than provided.</li><li><code>Close()</code> would close the iterator.</li></ul><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// kv/util/engine_util/cf_iterator.go</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">type</span> DBIterator <span class="keyword">interface</span> &#123;</span><br><span class="line">Item() DBItem</span><br><span class="line">Valid() <span class="type">bool</span></span><br><span class="line">Next()</span><br><span class="line">Seek([]<span class="type">byte</span>)</span><br><span class="line">Close()</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>The access to <code>DBIterm</code> is an interface that provides methods to get or copy the keys and values.</p><ul><li><code>KeyCopy(dst []byte) byte</code> and <code>ValueCopy(dst []byte) ([byte, error])</code> return a copy of the key or value of the item, writing it to dst slice. If <code>nil</code> is passed, or capacity of <code>dst</code> isn’t sufficient, a new slice would be allocated and returned.</li></ul><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">type</span> DBItem <span class="keyword">interface</span> &#123;</span><br><span class="line">Key() []<span class="type">byte</span></span><br><span class="line">KeyCopy(dst []<span class="type">byte</span>) []<span class="type">byte</span></span><br><span class="line">Value() ([]<span class="type">byte</span>, <span class="type">error</span>)</span><br><span class="line">ValueSize() <span class="type">int</span></span><br><span class="line">ValueCopy(dst []<span class="type">byte</span>) ([]<span class="type">byte</span>, <span class="type">error</span>)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>A <code>BadgerIterator</code> and <code>CFItem</code> is implemented that supports <code>DBIterator</code> and <code>DBItem</code>.</p><ul><li><code>func NewCFIterator(cf string, txn *badger.Txn) *BadgerIterator</code> can be used to create an iterator.</li><li>They are wrappers of <code>badger.Iterator</code> and <code>badger.Item</code> to support column family in <code>Valid</code> and <code>Seek</code> easier.</li><li>The prefix of the column family is stored inside that will be checked in <code>BadgerIterator.Valid</code> or removed in <code>CFItem.Key</code> and <code>CFItem.KeyCopy</code>.</li></ul></li></ol><h2 id="simple-example-project1-standalonekv"><a class="markdownIt-Anchor" href="#simple-example-project1-standalonekv"></a> Simple example: Project1 StandaloneKV</h2><ol><li>This project is to help us to learn how to write and read data with <a href="https://github.com/dgraph-io/badger">BadgerDB</a> and how are these interfaces used.</li><li>Both writing and reading are handled through a badger transaction.<ul><li>The BadgerDB transaction can use <code>Set</code>, <code>Delete</code> to process write requests and it will be committed after all write requests are finished.</li><li>The <code>BadgerIterator</code> uses the <code>NewIterator</code> method of the transaction to create a <code>badger.Iterator</code>.</li><li>When the iterator is no longer needed, <code>badger.Iterator</code> will be closed and the transaction will be discarded until reader is finished.</li></ul></li></ol><h2 id="raftstorage"><a class="markdownIt-Anchor" href="#raftstorage"></a> RaftStorage</h2><p>The code is in <code>kv/storage/raft_storage/raft_server.go</code>.</p><ol><li>On multi-Raft scenario, a <code>Store</code> stands for an instance of tinykv-server, a <code>Peer</code> stands for a Raft node which is running on a Store, while a <code>Region</code> is a collection of Peers, also called Raft group.</li><li>When starting a <code>RaftStorage</code>, it first starts a <code>rs.resolveWorker</code> and a <code>rs.snapWorker</code>. Then a <code>Node</code> is started.<ul><li>After a series of self-examinations, <code>Node</code> will start the core <code>Raftstore</code>.</li><li><code>Raftstore</code> first loads peers in this store. It scans the db engine, loads all regions and their peers from it and register them.</li><li>Then it begins to start workers to make jobs done.<ul><li>A <code>raftWorker</code> is used to execute Raft commands. Messages for all peers are received here, <code>raftWorker</code> needs to transmit to their destination.</li><li>A <code>storeWorker</code> is used to handle commands to the store.<ul><li>One kind is <code>MsgTypeStoreStart</code> that will be sent immediately after this worker is running.</li><li>Another kind is <code>MsgTypeStoreTick</code> to control the <code>tick()</code> on all peers in the same store. Another <code>tikerDriver</code> is used to generate this command.</li><li><code>MsgTypeStoreRaftMessage</code> can redirect a misplaced message.</li></ul></li><li>Other background threads, e.g. garbage collection or scheduler, are started as workers with different handler.</li></ul></li></ul></li><li>A <code>RaftstoreRouter</code> is created together with <code>Raftstore</code>.<ul><li>It has a <code>peerSender chan message.Msg</code> that will be used to communicate with <code>raftWorker</code> and another <code>storeSender chan&lt;- message.Msg</code> that will be read by <code>storeWorker</code>.</li><li>It provides <code>Send</code>, <code>SendRaftMessage</code> and <code>SendRaftCommand</code> for communication inside this store.</li></ul></li><li>In <code>Write</code> and <code>Reader</code>, It will generate a corresponding request of type <code>raft_cmdpb.RaftCmdRequest</code>.<ul><li>The request is a proposal to Raft group and the result will only be returned when its request entry is applied.</li><li>It is sent through a <code>router</code>, i.e. ignoring <code>RawXXX</code>, <code>Write</code> and <code>Reader</code> actually receive commands from other server or clients and forward them to peers.</li><li>Them command will be wrapped with a <code>Callback</code> that can be used to track the execution process of this command. When the <code>Callback</code> received done signal, it can return the response to the <code>Write</code> or <code>Reader</code>.</li></ul></li></ol><h1 id="raft-storage-raftstorage"><a class="markdownIt-Anchor" href="#raft-storage-raftstorage"></a> Raft storage (raft.Storage)</h1><p>This is the storage interface for Raft nodes to persist its internal states. Unlike the KV storage interface above, this is only used when implementing a Raft node.</p><h2 id="interface-2"><a class="markdownIt-Anchor" href="#interface-2"></a> Interface</h2><ol><li><p>The interfaces required are all read-only function. The writings are performed by upper applications.</p></li><li><p><code>InitialState()</code> returns the saved <code>HardState</code> and <code>ConfState</code> information.</p></li><li><p><code>Entries(lo, hi uint64)</code> returns a slice of log entries in the range <code>[lo,hi)</code>.</p><ul><li><code>MaxSize</code> limits the total size of the log entries returned, but it returns at least one entry if any.</li></ul></li><li><p><code>Term(i uint64)</code> returns the term of entry <code>i</code>, which must be in the range <code>[FirstIndex()-1, LastIndex()]</code>.</p><ul><li>The term of the entry before <code>FirstIndex</code> is retained for matching purposes even though the rest of that entry may not be available.</li></ul></li><li><p><code>LastIndex()</code> returns the index of the last entry in the log.</p></li><li><p><code>FirstIndex()</code> returns the index of the first log entry that is possibly available via <code>Entries</code> (older entries have been incorporated into the latest Snapshot; if storage only contains the dummy entry the first log entry is not available).</p></li><li><p><code>Snapshot()</code> returns the most recent snapshot.</p><ul><li>If snapshot is temporarily unavailable, it should return <code>ErrSnapshotTemporarilyUnavailable</code>, so raft state machine could know that Storage needs some time to prepare snapshot and call Snapshot later.</li></ul><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">type</span> Storage <span class="keyword">interface</span> &#123;</span><br><span class="line">InitialState() (pb.HardState, pb.ConfState, <span class="type">error</span>)</span><br><span class="line">Entries(lo, hi <span class="type">uint64</span>) ([]pb.Entry, <span class="type">error</span>)</span><br><span class="line">Term(i <span class="type">uint64</span>) (<span class="type">uint64</span>, <span class="type">error</span>)</span><br><span class="line">LastIndex() (<span class="type">uint64</span>, <span class="type">error</span>)</span><br><span class="line">FirstIndex() (<span class="type">uint64</span>, <span class="type">error</span>)</span><br><span class="line">Snapshot() (pb.Snapshot, <span class="type">error</span>)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li></ol><h2 id="simple-example-memstorage"><a class="markdownIt-Anchor" href="#simple-example-memstorage"></a> Simple example: MemStorage</h2><ol><li>This is defined in <code>raft/storage.go</code>. Besides those read-only interfaces, <code>MemStorage</code> also provides write methods for upper applications to change states.</li><li><code>SetHardState(st pb.HardState) error</code> changes the current <code>HardState</code> to the given one.</li><li><code>ApplySnapshot(snap pb.Snapshot) error</code> overwrites the contents of this Storage object with those of the given snapshot.<ul><li>In this case, it just overwrites the current snapshot and truncates <code>ents</code> with only a dummy entry.</li></ul></li><li><code>CreateSnapshot(i uint64, cs *pb.ConfState, data []byte) (pb.Snapshot, error)</code> makes a snapshot which can be used to reconstruct the state.<ul><li>If any configuration changes have been made since the last compaction, the result of the last <code>ApplyConfChange</code> must be passed in.</li><li>The data of state machine is acquired by the upper application not in this method.</li></ul></li><li><code>Compact(compactIndex uint64) error</code> discards all log entries prior to <code>compactIndex</code>.<ul><li>It is the application’s responsibility to not attempt to compact an index greater than <code>raftLog.applied</code>.</li></ul></li><li><code>Append(entries []pb.Entry) error</code> append the new entries to storage, i.e. persist Raft entries when this storage is writing to disk.</li></ol><h2 id="project-2b-peerstorage"><a class="markdownIt-Anchor" href="#project-2b-peerstorage"></a> Project 2B: PeerStorage</h2><ol><li>A peer storage needs to maintain the persistence of both Key-Value pairs in this peer and its Raft logs.<ul><li>The entries of Raft logs are stored with key <code>LocalPrefix_RegionRaftPrefix_regionID_RaftLogSuffix_entry index</code>.</li></ul></li><li>After acquired a value from <code>*badger.DB</code>, it can be transferred to correct type with the <code>Unmarshal</code> provided by the <code>struct</code> generated from protobuf.</li><li>The core of peer storage is <code>SaveReadyState</code> that will be used by <code>peerMsgHandler.HandleRaftReady</code> to persist according to <code>Ready</code>.<ul><li>In <code>ApplySnapshot</code>, if a snapshot is provided, it needs to update <code>ps.raftState</code>, <code>ps.applyState</code>, delete stale data and ask <code>regionRunner</code> to apply the snapshot.</li><li>In <code>Append</code>, if Raft entries are attached, it needs to append the given entries to the raft log and update <code>ps.raftState</code> also delete log entries that will never be committed.</li><li>If <code>HardState</code> is changed, update it.</li><li>Persist all changes.</li></ul></li></ol>]]></content>
      
      
      <categories>
          
          <category> Open Source Code </category>
          
          <category> TiKV/TinyKV </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Storage </tag>
            
            <tag> TinyKV </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>BusTub Overview</title>
      <link href="/2023/10/30/OpenSource/BusTub/BusTub-Overview/"/>
      <url>/2023/10/30/OpenSource/BusTub/BusTub-Overview/</url>
      
        <content type="html"><![CDATA[<p><ul class="markdownIt-TOC"><li><a href="#shell-execution">Shell execution</a></li></ul></p><h1 id="shell-execution"><a class="markdownIt-Anchor" href="#shell-execution"></a> Shell execution</h1><ol><li><p>The shell (in <a href="https://github.com/cmu-db/bustub/blob/master/tools/shell/shell.cpp">shell.cpp</a>) uses <code>linenoise</code> to read input lines until a line ending with <code>;</code> or beginning with <code>\</code>.</p><ul><li><code>;</code> means the end of a query while <code>\</code> leads an internal meta-command.</li><li>The backbone of the DBMS is <code>bustub::BustubInstance</code> (in <a href="https://github.com/cmu-db/bustub/blob/master/src/common/bustub_instance.cpp">bustub_instance.cpp</a>). It is initialized in the beginning of shell.</li><li>After reading the complete query, execute it with the <code>BustubInstance.ExecuteSql</code>. The result is writen in <code>bustub::FortTableWriter</code>.</li></ul></li><li><p>In <code>BustubInstance.ExecuteSqlTxn</code>:</p><ul><li>First determine whether this is an internal meta-command. If so, only executing the corresponding command and exit.</li><li>If this is a query, using <strong><code>bustub::Binder</code></strong> (in <a href="https://github.com/cmu-db/bustub/blob/master/src/binder/binder.cpp#L45">binder.cpp</a>) to parse the query into an AST. Handle the output format according to the statement type using <code>HandlexxxStatement</code>.</li><li>Then <strong><code>bustub::Planner</code></strong> will plan the query execution according to the generated AST. And <strong><code>bustub::Optimizer</code></strong> will optimize the plan tree with certain rules.</li><li>Then the plan will be executed by <strong><code>ExecutionEngine.Execute</code></strong> (in <a href="https://github.com/cmu-db/bustub/blob/master/src/include/execution/execution_engine.h#L54">execution_engine.h</a>).</li><li>Finally, the result will be written in the shell with writer.</li></ul></li><li><p>To provide easier format control, the <code>bustub::ResultWriter</code> provides interfaces for standard output.</p><ul><li><code>BeginHeader</code>, <code>EndHeader</code>, <code>BeginRow</code>, <code>EndRow</code> and <code>BeginTable</code>, <code>EndTable</code> to outputpre-defined message.</li><li><code>WriteCell</code> and <code>WriteHeaderCell</code> are used to output data and pre-defined separator.</li><li>Its sub-classes needs to override these methods to perform as they want.<ul><li><code>NoopWriter</code> simply does nothing in all these methods.</li><li><code>SimpleStreamWriter</code> will output simple plain text.</li><li><code>HtmlWriter</code> will output the results in HTML code that can be shown in browser.</li><li><code>FortTableWriter</code> uses <code>fort</code> to output table.</li></ul></li></ul></li></ol>]]></content>
      
      
      <categories>
          
          <category> Open Source Code </category>
          
          <category> BusTub </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Database System </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Data Define Language (DDL)</title>
      <link href="/2023/10/29/OpenSource/TinyDB/DDL/"/>
      <url>/2023/10/29/OpenSource/TinyDB/DDL/</url>
      
        <content type="html"><![CDATA[<p><ul class="markdownIt-TOC"><li><a href="#how-to-store-metadata">How to store metadata?</a></li><li><a href="#how-are-jobs-executed">How are jobs executed?</a></li></ul></p><h1 id="how-to-store-metadata"><a class="markdownIt-Anchor" href="#how-to-store-metadata"></a> How to store metadata?</h1><ol><li><p>Codes for metadata storage are in <code>parser/model</code>.</p></li><li><p>In <code>DBInfo</code>, each database stores the pointers of <code>TableInfo</code> in a slice <code>Table []*TableInfo</code>.</p><ul><li><p>In <code>TableInfo</code>, it contains all the information of the table including its columns <code>Columns []*ColumnInfo</code>, its indices <code>Indices []*IndexInfo</code>, its constraints <code>Constraints []*ConstraintInfo</code> and its foreign keys <code>ForeignKeys []*FKInfo</code>.</p><ul><li>The order of <code>Columns</code> is the same as the the order of logical order of columns.</li></ul></li><li><p>In <code>ColumnInfo</code>, it has an <code>Offset</code> to record its position in the table.</p></li><li><p>Except <code>DBInfo</code>, other information structures all have a <code>State</code> attribute that will be used when dealing with distributed DDL problem.</p></li></ul></li><li><p><code>Job</code> is specific for the DDL tasks.</p><ul><li>The <code>State JobState</code> attribute tracks its own state and <code>SchemaState SchemaState</code> tracks the state of changed schema.</li><li>The <code>CtxVars []interface&#123;&#125;</code> and <code>Args []interface&#123;&#125;</code> are variables attached to the job for internal usage. E.g. passing arguments between functions by one single <code>*Job</code> pointer.</li></ul></li></ol><h1 id="how-are-jobs-executed"><a class="markdownIt-Anchor" href="#how-are-jobs-executed"></a> How are jobs executed?</h1><ol><li>All TiDB nodes have a worker to process the DDL request from clients. However, only the worker in the owner can truely execute the DDL operation.<ul><li>Client can send their request to any TiDB node. The received node will ask a <code>start job</code> module to create a <code>Job</code> object, push it in the <code>job queue</code>.</li><li>The node will check whether it is the owner after pushed the job. If it is not, it just tracks the state of the job.</li></ul></li><li>The owner would periodically check the job queue to find unexecuted jobs and execute them. After a job is finished, it will be moved into the <code>job history queue</code>.</li><li>The <code>start job</code> can finish when it find the job it is tracking is in the <code>job history queue</code> and responses to  client.</li></ol><img src="/imgs/TiDB/ddl_job_exec.jpg" width="50%">]]></content>
      
      
      <categories>
          
          <category> Open Source Code </category>
          
          <category> TiDB </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Database </tag>
            
            <tag> Data Define Language </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Parser, goyacc and EBNF</title>
      <link href="/2023/10/23/OpenSource/TinyDB/Parser-goyacc-and-EBNF/"/>
      <url>/2023/10/23/OpenSource/TinyDB/Parser-goyacc-and-EBNF/</url>
      
        <content type="html"><![CDATA[<p><ul class="markdownIt-TOC"><li><a href="#what-are-the-components-of-parser">What are the components of parser?</a></li><li><a href="#yacc">Yacc</a><ul><li><a href="#what-is-the-input-of-yacc">What is the input of yacc?</a><ul><li><a href="#definitions">Definitions</a></li><li><a href="#rules">Rules</a></li></ul></li><li><a href="#what-is-generated-by-yacc">What is generated by yacc?</a></li><li><a href="#how-to-generate-a-y-file">How to generate a .y file?</a></li><li><a href="#how-to-cooperate-lex-with-parser-generated-by-yacc">How to cooperate Lex with parser generated by yacc?</a></li></ul></li><li><a href="#reference">Reference</a></li></ul></p><h1 id="what-are-the-components-of-parser"><a class="markdownIt-Anchor" href="#what-are-the-components-of-parser"></a> What are the components of parser?</h1><ol><li><code>Laxical anaylysis</code> identifies substrings in input string to produce a stream of tokens which is the input of the parser.<ul><li><code>Lex</code> is used to generate the <code>lexical analyzer</code> based on the user defined patterns.</li></ul></li><li><code>Parser</code> takes the input stream from lexical analysis to decide whether this string is a valid program. If so, an abstract syntax tree (AST) is generated for further process.<ul><li>Parser determines the validation and generates AST with reduction under rules described by context-free language.</li><li>We can use <code>yacc</code> to generate a parser based on the user defined rules.</li></ul></li></ol><img src="/imgs/TiDB/parser_comps.png" width="25%"><h1 id="yacc"><a class="markdownIt-Anchor" href="#yacc"></a> Yacc</h1><h2 id="what-is-the-input-of-yacc"><a class="markdownIt-Anchor" href="#what-is-the-input-of-yacc"></a> What is the input of yacc?</h2><ol><li><p>Like <code>Lex</code>, it takes a <code>.y</code> file that contains the rules as input.</p></li><li><p>A <code>.y</code> file separates different parts by <code>%%</code>, i.e.</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">%&#123;</span><br><span class="line">Embedding codes</span><br><span class="line">%&#125;</span><br><span class="line">/* Definitions */</span><br><span class="line">%%</span><br><span class="line">/* Rules */</span><br><span class="line">%%</span><br><span class="line">/* Subroutines */</span><br></pre></td></tr></table></figure></li></ol><h3 id="definitions"><a class="markdownIt-Anchor" href="#definitions"></a> Definitions</h3><ol><li><p>Embedding codes are written in GoLang that copied into the code file directly. Mostly declare package or import packages.</p></li><li><p>The definition part defines the combination of token types and operators.</p><table><thead><tr><th style="text-align:center">Describer</th><th style="text-align:center">Usage</th></tr></thead><tbody><tr><td style="text-align:center"><code>%union</code></td><td style="text-align:center">Identifies the yacc value stack as the union of the various type of values desired.</td></tr><tr><td style="text-align:center"><code>%struct</code></td><td style="text-align:center">Same as <code>%union</code>, <code>%union</code> is recommended</td></tr><tr><td style="text-align:center"><code>%token</code></td><td style="text-align:center">Identifies the type of terminals (tokens).</td></tr><tr><td style="text-align:center"><code>%type</code></td><td style="text-align:center">Identifies the type of nonterminals.</td></tr><tr><td style="text-align:center"><code>%start</code></td><td style="text-align:center">Identifies a non-terminal name for the start symbol. By default, it is the first non-terminal.</td></tr><tr><td style="text-align:center"><code>%left</code></td><td style="text-align:center">Identifies tokens that are left-associative with other tokens.</td></tr><tr><td style="text-align:center"><code>%right</code></td><td style="text-align:center">Identifies tokens that are right-associative with other tokens.</td></tr><tr><td style="text-align:center"><code>%nonasso</code></td><td style="text-align:center">Identifies tokens that are not associative with other tokens.</td></tr></tbody></table></li><li><p>The <code>%token</code>, <code>%left</code>, <code>%right</code>, and <code>%nonassoc</code> keywords optionally support the name of a union member (as defined by <code>%union</code>) called a <code>&lt;Tag&gt;</code>. The <code>%type</code> keyword requires a <code>&lt;Tag&gt;</code>.</p></li><li><p>All of the tokens on the same line have the same precedence level and associativity. The lines appear in the file in order of increasing precedence or binding strength.</p></li><li><p>All variables or constants in other parts of the file must have declaration in this section.</p></li></ol><h3 id="rules"><a class="markdownIt-Anchor" href="#rules"></a> Rules</h3><ol><li><p>For a production <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">⟨</mo><mi>l</mi><mi>e</mi><mi>f</mi><mi>t</mi><mo stretchy="false">⟩</mo><mo>→</mo><mo stretchy="false">⟨</mo><mi>a</mi><mi>l</mi><mi>t</mi><mtext> </mtext><mn>1</mn><mo stretchy="false">⟩</mo><mtext> </mtext><mi mathvariant="normal">∣</mi><mtext> </mtext><mo stretchy="false">⟨</mo><mi>a</mi><mi>l</mi><mi>t</mi><mtext> </mtext><mn>2</mn><mo stretchy="false">⟩</mo><mtext> </mtext><mi mathvariant="normal">∣</mi><mtext> </mtext><mo>…</mo><mi mathvariant="normal">∣</mi><mtext> </mtext><mo stretchy="false">⟨</mo><mi>a</mi><mi>l</mi><mi>t</mi><mtext> </mtext><mi>n</mi><mo stretchy="false">⟩</mo></mrow><annotation encoding="application/x-tex">\langle left\rangle\rightarrow \langle alt\ 1\rangle\ |\ \langle alt\ 2\rangle\ |\ \dots|\ \langle alt\ n\rangle</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">⟨</span><span class="mord mathnormal" style="margin-right:0.01968em;">l</span><span class="mord mathnormal">e</span><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="mord mathnormal">t</span><span class="mclose">⟩</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">→</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">⟨</span><span class="mord mathnormal">a</span><span class="mord mathnormal" style="margin-right:0.01968em;">l</span><span class="mord mathnormal">t</span><span class="mspace"> </span><span class="mord">1</span><span class="mclose">⟩</span><span class="mspace"> </span><span class="mord">∣</span><span class="mspace"> </span><span class="mopen">⟨</span><span class="mord mathnormal">a</span><span class="mord mathnormal" style="margin-right:0.01968em;">l</span><span class="mord mathnormal">t</span><span class="mspace"> </span><span class="mord">2</span><span class="mclose">⟩</span><span class="mspace"> </span><span class="mord">∣</span><span class="mspace"> </span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="minner">…</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord">∣</span><span class="mspace"> </span><span class="mopen">⟨</span><span class="mord mathnormal">a</span><span class="mord mathnormal" style="margin-right:0.01968em;">l</span><span class="mord mathnormal">t</span><span class="mspace"> </span><span class="mord mathnormal">n</span><span class="mclose">⟩</span></span></span></span>, we can write it as:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">&lt;left&gt; : &lt;alt&gt; &#123;action 1&#125;</span><br><span class="line">       | &lt;alt&gt; &#123;action 2&#125;</span><br><span class="line">       ...</span><br><span class="line">       | &lt;alt&gt; &#123;action n&#125;</span><br><span class="line">       ;</span><br></pre></td></tr></table></figure></li><li><p>The sematic actions will be executed when the corresponding reduction is happened in the generated parser. Actions return values and obtain the values returned by previous actions.</p><ul><li>The return value of this action is referred by <code>$$</code>.</li><li>Values returned by previous actions can be referred by <code>$n</code> which points to the returned value of the <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi></mrow><annotation encoding="application/x-tex">n</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathnormal">n</span></span></span></span>-th component. E.g. In <code>A : B C D &#123;&#125;;</code>, <code>$1</code>, <code>$2</code> and <code>$3</code> refer to the returned value of <code>B</code>, <code>C</code> and <code>D</code>.</li><li>By default, the value of a rule is the value of the first element in it (<code>$1</code>).</li><li><code>$&lt;tag&gt;$</code> and <code>$&lt;tag&gt;n</code> allow for type-checking.</li></ul></li><li><p>The actions should be written in the same language as the generated parser.</p></li></ol><h2 id="what-is-generated-by-yacc"><a class="markdownIt-Anchor" href="#what-is-generated-by-yacc"></a> What is generated by yacc?</h2><ol><li>It generates a program file, e.g. <code>.go</code> file for goyacc and <code>.c</code> file for yacc, that implements the <code>yyParser</code> according to the rules in the <code>.y</code> file.</li><li>The <code>%union</code> structure will become a structure called <code>yySymType</code> that contains all the attributes in union.</li><li>The <code>$n</code> in actions will be replaced by macro definitions.</li></ol><h2 id="how-to-generate-a-y-file"><a class="markdownIt-Anchor" href="#how-to-generate-a-y-file"></a> How to generate a .y file?</h2><p>Implementing a <code>.y</code> file from beginning requires great effort. Hence, we can directly generate a <code>.y</code> file using a tool <a href="https://github.com/cznic/ebnf2y/tree/master">ebnf2y</a> from another <code>.ebnf</code> file that uses the Extended BNF grammar.</p><table><thead><tr><th style="text-align:center">Usage</th><th style="text-align:center">Notation</th></tr></thead><tbody><tr><td style="text-align:center">Definition</td><td style="text-align:center"><code>=</code></td></tr><tr><td style="text-align:center">Concatenation</td><td style="text-align:center"><code>,</code></td></tr><tr><td style="text-align:center">Termination</td><td style="text-align:center"><code>;</code></td></tr><tr><td style="text-align:center">Alternation</td><td style="text-align:center">``</td></tr><tr><td style="text-align:center">Optional</td><td style="text-align:center"><code>[ ... ]</code></td></tr><tr><td style="text-align:center">Repetition</td><td style="text-align:center"><code>&#123; ... &#125; </code></td></tr><tr><td style="text-align:center">Grouping</td><td style="text-align:center"><code>( ... )</code></td></tr><tr><td style="text-align:center">Terminal string</td><td style="text-align:center"><code>&quot; ... &quot;</code></td></tr><tr><td style="text-align:center">Terminal string</td><td style="text-align:center"><code>' ... '</code></td></tr><tr><td style="text-align:center">Comment</td><td style="text-align:center"><code>(* ... *)</code></td></tr><tr><td style="text-align:center">Special sequence</td><td style="text-align:center"><code>? ... ?</code></td></tr><tr><td style="text-align:center">Exception</td><td style="text-align:center"><code>-</code></td></tr></tbody></table><h2 id="how-to-cooperate-lex-with-parser-generated-by-yacc"><a class="markdownIt-Anchor" href="#how-to-cooperate-lex-with-parser-generated-by-yacc"></a> How to cooperate Lex with parser generated by yacc?</h2><ol><li><p>The <code>yyParser</code> requires the lexical analyzer to implement one of the following interfaces.</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">type</span> yyLexer <span class="keyword">interface</span> &#123;</span><br><span class="line">    Lex(lval *yySymType) <span class="type">int</span></span><br><span class="line">    Error(e <span class="type">string</span>)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">type</span> yyLexerEx <span class="keyword">interface</span> &#123;</span><br><span class="line">    yyLexer</span><br><span class="line">    <span class="comment">// Hook for recording a reduction.</span></span><br><span class="line">    Reduced(rule, state <span class="type">int</span>, lval *yySymType) (stop <span class="type">bool</span>) <span class="comment">// Client should copy *lval.</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>Under the consideration of performance, the TiDB uses a manually implemented lexical analyzer instead of generating one from <code>Lex</code>.</p></li></ol><h1 id="reference"><a class="markdownIt-Anchor" href="#reference"></a> Reference</h1><p><a href="https://www.ibm.com/docs/sv/aix/7.2?topic=information-yacc-grammar-file-declarations">yacc grammar file declarations</a><br /><a href="https://www.ibm.com/docs/sv/aix/7.2?topic=information-yacc-rules">yacc rules</a><br /><a href="https://www.ibm.com/docs/sv/aix/7.2?topic=information-yacc-actions">yacc actions</a><br /><a href="https://cloud.tencent.com/developer/article/1744609">goyacc 实战</a><br /><a href="https://cn.pingcap.com/blog/tidb-source-code-reading-5/">TiDB 源码阅读系列文章（五）TiDB SQL Parser 的实现</a></p>]]></content>
      
      
      <categories>
          
          <category> Open Source Code </category>
          
          <category> TiDB </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Compiler </tag>
            
            <tag> Parser </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>01 TiDB Overview</title>
      <link href="/2023/10/23/OpenSource/TinyDB/TiDB-Overview/"/>
      <url>/2023/10/23/OpenSource/TinyDB/TiDB-Overview/</url>
      
        <content type="html"><![CDATA[<p><ul class="markdownIt-TOC"><li><a href="#how-to-execute-a-sql-statement">How to execute a SQL statement?</a></li><li><a href="#how-to-run-a-distributed-database">How to run a distributed database?</a></li><li><a href="#reference">Reference</a></li></ul></p><h1 id="how-to-execute-a-sql-statement"><a class="markdownIt-Anchor" href="#how-to-execute-a-sql-statement"></a> How to execute a SQL statement?</h1><ol><li><p>Parser takes the string of statement and generates an abstract syntax tree (AST).</p><ul><li>Lexer takes the string and generate a stream of tokens for parser.</li><li>Parser reducts the stream of tokens based on pre-defined grammar.</li></ul></li><li><p>Then the plan tree is generated based on the AST and further optimizations are applied on the plan tree.</p></li><li><p>The executors are transformed from nodes of the plan tree to excute the plans.</p><ul><li>The executors are also in a tree-form. Each executor acquires their input data from children by calling <code>Next</code> of their children executors.</li></ul><img src="/imgs/TiDB/overview.png" width="50%"></li></ol><h1 id="how-to-run-a-distributed-database"><a class="markdownIt-Anchor" href="#how-to-run-a-distributed-database"></a> How to run a distributed database?</h1><ol><li><p>The distributed database follows the design of compute-storage decoupling.</p><ul><li>Several TiDB nodes only responsible for executing SQL statements. They are stateless and do not store the database.</li><li>Other TiKV nodes are the distributed storage system for the database that provides desired features, e.g. transaction, persistent, fault-tolerance.</li></ul></li><li><p>The TiDB nodes communicate with clients through protocol layers that support MySQL protocol or othre specific grammar protocol that determines the support grammar and API for the client to write programs.</p><ul><li>TiDB nodes hide the SQL execution from the clients.</li></ul></li><li><p>The TiKV provides KV API for the TiDB to read and write data.</p><ul><li>TiKV nodes hide the distributed storage from the TiDB nodes.</li><li>To map the data in a table into Key-Value format, the keys are <code>&quot;Table ID : Row ID : Column ID&quot;</code>. Each operation can correspond to a series of <code>Get</code> or <code>Set</code> operations.</li></ul><img src="/imgs/TiDB/arch.png" width="25%"></li></ol><h1 id="reference"><a class="markdownIt-Anchor" href="#reference"></a> Reference</h1><p><a href="https://cn.pingcap.com/blog/tidb-source-code-reading-2/">TiDB 源码阅读系列文章（二）初识 TiDB 源码</a></p><p><a href="https://cn.pingcap.com/blog/tidb-source-code-reading-3/">TiDB 源码阅读系列文章（三）SQL 的一生</a></p><p><a href="https://mp.weixin.qq.com/s?__biz=MjM5NzAyNTE0Ng==&amp;mid=207965954&amp;idx=1&amp;sn=783af058186bd609de2217f8e66e65c5&amp;scene=1&amp;srcid=0924EIXcHcSkVbxXKB6Is4Nh&amp;key=2877d24f51fa53844c7857f54ec17b391aff4e8307a08c149b7dc98bc700fc5c6f0de582d60b6ea2b3501309f90e3e86&amp;ascene=0&amp;uin=Mjk1NDA3MjkyMw%3D%3D&amp;devicetype=iMac+MacBookAir6%2C2+OSX+OSX+10.10.5+build%2814F27%29&amp;version=11020201&amp;pass_ticket=wonB1CX4A%2BSIp9Ze%2B3aqrOLrAQlXwspyhR1AlXxpsMAo5QnqYjvByd6Dgm5W%2FC1T">如何编写一个分布式数据库</a></p>]]></content>
      
      
      <categories>
          
          <category> Open Source Code </category>
          
          <category> TiDB </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Database </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>RPC</title>
      <link href="/2023/10/14/OpenSource/6.824/RPC/"/>
      <url>/2023/10/14/OpenSource/6.824/RPC/</url>
      
        <content type="html"><![CDATA[<p></p>]]></content>
      
      
      <categories>
          
          <category> Open Source Code </category>
          
          <category> 6.824 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Distributed System </tag>
            
            <tag> Communication </tag>
            
            <tag> RPC </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Project #4: Concurrency Control</title>
      <link href="/2023/10/12/OpenSource/BusTub/Project-4-Concurrency-Control/"/>
      <url>/2023/10/12/OpenSource/BusTub/Project-4-Concurrency-Control/</url>
      
        <content type="html"><![CDATA[<p><ul class="markdownIt-TOC"><li><a href="#lockmanager">LockManager</a><ul><li><a href="#locks">Locks</a></li><li><a href="#lock">Lock</a><ul><li><a href="#before-granting-locks">Before granting locks</a></li><li><a href="#grant-locks">Grant locks</a></li></ul></li><li><a href="#unlocktable">UnlockTable</a></li></ul></li><li><a href="#concurrent-query-execution">Concurrent query execution</a><ul><li><a href="#seqscan-executor">SeqScan Executor</a></li><li><a href="#insert-delete-and-update-executors">Insert, Delete and Update Executors</a></li><li><a href="#transaction-manager">Transaction manager</a></li></ul></li></ul></p><h1 id="lockmanager"><a class="markdownIt-Anchor" href="#lockmanager"></a> LockManager</h1><h2 id="locks"><a class="markdownIt-Anchor" href="#locks"></a> Locks</h2><ol><li><code>LockManager</code> is used to protect the data in database. According to the lock granularities, the lock information is stored in <code>table_lock_map_</code> and <code>row_lock_map_</code>.</li><li>The interface of <code>LockManager</code> may be executed concurrently by each transaction. Hence <code>table_lock_map_latch_</code> and <code>row_lock_map_latch_</code> are necessary to protect the data of <code>LockManager</code>.</li><li>The information of each object is stored in <code>LockRequestQueue</code> where all requests are stored including both granted and waiting requests. Each queue has a <code>latch_</code> to protect its data and also as the lock of condition variable.</li><li>The <code>table_lock_map_latch_</code> or <code>row_lock_map_latch_</code> can be released one the <code>latch_</code> of correspongding queue is acquired to support better throughput of processing lock requests.</li></ol><h2 id="lock"><a class="markdownIt-Anchor" href="#lock"></a> Lock</h2><h3 id="before-granting-locks"><a class="markdownIt-Anchor" href="#before-granting-locks"></a> Before granting locks</h3><ol><li>Check whether this transaction is allowed to acquire this lock based on its isolation level and current state.</li><li>Check whether this transaction is upgrading its lock.<ul><li>If so, chekc whether there is another transaction is upgrading.</li><li>If not, check whether it can upgrade to this new lock mode.</li><li>If can, set the <code>upgrading_</code> of this queue, remove the recording of currently holding lock from the transaction, update the <code>lock_mode_</code> and <code>granted_</code> of the request in queue, use this request as the request to be granted.</li></ul></li><li>If this is not an upgrading, create a new request and insert it into the queue.</li><li>When locking a row, we also need to ensure that appropriate locks are held in table.</li></ol><h3 id="grant-locks"><a class="markdownIt-Anchor" href="#grant-locks"></a> Grant locks</h3><ol><li>As long as the transaction is not aborted, try to grant the lock. If failed, sleep the process with condition variable.</li><li>The rules of granting locks are as followed:<ul><li>If there are granted locks and it is compatible with all granted locks, grant the lock.</li><li>If there is no granted lock,<ul><li>If there is an upgrading request, when this is the upgrading request or this is compatible with the upgrading request, grant the lock.</li><li>If there is no upgrading request, when this is the first requst in waiting list or this is compatible with the first request, grant the lock.</li></ul></li></ul></li><li>If exit the loop of trying to grant the lock due to the transaction is aborted, its request need to be deleted from the queue. Else, add the record of holding lock to the transaction.</li></ol><h2 id="unlocktable"><a class="markdownIt-Anchor" href="#unlocktable"></a> UnlockTable</h2><ol><li>The transaction should not have any record of holding locks of rows of this table.</li><li>Find the request of this transaction, remove it from the queue, update transaction state according to the isolation level and unlocked lock, remove the recording from transaction.</li><li>When unlocking a table, we need to ensure that no lock of rows in that table is held.</li></ol><h1 id="concurrent-query-execution"><a class="markdownIt-Anchor" href="#concurrent-query-execution"></a> Concurrent query execution</h1><h2 id="seqscan-executor"><a class="markdownIt-Anchor" href="#seqscan-executor"></a> SeqScan Executor</h2><ol><li>The concurrency control of delete depends on the <code>SeqScan</code> executor. In <code>Init()</code>, we need to determine the lock type according to <code>exec_ctx_-&gt;IsDelete()</code>.<ul><li>If this scan is for future deletion, we need to acquire an exclusive lock on rows and an intension-exclusive lock on table.</li><li>Otherwise, we just lock table with intension-shared lock if the isolation level is not <code>READ_UNCOMMITED</code>.</li></ul></li><li>In <code>Next</code>, if there are shared lock on previous row and the isolation level is <code>READ_COMMITTED</code>, we need to release the shared lock first. Hence we can only execute <code>++(*iter_)</code> at the beginning, instead of right after fetched the row.<ul><li>Also, when reading tuples, we always acquire a lock first. If, after reading, the tuple does not match the predicate, we should force unlock the lock despite the lock mode.</li></ul></li><li>A corner case for this is that some transactions may execute a deletion before another sequential scan. Then the later sequential scan should only acquire shared lock while the first deletion has already acquired an exclusive lock.</li><li>When there is no more tuple to emit, we should unlock the shared lock locked by this executor on the table.</li></ol><h2 id="insert-delete-and-update-executors"><a class="markdownIt-Anchor" href="#insert-delete-and-update-executors"></a> Insert, Delete and Update Executors</h2><ol><li>As aforementioned, the concurrency control of deletion depends on <code>SeqScan</code>. Therefore, we do not need to do anything extra in <code>Delete</code> executor.</li><li>For insert and update, we need to acquire an intension-exclusive lock on the table in the <code>Init</code>.</li><li>Insert needs to acquire an exclusive lock on the inserted row, but only after the row in generated.</li><li>Update can use an in-place update and needs an exclusive lock before that.</li></ol><h2 id="transaction-manager"><a class="markdownIt-Anchor" href="#transaction-manager"></a> Transaction manager</h2><ol><li>On abort, transaction manager need to restore the changes made by this transaction. The first is to restore the changes maken to tables directly.<ul><li>The reversion must be performed in the opposite order as the modification.</li><li>If the transaction inserted or deleted some tuples, we just need to reverse the <code>is_deleted_</code> flag in metadata.</li><li>If the transaction updated some tuples without in-place upate optimization, we need to insert a delete record and an insert record.</li><li>If the transaction uses in-place update optimization, we need to keep the old tuples and their meta in the record to restore when aborted.</li><li>Modification to indexes needs to be reverted similarly.</li></ul></li><li>After reverted modifications in abort, or entered commit, all locks held by the transaction need to be released. We only need to check the lock sets in transaction.</li></ol>]]></content>
      
      
      <categories>
          
          <category> Open Source Code </category>
          
          <category> BusTub </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Database System </tag>
            
            <tag> Transaction </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Parameter Server</title>
      <link href="/2023/10/09/Paper/Sys4AI/Parameter-Server/"/>
      <url>/2023/10/09/Paper/Sys4AI/Parameter-Server/</url>
      
        <content type="html"><![CDATA[<p>Paper: <a href="https://www.usenix.org/system/files/conference/osdi14/osdi14-paper-li_mu.pdf">Scaling Distributed Machine Learning with the Parameter Server</a></p><p><ul class="markdownIt-TOC"><li><a href="#purpose">Purpose</a></li><li><a href="#model">Model</a><ul><li><a href="#what-is-a-conventional-distributed-ml-system">What is a conventional distributed ML system?</a></li><li><a href="#what-is-the-structure-of-this-new-parameter-server">What is the structure of this new parameter server?</a></li><li><a href="#how-to-optimize-the-cost-of-communication-of-pulling-parameters">How to optimize the cost of communication of pulling parameters?</a></li><li><a href="#how-to-support-flexible-consistency">How to support flexible consistency?</a></li><li><a href="#well-defined-behavior-background">Well-defined behavior (Background)</a><ul><li><a href="#how-to-provide-a-well-defined-behavior-after-failure">How to provide a well-defined behavior after failure?</a></li><li><a href="#what-is-the-problem-of-lamport-clock">What is the problem of Lamport clock?</a></li></ul></li><li><a href="#what-is-the-problem-of-vector-clock-in-parameter-server">What is the problem of vector clock in parameter server?</a></li><li><a href="#how-to-optimize-cost-of-communication">How to optimize cost of communication?</a></li><li><a href="#what-is-the-difference-of-fault-tolerance-between-parameter-server-and-conventional-distributed-system">What is the difference of fault tolerance between parameter server and conventional distributed system?</a></li></ul></li><li><a href="#evaluation">Evaluation</a></li></ul></p><h1 id="purpose"><a class="markdownIt-Anchor" href="#purpose"></a> Purpose</h1><ol><li>Issues:<ul><li>Many research settings run jobs exclusively on a clusteer without contention.</li></ul></li><li>Challenges:<ul><li>Sharing imposes three challenges:<ul><li>Accessing the parameters requires an enormous amount of network bandwidth.</li><li>Many machine learning algorithms are sequential.</li><li>At scale, fault tolerance is critical.</li></ul></li><li>When solving distributed data analysis problems, the issue of reading and updating parameters shared between different worker nodes is ubiquitous.<ul><li>Using key-value pair abstraction to update parameters naively is inefficient: values are typically small (floats or integers), and the overhead of sending each update as a key value operation is high.</li></ul></li><li>For efficient operation, fault tolerance must not require a full restart of a long-running computation.</li></ul></li><li>Contributions:<ul><li>By factoring out commonly required components of machine learning systems, it enables application-specific code to remain concise.</li><li>As a shared platform to target for systemslevel optimizations, it provides a robust, versatile, and high-performance implementation capable of handling a diverse array of algorithms from sparse logistic regression to topic models and distributed sketching.</li><li>Five key features:<ul><li><strong>Efficient communication</strong> is achieved through asynchronous communication model.</li><li><strong>Flexible consistency models</strong> to balance algorithmic convergence rate and system efficiency.</li><li><strong>Elastic scalability</strong> where new nodes can be added without restarting the running framework.</li><li><strong>Fault tolerance and durability</strong> provides fast recovery and well-defined behavior.</li><li><strong>Ease of use</strong>.</li></ul></li><li>Achieved the synergy by picking the right systems techniques, adapting them to the machine learning algorithms, and modifying the machine learning algorithms to be more systemsfriendly.</li></ul></li></ol><h1 id="model"><a class="markdownIt-Anchor" href="#model"></a> Model</h1><h2 id="what-is-a-conventional-distributed-ml-system"><a class="markdownIt-Anchor" href="#what-is-a-conventional-distributed-ml-system"></a> What is a conventional distributed ML system?</h2><ol><li>Training typically consists of three components: feature extraction, the objective function, and learning.<ul><li>Feature extraction processes the raw training data to obtain feature vectors, where each feature captures an attribute of the training data.</li><li>Preprocessing can be executed efficiently by existing frameworks such as MapReduce.</li></ul></li><li>There are three components: task scheduler, worker and server.<ul><li>The parameters are stored in servers while the training data is partitioned among all of the workers.</li><li>Task scheduler first notify each worker to execute <code>LoadData</code>. Then in each iteration, it issues each worker to execute <code>WorkerIterate</code>.</li><li>Each worker has two functions:<ul><li><code>LoadData</code> will load and cache a part of training data which will not change in all iterations. It will also pull the initial working set of parameter from server.</li><li><code>WorkIterate</code> will calculate the gradient based on the current parameter and send this gradient to server before pulling new parameters.</li></ul></li><li>Servers only need to aggregate gradients from workers and update parameters in each iteration in <code>ServerIterate</code>.</li></ul></li><li>In each iteration, every worker independently uses its own training data to determine what changes should be made to w in order to get closer to an optimal value.<ul><li>Because each worker’s updates reflect only its own training data, the system needs a mechanism to allow these updates to mix. It does so by expressing the updates as a subgradient.</li></ul></li><li>The most expensive step in algorithm is computing the subgradient to update <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>w</mi></mrow><annotation encoding="application/x-tex">w</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.02691em;">w</span></span></span></span>. This task is divided among all of the workers, each of which execute <code>WorkerIterate</code>.</li><li>The total size of <code>w</code> may exceed the capacity of a single machine.<ul><li>A worker needs to know a coordinate of w if and only if some of its training data references that entry.</li><li>The working set of entries needed by a particular worker can be trivially cached locally.</li></ul></li></ol><img src="/imgs/Sys4ai/PS/subgradient.png" width="25%"><h2 id="what-is-the-structure-of-this-new-parameter-server"><a class="markdownIt-Anchor" href="#what-is-the-structure-of-this-new-parameter-server"></a> What is the structure of this new parameter server?</h2><ol><li>Parameter server nodes are grouped into a server group and several worker groups.<ul><li>A server node in the server group maintains a partition of the globally shared parameters.</li><li>Workers communicate only with the server nodes (not among themselves), updating and retrieving the shared parameters.</li></ul></li><li>There is a scheduler node for each worker group. It assigns tasks to workers and monitors their progress. If workers are added or removed, it reschedules unfinished tasks.</li><li>The parameter server supports independent parameter namespaces.<ul><li>This allows a worker group to isolate its set of shared parameters from others.</li><li>Several worker groups may also share the same namespace: we may use more than one worker group to solve the same deep learning application to increase parallelization.</li></ul></li></ol><img src="/imgs/Sys4ai/PS/arch.png" width="25%"><h2 id="how-to-optimize-the-cost-of-communication-of-pulling-parameters"><a class="markdownIt-Anchor" href="#how-to-optimize-the-cost-of-communication-of-pulling-parameters"></a> How to optimize the cost of communication of pulling parameters?</h2><ol><li>Many learning algorithms represent parameters as structured mathematical objects.<ul><li>Workers usually send a segment of a vector, or an entire row of the matrix.</li></ul></li><li>Batch both the communication of updates and their processing on the parameter server, and allows the consistency tracking to be implemented efficiently.<ul><li>This lets us treat the parameters as (key,value) pairs while endowing them with vector and matrix semantics, where non-existing keys are associated with zeros.</li></ul></li><li>Data is sent between nodes using push and pull operations.<ul><li>If <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>R</mi></mrow><annotation encoding="application/x-tex">R</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.00773em;">R</span></span></span></span> is a key range, then <code>w.push(R, dest)</code> sends all existing entries of <code>w</code> in key range <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>R</mi></mrow><annotation encoding="application/x-tex">R</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.00773em;">R</span></span></span></span> to the destination, which can be either a particular node, or a node group such as the server group.</li><li>Similarly, <code>w.pull(R, dest)</code> reads all existing entries of <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>w</mi></mrow><annotation encoding="application/x-tex">w</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.02691em;">w</span></span></span></span> in key range <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>R</mi></mrow><annotation encoding="application/x-tex">R</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.00773em;">R</span></span></span></span> from the destination.</li><li>Gradients share the keys of the worker’s working set <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>w</mi></mrow><annotation encoding="application/x-tex">w</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.02691em;">w</span></span></span></span>. Hence the programmer can use <code>w.push(R, g, dest)</code> for the local gradients to save memory.</li></ul></li><li>The system also supports user-defined filters to selectively synchronize individual (key,value) pairs, allowing fine-grained control of data consistency within a task.<ul><li>The optimization algorithm itself usually possesses information on which parameters are most useful for synchronization.</li><li>One example is the significantly modified filter, which only pushes entries that have changed by more than a threshold since their last synchronization.</li></ul></li></ol><h2 id="how-to-support-flexible-consistency"><a class="markdownIt-Anchor" href="#how-to-support-flexible-consistency"></a> How to support flexible consistency?</h2><ol><li>A tasks is issued by a remote procedure call. It can be a push or a pull that a worker issues to servers. Tasks may include any number of subtasks.</li><li>Tasks are executed asynchronously.<ul><li>The caller can perform further computation immediately after issuing a task.</li><li>The caller marks a task as finished only once it receives the callee’s reply. The callee marks a task as finished only if the call of the task is returned and all subtasks issued by this call are finished.</li><li>A caller that wishes to serialize task execution can place an execute-after-finished dependency between tasks.</li></ul></li><li>We can implement different models by task dependency.<ul><li><strong>Sequential</strong>: All tasks are executed one by one.</li><li><strong>Eventual</strong>: All tasks may be started simultaneously. This is only recommendable if the underlying algorithms are robust with regard to delays.</li><li><strong>Bounded Delay</strong>: When a maximal delay time <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>τ</mi></mrow><annotation encoding="application/x-tex">\tau</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.1132em;">τ</span></span></span></span> is set, a new task will be blocked until all previous tasks <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>τ</mi></mrow><annotation encoding="application/x-tex">\tau</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.1132em;">τ</span></span></span></span> times ago have been finished.<ul><li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>τ</mi><mo>=</mo><mn>0</mn></mrow><annotation encoding="application/x-tex">\tau=0</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.1132em;">τ</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">0</span></span></span></span> is the sequential consistency model, and an infinite delay <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>τ</mi><mo>=</mo><mi mathvariant="normal">∞</mi></mrow><annotation encoding="application/x-tex">\tau = \infty</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.1132em;">τ</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord">∞</span></span></span></span> becomes the eventual consistency model.</li></ul></li></ul></li><li>The dependency graphs may be dynamic, then the caller traverses the DAG.<ul><li>If the graph is static, the caller can send all tasks with the DAG to the callee to reduce synchronization cost.</li></ul></li><li>This inconsistency potentially slows down the convergence progress. Some algorithms may be less sensitive to this type of inconsistency.<ul><li>The best trade-off between system efficiency and algorithm convergence rate usually depends on a variety of factors, including the algorithm’s sensitivity to data inconsistency, feature correlation in training data, and capacity difference of hardware components.</li></ul></li></ol><img src="/imgs/Sys4ai/PS/dag.png" width="50%"><h2 id="well-defined-behavior-background"><a class="markdownIt-Anchor" href="#well-defined-behavior-background"></a> Well-defined behavior (Background)</h2><h3 id="how-to-provide-a-well-defined-behavior-after-failure"><a class="markdownIt-Anchor" href="#how-to-provide-a-well-defined-behavior-after-failure"></a> How to provide a well-defined behavior after failure?</h3><ol><li>To provide a well-defined behavior, we only need to find a way to determine the logical order of concurrent operations.<ul><li>In a single machine situation, suppose we perform a write to key <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi></mrow><annotation encoding="application/x-tex">k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.03148em;">k</span></span></span></span> with timestamp <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>t</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">t_1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.76508em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">t</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> and then perform another write to <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi></mrow><annotation encoding="application/x-tex">k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.03148em;">k</span></span></span></span> with timestamp <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>t</mi><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">t_2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.76508em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">t</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>.<ul><li>Since <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>t</mi><mn>2</mn></msub><mo>&gt;</mo><msub><mi>t</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">t_2 &gt; t_1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.76508em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">t</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">&gt;</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.76508em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">t</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>, the second write must be newer than the first write, and therefore the database can safely overwrite the original value.</li></ul></li><li>In a distributed system, this assumption does not hold. The problem is <strong>clock skew</strong>, such as, different clocks tend to run at different rates, so we cannot assume that time <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>t</mi></mrow><annotation encoding="application/x-tex">t</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.61508em;vertical-align:0em;"></span><span class="mord mathnormal">t</span></span></span></span> on node <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>a</mi></mrow><annotation encoding="application/x-tex">a</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathnormal">a</span></span></span></span> happened before time <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>t</mi><mo>+</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">t + 1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69841em;vertical-align:-0.08333em;"></span><span class="mord mathnormal">t</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">1</span></span></span></span> on node <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>b</mi></mrow><annotation encoding="application/x-tex">b</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathnormal">b</span></span></span></span>.</li></ul></li><li>Lamport clock is a logical clock that provides partial order of events. If an event <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>A</mi></mrow><annotation encoding="application/x-tex">A</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal">A</span></span></span></span> causally happens before another event <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>B</mi></mrow><annotation encoding="application/x-tex">B</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.05017em;">B</span></span></span></span>, i.e. <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>A</mi><mo>→</mo><mi>B</mi></mrow><annotation encoding="application/x-tex">A\rightarrow B</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal">A</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">→</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.05017em;">B</span></span></span></span>, then <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>t</mi><mi>i</mi><mi>m</mi><mi>e</mi><mi>s</mi><mi>t</mi><mi>a</mi><mi>m</mi><mi>p</mi><mo stretchy="false">(</mo><mi>A</mi><mo stretchy="false">)</mo><mo>&lt;</mo><mi>t</mi><mi>i</mi><mi>m</mi><mi>e</mi><mi>s</mi><mi>t</mi><mi>a</mi><mi>m</mi><mi>p</mi><mo stretchy="false">(</mo><mi>B</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">timestamp(A) &lt; timestamp(B)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">t</span><span class="mord mathnormal">i</span><span class="mord mathnormal">m</span><span class="mord mathnormal">e</span><span class="mord mathnormal">s</span><span class="mord mathnormal">t</span><span class="mord mathnormal">a</span><span class="mord mathnormal">m</span><span class="mord mathnormal">p</span><span class="mopen">(</span><span class="mord mathnormal">A</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">&lt;</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">t</span><span class="mord mathnormal">i</span><span class="mord mathnormal">m</span><span class="mord mathnormal">e</span><span class="mord mathnormal">s</span><span class="mord mathnormal">t</span><span class="mord mathnormal">a</span><span class="mord mathnormal">m</span><span class="mord mathnormal">p</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.05017em;">B</span><span class="mclose">)</span></span></span></span>.<ul><li>The term Causality here means that if one event leads to another, then there is a path of events from the first event to the second event.</li><li>The algorithm provides only partial order of events as we cannot relate all the events with the “happened before” relationship.</li></ul></li><li>In a distributed system, we can define mainly 3 types of events that each process can execute, a local event, a send event and a receive event. Then the rules are defined as:<ul><li>For a local event, <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>a</mi><mo>→</mo><mi>b</mi></mrow><annotation encoding="application/x-tex">a \rightarrow b</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathnormal">a</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">→</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathnormal">b</span></span></span></span>, if <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>t</mi><mi>i</mi><mi>m</mi><mi>e</mi><mi>s</mi><mi>t</mi><mi>a</mi><mi>m</mi><mi>p</mi><mo stretchy="false">(</mo><mi>a</mi><mo stretchy="false">)</mo><mo>&lt;</mo><mi>t</mi><mi>i</mi><mi>m</mi><mi>e</mi><mi>s</mi><mi>t</mi><mi>a</mi><mi>m</mi><mi>p</mi><mo stretchy="false">(</mo><mi>b</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">timestamp(a) &lt; timestamp(b)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">t</span><span class="mord mathnormal">i</span><span class="mord mathnormal">m</span><span class="mord mathnormal">e</span><span class="mord mathnormal">s</span><span class="mord mathnormal">t</span><span class="mord mathnormal">a</span><span class="mord mathnormal">m</span><span class="mord mathnormal">p</span><span class="mopen">(</span><span class="mord mathnormal">a</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">&lt;</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">t</span><span class="mord mathnormal">i</span><span class="mord mathnormal">m</span><span class="mord mathnormal">e</span><span class="mord mathnormal">s</span><span class="mord mathnormal">t</span><span class="mord mathnormal">a</span><span class="mord mathnormal">m</span><span class="mord mathnormal">p</span><span class="mopen">(</span><span class="mord mathnormal">b</span><span class="mclose">)</span></span></span></span>.</li><li>If process <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>P</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">P_1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> sends a message to process <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>P</mi><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">P_2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>, then, <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>s</mi><mi>e</mi><mi>n</mi><mi>d</mi><mo stretchy="false">(</mo><mi>m</mi><mi>e</mi><mi>s</mi><mi>s</mi><mi>a</mi><mi>g</mi><mi>e</mi><mo stretchy="false">)</mo><mo>→</mo><mi>r</mi><mi>e</mi><mi>c</mi><mi>e</mi><mi>i</mi><mi>v</mi><mi>e</mi><mo stretchy="false">(</mo><mi>m</mi><mi>e</mi><mi>s</mi><mi>s</mi><mi>a</mi><mi>g</mi><mi>e</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">send(message) \rightarrow receive(message)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">s</span><span class="mord mathnormal">e</span><span class="mord mathnormal">n</span><span class="mord mathnormal">d</span><span class="mopen">(</span><span class="mord mathnormal">m</span><span class="mord mathnormal">e</span><span class="mord mathnormal">s</span><span class="mord mathnormal">s</span><span class="mord mathnormal">a</span><span class="mord mathnormal" style="margin-right:0.03588em;">g</span><span class="mord mathnormal">e</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">→</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mord mathnormal">e</span><span class="mord mathnormal">c</span><span class="mord mathnormal">e</span><span class="mord mathnormal">i</span><span class="mord mathnormal" style="margin-right:0.03588em;">v</span><span class="mord mathnormal">e</span><span class="mopen">(</span><span class="mord mathnormal">m</span><span class="mord mathnormal">e</span><span class="mord mathnormal">s</span><span class="mord mathnormal">s</span><span class="mord mathnormal">a</span><span class="mord mathnormal" style="margin-right:0.03588em;">g</span><span class="mord mathnormal">e</span><span class="mclose">)</span></span></span></span>.</li><li>If <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>a</mi><mo>→</mo><mi>b</mi></mrow><annotation encoding="application/x-tex">a \rightarrow b</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathnormal">a</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">→</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathnormal">b</span></span></span></span> and <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>b</mi><mo>→</mo><mi>c</mi></mrow><annotation encoding="application/x-tex">b\rightarrow c</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathnormal">b</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">→</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathnormal">c</span></span></span></span> then <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>a</mi><mo>→</mo><mi>c</mi></mrow><annotation encoding="application/x-tex">a \rightarrow c</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathnormal">a</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">→</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathnormal">c</span></span></span></span>.</li></ul></li><li>The time stamps of each node are updated as followed rules:<ul><li>Before executing an event, the process increments the logical timestamp by <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1</mn></mrow><annotation encoding="application/x-tex">1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">1</span></span></span></span>.</li><li>During a send event, the process increments the logical timestamp by <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1</mn></mrow><annotation encoding="application/x-tex">1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">1</span></span></span></span> and sends the time along with the message.</li><li>During a receive event, the counter of the recipient is updated to the max value of its own time stamp and the timestamp in the received message. It then increments the timestamp by <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1</mn></mrow><annotation encoding="application/x-tex">1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">1</span></span></span></span>.</li></ul></li></ol><h3 id="what-is-the-problem-of-lamport-clock"><a class="markdownIt-Anchor" href="#what-is-the-problem-of-lamport-clock"></a> What is the problem of Lamport clock?</h3><ol><li>One of the shortcomings of Lamport’s clock is that it cannot identify concurrent events that are causally related.</li></ol><ul><li>When two nodes concurrently modified the same object, and send the result to a third node, the third node cannot determine which modification happens first.</li></ul><ol start="2"><li>Instead of using integer values for the timestamp, vector clock uses a vector of integer values to represent the timestamp.<ul><li>If we have <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>N</mi></mrow><annotation encoding="application/x-tex">N</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">N</span></span></span></span> processes in the group, then each process will have a vector with <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>N</mi></mrow><annotation encoding="application/x-tex">N</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">N</span></span></span></span> elements.</li><li>Before executing an event, the process <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>i</mi></mrow><annotation encoding="application/x-tex">i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.65952em;vertical-align:0em;"></span><span class="mord mathnormal">i</span></span></span></span> increments the <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>i</mi></mrow><annotation encoding="application/x-tex">i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.65952em;vertical-align:0em;"></span><span class="mord mathnormal">i</span></span></span></span>-th element of its vector clock by <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1</mn></mrow><annotation encoding="application/x-tex">1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">1</span></span></span></span>.</li><li>During a send event, the process <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>i</mi></mrow><annotation encoding="application/x-tex">i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.65952em;vertical-align:0em;"></span><span class="mord mathnormal">i</span></span></span></span> increments the <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>i</mi></mrow><annotation encoding="application/x-tex">i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.65952em;vertical-align:0em;"></span><span class="mord mathnormal">i</span></span></span></span>-th element of its vector clock by <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1</mn></mrow><annotation encoding="application/x-tex">1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">1</span></span></span></span> and sends the vector along with the message.</li><li>During a receive event, the process <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>i</mi></mrow><annotation encoding="application/x-tex">i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.65952em;vertical-align:0em;"></span><span class="mord mathnormal">i</span></span></span></span> increments the <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>i</mi></mrow><annotation encoding="application/x-tex">i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.65952em;vertical-align:0em;"></span><span class="mord mathnormal">i</span></span></span></span>-th element of its vector clock by <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1</mn></mrow><annotation encoding="application/x-tex">1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">1</span></span></span></span>. For all other processes, it takes the maximum of the corresponding element in the incoming message and its own local vector and sets it as the corresponding element in the local clock itself.</li></ul></li><li>The vector clocks are compared as followed:<ul><li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>V</mi><mn>1</mn></msub><mo>=</mo><msub><mi>V</mi><mn>2</mn></msub><mtext>  </mtext><mo>⟺</mo><mtext>  </mtext><mi mathvariant="normal">∀</mi><mi>i</mi><mo>=</mo><mn>1</mn><mo>→</mo><mi>N</mi><mo separator="true">,</mo><msub><mi>V</mi><mn>1</mn></msub><mo stretchy="false">[</mo><mi>i</mi><mo stretchy="false">]</mo><mo>=</mo><msub><mi>V</mi><mn>2</mn></msub><mo stretchy="false">[</mo><mi>i</mi><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">V_1 = V_2\iff \forall i=1\to N,V_1[i]=V_2[i]</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.22222em;">V</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.22222em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.22222em;">V</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.22222em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">⟺</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord">∀</span><span class="mord mathnormal">i</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">1</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">→</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">N</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.22222em;">V</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.22222em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mopen">[</span><span class="mord mathnormal">i</span><span class="mclose">]</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.22222em;">V</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.22222em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mopen">[</span><span class="mord mathnormal">i</span><span class="mclose">]</span></span></span></span>.</li><li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>V</mi><mn>1</mn></msub><mo>≤</mo><msub><mi>V</mi><mn>2</mn></msub><mtext>  </mtext><mo>⟺</mo><mtext>  </mtext><mi mathvariant="normal">∀</mi><mi>i</mi><mo>=</mo><mn>1</mn><mo>→</mo><mi>N</mi><mo separator="true">,</mo><msub><mi>V</mi><mn>1</mn></msub><mo stretchy="false">[</mo><mi>i</mi><mo stretchy="false">]</mo><mo>≤</mo><msub><mi>V</mi><mn>2</mn></msub><mo stretchy="false">[</mo><mi>i</mi><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">V_1\le V_2\iff \forall i=1\to N,V_1[i]\le V_2[i]</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.22222em;">V</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.22222em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">≤</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.22222em;">V</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.22222em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">⟺</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord">∀</span><span class="mord mathnormal">i</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">1</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">→</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">N</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.22222em;">V</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.22222em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mopen">[</span><span class="mord mathnormal">i</span><span class="mclose">]</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">≤</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.22222em;">V</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.22222em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mopen">[</span><span class="mord mathnormal">i</span><span class="mclose">]</span></span></span></span>.</li><li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>V</mi><mn>1</mn></msub><mo>&lt;</mo><msub><mi>V</mi><mn>2</mn></msub><mtext>  </mtext><mo>⟺</mo><mtext>  </mtext><msub><mi>V</mi><mn>1</mn></msub><mo>≤</mo><msub><mi>V</mi><mn>2</mn></msub><mo>∧</mo><mi mathvariant="normal">∃</mi><mi>j</mi><mo separator="true">,</mo><msub><mi>V</mi><mn>1</mn></msub><mo stretchy="false">[</mo><mi>j</mi><mo stretchy="false">]</mo><mo>&lt;</mo><msub><mi>V</mi><mn>2</mn></msub><mo stretchy="false">[</mo><mi>j</mi><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">V_1&lt;V_2\iff V_1\le V_2\land\exist j, V_1[j]&lt;V_2[j]</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.22222em;">V</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.22222em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">&lt;</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.22222em;">V</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.22222em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">⟺</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.22222em;">V</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.22222em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">≤</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.22222em;">V</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.22222em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">∧</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord">∃</span><span class="mord mathnormal" style="margin-right:0.05724em;">j</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.22222em;">V</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.22222em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mopen">[</span><span class="mord mathnormal" style="margin-right:0.05724em;">j</span><span class="mclose">]</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">&lt;</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.22222em;">V</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.22222em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mopen">[</span><span class="mord mathnormal" style="margin-right:0.05724em;">j</span><span class="mclose">]</span></span></span></span>.</li></ul></li><li>We can identify the concurrent events when <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>N</mi><mi>O</mi><mi>T</mi><mo stretchy="false">(</mo><msub><mi>V</mi><mn>1</mn></msub><mo>≤</mo><msub><mi>V</mi><mn>2</mn></msub><mo stretchy="false">)</mo><mo>∧</mo><mi>N</mi><mi>O</mi><mi>T</mi><mo stretchy="false">(</mo><msub><mi>V</mi><mn>2</mn></msub><mo>≤</mo><msub><mi>V</mi><mn>1</mn></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">NOT(V_1\le V_2)\land NOT(V_2\le V_1)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">N</span><span class="mord mathnormal" style="margin-right:0.02778em;">O</span><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.22222em;">V</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.22222em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">≤</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.22222em;">V</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.22222em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">∧</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">N</span><span class="mord mathnormal" style="margin-right:0.02778em;">O</span><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.22222em;">V</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.22222em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">≤</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.22222em;">V</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.22222em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span>.<ul><li>When concurrent events are detected, it requires the system to resolve the conflicts. Vector clock only provides a method to find concurrent event.</li><li>One way to resolve conflicts is to leave it to the client who knows the semantic to decide which version is correct.</li></ul></li></ol><h2 id="what-is-the-problem-of-vector-clock-in-parameter-server"><a class="markdownIt-Anchor" href="#what-is-the-problem-of-vector-clock-in-parameter-server"></a> What is the problem of vector clock in parameter server?</h2><ol><li>Each (key,value) pair is associated with a vector clock, which records the time of each individual node on this (key,value) pair. Hence a naive vector clock implementation requires <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>O</mi><mo stretchy="false">(</mo><mi>n</mi><mi>m</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">O(nm)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">O</span><span class="mopen">(</span><span class="mord mathnormal">n</span><span class="mord mathnormal">m</span><span class="mclose">)</span></span></span></span> space to handle <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi></mrow><annotation encoding="application/x-tex">n</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathnormal">n</span></span></span></span> nodes and <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>m</mi></mrow><annotation encoding="application/x-tex">m</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathnormal">m</span></span></span></span> parameters.<ul><li>With thousands of nodes and billions of parameters, this is infeasible in terms of memory and bandwidth.</li></ul></li><li>Many parameters hare the same timestamp as a result of the range-based communication pattern of the parameter server.<ul><li>If a node pushes the parameters in a range, then the timestamps of the parameters associated with the node are likely the same.</li><li>Assume that <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>V</mi><mi>i</mi></msub><mo stretchy="false">(</mo><mi>k</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">V_i(k)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.22222em;">V</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.22222em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.03148em;">k</span><span class="mclose">)</span></span></span></span> is the time of key <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi></mrow><annotation encoding="application/x-tex">k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.03148em;">k</span></span></span></span> for node <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>i</mi></mrow><annotation encoding="application/x-tex">i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.65952em;vertical-align:0em;"></span><span class="mord mathnormal">i</span></span></span></span>. Given a key range <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>R</mi></mrow><annotation encoding="application/x-tex">R</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.00773em;">R</span></span></span></span>, the ranged vector clock <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>V</mi><mi>i</mi></msub><mo stretchy="false">(</mo><mi>R</mi><mo stretchy="false">)</mo><mo>=</mo><mi>t</mi></mrow><annotation encoding="application/x-tex">V_i(R)=t</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.22222em;">V</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.22222em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.61508em;vertical-align:0em;"></span><span class="mord mathnormal">t</span></span></span></span> means <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal">∀</mi><mi>k</mi><mo>∈</mo><mi>R</mi><mo separator="true">,</mo><msub><mi>V</mi><mi>i</mi></msub><mo stretchy="false">(</mo><mi>k</mi><mo stretchy="false">)</mo><mo>=</mo><mi>t</mi></mrow><annotation encoding="application/x-tex">\forall k\in R, V_i(k)=t</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.73354em;vertical-align:-0.0391em;"></span><span class="mord">∀</span><span class="mord mathnormal" style="margin-right:0.03148em;">k</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.22222em;">V</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.22222em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.03148em;">k</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.61508em;vertical-align:0em;"></span><span class="mord mathnormal">t</span></span></span></span>.</li></ul></li><li>Initially, there is only one range vector clock for each node <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>i</mi></mrow><annotation encoding="application/x-tex">i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.65952em;vertical-align:0em;"></span><span class="mord mathnormal">i</span></span></span></span>. It covers the entire parameter key space as its range with <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>0</mn></mrow><annotation encoding="application/x-tex">0</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">0</span></span></span></span> as its initial timestamp. Each range set may split the range and create at most <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>3</mn></mrow><annotation encoding="application/x-tex">3</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">3</span></span></span></span> new vector clocks.</li></ol><h2 id="how-to-optimize-cost-of-communication"><a class="markdownIt-Anchor" href="#how-to-optimize-cost-of-communication"></a> How to optimize cost of communication?</h2><ol><li>A worker might send the same key lists again. Hence it is desirable for the receiving node to cache the key lists. Later, the sender only needs to send a hash of the list rather than the list itself.</li><li>Values may contain many zero entries. Hence we need only send nonzero (key,value) pairs. We use the fast Snappy compression library to compress messages, effectively removing the zeros.</li><li>Naive replication potentially increases the network traffic by <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi></mrow><annotation encoding="application/x-tex">k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.03148em;">k</span></span></span></span> times, where <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi></mrow><annotation encoding="application/x-tex">k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.03148em;">k</span></span></span></span> is the number of replications.<ul><li>The parameter server framework permits replication after aggregation for many algorithms.</li><li>With n workers, replication uses only k/n bandwidth. Often k is a small constant, while n is hundreds to thousands.</li><li>While aggregation increases the delay of the task reply, it can be hidden by relaxed consistency conditions.</li></ul></li></ol><h2 id="what-is-the-difference-of-fault-tolerance-between-parameter-server-and-conventional-distributed-system"><a class="markdownIt-Anchor" href="#what-is-the-difference-of-fault-tolerance-between-parameter-server-and-conventional-distributed-system"></a> What is the difference of fault tolerance between parameter server and conventional distributed system?</h2><ol><li>Servers replicate parameters wtih consistent hashing.</li><li>When a worker failed, the recovery depends on the algorithm designer.<ul><li>If the training data is huge, recovering a worker node be may more expensive than recovering a server node.</li><li>Losing a small amount of training data during optimization typically affects the model only a little.</li></ul></li></ol><h1 id="evaluation"><a class="markdownIt-Anchor" href="#evaluation"></a> Evaluation</h1><ol><li>The author evaluated the system on Sparse Logistic Regression and Latent Dirichlet Allocation.</li><li>They compare systems by running them to reach the same objective value. A better system achieves a lower objective in less time. They also compared the worker node utilization in different systems.</li><li>The reduction of network traffic by each system components is measured.</li></ol>]]></content>
      
      
      <categories>
          
          <category> Paper Notebook </category>
          
          <category> Sys4AI </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Distributed System </tag>
            
            <tag> Sys4AI </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>SparDA</title>
      <link href="/2023/10/06/Paper/Sys4AI/SparDA/"/>
      <url>/2023/10/06/Paper/Sys4AI/SparDA/</url>
      
        <content type="html"><![CDATA[<p>Paper: <a href="https://arxiv.org/abs/2301.10936">SparDA: Accelerating Dynamic Sparse Deep Neural Networks via Sparse-Dense Transformation</a></p><p><ul class="markdownIt-TOC"><li><a href="#purpose">Purpose</a></li><li><a href="#model">Model</a><ul><li><a href="#what-is-the-pipeline-of-sparda">What is the pipeline of SparDA?</a></li><li><a href="#what-is-permutation-invariant">What is permutation invariant?</a></li><li><a href="#what-are-the-rules-of-applying-permutation-invariant">What are the rules of applying permutation invariant?</a></li><li><a href="#what-is-stile">What is STile?</a></li><li><a href="#how-to-transform-input-and-eliminate-overhead">How to transform input and eliminate overhead?</a></li><li><a href="#how-to-choose-an-efficient-stile">How to choose an efficient STile?</a></li><li><a href="#how-to-represent-dynamic-sparsity">How to represent dynamic sparsity?</a></li><li><a href="#what-are-the-apis-of-sparda-what-is-its-working-pipeline">What are the APIs of SparDA? What is its working pipeline?</a></li></ul></li><li><a href="#evaluation">Evaluation</a></li></ul></p><h1 id="purpose"><a class="markdownIt-Anchor" href="#purpose"></a> Purpose</h1><ol><li>Sparsity has become the most important and efficient approach to accelerate neural networks by erasing a large portion of computation without unraveling model accuracy.</li><li>Issues:<ul><li>Most commodity accelerators (e.g., GPUs and TPUs) are mainly designed for efficient dense computations.</li><li>To fit sparse computation, previous research works propose sparsity optimizations, which only work for fixed granularities and perform badly when the granularity mismatches.<ul><li>Fine-grained computation kernels cannot well saturate hardware due to the random memory access caused by fine-grained data.</li></ul></li><li>Existing solutions have to use time-consuming compiling to improve the efficiency of sparse kernels in an ahead-of-time manner and thus are limited to static sparsity.</li><li>An efficient general index construction mechanism for all kinds of data granularities is still missing.<ul><li>The performance of previous sparse index construction methodology is also poor due to the constraint of sparse computation kernels.</li></ul></li></ul></li><li>Challenges:<ul><li>The dynamic sparsity pattern in different scenarios, even with the same scenario, is quite diverse and complex.</li><li>The key to optimizing such dynamic sparsity is to perform the calculations with and efficient kernel without computation waste at the same time.<ul><li>Therefore, optimizing such complex dynamic sparsity patterns requires breaking the binding between the data granularity and computation granularity.</li></ul></li></ul></li><li>Contribution:<ul><li>Identified an important property called <em>permutation invariant</em>.<ul><li>It enables SparDA to extract dynamic sparsity patterns of tensors that are only known at runtime with negligible overhead.</li><li>It can transform the dynamic sparse computation into an equivalent dense computation which has been extremely optimized on commodity accelerators.</li></ul></li><li>By combining permutation invariant with computation tiling, SparDA exploits the effect of permutation invariant to allow permutation on finer-grained granularity instead of the whole row or column of a tensor.<ul><li>It implies that the sparsity could be more fine-grained and irregular, as long as the non-zero values can be compacted into multiple dense computation tiles.</li><li>Define the sparsity pattern of the non-zero values and the compacted computation tile as sparse tile, i.e., STile.</li></ul></li></ul></li></ol><h1 id="model"><a class="markdownIt-Anchor" href="#model"></a> Model</h1><h2 id="what-is-the-pipeline-of-sparda"><a class="markdownIt-Anchor" href="#what-is-the-pipeline-of-sparda"></a> What is the pipeline of SparDA?</h2><ol><li>The design of STile naturally splits sparse computation into two decoupled stages: data permutation and dense computation.<ul><li>The decoupling makes the computation stage free from handling the intricate encoding and decoding of sparse tensors, thus, the computation can more efficiently utilize the accelerators.</li><li>With the decoupled stages, SparDA can leverage a wide range of well-optimized implementation of dense computation, including hardware instructions, manually optimized kernels, and automatically tuned kernels.</li><li>The data permutation stage transforms sparse data into a dense format with a new primitive <code>SLoad</code>. After the computation, the produced dense data is transformed back to the required format (e.g., sparse format) with the other primitive <code>SWrite</code>.</li></ul></li><li>The first stage is to learn the sparsity distribution from only a few samples.<ul><li>The STile optimizer analyzes the sparsity of each operator and selects the most suitable STile from a set of pre-constructed STiles, each of which is connected to a well-optimized dense computation tile.</li><li>SparDA generates a sparse kernel for the operator based on the selected STile.</li><li>This stage can be executed during the initialization, and also can be executed periodically to deal with possible shifting of sparsity distribution.</li></ul></li><li>The second stage is applying the generated sparse kernel at runtime.<ul><li>To deal with the dynamically changed sparsity, SparDA detects the sparsity online and builds the index of the sparse data following the requirement of the STile.</li></ul></li><li>There are two components in the sparse kernel.<ul><li>The first one rearranges the sparse data into dense format when loading data across different memory hierarchies.</li><li>The second one applies the dense computation on the condensed data without knowing their indices.</li></ul></li></ol><h2 id="what-is-permutation-invariant"><a class="markdownIt-Anchor" href="#what-is-permutation-invariant"></a> What is permutation invariant?</h2><ol><li>Tensor Expression (TE) is used to describe deep learning computation in existing deep learning compilers.<ul><li>ReduceSum: <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>C</mi><mo stretchy="false">[</mo><mi>p</mi><mo stretchy="false">]</mo><mo>+</mo><mo>=</mo><mi>A</mi><mo stretchy="false">[</mo><mi>p</mi><mo separator="true">,</mo><mi>l</mi><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">C[p]+=A[p,l]</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.07153em;">C</span><span class="mopen">[</span><span class="mord mathnormal">p</span><span class="mclose">]</span><span class="mord">+</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">A</span><span class="mopen">[</span><span class="mord mathnormal">p</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal" style="margin-right:0.01968em;">l</span><span class="mclose">]</span></span></span></span></li><li>Addition: <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>C</mi><mo stretchy="false">[</mo><mi>p</mi><mo stretchy="false">]</mo><mo>=</mo><mi>A</mi><mo stretchy="false">[</mo><mi>p</mi><mo stretchy="false">]</mo><mo>+</mo><mi>B</mi><mo stretchy="false">[</mo><mi>p</mi><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">C[p]=A[p]+B[p]</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.07153em;">C</span><span class="mopen">[</span><span class="mord mathnormal">p</span><span class="mclose">]</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">A</span><span class="mopen">[</span><span class="mord mathnormal">p</span><span class="mclose">]</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.05017em;">B</span><span class="mopen">[</span><span class="mord mathnormal">p</span><span class="mclose">]</span></span></span></span></li><li>MatMul: <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>C</mi><mo stretchy="false">[</mo><mi>m</mi><mo separator="true">,</mo><mi>n</mi><mo stretchy="false">]</mo><mo>+</mo><mo>=</mo><mi>A</mi><mo stretchy="false">[</mo><mi>m</mi><mo separator="true">,</mo><mi>k</mi><mo stretchy="false">]</mo><mo>×</mo><mi>B</mi><mo stretchy="false">[</mo><mi>k</mi><mo separator="true">,</mo><mi>n</mi><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">C[m,n]+=A[m,k]\times B[k,n]</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.07153em;">C</span><span class="mopen">[</span><span class="mord mathnormal">m</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal">n</span><span class="mclose">]</span><span class="mord">+</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">A</span><span class="mopen">[</span><span class="mord mathnormal">m</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal" style="margin-right:0.03148em;">k</span><span class="mclose">]</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.05017em;">B</span><span class="mopen">[</span><span class="mord mathnormal" style="margin-right:0.03148em;">k</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal">n</span><span class="mclose">]</span></span></span></span></li><li>BatchMatMul: <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>C</mi><mo stretchy="false">[</mo><mi>b</mi><mo separator="true">,</mo><mi>m</mi><mo separator="true">,</mo><mi>n</mi><mo stretchy="false">]</mo><mo>+</mo><mo>=</mo><mi>A</mi><mo stretchy="false">[</mo><mi>b</mi><mo separator="true">,</mo><mi>m</mi><mo separator="true">,</mo><mi>k</mi><mo stretchy="false">]</mo><mo>×</mo><mi>B</mi><mo stretchy="false">[</mo><mi>b</mi><mo separator="true">,</mo><mi>k</mi><mo separator="true">,</mo><mi>n</mi><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">C[b,m,n]+=A[b,m,k]\times B[b,k,n]</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.07153em;">C</span><span class="mopen">[</span><span class="mord mathnormal">b</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal">m</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal">n</span><span class="mclose">]</span><span class="mord">+</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">A</span><span class="mopen">[</span><span class="mord mathnormal">b</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal">m</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal" style="margin-right:0.03148em;">k</span><span class="mclose">]</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.05017em;">B</span><span class="mopen">[</span><span class="mord mathnormal">b</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal" style="margin-right:0.03148em;">k</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal">n</span><span class="mclose">]</span></span></span></span></li><li>Convolution: <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>C</mi><mo stretchy="false">[</mo><mi>n</mi><mo separator="true">,</mo><mi>f</mi><mo separator="true">,</mo><mi>x</mi><mo separator="true">,</mo><mi>y</mi><mo stretchy="false">]</mo><mo>+</mo><mo>=</mo><mi>A</mi><mo stretchy="false">[</mo><mi>n</mi><mo separator="true">,</mo><mi>m</mi><mo separator="true">,</mo><mi>x</mi><mo>+</mo><mi>i</mi><mo separator="true">,</mo><mi>y</mi><mo>+</mo><mi>j</mi><mo stretchy="false">]</mo><mo>×</mo><mi>B</mi><mo stretchy="false">[</mo><mi>f</mi><mo separator="true">,</mo><mi>m</mi><mo separator="true">,</mo><mi>i</mi><mo separator="true">,</mo><mi>j</mi><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">C[n,f,x,y]+=A[n,m,x+i,y+j]\times B[f,m,i,j]</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.07153em;">C</span><span class="mopen">[</span><span class="mord mathnormal">n</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal">x</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="mclose">]</span><span class="mord">+</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">A</span><span class="mopen">[</span><span class="mord mathnormal">n</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal">m</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal">x</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.85396em;vertical-align:-0.19444em;"></span><span class="mord mathnormal">i</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.05724em;">j</span><span class="mclose">]</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.05017em;">B</span><span class="mopen">[</span><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal">m</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal">i</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal" style="margin-right:0.05724em;">j</span><span class="mclose">]</span></span></span></span></li></ul></li><li>Definition of permutation invariant dimension:<ul><li>In a tensor expression <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>Y</mi><mo>←</mo><mi>f</mi><mo stretchy="false">(</mo><msub><mi>X</mi><mn>1</mn></msub><mo separator="true">,</mo><mo>…</mo><mo separator="true">,</mo><msub><mi>X</mi><mi>n</mi></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">Y \leftarrow f (X_1,\dots , X_n)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.22222em;">Y</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">←</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.07847em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="minner">…</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:-0.07847em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">n</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span>, where <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>f</mi></mrow><annotation encoding="application/x-tex">f</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord mathnormal" style="margin-right:0.10764em;">f</span></span></span></span> is an operator, <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>X</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">X_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.07847em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> and <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>Y</mi></mrow><annotation encoding="application/x-tex">Y</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.22222em;">Y</span></span></span></span> are its input and output tensors respectively.</li><li>A dimension <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi></mrow><annotation encoding="application/x-tex">k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.03148em;">k</span></span></span></span> in the operator is <strong>permutation invariant</strong> if it satisfies: <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal">∀</mi><mi>P</mi><mo>∈</mo><msub><mi mathvariant="normal">Φ</mi><mi>k</mi></msub><mo separator="true">,</mo><mi mathvariant="normal">∃</mi><msup><mi>P</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msup><mo>∈</mo><msub><mi mathvariant="normal">Φ</mi><mi>k</mi></msub><mtext>s.t. </mtext><msup><mi>P</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msup><mo stretchy="false">(</mo><mi>f</mi><mo stretchy="false">(</mo><mi>P</mi><mo stretchy="false">(</mo><msub><mi>X</mi><mn>1</mn></msub><mo stretchy="false">)</mo><mo separator="true">,</mo><mo>…</mo><mo separator="true">,</mo><mi>P</mi><mo stretchy="false">(</mo><msub><mi>X</mi><mi>n</mi></msub><mo stretchy="false">)</mo><mo stretchy="false">)</mo><mo>=</mo><mi>Y</mi></mrow><annotation encoding="application/x-tex">\forall P \in \Phi_k, ∃ P&#x27; ∈ \Phi_k \text{s.t. }P&#x27;(f(P(X_1),\dots , P(X_n))=Y</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.73354em;vertical-align:-0.0391em;"></span><span class="mord">∀</span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.946332em;vertical-align:-0.19444em;"></span><span class="mord"><span class="mord">Φ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord">∃</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.751892em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.001892em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord">Φ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord text"><span class="mord">s.t. </span></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.751892em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.07847em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="minner">…</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:-0.07847em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">n</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.22222em;">Y</span></span></span></span></li><li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="normal">Φ</mi><mi>k</mi></msub></mrow><annotation encoding="application/x-tex">\Phi_k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord">Φ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> is the set of all permutation functions on <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi></mrow><annotation encoding="application/x-tex">k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.03148em;">k</span></span></span></span> dimension. <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>P</mi><mo stretchy="false">(</mo><mi>X</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">P (X)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class="mclose">)</span></span></span></span> means a permutation function <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>P</mi></mrow><annotation encoding="application/x-tex">P</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span></span></span></span> is applied on the <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi></mrow><annotation encoding="application/x-tex">k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.03148em;">k</span></span></span></span> dimension of the tensor <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>X</mi></mrow><annotation encoding="application/x-tex">X</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.07847em;">X</span></span></span></span>, to shuffle the elements on <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi></mrow><annotation encoding="application/x-tex">k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.03148em;">k</span></span></span></span> dimension to a new order. If <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi></mrow><annotation encoding="application/x-tex">k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.03148em;">k</span></span></span></span> dimension does not exist in <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>X</mi></mrow><annotation encoding="application/x-tex">X</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.07847em;">X</span></span></span></span>, <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>P</mi><mo stretchy="false">(</mo><mi>X</mi><mo stretchy="false">)</mo><mo>=</mo><mi>X</mi></mrow><annotation encoding="application/x-tex">P (X) = X</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.07847em;">X</span></span></span></span>.</li></ul></li><li>For a permutation invariant dimension, when permutation is applied on this dimension of the input tensors, there exists a reverse permutation on the output tensor to make the result the same as the original computation.</li></ol><h2 id="what-are-the-rules-of-applying-permutation-invariant"><a class="markdownIt-Anchor" href="#what-are-the-rules-of-applying-permutation-invariant"></a> What are the rules of applying permutation invariant?</h2><ol><li>Permutation invariant of tensor dimensions can be classified into three categories:<ul><li><strong>Sporadic dimension</strong> is the dimension that exists in one or more tensors of a tensor expression, but does not span in all tensors. For example, <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>m</mi></mrow><annotation encoding="application/x-tex">m</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathnormal">m</span></span></span></span>, <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi></mrow><annotation encoding="application/x-tex">n</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathnormal">n</span></span></span></span>, <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi></mrow><annotation encoding="application/x-tex">k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.03148em;">k</span></span></span></span>, <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>f</mi></mrow><annotation encoding="application/x-tex">f</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord mathnormal" style="margin-right:0.10764em;">f</span></span></span></span>, <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>l</mi></mrow><annotation encoding="application/x-tex">l</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.01968em;">l</span></span></span></span> of the tensor expressions.</li><li><strong>Prevalent dimension</strong> is the dimension that exists in all the tensors (i.e., input and output tensors) of a tensor expression. Examples of prevalent dimension are <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi></mrow><annotation encoding="application/x-tex">p</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord mathnormal">p</span></span></span></span> and <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>b</mi></mrow><annotation encoding="application/x-tex">b</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathnormal">b</span></span></span></span>.</li><li><strong>Compound dimension</strong> is the dimension that is involved in an arithmetic expression. E.g. <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>x</mi></mrow><annotation encoding="application/x-tex">x</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathnormal">x</span></span></span></span>, <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>y</mi></mrow><annotation encoding="application/x-tex">y</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span></span></span></span> and <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>i</mi></mrow><annotation encoding="application/x-tex">i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.65952em;vertical-align:0em;"></span><span class="mord mathnormal">i</span></span></span></span>, <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>j</mi></mrow><annotation encoding="application/x-tex">j</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.85396em;vertical-align:-0.19444em;"></span><span class="mord mathnormal" style="margin-right:0.05724em;">j</span></span></span></span> in Convolution.</li></ul></li><li>When permutation invariant is applied on only one dimension of a tensor expression, the dimension can be sporadic dimension or prevalent dimension, but not compound dimension.<ul><li>Because permuting a compound dimension violates its corresponding arithmetic expression.</li></ul></li><li>When permutation invariant is applied on multiple dimensions of a tensor expression:<ul><li>When the permuted dimensions are all sporadic dimension, each dimension can only have a single permutation function.</li><li>When the permuted dimensions include a prevalent dimension, the permutation function on each element of the prevalent dimension could be different.</li></ul></li></ol><h2 id="what-is-stile"><a class="markdownIt-Anchor" href="#what-is-stile"></a> What is STile?</h2><ol><li>A tile is a sliced piece of an operator’s computation.<ul><li>Computation tiling slices the computation into many small homogeneous pieces, to parallelize the computation and increase data reuse.</li></ul></li><li>Permutation invariance can be applied on each tile independently, that is, the permutation functions on each tile can be different, leading to more diverse and fine-grained sparsity granularity.</li><li>An STile is a group of non-redundant elements following a specific type of layout, associated with a dense computation tile.<ul><li>The non-redundant element is called the data tile which represents the sparsity granularity. The scattered data tiles can be condensed to be a dense tile.</li><li>In reverse, a dense tile can correspond to different STiles with different permutation functions.</li></ul></li></ol><img src="/imgs/Sys4ai/SparDA/tile.png" width="50%"><h2 id="how-to-transform-input-and-eliminate-overhead"><a class="markdownIt-Anchor" href="#how-to-transform-input-and-eliminate-overhead"></a> How to transform input and eliminate overhead?</h2><ol><li><strong>Sparse-Dense Transform</strong>: With permutation invariant, we can construct a permutation function <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>P</mi></mrow><annotation encoding="application/x-tex">P</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span></span></span></span> to move all the redundant elements to the end while all the non-redundant elements to the front. The redundant elements can be safely removed to build a shorter <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi></mrow><annotation encoding="application/x-tex">k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.03148em;">k</span></span></span></span> dimension.</li><li><code>SLoad</code> maps sparse data tiles in input tensors to dense data block, while <code>SWrite</code> writes the output dense data block to the specified output data format, which could be sparse or dense.<ul><li><code>SLoad</code> and <code>SWrite</code> works on data rearrangement when the data is moving from global memory to shared memory and in reverse.</li><li>As long as the data tile could saturate read/write transaction of the memory (e.g., <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>32</mn></mrow><annotation encoding="application/x-tex">32</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">3</span><span class="mord">2</span></span></span></span> bytes in CUDA GPUs), the data rearrangement would introduce little overhead, because the loading of sparse data tiles does not waste memory bandwidth.</li><li>This property further enables zero-copy of sparse data in online dynamic sparsity scenario, because the effective data tiles can be directly selected from their original data format and written to the higher level memory with the desired format.</li></ul></li></ol><h2 id="how-to-choose-an-efficient-stile"><a class="markdownIt-Anchor" href="#how-to-choose-an-efficient-stile"></a> How to choose an efficient STile?</h2><ol><li>The most efficient STile for a sparse operator is determined mainly by two factors, i.e., the efficiency of its associated dense computation tile and the operator’s dynamic sparsity.</li><li>For the first factor, though different-sized computation tiles are all dense, they have different computation efficiency.<ul><li>Usually, the smaller the computation tile is, the less efficient it is. Because it is harder to saturate all the available cores.</li><li>Some carefully designed coordination of threads could greatly improve the computation efficiency of small computation tiles, leading to many efficient small computation tiles.</li><li>These welloptimized computation tiles are stored in a tile database of SparDA and serve as the base of STiles.</li></ul></li><li>For the second factor, all the STiles can be applied to a given sparsity but lead to varied computation efficiency.<ul><li>If the data tile of an STile is larger than the granularity of the given sparsity, a proportion of the computation is wasted.</li><li>While if the data tile is much smaller than the sparsity granularity, the computation tile is not efficient.</li></ul></li><li>In online dynamic sparsity, the most suitable STile is chosen based on several representative sparsity samples.<ul><li>It traverses all the STiles in the tile database to compute their cost on the given dynamically sparse operator and picks the best.</li><li><code>CoverAlgo</code> outputs the number of STiles needed to cover all the non-zero values of a given sparsity sample. The cost is the sum of the n sparsity samples.</li></ul></li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">@param  OP       : a dynamically sparse operator,</span></span><br><span class="line"><span class="string">        D_sparse : a list of n sparsity samples of Op</span></span><br><span class="line"><span class="string">@return Best_tile: the best STile for Op</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">ChooseStile</span>(<span class="params">D_sparse, Op</span>):</span><br><span class="line">  Best_stile, Cost_opt = null, inf</span><br><span class="line">  <span class="keyword">for</span> S <span class="keyword">in</span> GetStileFromTileDB(Op):</span><br><span class="line">    Cost = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> D <span class="keyword">in</span> D_sparse:</span><br><span class="line">      num_stiles = CoverAlgo(D, S.data_tile)</span><br><span class="line">      Cost += Num_stiles * S.tile_cost</span><br><span class="line">    <span class="keyword">if</span> Cost &lt; Cost_opt:</span><br><span class="line">      Best_stile = S</span><br><span class="line">      Cost_opt = Cost</span><br><span class="line">  <span class="keyword">return</span> Best_stile</span><br></pre></td></tr></table></figure><h2 id="how-to-represent-dynamic-sparsity"><a class="markdownIt-Anchor" href="#how-to-represent-dynamic-sparsity"></a> How to represent dynamic sparsity?</h2><ol><li>The representation is a sparsity attribute that can be efficiently constructed and parsed while consuming less memory.<ul><li>The sparsity attribute combines a <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>0</mn><mo>−</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">0-1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.72777em;vertical-align:-0.08333em;"></span><span class="mord">0</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">1</span></span></span></span> attribute matrix along with a sparsity granularity. Each value in the attribute matrix represents the existence of a data block which is the size of the sparsity granularity.<ul><li>One type that it can represent is that the location of sparse values keeps changing while the granularity is the same. Another type allows the granularity to change.</li></ul></li><li>The sparsity granularity is in the form of <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">(</mo><msub><mi>S</mi><mrow><mi>d</mi><mi>i</mi><mi>m</mi><mn>1</mn></mrow></msub><mo separator="true">,</mo><mo>…</mo><mo separator="true">,</mo><msub><mi>S</mi><mrow><mi>d</mi><mi>i</mi><mi>m</mi><mi>N</mi></mrow></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">(S_{dim1},\dots , S_{dimN} )</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05764em;">S</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:-0.05764em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">d</span><span class="mord mathnormal mtight">i</span><span class="mord mathnormal mtight">m</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="minner">…</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05764em;">S</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:-0.05764em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">d</span><span class="mord mathnormal mtight">i</span><span class="mord mathnormal mtight">m</span><span class="mord mathnormal mtight" style="margin-right:0.10903em;">N</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span>, where <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>S</mi><mrow><mi>d</mi><mi>i</mi><mi>m</mi></mrow></msub></mrow><annotation encoding="application/x-tex">S_{dim}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05764em;">S</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:-0.05764em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">d</span><span class="mord mathnormal mtight">i</span><span class="mord mathnormal mtight">m</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> is the size of the granularity on dimension dim.</li></ul></li><li>During online model execution, SparDA detects the annotated sparsity and builds the index of the non-zero blocks in every sparse tensor.<ul><li>The non-zero blocks are in the granularity of the data tile of the chosen STile. The blocks are translated into a bunch of STiles in an online manner.</li><li>SparDA constructs the sparsity index in an out-of-order manner, because the permutation invariant property relaxes the order of the indices in a sparse data format.</li></ul></li><li>Unlike traditional sparse data format which has data in it, SparDA only constructs index while leaving the data as is. The index directly references the data blocks in their original tensor.<ul><li>STile uses the index to load the data blocks across memory hierarchies and rearranges the data blocks on-the-fly into the dense format.</li></ul></li></ol><h2 id="what-are-the-apis-of-sparda-what-is-its-working-pipeline"><a class="markdownIt-Anchor" href="#what-are-the-apis-of-sparda-what-is-its-working-pipeline"></a> What are the APIs of SparDA? What is its working pipeline?</h2><ol><li>Its working pipeline is as followed:<ul><li>To make PyTorch sparsity-aware, we first integrated the representation of dynamic sparsity into PyTorch with a class called <code>DSparsity</code>.</li><li>Users can annotate the arbitrary dynamic sparsity pattern with a unified interface called <code>SetDSparsity</code>.</li><li>After annotation, SparDA builds the sparse indexes through the fast index constructor with negligible overhead.</li><li>After index construction, the STile optimization policy will choose an appropriate STile from the STile database according to the offline profiled performance table.</li><li>The just-in-time code generator emits and compiles the corresponding STile for sparse computation.</li></ul></li><li>SparDA already constructs around <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1500</mn></mrow><annotation encoding="application/x-tex">1500</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">1</span><span class="mord">5</span><span class="mord">0</span><span class="mord">0</span></span></span></span> STiles from the dense computation kernels and profiles the performance of these STiles under different sparsity ratios.</li><li>Users can easily customize the online STile optimization policy through the interface <code>RegisterOptPolicy</code> for different scenarios.<ul><li>Users can also easily expand more STiles by adding corresponding dense computation kernels and their tensor expressions into the database.</li></ul></li></ol><h1 id="evaluation"><a class="markdownIt-Anchor" href="#evaluation"></a> Evaluation</h1><ol><li>The authors evaluate SparDA on four representative dynamic sparse scenarios: MoE models, dynamic sparsity caused by different sequence length, dynamic sparse algorithms, and sparse training.</li><li>They compared SparDA with the state-of-art dense and sparse baselines: PyTorch (v1.11.0) and PyTorch with state-of-art sparse kernels (PyTorch-S).<ul><li>To construct PyTorch-S, we integrate the state-of-art sparse libraries including cuSPARSE (v11.6), Sputnik, Triton. We select the best performance of all the sparse libraries as the final results of PyTorch-S.</li></ul></li></ol>]]></content>
      
      
      <categories>
          
          <category> Paper Notebook </category>
          
          <category> Sys4AI </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Sys4AI </tag>
            
            <tag> Sparsity </tag>
            
            <tag> Accelerator </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Elf</title>
      <link href="/2023/10/04/Paper/Sys4AI/ELF/"/>
      <url>/2023/10/04/Paper/Sys4AI/ELF/</url>
      
        <content type="html"><![CDATA[<p>Paper: <a href="https://dl.acm.org/doi/abs/10.1145/3447993.3448628">Elf: Accelerate High-resolution Mobile Deep Vision with Content-aware Parallel Offloading</a></p><p><ul class="markdownIt-TOC"><li><a href="#purpose">Purpose</a></li><li><a href="#model">Model</a><ul><li><a href="#what-is-the-pipeline-of-elf">What is the pipeline of Elf?</a></li><li><a href="#region-proposals">Region proposals</a><ul><li><a href="#how-to-predict-region-proposals">How to predict region proposals?</a></li><li><a href="#how-to-index-region-proposals">How to index region proposals?</a></li></ul></li><li><a href="#offloading">Offloading</a><ul><li><a href="#how-to-optimize-elf-schedule-problem">How to optimize Elf schedule problem?</a></li><li><a href="#why-sending-rp-coordinates-and-original-image-instead-of-cropped-rp-task">Why sending RP coordinates and original image instead of cropped RP task?</a></li><li><a href="#how-to-generate-rp-boxes">How to generate RP boxes?</a></li><li><a href="#how-do-we-estimate-server-capacity-and-rp-computation-cost">How do we estimate server capacity and RP computation cost?</a></li></ul></li></ul></li><li><a href="#evaluation">Evaluation</a></li></ul></p><h1 id="purpose"><a class="markdownIt-Anchor" href="#purpose"></a> Purpose</h1><ol><li>To support applications running deep neural networks on multimedia data in real-time, having mobile devices offload the computation, especially the neural network inference, to edge clouds has proved effective.</li><li>Issues:<ul><li>In reality, we may not be able to find a dedicated and powerful server but need to make do with less powerful ones.</li><li>Various techniques to make DNN models smaller to reduce the computation load lead to compromised model accuracy due to the fundamental trade-off between model size and model accuracy.</li><li>By offloading the intensive model inference to a powerful edge server and with the high bandwidth and low latency provided by the emerging 5G networks, the inference latency can be significantly reduced.<ul><li>Most existing solutions use low-resolution images through the entire pipeline.</li><li>Most existing methods only consider offloading tasks between a single pair of server and client, assuming that no competing clients or extra edge resources available.</li><li>The heterogeneous resource demands of applications running on edge servers and highly dynamic workloads by mobile users lead to resource fragmentation.</li></ul></li></ul></li><li>Challenges:<ul><li>It requires the client to effectively partition the inference job into multiple pieces while maintaining the inference accuracy.</li><li>The system needs to be aware of available computation resources on each server and dynamically develops the frame partitioning solution, so that it can ensure no server in the parallel offloading procedure to become the bottleneck.</li><li>Such a system should have a general framework design that is independent of its host deep vision applications.</li></ul></li><li>Contribution:<ul><li>The idea is to partition the video frame and offload the partial inference tasks to multiple servers for parallel processing.</li><li>Elf is a framework to accelerate high-resolution mobile deep vision offloading in heterogeneous client and edge server environment, by distributing the computation to available edge servers adaptively.</li><li>It employs a recurrent region proposal prediction algorithm, a region proposal centric frame partitioning, and a resource-aware multi-offloading scheme.</li></ul></li></ol><h1 id="model"><a class="markdownIt-Anchor" href="#model"></a> Model</h1><h2 id="what-is-the-pipeline-of-elf"><a class="markdownIt-Anchor" href="#what-is-the-pipeline-of-elf"></a> What is the pipeline of Elf?</h2><ol><li>The first phase is recurrent region proposal prediction.<ul><li>On the mobile end, whenever a new video frame arrives, Elf predicts its region proposals (RPs) based on the ones detected in historical frames.</li><li>The algorithm must be lightweight, can effectively learn the motion model of the objects/RPs from history frames and pays more attention to more recent frames.</li><li>Efficiently utilizing the historical RP inference results converts the computing-intensive image regression problem to a light-weight time series prediction problem.</li><li>An RP indexing algorithm keeps track of the motion across frames. A Low Resolution Compensation scheme is proposed to handle new objects when they first appear.</li></ul></li><li>The second phase is frame partitioning and offloading.<ul><li>Ideally, a well-designed frame partitioning scheme should show a negligible overhead and have heterogeneous edge servers to finish parallel inference tasks at the same time.</li><li>The partitioning algorithm should be aware of the number of and locations of RPs in a frame and be inclusive. Also, Elf discards background pixels that are unlikely contain any RPs.</li><li>Depending upon the objects contained in each partition, partitions have different computation costs. The algorithm should take into consideration this cost heterogeneity to achieve load balancing among the servers.</li><li>Unlike central clouds, edge cloud servers exhibit heterogeneous computing/storage/networking resources due to the distributed nature and high user mobility. A poor offloading may result in job stragglers that complete much slower than their peers and thus significantly increases the overall latency.</li></ul></li><li>The last phase is partial inference and result integration.<ul><li>Taking the offloaded partitions as input, the edge servers run the applicationspecific CNN models to yield partial inference results.</li><li>These partial results are finally integrated at the mobile side to render the final result.</li></ul></li></ol><h2 id="region-proposals"><a class="markdownIt-Anchor" href="#region-proposals"></a> Region proposals</h2><h3 id="how-to-predict-region-proposals"><a class="markdownIt-Anchor" href="#how-to-predict-region-proposals"></a> How to predict region proposals?</h3><ol><li>An attention-based LSTM network is used to predict region proposals.<ul><li>It takes only the RPs of the past <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>N</mi></mrow><annotation encoding="application/x-tex">N</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">N</span></span></span></span> frames without the image of the currect frame as its input and outputs the RPs of current frame.</li><li>It can only handle the objects that already occurred in the previous frame.</li></ul></li><li>To handle new objects and to reduce the computation overhead, Elf runs LRC once per n frames to reduce such an overhead.<ul><li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi></mrow><annotation encoding="application/x-tex">n</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathnormal">n</span></span></span></span> is a hyperparameter, indicating the trade-off between computation cost and at most <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi></mrow><annotation encoding="application/x-tex">n</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathnormal">n</span></span></span></span>-frame delay to realize new objects.</li><li>First, LRC down-samples a high-resolution video frame by a max-pooling operation.</li><li>Then Elf offloads the resized video frame, along with the partitions from regular sized partitions, to edge servers to run application-specific models, which usually consist of an object detection component.</li><li>Based on the inference results, Elf can roughly locate the new objects in the frame.</li></ul></li><li>The predicted RP bounding box may not cover all the pixels of an object due to motion.<ul><li>The bounding box is expanded by <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi><mi mathvariant="normal">%</mi></mrow><annotation encoding="application/x-tex">p\%</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.94444em;vertical-align:-0.19444em;"></span><span class="mord mathnormal">p</span><span class="mord">%</span></span></span></span>. The downside of this scheme is the increased data transmission and computation.</li><li>It consults the corresponding RP position shift and the prediction confidence level as the indicators to assign different weights on <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi></mrow><annotation encoding="application/x-tex">p</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord mathnormal">p</span></span></span></span>.</li></ul></li></ol><h3 id="how-to-index-region-proposals"><a class="markdownIt-Anchor" href="#how-to-index-region-proposals"></a> How to index region proposals?</h3><ol><li>Vision-based matching algorithms are not considered because they introduce significant overheads in hundreds of milliseconds.</li><li>From the very first video frame, Elf assigns a unique index to each region proposal.<ul><li>In each upcoming frame, Elf matches each RP with the corresponding index assigned earlier.</li><li>If an RP includes a new object that was not seen before, a new index will be automatically assigned.</li></ul></li><li>Match the RPs across frames with a combination of RP position shift and RP area shift.<ul><li>The RP position shift measures the change of the center point along the x-/y-axis between the current frame and the previous frame. A larger value indicates a bigger spatial shift and thus a lower matching probability.</li><li>The RP area shift measures the amount of area change between the RPs in two adjacent frames. A lower value indicates a higher matching probability.</li><li>When the x and y RP position shift are both under <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>0.02</mn></mrow><annotation encoding="application/x-tex">0.02</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">0</span><span class="mord">.</span><span class="mord">0</span><span class="mord">2</span></span></span></span> and the area shift ratio is under <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>0.2</mn></mrow><annotation encoding="application/x-tex">0.2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">0</span><span class="mord">.</span><span class="mord">2</span></span></span></span>, we declare a match.</li></ul></li></ol><h2 id="offloading"><a class="markdownIt-Anchor" href="#offloading"></a> Offloading</h2><h3 id="how-to-optimize-elf-schedule-problem"><a class="markdownIt-Anchor" href="#how-to-optimize-elf-schedule-problem"></a> How to optimize Elf schedule problem?</h3><ol><li>Assuming <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>M</mi></mrow><annotation encoding="application/x-tex">M</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">M</span></span></span></span> is the total number of RPs while <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>N</mi></mrow><annotation encoding="application/x-tex">N</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">N</span></span></span></span> is the total number of servers, Elf packs the <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>M</mi></mrow><annotation encoding="application/x-tex">M</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">M</span></span></span></span> RP processing tasks and one LRC task into <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>N</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msup></mrow><annotation encoding="application/x-tex">N&#x27;</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.751892em;vertical-align:0em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.10903em;">N</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.751892em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span></span></span></span></span></span></span></span> offloading tasks (<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>N</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msup><mo>≤</mo><mi>N</mi></mrow><annotation encoding="application/x-tex">N&#x27;≤N</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.887862em;vertical-align:-0.13597em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.10903em;">N</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.751892em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">≤</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">N</span></span></span></span> ), and offloads each task onto an edge server.</li><li>The overall objective of the partitioning and the offloading process is to minimize the completion time of the offloading tasks that are distributed across <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>N</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msup></mrow><annotation encoding="application/x-tex">N&#x27;</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.751892em;vertical-align:0em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.10903em;">N</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.751892em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span></span></span></span></span></span></span></span> edge servers, i.e. minimizing the completion time of the task which has the longest execution time among all the tasks.</li><li>The optimization objective can be written as<ul><li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>min</mi><mo>⁡</mo><mi>max</mi><mo>⁡</mo><mo stretchy="false">(</mo><mo stretchy="false">{</mo><msubsup><mi>T</mi><mi>k</mi><mi>t</mi></msubsup><mo stretchy="false">}</mo><mo stretchy="false">)</mo><mo separator="true">,</mo><mi>k</mi><mo>∈</mo><mo stretchy="false">[</mo><mn>1</mn><mo separator="true">,</mo><mo>…</mo><mo separator="true">,</mo><msup><mi>N</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msup><mo stretchy="false">]</mo><mtext>,</mtext><mspace linebreak="newline"></mspace><mtext>s.t.  </mtext><msubsup><mi>T</mi><mi>k</mi><mi>t</mi></msubsup><mo>=</mo><msubsup><mi>T</mi><mrow><mi>r</mi><mi>e</mi><mi>s</mi><mo separator="true">,</mo><mi>k</mi></mrow><mi>t</mi></msubsup><mo>+</mo><msubsup><mi>T</mi><mrow><mi>l</mi><mi>r</mi><mi>c</mi><mo separator="true">,</mo><mi>k</mi></mrow><mi>t</mi></msubsup><mo>⋅</mo><mn>1</mn><mo stretchy="false">(</mo><mi>t</mi><mspace></mspace><mspace width="0.6666666666666666em"/><mrow><mi mathvariant="normal">m</mi><mi mathvariant="normal">o</mi><mi mathvariant="normal">d</mi></mrow><mtext> </mtext><mtext> </mtext><mi>n</mi><mo>=</mo><mn>0</mn><mo stretchy="false">)</mo><mo>⋅</mo><mn>1</mn><mo stretchy="false">(</mo><mi>arg</mi><mo>⁡</mo><mi>max</mi><mo>⁡</mo><mo stretchy="false">{</mo><msup><mi>p</mi><mi>t</mi></msup><mo stretchy="false">}</mo><mo>=</mo><mi>k</mi><mo stretchy="false">)</mo><mtext>, </mtext><msubsup><mi>T</mi><mrow><mi>r</mi><mi>p</mi><mi>s</mi><mo separator="true">,</mo><mi>k</mi></mrow><mi>t</mi></msubsup><mo>≈</mo><mfrac><msubsup><mi>C</mi><mrow><mi>r</mi><mi>p</mi><mi>s</mi><mo separator="true">,</mo><mi>k</mi></mrow><mi>t</mi></msubsup><msubsup><mi>p</mi><mi>k</mi><mi>t</mi></msubsup></mfrac><mtext>, </mtext><msubsup><mi>T</mi><mrow><mi>l</mi><mi>r</mi><mi>c</mi><mo separator="true">,</mo><mi>k</mi></mrow><mi>t</mi></msubsup><mo>≈</mo><mfrac><msubsup><mi>C</mi><mrow><mi>l</mi><mi>r</mi><mi>c</mi><mo separator="true">,</mo><mi>k</mi></mrow><mi>t</mi></msubsup><msubsup><mi>p</mi><mi>k</mi><mi>t</mi></msubsup></mfrac></mrow><annotation encoding="application/x-tex">\min\max(\{T^t_k\}), k\in[1,\dots,N&#x27;]\text{,}\\ \text{s.t. }\ T^t_k=T^t_{res,k}+T^t_{lrc,k}\cdot1(t\mod n=0)\cdot1(\arg\max\{p^t\}=k)\text{, }T^t_{rps,k}\approx\frac{C^t_{rps,k}}{p^t_k}\text{, }T^t_{lrc,k}\approx\frac{C^t_{lrc,k}}{p^t_k}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.0766639999999998em;vertical-align:-0.2831079999999999em;"></span><span class="mop">min</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mop">max</span><span class="mopen">(</span><span class="mopen">{</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.7935559999999999em;"><span style="top:-2.4168920000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2831079999999999em;"><span></span></span></span></span></span></span><span class="mclose">}</span><span class="mclose">)</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal" style="margin-right:0.03148em;">k</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.001892em;vertical-align:-0.25em;"></span><span class="mopen">[</span><span class="mord">1</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="minner">…</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.10903em;">N</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.751892em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span></span></span></span></span><span class="mclose">]</span><span class="mord text"><span class="mord">,</span></span></span><span class="mspace newline"></span><span class="base"><span class="strut" style="height:1.0766639999999998em;vertical-align:-0.2831079999999999em;"></span><span class="mord text"><span class="mord">s.t. </span></span><span class="mspace"> </span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.7935559999999999em;"><span style="top:-2.4168920000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2831079999999999em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.2127719999999997em;vertical-align:-0.4192159999999999em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.7935559999999999em;"><span style="top:-2.4168920000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span><span class="mord mathnormal mtight">e</span><span class="mord mathnormal mtight">s</span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.4192159999999999em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1.2127719999999997em;vertical-align:-0.4192159999999999em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.7935559999999999em;"><span style="top:-2.4168920000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.01968em;">l</span><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span><span class="mord mathnormal mtight">c</span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.4192159999999999em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord">1</span><span class="mopen">(</span><span class="mord mathnormal">t</span><span class="mspace allowbreak"></span><span class="mspace" style="margin-right:0.6666666666666666em;"></span></span><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord"><span class="mord"><span class="mord mathrm">m</span><span class="mord mathrm">o</span><span class="mord mathrm">d</span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal">n</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord">0</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1.043556em;vertical-align:-0.25em;"></span><span class="mord">1</span><span class="mopen">(</span><span class="mop">ar<span style="margin-right:0.01389em;">g</span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mop">max</span><span class="mopen">{</span><span class="mord"><span class="mord mathnormal">p</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.7935559999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span></span></span></span></span><span class="mclose">}</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.2127719999999997em;vertical-align:-0.4192159999999999em;"></span><span class="mord mathnormal" style="margin-right:0.03148em;">k</span><span class="mclose">)</span><span class="mord text"><span class="mord">, </span></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.7935559999999999em;"><span style="top:-2.4168920000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span><span class="mord mathnormal mtight">p</span><span class="mord mathnormal mtight">s</span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.4192159999999999em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">≈</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.81862em;vertical-align:-0.60196em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.2166599999999999em;"><span style="top:-2.6411em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight">p</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.7841428571428573em;"><span style="top:-2.1527714285714286em;margin-left:0em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span><span style="top:-2.8448em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.3472285714285714em;"><span></span></span></span></span></span></span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.60742em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.07153em;">C</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8703428571428571em;"><span style="top:-2.214em;margin-left:-0.07153em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span><span class="mord mathnormal mtight">p</span><span class="mord mathnormal mtight">s</span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span><span style="top:-2.931em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.42488571428571426em;"><span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.60196em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mord text"><span class="mord">, </span></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.7935559999999999em;"><span style="top:-2.4168920000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.01968em;">l</span><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span><span class="mord mathnormal mtight">c</span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.4192159999999999em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">≈</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.81862em;vertical-align:-0.60196em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.2166599999999999em;"><span style="top:-2.6411em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight">p</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.7841428571428573em;"><span style="top:-2.1527714285714286em;margin-left:0em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span><span style="top:-2.8448em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.3472285714285714em;"><span></span></span></span></span></span></span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.60742em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.07153em;">C</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8703428571428571em;"><span style="top:-2.214em;margin-left:-0.07153em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.01968em;">l</span><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span><span class="mord mathnormal mtight">c</span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span><span style="top:-2.931em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.42488571428571426em;"><span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.60196em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></li><li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msubsup><mi>T</mi><mi>k</mi><mi>t</mi></msubsup></mrow><annotation encoding="application/x-tex">T^t_k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.0766639999999998em;vertical-align:-0.2831079999999999em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.7935559999999999em;"><span style="top:-2.4168920000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2831079999999999em;"><span></span></span></span></span></span></span></span></span></span> is the completion time on the <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi></mrow><annotation encoding="application/x-tex">k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.03148em;">k</span></span></span></span>-th server at time-<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>t</mi></mrow><annotation encoding="application/x-tex">t</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.61508em;vertical-align:0em;"></span><span class="mord mathnormal">t</span></span></span></span>, which consists of two completion-time terms, <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msubsup><mi>T</mi><mrow><mi>r</mi><mi>p</mi><mi>s</mi><mo separator="true">,</mo><mi>k</mi></mrow><mi>t</mi></msubsup></mrow><annotation encoding="application/x-tex">T^t_{rps,k}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.2127719999999997em;vertical-align:-0.4192159999999999em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.7935559999999999em;"><span style="top:-2.4168920000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span><span class="mord mathnormal mtight">p</span><span class="mord mathnormal mtight">s</span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.4192159999999999em;"><span></span></span></span></span></span></span></span></span></span> and <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msubsup><mi>T</mi><mrow><mi>l</mi><mi>r</mi><mi>c</mi><mo separator="true">,</mo><mi>k</mi></mrow><mi>t</mi></msubsup></mrow><annotation encoding="application/x-tex">T^t_{lrc,k}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.2127719999999997em;vertical-align:-0.4192159999999999em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.7935559999999999em;"><span style="top:-2.4168920000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.01968em;">l</span><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span><span class="mord mathnormal mtight">c</span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.4192159999999999em;"><span></span></span></span></span></span></span></span></span></span> for RPs and LRC respectively.</li><li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msubsup><mi>C</mi><mrow><mi>r</mi><mi>p</mi><mi>s</mi><mo separator="true">,</mo><mi>k</mi></mrow><mi>t</mi></msubsup></mrow><annotation encoding="application/x-tex">C^t_{rps,k}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.2127719999999997em;vertical-align:-0.4192159999999999em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07153em;">C</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.7935559999999999em;"><span style="top:-2.4168920000000003em;margin-left:-0.07153em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span><span class="mord mathnormal mtight">p</span><span class="mord mathnormal mtight">s</span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.4192159999999999em;"><span></span></span></span></span></span></span></span></span></span> and <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msubsup><mi>C</mi><mrow><mi>l</mi><mi>r</mi><mi>c</mi><mo separator="true">,</mo><mi>k</mi></mrow><mi>t</mi></msubsup></mrow><annotation encoding="application/x-tex">C^t_{lrc,k}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.2127719999999997em;vertical-align:-0.4192159999999999em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07153em;">C</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.7935559999999999em;"><span style="top:-2.4168920000000003em;margin-left:-0.07153em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.01968em;">l</span><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span><span class="mord mathnormal mtight">c</span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.4192159999999999em;"><span></span></span></span></span></span></span></span></span></span> are the computing cost of RP box and LRC offloading to server <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi></mrow><annotation encoding="application/x-tex">k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.03148em;">k</span></span></span></span> while <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msubsup><mi>p</mi><mi>k</mi><mi>t</mi></msubsup></mrow><annotation encoding="application/x-tex">p^t_k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.0766639999999998em;vertical-align:-0.2831079999999999em;"></span><span class="mord"><span class="mord mathnormal">p</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.7935559999999999em;"><span style="top:-2.4168920000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2831079999999999em;"><span></span></span></span></span></span></span></span></span></span> is the available resource capacity of the <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi></mrow><annotation encoding="application/x-tex">k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.03148em;">k</span></span></span></span>-th server.</li></ul></li></ol><h3 id="why-sending-rp-coordinates-and-original-image-instead-of-cropped-rp-task"><a class="markdownIt-Anchor" href="#why-sending-rp-coordinates-and-original-image-instead-of-cropped-rp-task"></a> Why sending RP coordinates and original image instead of cropped RP task?</h3><ol><li>The execution time of <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>r</mi></mrow><annotation encoding="application/x-tex">r</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span></span></span></span> (<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>r</mi></mrow><annotation encoding="application/x-tex">r</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span></span></span></span> is a small number such as <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>2</mn></mrow><annotation encoding="application/x-tex">2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">2</span></span></span></span> and <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>3</mn></mrow><annotation encoding="application/x-tex">3</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">3</span></span></span></span>) small RP (e.g., <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>&lt;</mo><mn>5</mn><mi mathvariant="normal">%</mi></mrow><annotation encoding="application/x-tex">&lt;5\%</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5782em;vertical-align:-0.0391em;"></span><span class="mrel">&lt;</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.80556em;vertical-align:-0.05556em;"></span><span class="mord">5</span><span class="mord">%</span></span></span></span> size of the original image) tasks is not much less than <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>r</mi></mrow><annotation encoding="application/x-tex">r</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span></span></span></span> times of the execution time of running a single <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>r</mi></mrow><annotation encoding="application/x-tex">r</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span></span></span></span>-fold RP task.</li><li>It is hard to determine a good cropping strategy.<ul><li>The precise cut-out individual RPs will lead to poor detection inference accuracy due to the lack of necessary background pixels.</li><li>If we leave large padding around the RPs, then the total offloaded data will be too large to be efficient.</li></ul></li><li>Too many cropping operations generate high memory copy overheads which may likely become problematic on mobile devices.</li></ol><h3 id="how-to-generate-rp-boxes"><a class="markdownIt-Anchor" href="#how-to-generate-rp-boxes"></a> How to generate RP boxes?</h3><ol><li>Compared to a single RP, an RP-box is larger and consists of one or more nearby RPs.<ul><li>Each offloading task consists of either an LRC task, or an RP-box processing task, or both.</li><li>By scheduling an RP box instead of individual RPs, we can avoid the fragmentation problems.</li></ul></li><li>The number of offloading tasks is determined by the number of available edge servers.</li><li><strong>RP box initialization</strong>: Before partitioning a frame, Elf first crops the area with all the RPs and horizontally partitions it into <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>N</mi></mrow><annotation encoding="application/x-tex">N</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">N</span></span></span></span> segments (<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>N</mi></mrow><annotation encoding="application/x-tex">N</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">N</span></span></span></span> is the number of available servers), where each segment corresponds to an initial RP box.<ul><li>The size of each RP box is initialized to be proportional to the available resource of the corresponding server</li><li>At the LRC round, we partition the cropped image into <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>N</mi><mtext>−</mtext><mn>1</mn></mrow><annotation encoding="application/x-tex">N − 1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.76666em;vertical-align:-0.08333em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">N</span><span class="mord">−</span><span class="mord">1</span></span></span></span> segments and have <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>N</mi><mtext>−</mtext><mn>1</mn></mrow><annotation encoding="application/x-tex">N − 1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.76666em;vertical-align:-0.08333em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">N</span><span class="mord">−</span><span class="mord">1</span></span></span></span> RP boxes accordingly. We reserve one server for the LRC task.</li></ul></li><li><strong>RP association</strong>: For each RP, Elf evaluates its spatial relationship with all the RP boxes. Given a pair of RP <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>r</mi></mrow><annotation encoding="application/x-tex">r</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span></span></span></span> and box <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>b</mi></mrow><annotation encoding="application/x-tex">b</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathnormal">b</span></span></span></span>,<ul><li>If <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>r</mi></mrow><annotation encoding="application/x-tex">r</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span></span></span></span> is completely included in <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>b</mi></mrow><annotation encoding="application/x-tex">b</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathnormal">b</span></span></span></span> and we conveniently associate them.</li><li>If <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>r</mi></mrow><annotation encoding="application/x-tex">r</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span></span></span></span> and <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>b</mi></mrow><annotation encoding="application/x-tex">b</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathnormal">b</span></span></span></span> are not overlap, <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>r</mi></mrow><annotation encoding="application/x-tex">r</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span></span></span></span> is not associated with <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>b</mi></mrow><annotation encoding="application/x-tex">b</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathnormal">b</span></span></span></span>.</li><li>If <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>r</mi></mrow><annotation encoding="application/x-tex">r</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span></span></span></span> and <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>b</mi></mrow><annotation encoding="application/x-tex">b</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathnormal">b</span></span></span></span> are partial overlapped, it partially overlaps with at least one other box as well. We choose to associate with the RP box that has the most overlap with the RP.<ul><li>If there is a tie, we choose the RP box with a larger gap between the server resource capacity and the computation costs of the RPs that are already associated.</li></ul></li></ul></li><li><strong>RP box adjustment</strong>: Elf resizes each RP box such that it can fully cover all the RPs that are associated with it.<ul><li>The computation cost of some RP boxes may drastically increase compared to the initialization stage and thus break the intended load balancing.</li><li>We examine those RP boxes whose cost increase exceeds a pre-defined threshold. For these boxes, we try to re-associate the RP with the lowest cost to the neighboring box who has enough computation capacity to hold this RP.</li><li>After each re-association, the two boxes need to adjust their sizes accordingly and estimate the new computation cost. We stop this process if the re-association results in an even higher load imbalance.</li></ul></li><li>The <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msubsup><mi>C</mi><mrow><mi>r</mi><mi>p</mi><mi>s</mi><mo separator="true">,</mo><mi>k</mi></mrow><mi>t</mi></msubsup><mo>=</mo><msub><mo>∑</mo><mi>v</mi></msub><mo stretchy="false">{</mo><msubsup><mi>C</mi><mrow><mi>r</mi><mi>p</mi><mo separator="true">,</mo><mi>v</mi></mrow><mi>t</mi></msubsup><mo stretchy="false">}</mo></mrow><annotation encoding="application/x-tex">C^t_{rps,k}=\sum_v\{C^t_{rp,v}\}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.2127719999999997em;vertical-align:-0.4192159999999999em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07153em;">C</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.7935559999999999em;"><span style="top:-2.4168920000000003em;margin-left:-0.07153em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span><span class="mord mathnormal mtight">p</span><span class="mord mathnormal mtight">s</span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.4192159999999999em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.176664em;vertical-align:-0.383108em;"></span><span class="mop"><span class="mop op-symbol small-op" style="position:relative;top:-0.0000050000000000050004em;">∑</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.0016819999999999613em;"><span style="top:-2.40029em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03588em;">v</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.29971000000000003em;"><span></span></span></span></span></span></span><span class="mopen">{</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07153em;">C</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.7935559999999999em;"><span style="top:-2.4530000000000003em;margin-left:-0.07153em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span><span class="mord mathnormal mtight">p</span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight" style="margin-right:0.03588em;">v</span></span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.383108em;"><span></span></span></span></span></span></span><span class="mclose">}</span></span></span></span> and <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msubsup><mi>C</mi><mrow><mi>l</mi><mi>r</mi><mi>c</mi></mrow><mi>t</mi></msubsup><mo>=</mo><mi>α</mi><mo>⋅</mo><mo stretchy="false">(</mo><msubsup><mo>∑</mo><mrow><mi>k</mi><mo>=</mo><mn>1</mn></mrow><mi>M</mi></msubsup><msubsup><mi>C</mi><mrow><mi>r</mi><mi>p</mi><mi>s</mi><mo separator="true">,</mo><mi>k</mi></mrow><mi>t</mi></msubsup><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">C^t_{lrc}=\alpha\cdot(\sum^M_{k=1}C^t_{rps,k})</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.0766639999999998em;vertical-align:-0.2831079999999999em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07153em;">C</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.7935559999999999em;"><span style="top:-2.4168920000000003em;margin-left:-0.07153em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.01968em;">l</span><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span><span class="mord mathnormal mtight">c</span></span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2831079999999999em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.44445em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.0037em;">α</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1.4004469999999998em;vertical-align:-0.4192159999999999em;"></span><span class="mopen">(</span><span class="mop"><span class="mop op-symbol small-op" style="position:relative;top:-0.0000050000000000050004em;">∑</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.981231em;"><span style="top:-2.40029em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.2029em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em;">M</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.29971000000000003em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07153em;">C</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.7935559999999999em;"><span style="top:-2.4168920000000003em;margin-left:-0.07153em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span><span class="mord mathnormal mtight">p</span><span class="mord mathnormal mtight">s</span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.4192159999999999em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span>.<br /><img src="/imgs/Sys4ai/Elf/partition.png" width="50%"></li></ol><h3 id="how-do-we-estimate-server-capacity-and-rp-computation-cost"><a class="markdownIt-Anchor" href="#how-do-we-estimate-server-capacity-and-rp-computation-cost"></a> How do we estimate server capacity and RP computation cost?</h3><ol><li>There are two approaches to estimate server capacity.<ul><li>The first approach is through passive profiling.<ul><li>It calculates server m’s average end-to-end latency <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>T</mi><mi>m</mi></msub></mrow><annotation encoding="application/x-tex">T_m</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">m</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> over the last <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi></mrow><annotation encoding="application/x-tex">n</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathnormal">n</span></span></span></span> (default value of <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>7</mn></mrow><annotation encoding="application/x-tex">7</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">7</span></span></span></span>) offloading requests that are served by <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>m</mi></mrow><annotation encoding="application/x-tex">m</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathnormal">m</span></span></span></span>. Then the resource capacity is defined as <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1</mn><mi mathvariant="normal">/</mi><msub><mi>T</mi><mi>m</mi></msub></mrow><annotation encoding="application/x-tex">1/T_m</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord">1</span><span class="mord">/</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">m</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>.</li><li>This passive profiling can help evaluate the trade-off between computing and network resources.</li></ul></li><li>The second approach is through proactive profiling: Elf periodically queries the server for its GPU utilization.</li></ul></li><li>There also are two ways of estimating an RP’s computation cost.<ul><li>The first approach is based on the RP’s area, assuming the cost is linearly proportional to the RP area.</li><li>The second approach is through Spatially Adaptive Computation Time (SACT). Elf can accordingly estimate the cost of an RP at the pixel level.<ul><li>SACT is an optimization that early stops partial convolutional operations by evaluating the confidence upon the outputs of intermediate layers.</li><li>SACT indicates how much computation has been applied with each pixel of a raw frame input.</li></ul></li></ul></li></ol><h1 id="evaluation"><a class="markdownIt-Anchor" href="#evaluation"></a> Evaluation</h1><ol><li>The author measured the latency of Elf using different number of servers.<ul><li>The latency with different server numbers highly depends on the size of the RP boxes shipped to each edge server.</li><li>The inference time shows distinct sensitivity among different deep vision models.<ul><li>The models with more, even fully, convolutional operations present a stronger correlation between frame resolution and inference latency.</li><li>Two-stage models usually generate the same number of Regions of Interest (ROI) independent of the input resolution and then ship each of them down the pipeline. The second stage thus costs the same time.</li><li>Two-stage models can dynamically adjust the number of ROI based on the frame resolution as a higher resolution input potentially involves more objects.<br /><img src="/imgs/Sys4ai/Elf/server_num.png" width="15%"></li></ul></li></ul></li><li>The cost at each processing part:<ul><li>At the server end, the GPU utilization v.s. GPU numbers is measured.<ul><li>On average, Elf-3 only consumes <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1.7</mn><mo>×</mo></mrow><annotation encoding="application/x-tex">1.7\times</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.72777em;vertical-align:-0.08333em;"></span><span class="mord">1</span><span class="mord">.</span><span class="mord">7</span><span class="mord">×</span></span></span></span> GPU utilization in total running with <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>3</mn></mrow><annotation encoding="application/x-tex">3</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">3</span></span></span></span> GPUs, than <em>SO</em> to finish a single request.</li><li>A lower per GPU utilization allows Elf to have more chance to efficiently utilize those resource fragmentation and thus improve the total GPU utilization of edge servers.<br /><img src="/imgs/Sys4ai/Elf/GPUutilization.png" width="15%"></li></ul></li><li>At the communication side, they measured the latency under different network condition.<ul><li>Elf is less sensitive to the network bandwidth because it offloads much less data than SO.<br /><img src="/imgs/Sys4ai/Elf/network.png" width="15%"></li></ul></li><li>At the mobile end, they measured the overhead of Elf.<ul><li>RP prediction costs 70%+ of the total time as the attention LSTM model is implemented in Python and exported to C++ with TorchScript. It can be improved by rewrite the prediction model with TensorRT.<br /><img src="/imgs/Sys4ai/Elf/overhead.png" width="15%"></li></ul></li></ul></li><li>The inference accuracy and offload ratio of using attention based LSTM against vanilla LSTM the fast tracker showed the effectiveness of attention based LSTM.</li><li>The impact of hyperparameters, e.g. LRC parameter and RP expansion ratio, is measured.</li></ol>]]></content>
      
      
      <categories>
          
          <category> Paper Notebook </category>
          
          <category> Sys4AI </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Sys4AI </tag>
            
            <tag> Deployment </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>SiloD</title>
      <link href="/2023/09/27/Paper/Sys4AI/SiloD/"/>
      <url>/2023/09/27/Paper/Sys4AI/SiloD/</url>
      
        <content type="html"><![CDATA[<p>Paper: <a href="https://dl.acm.org/doi/abs/10.1145/3552326.3567499">SiloD: A Co-design of Caching and Scheduling for Deep Learning Clusters</a></p><p><ul class="markdownIt-TOC"><li><a href="#background">Background</a><ul><li><a href="#how-to-separate-storage-and-computing-in-dl-training">How to separate storage and computing in DL training?</a></li><li><a href="#how-to-levarage-cache-subsystem-for-dl-training">How to levarage cache subsystem for DL training?</a></li><li><a href="#how-to-cache-data-for-dl-training">How to cache data for DL training?</a></li><li><a href="#what-is-the-problem-of-static-allocation">What is the problem of static allocation?</a></li></ul></li><li><a href="#purpose">Purpose</a></li><li><a href="#model">Model</a><ul><li><a href="#what-does-silod-do">What does SiloD do?</a></li><li><a href="#how-does-silod-estimate-performance">How does SiloD estimate performance?</a></li><li><a href="#how-to-integrate-silod-with-existing-scheduler">How to integrate SiloD with existing scheduler?</a></li><li><a href="#how-to-use-silod-without-modifying-existing-scheduler">How to use SiloD without modifying existing scheduler?</a></li><li><a href="#how-does-silod-allocate-resources">How does SiloD allocate resources?</a></li><li><a href="#how-to-handle-delayed-data-access-and-irregular-data-access">How to handle delayed data access and irregular data access?</a></li><li><a href="#how-does-silod-support-fault-tolerance">How does SiloD support fault tolerance?</a></li></ul></li><li><a href="#evaluation">Evaluation</a></li></ul></p><h1 id="background"><a class="markdownIt-Anchor" href="#background"></a> Background</h1><h2 id="how-to-separate-storage-and-computing-in-dl-training"><a class="markdownIt-Anchor" href="#how-to-separate-storage-and-computing-in-dl-training"></a> How to separate storage and computing in DL training?</h2><ol><li>Separate storage and computing. The training executes on a compute cluster equipped with GPUs/TPUs while reading data from a separate cluster hosting the storage service.</li><li>When submitting a DL job, users can simply specify the storage account and the location of the desired dataset, and the job can directly load the data through remote IO.</li><li>The remote IO between compute and storage services could become a bottleneck. The worst case is to read the entire training dataset remotely in each epoch.</li><li>The data access pattern and the computation pattern, despite being highly diverse for different training jobs, are both highly stable and predictable within each individual job.</li></ol><h2 id="how-to-levarage-cache-subsystem-for-dl-training"><a class="markdownIt-Anchor" href="#how-to-levarage-cache-subsystem-for-dl-training"></a> How to levarage cache subsystem for DL training?</h2><ol><li>Leverage local disks of GPU servers, instead of the small cache memory in traditional systems, to cache a subset of data to reduce the demands to remote IO.</li><li>The first type of cache subsystem is built into a data loading library.<ul><li>The cache is built with the processes of a training job, and is statically allocated.</li><li>DL training jobs have diverse demands on cache and remote IO. Isolated cache with a static allocation can neither satisfy nor exploit such diversity.</li></ul></li><li>The second type of cache subsystem is distributed cache which consolidates the local storage of all cluster servers into a large storage pool shared by all jobs.<ul><li>Modern GPU cluster usually has a high-speed storage fabric (separate from the InfiniBand network used for distributed training) that supports accessing data from peer servers as fast as local disk.</li><li>A distributed cache across the local cluster can generally satisfy the IO demands of training jobs.</li></ul></li></ol><h2 id="how-to-cache-data-for-dl-training"><a class="markdownIt-Anchor" href="#how-to-cache-data-for-dl-training"></a> How to cache data for DL training?</h2><ol><li><p>Due to the random-and-exactly-once data access pattern, it has been shown that uniform caching is optimal for single training job.</p></li><li><p>In uniform caching, accessed data items are cached until the cache capacity is reached, and will not be evicted thereafter. There is no eviction unless the cache capacity is reduced.</p><ul><li>Other cache eviction policies like LRU (Least-Recently-Used) may evict useful items, leading to the thrashing issue.</li><li>In uniform caching, part of the dataset is staying at the local disk permanently and can be used in each epoch.</li><li>LRU will only reserve data used recently while they won’t be used in near future.</li></ul></li><li><p>It is noteworthy that the cached data are evenly distributed in each batch, instead of cache some batches entirely.</p><ul><li>Each data item has a unique ID. The missed data items are fetched from the remote storage. Because each epoch shuffles the data loading order, the expected cache hit ratio is uniform for all items.</li><li>In this way, we can improve the performance of the pipeline of data loading.</li></ul></li><li><p>For deep learning training, uniform caching leads to a constant and predictable cache hit ratio w.r.t. the cache capacity regardless of which items being cached.</p><img src="/imgs/Sys4ai/SiloD/cache.png" width="50%"></li></ol><h2 id="what-is-the-problem-of-static-allocation"><a class="markdownIt-Anchor" href="#what-is-the-problem-of-static-allocation"></a> What is the problem of static allocation?</h2><ol><li>When there are multiple jobs in a cluster, uniform caching transforms the cache management from cache eviction problem to a cache space allocation problem.</li><li>The job’s cache efficiency as the amount of remote IO (in MB/s) saved per GB of cache allocated.</li><li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>𝑓</mi><mo>∗</mo></msup></mrow><annotation encoding="application/x-tex">𝑓^\ast</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.688696em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mbin mtight">∗</span></span></span></span></span></span></span></span></span></span></span> and <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>d</mi></mrow><annotation encoding="application/x-tex">d</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathnormal">d</span></span></span></span> are the IO demand to achieve the ideal training speed and the dataset size, respectively. A job’s cache efficiency is <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><msup><mi>𝑓</mi><mo>∗</mo></msup><mi>d</mi></mfrac></mrow><annotation encoding="application/x-tex">\frac{𝑓^\ast}{d}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.325448em;vertical-align:-0.345em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.980448em;"><span style="top:-2.6550000000000002em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">d</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.446108em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.10764em;">f</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.7633428571428571em;"><span style="top:-2.931em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mbin mtight">∗</span></span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.345em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span>.</li><li>The cache efficiency of different dataset can varies largely. A static cache allocation could not take advantage of the diverse cache-efficiency of DL jobs.</li></ol><h1 id="purpose"><a class="markdownIt-Anchor" href="#purpose"></a> Purpose</h1><ol><li>Issue:<ul><li>Existing deep learning schedulers do not manage storage resources thus fail to consider the diverse caching effects across different training jobs.</li><li>State-of-the-art deep learning schedulers focus on arbitrating compute resources (e.g., GPUs and CPUs) with different optimization objectives like job completion time (JCT), fairness, or cluster utilization.</li></ul></li><li>Challenge:<ul><li>Deep learning schedulers have diverse scheduling objectives. An ad-hoc solution to every scheduling policy increases design complexity and is hard to scale.</li><li>Deep learning training exhibits highly diverse performance patterns: different jobs impose different cache and IO demands. This further complicates the system design.</li><li>Even deep learning-aware cache systems could exhibit poor performance because of caching policies that ignore scheduling impacts.</li></ul></li><li>Contribution:<ul><li>Co-design the cluster scheduler and the cache subsystems for deep learning training.</li><li>The job performance estimator is enhanced.<ul><li>To help different schedulers to jointly consider the impact of storage and compute resource allocation while preserving their respective scheduling objectives.</li><li>SiloD derives a unified way of performance estimation by further leveraging the pipelined execution of data loading and computation.</li><li>SiloD is able to augment different state-of-the-art deep learning schedulers to jointly perform cache and remote IO allocation while preserving the original objectives of these scheduling policies.</li></ul></li></ul></li></ol><h1 id="model"><a class="markdownIt-Anchor" href="#model"></a> Model</h1><h2 id="what-does-silod-do"><a class="markdownIt-Anchor" href="#what-does-silod-do"></a> What does SiloD do?</h2><ol><li>SiloD allocates compute and cache-related resources jointly to training jobs. SiloD treats cache and remote IO as first-class citizens.<ul><li>Existing multi-resource schedulers can just treat storage resources as yet another resource types whose impact has already been captured by the performance estimator</li></ul></li><li>The scheduling problem can be generally abstracted as allocating cluster resources defined in <code>totalResource</code> to jobs with the help of a performance estimator <code>perf(j, R)</code>.</li><li>SiloD further enhances the estimator <code>perf</code> with <code>SiloDPerf</code> to estimate the joint impact of compute and storage resources.<ul><li>The SiloD-augmented performance estimator transforms a joint performance estimation into a two-step process.</li><li>It first estimates whether data loading will become the bottleneck of the entire training.</li><li>If so, SiloD will use <code>IOPerf</code>, a performance estimator we introduce to analyze the impact of storage to estimate the job performance under IO bottleneck.</li></ul></li></ol><h2 id="how-does-silod-estimate-performance"><a class="markdownIt-Anchor" href="#how-does-silod-estimate-performance"></a> How does SiloD estimate performance?</h2><ol><li>The end-to-end throughput is then determined by the bottleneck stage, i.e. <code>SiloDPerf</code><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>=</mo><mi>m</mi><mi>i</mi><mi>n</mi><mo stretchy="false">{</mo><msup><mi>f</mi><mo>∗</mo></msup><mo separator="true">,</mo><mi>f</mi><mo stretchy="false">}</mo></mrow><annotation encoding="application/x-tex">=min\{f^\ast,f\}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.36687em;vertical-align:0em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">m</span><span class="mord mathnormal">i</span><span class="mord mathnormal">n</span><span class="mopen">{</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.688696em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mbin mtight">∗</span></span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="mclose">}</span></span></span></span>.<ul><li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>f</mi><mo>∗</mo></msup></mrow><annotation encoding="application/x-tex">f^\ast</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.688696em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mbin mtight">∗</span></span></span></span></span></span></span></span></span></span></span> is a job’s computation throughput when IO is not the bottleneck, i.e., <code>perf</code>, which is the original estimator used by an existing scheduler.</li><li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>f</mi></mrow><annotation encoding="application/x-tex">f</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord mathnormal" style="margin-right:0.10764em;">f</span></span></span></span> is the throughput of data loading, i.e., <code>IOPerf</code>, which is the estimator for IO given some cache allocation.</li></ul></li><li>A job’s remote IO demand can be calculated as <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>b</mi><mo>=</mo><mi>f</mi><mo>⋅</mo><mo stretchy="false">(</mo><mn>1</mn><mo>−</mo><mfrac><mi>c</mi><mi>d</mi></mfrac><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">b=f\cdot (1-\frac{c}{d})</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathnormal">b</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord">1</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1.095em;vertical-align:-0.345em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.695392em;"><span style="top:-2.6550000000000002em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">d</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">c</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.345em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mclose">)</span></span></span></span>.<ul><li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>𝑐</mi></mrow><annotation encoding="application/x-tex">𝑐</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathnormal">c</span></span></span></span> is the allocated cache space and <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>𝑑</mi></mrow><annotation encoding="application/x-tex">𝑑</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathnormal">d</span></span></span></span> the size of the training dataset. The expected cache hit ratio of a job is <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mi>c</mi><mi>d</mi></mfrac></mrow><annotation encoding="application/x-tex">\frac{c}{d}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.040392em;vertical-align:-0.345em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.695392em;"><span style="top:-2.6550000000000002em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">d</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">c</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.345em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span>.</li><li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>𝑏</mi></mrow><annotation encoding="application/x-tex">𝑏</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathnormal">b</span></span></span></span> is the remote IO demand of a job, which equals to the data loading throughput multiplied by the cache miss ratio.</li></ul></li><li>A job’s IO throughput 𝑓 (i.e., <code>IOPerf</code>) can be estimated by <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>f</mi><mo>=</mo><mfrac><mi>b</mi><mrow><mn>1</mn><mo>−</mo><mi>c</mi><mi mathvariant="normal">/</mi><mi>d</mi></mrow></mfrac></mrow><annotation encoding="application/x-tex">f=\frac{b}{1-c/d}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.400108em;vertical-align:-0.52em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8801079999999999em;"><span style="top:-2.655em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span><span class="mbin mtight">−</span><span class="mord mathnormal mtight">c</span><span class="mord mtight">/</span><span class="mord mathnormal mtight">d</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">b</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.52em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span>.</li><li>When a job is fetching data at its ideal throughput (i.e., <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>f</mi><mo>=</mo><msup><mi>f</mi><mo>∗</mo></msup></mrow><annotation encoding="application/x-tex">f = f^\ast</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.688696em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mbin mtight">∗</span></span></span></span></span></span></span></span></span></span></span>), its cache efficiency is exactly the negative derivative of <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>b</mi></mrow><annotation encoding="application/x-tex">b</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathnormal">b</span></span></span></span>, i.e. Cache Efficiency<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>=</mo><mo>−</mo><mfrac><mrow><mi mathvariant="normal">∂</mi><mi>b</mi></mrow><mrow><mi mathvariant="normal">∂</mi><mi>c</mi></mrow></mfrac><mo>=</mo><mfrac><msup><mi>f</mi><mo>∗</mo></msup><mi>d</mi></mfrac></mrow><annotation encoding="application/x-tex">=-\frac{\partial b}{\partial c}=\frac{f^\ast}{d}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.36687em;vertical-align:0em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.2251079999999999em;vertical-align:-0.345em;"></span><span class="mord">−</span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8801079999999999em;"><span style="top:-2.6550000000000002em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight" style="margin-right:0.05556em;">∂</span><span class="mord mathnormal mtight">c</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight" style="margin-right:0.05556em;">∂</span><span class="mord mathnormal mtight">b</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.345em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.325448em;vertical-align:-0.345em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.980448em;"><span style="top:-2.6550000000000002em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">d</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.446108em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.10764em;">f</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.7633428571428571em;"><span style="top:-2.931em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mbin mtight">∗</span></span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.345em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span>.<ul><li>The different computation throughput <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>f</mi><mo>∗</mo></msup></mrow><annotation encoding="application/x-tex">f^\ast</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.688696em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mbin mtight">∗</span></span></span></span></span></span></span></span></span></span></span> of different neural model and dataset size <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>d</mi></mrow><annotation encoding="application/x-tex">d</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathnormal">d</span></span></span></span> is the sources of the heterogeneity.</li></ul></li><li>The policy assumes the ideal throughput of a job <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>𝑓</mi><mo>∗</mo></msup></mrow><annotation encoding="application/x-tex">𝑓^\ast</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.688696em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mbin mtight">∗</span></span></span></span></span></span></span></span></span></span></span> (when IO is not a bottleneck) can be profiled offline.</li></ol><h2 id="how-to-integrate-silod-with-existing-scheduler"><a class="markdownIt-Anchor" href="#how-to-integrate-silod-with-existing-scheduler"></a> How to integrate SiloD with existing scheduler?</h2><ol><li>In Shortest Job First (SJF), each job will have a performance score defined as its weighted sum of resource demand of all resource types multiplied by its duration.<ul><li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>s</mi><mi>c</mi><mi>o</mi><mi>r</mi><mi>e</mi><mo>=</mo><mstyle scriptlevel="0" displaystyle="true"><munder><mo><mi>min</mi><mo>⁡</mo></mo><mi>R</mi></munder><munder><mo>∑</mo><mi>t</mi></munder><msub><mi>w</mi><mi>t</mi></msub><mo>⋅</mo><msub><mi>R</mi><mi>t</mi></msub><mo>⋅</mo><mo stretchy="false">(</mo><mfrac><mrow><mi>j</mi><mi mathvariant="normal">.</mi><mi>n</mi><mi>u</mi><mi>m</mi><mi>S</mi><mi>t</mi><mi>e</mi><mi>p</mi><mi>s</mi><mo>⋅</mo><mi>j</mi><mi mathvariant="normal">.</mi><mi>s</mi><mi>t</mi><mi>e</mi><mi>p</mi><mi>D</mi><mi>a</mi><mi>t</mi><mi>a</mi><mi>S</mi><mi>i</mi><mi>z</mi><mi>e</mi></mrow><mrow><mi>p</mi><mi>e</mi><mi>r</mi><mi>f</mi><mo stretchy="false">(</mo><mi>j</mi><mo separator="true">,</mo><mi mathvariant="bold">R</mi><mo stretchy="false">)</mo></mrow></mfrac><mo stretchy="false">)</mo></mstyle></mrow><annotation encoding="application/x-tex">score=\displaystyle\min_{R}\sum_{t}w_t\cdot R_t\cdot (\frac{j.numSteps\cdot j.stepDataSize}{perf(j,\bold{R})})</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathnormal">s</span><span class="mord mathnormal">c</span><span class="mord mathnormal">o</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mord mathnormal">e</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:2.3000100000000003em;vertical-align:-1.250005em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.66786em;"><span style="top:-2.355669em;margin-left:0em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.00773em;">R</span></span></span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span><span class="mop">min</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.744331em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.050005em;"><span style="top:-1.8999949999999999em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span style="top:-3.0500049999999996em;"><span class="pstrut" style="height:3.05em;"></span><span><span class="mop op-symbol large-op">∑</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.250005em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02691em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2805559999999999em;"><span style="top:-2.5500000000000003em;margin-left:-0.02691em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2805559999999999em;"><span style="top:-2.5500000000000003em;margin-left:-0.00773em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:2.2963299999999998em;vertical-align:-0.936em;"></span><span class="mopen">(</span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.3603299999999998em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathnormal">p</span><span class="mord mathnormal">e</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.05724em;">j</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathbf">R</span></span><span class="mclose">)</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05724em;">j</span><span class="mord">.</span><span class="mord mathnormal">n</span><span class="mord mathnormal">u</span><span class="mord mathnormal">m</span><span class="mord mathnormal" style="margin-right:0.05764em;">S</span><span class="mord mathnormal">t</span><span class="mord mathnormal">e</span><span class="mord mathnormal">p</span><span class="mord mathnormal">s</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mord mathnormal" style="margin-right:0.05724em;">j</span><span class="mord">.</span><span class="mord mathnormal">s</span><span class="mord mathnormal">t</span><span class="mord mathnormal">e</span><span class="mord mathnormal">p</span><span class="mord mathnormal" style="margin-right:0.02778em;">D</span><span class="mord mathnormal">a</span><span class="mord mathnormal">t</span><span class="mord mathnormal">a</span><span class="mord mathnormal" style="margin-right:0.05764em;">S</span><span class="mord mathnormal">i</span><span class="mord mathnormal" style="margin-right:0.04398em;">z</span><span class="mord mathnormal">e</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.936em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mclose">)</span></span></span></span></li><li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>w</mi><mi>t</mi></msub></mrow><annotation encoding="application/x-tex">w_t</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02691em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2805559999999999em;"><span style="top:-2.5500000000000003em;margin-left:-0.02691em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> is the weight of the <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>t</mi></mrow><annotation encoding="application/x-tex">t</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.61508em;vertical-align:0em;"></span><span class="mord mathnormal">t</span></span></span></span>-th resource type, <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="bold">R</mi></mrow><annotation encoding="application/x-tex">\bold{R}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68611em;vertical-align:0em;"></span><span class="mord"><span class="mord mathbf">R</span></span></span></span></span> is a vector of allocation of all resource types, and <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>R</mi><mi>t</mi></msub></mrow><annotation encoding="application/x-tex">R_{t}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2805559999999999em;"><span style="top:-2.5500000000000003em;margin-left:-0.00773em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> is the allocation of the <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>t</mi></mrow><annotation encoding="application/x-tex">t</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.61508em;vertical-align:0em;"></span><span class="mord mathnormal">t</span></span></span></span>-th resource type in <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="bold">R</mi></mrow><annotation encoding="application/x-tex">\bold{R}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68611em;vertical-align:0em;"></span><span class="mord"><span class="mord mathbf">R</span></span></span></span></span>, <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>𝑗</mi><mi mathvariant="normal">.</mi><mi>n</mi><mi>u</mi><mi>m</mi><mi>S</mi><mi>t</mi><mi>e</mi><mi>p</mi><mi>s</mi></mrow><annotation encoding="application/x-tex">𝑗.numSteps</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8777699999999999em;vertical-align:-0.19444em;"></span><span class="mord mathnormal" style="margin-right:0.05724em;">j</span><span class="mord">.</span><span class="mord mathnormal">n</span><span class="mord mathnormal">u</span><span class="mord mathnormal">m</span><span class="mord mathnormal" style="margin-right:0.05764em;">S</span><span class="mord mathnormal">t</span><span class="mord mathnormal">e</span><span class="mord mathnormal">p</span><span class="mord mathnormal">s</span></span></span></span> is the total number of steps and <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>𝑗</mi><mi mathvariant="normal">.</mi><mi>s</mi><mi>t</mi><mi>e</mi><mi>p</mi><mi>D</mi><mi>a</mi><mi>t</mi><mi>a</mi><mi>S</mi><mi>i</mi><mi>z</mi><mi>e</mi></mrow><annotation encoding="application/x-tex">𝑗.stepDataSize</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8777699999999999em;vertical-align:-0.19444em;"></span><span class="mord mathnormal" style="margin-right:0.05724em;">j</span><span class="mord">.</span><span class="mord mathnormal">s</span><span class="mord mathnormal">t</span><span class="mord mathnormal">e</span><span class="mord mathnormal">p</span><span class="mord mathnormal" style="margin-right:0.02778em;">D</span><span class="mord mathnormal">a</span><span class="mord mathnormal">t</span><span class="mord mathnormal">a</span><span class="mord mathnormal" style="margin-right:0.05764em;">S</span><span class="mord mathnormal">i</span><span class="mord mathnormal" style="margin-right:0.04398em;">z</span><span class="mord mathnormal">e</span></span></span></span> is the size of data consumed per step of job <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>j</mi></mrow><annotation encoding="application/x-tex">j</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.85396em;vertical-align:-0.19444em;"></span><span class="mord mathnormal" style="margin-right:0.05724em;">j</span></span></span></span>.</li><li>The jobs with the least score will be scheduled first by the multi-resource SJF policy.</li></ul></li><li>The vanilla programming in Gavel’s max-min fairness is <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mstyle scriptlevel="0" displaystyle="true"><munder><mo><mi>max</mi><mo>⁡</mo></mo><mi>R</mi></munder><munder><mo><mi>min</mi><mo>⁡</mo></mo><mi>j</mi></munder><mfrac><mrow><mi>p</mi><mi>e</mi><mi>r</mi><mi>f</mi><mo stretchy="false">(</mo><mi>j</mi><mo separator="true">,</mo><mi>R</mi><mo stretchy="false">[</mo><mi>j</mi><mo stretchy="false">]</mo><mo stretchy="false">)</mo></mrow><mrow><mi>p</mi><mi>e</mi><mi>r</mi><mi>f</mi><mo stretchy="false">(</mo><mi>j</mi><mo separator="true">,</mo><msup><mi>R</mi><mrow><mi>e</mi><mi>q</mi><mi>u</mi><mi>a</mi><mi>l</mi></mrow></msup><mo stretchy="false">)</mo></mrow></mfrac><mo separator="true">,</mo><mi>s</mi><mi mathvariant="normal">.</mi><mi>t</mi><mi mathvariant="normal">.</mi><mi>S</mi><mi>u</mi><mi>m</mi><mo stretchy="false">(</mo><mi>R</mi><mo stretchy="false">)</mo><mo>≤</mo><mi>t</mi><mi>o</mi><mi>t</mi><mi>a</mi><mi>l</mi><mi>R</mi><mi>e</mi><mi>s</mi><mi>o</mi><mi>u</mi><mi>r</mi><mi>c</mi><mi>e</mi></mstyle></mrow><annotation encoding="application/x-tex">\displaystyle\max_{R}\min_{j}\frac{perf(j,R[j])}{perf(j,R^{equal})},s.t. Sum(R)≤totalResource</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:2.363em;vertical-align:-0.936em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.43055999999999983em;"><span style="top:-2.355669em;margin-left:0em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.00773em;">R</span></span></span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span><span class="mop">max</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.7443310000000001em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.66786em;"><span style="top:-2.3723360000000002em;margin-left:0em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span><span class="mop">min</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.863772em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.427em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathnormal">p</span><span class="mord mathnormal">e</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.05724em;">j</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.7751079999999999em;"><span style="top:-2.9890000000000003em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">e</span><span class="mord mathnormal mtight" style="margin-right:0.03588em;">q</span><span class="mord mathnormal mtight">u</span><span class="mord mathnormal mtight">a</span><span class="mord mathnormal mtight" style="margin-right:0.01968em;">l</span></span></span></span></span></span></span></span></span><span class="mclose">)</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathnormal">p</span><span class="mord mathnormal">e</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.05724em;">j</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="mopen">[</span><span class="mord mathnormal" style="margin-right:0.05724em;">j</span><span class="mclose">]</span><span class="mclose">)</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.936em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal">s</span><span class="mord">.</span><span class="mord mathnormal">t</span><span class="mord">.</span><span class="mord mathnormal" style="margin-right:0.05764em;">S</span><span class="mord mathnormal">u</span><span class="mord mathnormal">m</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">≤</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathnormal">t</span><span class="mord mathnormal">o</span><span class="mord mathnormal">t</span><span class="mord mathnormal">a</span><span class="mord mathnormal" style="margin-right:0.01968em;">l</span><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="mord mathnormal">e</span><span class="mord mathnormal">s</span><span class="mord mathnormal">o</span><span class="mord mathnormal">u</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mord mathnormal">c</span><span class="mord mathnormal">e</span></span></span></span>.<ul><li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>𝑅</mi><mo stretchy="false">[</mo><mi>𝑗</mi><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">𝑅[𝑗]</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="mopen">[</span><span class="mord mathnormal" style="margin-right:0.05724em;">j</span><span class="mclose">]</span></span></span></span> is the resource allocated to job <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>j</mi></mrow><annotation encoding="application/x-tex">j</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.85396em;vertical-align:-0.19444em;"></span><span class="mord mathnormal" style="margin-right:0.05724em;">j</span></span></span></span> and <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>R</mi><mrow><mi>e</mi><mi>q</mi><mi>u</mi><mi>a</mi><mi>l</mi></mrow></msup></mrow><annotation encoding="application/x-tex">R^{equal}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8491079999999999em;vertical-align:0em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8491079999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">e</span><span class="mord mathnormal mtight" style="margin-right:0.03588em;">q</span><span class="mord mathnormal mtight">u</span><span class="mord mathnormal mtight">a</span><span class="mord mathnormal mtight" style="margin-right:0.01968em;">l</span></span></span></span></span></span></span></span></span></span></span></span> is the equal resource division among all jobs.</li><li>The max-min fairness objective maximizes the job with the least performance improvement over the equal resource division.</li></ul></li><li>When intergrate SiloD, <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="bold">R</mi></mrow><annotation encoding="application/x-tex">\bold{R}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68611em;vertical-align:0em;"></span><span class="mord"><span class="mord mathbf">R</span></span></span></span></span> includes cache and remote IO as another two types of resources in addition to compute resources and the performance estimator function <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi><mi>e</mi><mi>r</mi><mi>f</mi><mo stretchy="false">(</mo><mi>j</mi><mo separator="true">,</mo><mi mathvariant="bold">R</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">perf(j,\bold{R})</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">p</span><span class="mord mathnormal">e</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.05724em;">j</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathbf">R</span></span><span class="mclose">)</span></span></span></span> is replaced by <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>S</mi><mi>i</mi><mi>l</mi><mi>o</mi><mi>D</mi><mi>P</mi><mi>e</mi><mi>r</mi><mi>f</mi><mo stretchy="false">(</mo><mi>j</mi><mo separator="true">,</mo><mi mathvariant="bold">R</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">SiloDPerf(j,\bold{R})</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.05764em;">S</span><span class="mord mathnormal">i</span><span class="mord mathnormal" style="margin-right:0.01968em;">l</span><span class="mord mathnormal">o</span><span class="mord mathnormal" style="margin-right:0.02778em;">D</span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="mord mathnormal">e</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.05724em;">j</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathbf">R</span></span><span class="mclose">)</span></span></span></span>.</li></ol><h2 id="how-to-use-silod-without-modifying-existing-scheduler"><a class="markdownIt-Anchor" href="#how-to-use-silod-without-modifying-existing-scheduler"></a> How to use SiloD without modifying existing scheduler?</h2><ol><li>The greedy policy minimizes the remote IO consumption in a best-effort manner so that the impact of IO to original scheduling objectives can be minimized.</li><li>It can be done by allocating more cache to the most cache-efficient jobs.</li><li>Each job first calculates its cache efficiency. The datasets with the highest cache efficiency are first cached until the cache space is full.<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> job j <span class="keyword">in</span> <span class="keyword">all</span> jobs do</span><br><span class="line">  j.CacheEfficiency <span class="operator">=</span> j.fStar <span class="operator">/</span> j.datasetSize</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> job j <span class="keyword">in</span> descending <span class="keyword">order</span> <span class="keyword">of</span> j.CacheEfficiency do</span><br><span class="line">  alloc.Cache[j] <span class="operator">=</span> <span class="built_in">min</span>(j.datasetSize, totalCache)</span><br><span class="line">  totalCache <span class="operator">-</span><span class="operator">=</span> alloc.Cache[j]</span><br><span class="line"> </span><br><span class="line"><span class="keyword">return</span> alloc</span><br></pre></td></tr></table></figure></li></ol><h2 id="how-does-silod-allocate-resources"><a class="markdownIt-Anchor" href="#how-does-silod-allocate-resources"></a> How does SiloD allocate resources?</h2><ol><li>SiloD Data Manager serves in the storage layer to enforce the allocations made by the scheduler.<ul><li>A cluster scheduler uses the interface to allocate cache and remote IO to two types of entities: jobs and datasets.<ul><li>Remote IO is allocated to jobs directly, while cache is allocated to datasets, and to the associated jobs indirectly.</li><li>Multiple jobs can transparently share the same cache space for the same dataset. In contrast, since jobs using the same dataset still read data items in different order, remote IO is exclusive to each job.</li><li>The cache consumption is charged by only once for each dataset instead for every jobs. The cache efficiency is defined at dataset-level, which is the sum of all jobs’ cache efficiency using the same dataset.</li><li>For distributed data-parallel training, the remote IO allocation is equally distributed to each worker of the job.</li></ul></li><li>SiloD data manager sets up FUSE (Filesystem in USErspace) clients co-located with training tasks to manage the cache, throttling remote IO and maintaining the metadata of datasets on each server.</li></ul></li><li>SiloD Scheduler extends the responsibility of the compute-only resource scheduler from job scheduling to compute-storage joint allocation.<br /><img src="/imgs/Sys4ai/SiloD/structure.png" width="50%"></li></ol><h2 id="how-to-handle-delayed-data-access-and-irregular-data-access"><a class="markdownIt-Anchor" href="#how-to-handle-delayed-data-access-and-irregular-data-access"></a> How to handle delayed data access and irregular data access?</h2><ol><li>Since DL training reads each data item exactly once per epoch, any newly cached data items will never be accessed again until the next epoch.<ul><li>Even though the newly cached item consumes the cache space, but it does not help to reduce the remote IO until the next epoch. Therefore, accurate estimation of job performance should use the effective cache size.</li><li>However, since multiple jobs may use the same dataset, it is unknown beforehand if a newly cached item by one job is effective or not for other jobs.</li><li>The delayed effectiveness only has a limited impact that lasts for at most one epoch for newly cached items. A DL job usually trains a model for tens of epochs, thus for most of the time, the cached data are effective.</li><li>SiloD also supports fine-grained management for policies to inspect the effective cache size and the instantaneous remote IO demand, by maintaining a bitset for each job to track its accessed items.</li></ul></li><li>When a cluster is mixed by regular jobs satisfying SiloD’s assumptions and irregular jobs, we partition the cache and remote IO into two parts for all regular jobs and irregular jobs, respectively.<ul><li>Allocate resources to the regular jobs in the first partition still using <code>SiloDPerf</code>.</li><li>The irregular jobs in the second partition fall back to the original scheduling policy and estimator, and share the cache and remote IO within the partition.</li><li>In this way, the regular DL jobs can still benefit from exploiting the heterogeneous cache efficiency without being impacted by potential anomalies due to mis-estimation of irregular jobs.</li></ul></li></ol><h2 id="how-does-silod-support-fault-tolerance"><a class="markdownIt-Anchor" href="#how-does-silod-support-fault-tolerance"></a> How does SiloD support fault tolerance?</h2><ol><li>The allocation of remote IO and cache is stored in “pod annotation” for the pods of each job, which is kept reliably by Kubernetes.</li><li>For the job with multiple pods, the remote IO allocation is proportionally divided to each pod and the cache allocation is same for all pods.</li><li>When SiloD Data Manager recovers from crashes, it reconstructs the status by collecting the information from pods.</li><li>The cache content on each server is stored on local disk thus can be reliably restored when the server restarts.</li><li>SiloD does not add stateful information into the cluster scheduler, thus their fault tolerance is handled by their original approach.</li></ol><h1 id="evaluation"><a class="markdownIt-Anchor" href="#evaluation"></a> Evaluation</h1><ol><li>First, the author showed the evidence of the issues:<ul><li><p>They presented the increasing of dataset size and the GPU performance as the indirect evidence of remote IO bottleneck.<br /><img src="/imgs/Sys4ai/SiloD/indirect.png" width="50%"></p></li><li><p>Then the required remote IO to reach the optimal speed for GPU is calculated and the GPU cluster’s aggregate IO demand is profiled to prove that remote IO without cache is slowing down the training prosedure.<br /><img src="/imgs/Sys4ai/SiloD/optimal.png" width="25%"><br /><img src="/imgs/Sys4ai/SiloD/demand.png" width="25%"></p></li><li><p>When discussing design for cache subsystem, the author also provided the sub-optimal evidence of current scheduler without knowing the cache subsystem.<br /><img src="/imgs/Sys4ai/SiloD/quiver.png" width="50%"></p></li></ul></li><li>When further exploring the cache efficiency, the author showed the variance between difference datasets and effective cache size.<br /><img src="/imgs/Sys4ai/SiloD/variance.png" width="35%" /> <img src="/imgs/Sys4ai/SiloD/effective.png" width="35%" /></li><li>To evaluate SiloD in a large-scale cluster of fast V100 GPUs with a lower cost, the authors design an approach to accelerating the training on a K80 GPU cluster to investigate the data loading performance of running the same trace in a V100 GPU cluster.<ul><li>In the experiment, they first profile the training speed of selected models on real V100 GPUs.</li><li>Then, execute the same model on K80 GPUs by processing the same training pipeline of data loading, preprocessing and model aggregation, but replacing the model execution (forward pass and backward pass) with “<code>sleep()</code>” for the profiled duration from V100.</li><li>Since deep learning training usually has a very stable mini-batch duration, the IO behaviour in accelerated K80 GPUs is almost the same as real training of V100 GPUs.</li></ul></li></ol>]]></content>
      
      
      <categories>
          
          <category> Paper Notebook </category>
          
          <category> Sys4AI </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Cache System </tag>
            
            <tag> Sys4AI </tag>
            
            <tag> Scheduler </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>6.824 Labs</title>
      <link href="/2023/09/26/OpenSource/6.824/6-824-Labs/"/>
      <url>/2023/09/26/OpenSource/6.824/6-824-Labs/</url>
      
        <content type="html"><![CDATA[<p><ul class="markdownIt-TOC"><li><a href="#lab-2-raft">Lab 2: Raft</a><ul><li><a href="#2a-leader-election">2A: Leader election</a></li><li><a href="#2b-log">2B: Log</a></li><li><a href="#2c-persistence">2C: Persistence</a></li><li><a href="#2d-log-compaction">2D: Log compaction</a></li></ul></li><li><a href="#lab-3-fault-tolerant-keyvalue-service">Lab 3: Fault-tolerant Key/Value Service</a></li><li><a href="#lab-4-shardkv">Lab 4: ShardKV</a></li></ul></p><h1 id="lab-2-raft"><a class="markdownIt-Anchor" href="#lab-2-raft"></a> Lab 2: Raft</h1><h2 id="2a-leader-election"><a class="markdownIt-Anchor" href="#2a-leader-election"></a> 2A: Leader election</h2><ol><li><strong>How to count the votes a candidate gotten?</strong><ul><li>The candidate begins a new goroutine to request vote from each server.</li><li>Use a shared variable to track how many votes has the candidate gotten. Each goroutine monitor that after this vote, has the candidate gotten enough votes to become a leader independently.</li><li>When each goroutine received reply from other peers, it needs to check whether the reply is still in the same term as the term where it is now and whether it is still a candidate.<ul><li>Only check its state is insufficient. The check of term is to prevent delayed replies arrives in the future election initialed by this server.</li></ul></li><li>My initial thought<ul><li>The election goroutine will monitor the process of votes instead of the request goroutines.</li><li>Then the check loop in election goroutine need to sleep after each time it failed. Or the election would be hard to converge.</li><li>I GUESS that the reason is the for-loop never ends and takes too many resources, causing the CPU cannot schedule those RequestVote goroutine and later eletion goroutine in time.</li></ul></li></ul></li><li><strong>How to does each server initial an election?</strong><ul><li>A timestamp is used to record the last time heard from leader or candidate. And <code>electionTimeout</code> is set randomly in startup and beginning of election.<ul><li>Each time the server wants to change its state into follower, it needs to reset timestamp before switch state, or it may trigger a new election due to the stale timeStamp.</li><li>When the replied term is larger than the term of sending <code>AppendEntries</code>, the leader should known that itself is out-of-date. But before any further settings, it should check that whether the replied term is larger than the term where it is now to prevent this is a stale reply processed with a stale term, causing <code>currectTerm</code> decreasing.</li></ul></li><li><code>ticker()</code> will check whether the time since timestamp is larger than the <code>electionTimeout</code> periodically, and if so, an new election is initiated.<ul><li>When the checking is failed, this goroutine should sleep for a short time. But it cannot simply sleep as long as <code>electionTimeout</code>, because the next sleep may be shorter then <code>electionTimeout</code>.</li></ul></li><li>Another way is to set the <code>electionTimeout </code> when checking the condition instead of fixed <code>electionTimeout</code> between two elections.<ul><li>But this will cause multiple peers initiate election in short gap. In addition to the unreliable network and the burden of scheduling goroutines, the <code>RequestVote()</code> may not be executed by others immediately and causing severe split brain and re-elections.</li><li>The reason, I GUESS, is that it only need one short sleep time to kick off election. And with a new random sleep time every <code>CHECKTIMEOUT</code> ms, there is a greater probability that one sleep time is short and it actually shortened the <code>electionTimeout</code> I want.</li></ul></li></ul></li></ol><h2 id="2b-log"><a class="markdownIt-Anchor" href="#2b-log"></a> 2B: Log</h2><ol><li><p><strong>How does the leader sending log entries to followers?</strong></p><ul><li><code>nextIndex</code> is the lowest indices of entries missed by each peers known by leader.</li><li>There are two situations of sending log entries: the first is when there are some un-replicated entries for some follower, and the second is the heartbeat message.<ul><li><code>SyncLogWithFollower(x int)</code> is implemented to check whether server x has some missing entries.</li><li><code>Heartbeat()</code> is implemented to send heartbeat message.</li><li><code>SendEntriesOnceTo(x int)</code> is implemented to actually send log entries to server x.</li><li>The <code>SyncLogWIthFollower()</code> goroutine for each server and the <code>Heartbeat()</code> goroutine is initiated when the server is elected to be leader.</li></ul></li><li>The difference between <code>SyncLogWithFollower()</code> and <code>Heartbeat()</code><ul><li><code>SyncLogWithFollower()</code> sends entries only when there are missing entries in server x. But <code>Heartbeat()</code> always sends entries even when there is no missing entries in which case an empty log is sent.</li><li>The check cycle in <code>SyncLogWithFollower()</code> is way more short than the sending cycle in <code>Heartbeat()</code> to ensure the missing entries can be replicated as soon as possible.</li></ul></li><li>When <code>SyncLogWithFollower()</code> calls <code>SendEntriesOnceTo()</code>, it cannot create a goroutine.<ul><li>Because the check cycle in <code>SyncLogWithFollower()</code> is quite short, if the <code>SyncLogWithFollower()</code> goroutine keeps being scheduled, the <code>SendEntriesOnceTo()</code> cannot send entries to follower. And thus <code>SyncLogWithFollower()</code> goroutine keeps creating too many <code>SendEntriesOnceTo()</code> goroutine.</li></ul></li><li>My initial thought<ul><li>Start a <code>SendEntriesOnceTo()</code> goroutine for every follower after <code>Start()</code> has added a new log entry to leader’s logs instead of using <code>SyncLogWithFollower()</code> goroutine.</li><li>But when there are concurrent <code>Start()</code>, this may cause mulitple <code>SendEntriesOnceTo()</code> goroutine sending the same RPC to the same follower.</li></ul></li></ul></li><li><p><strong>How to optimize the consistency check protocol?</strong></p><ul><li>Additional AppenEntries RPC results for fast roll back:<ul><li><code>Xterm</code>: the term of the conflicting entry.</li><li><code>Xindex</code>: the first index that is in <code>Xterm</code>.</li><li><code>Xlen</code>: the length of log</li></ul></li><li>Fast roll back implementation:<ul><li>If the leader doesn’t have <code>Xterm</code>, then every entries of <code>Xterm</code> in follower’s log will causing conflict. Hence the <code>nextIndex</code> can backup to <code>Xindex</code>.</li><li>If the leader has <code>Xterm</code>, the matching entry in leader’s log must have a term no larger than <code>Xterm</code>. Hence, the <code>nextIndex</code> should backup to the next entry of the last <code>Xterm</code> in leader’s log.</li><li>If the follower’s conflicting is due to empty in <code>prevLogTerm</code>, then <code>Xterm</code> is set to <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>−</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">-1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.72777em;vertical-align:-0.08333em;"></span><span class="mord">−</span><span class="mord">1</span></span></span></span>, and leader should backup to <code>Xlen</code>.</li></ul></li></ul></li><li><p><strong>How should a follower accept log entries after passing all consistency check?</strong></p><ul><li>The <code>nextIndex</code> and <code>logs</code> of the leader can be updated by different goroutines of <code>SendEntriesOnce()</code> and <code>Start()</code>. So it is possible that <code>args.Entries</code> are chosen through a stale <code>nextIndex</code> and an up-to-date <code>log</code>, or even a stale <code>nextIndex</code> and a stale <code>log</code>.</li><li>If the <code>nextIndex</code> is stale while the <code>log</code> is up-to-date, i.e. there are some entries after the <code>nextIndex</code> is already replicated by follower.<ul><li>Then we need to drop those replicated entries but not all the entries since there still could have some new entries.</li><li>We need to drop those entries with the same index and the same term according to the Log Matching property and append only those different entries.</li><li>I didn’t consider the case of <code>nextIndex</code> being larger than the follower’s replicated indices. Since in this case, transmission won’tsuccess and a fast backup will be triggered.</li></ul></li><li>If both the <code>nextIndex</code> and <code>logs</code> are stale, it is similar to the former situation, since the only additional problem is that it cannot be brought up-to-date by one <code>AppendEntries</code>.</li></ul></li><li><p><strong>How will each server commit index?</strong></p><ul><li><code>commitIndex</code> is the highest index of entries that can commit now. This is included in the <code>AppendEntries</code> arguments from leader to followers.</li><li><code>lastApplied</code> is the highest index of entries that is committed. If <code>lastApplied</code> no larger than <code>commitIndex</code>, then a server can commit the entry next to <code>lastApplied</code>.</li><li>Followers cannot modify <code>commitIndex</code> before the logs are synchronized, since there may have some entries need to wipe out by the leader.</li></ul></li><li><p><strong>How do the leader check which entries can be committed?</strong></p><ul><li><p>My solution</p><ul><li><p><code>matchIndex</code> is used to track the highest indices of entries replicated by each peers.</p></li><li><p>When a group of entries that ends with index <code>i</code> is accepted by one peer, the leader first set the corresponding <code>matchIndex</code> to <code>i</code>.</p></li><li><p>Than check whether a majority of <code>matchIndex</code> is larger than <code>i</code>. If so, than the leader can commit at least until <code>i</code>. Or, it won’t commit any entry.</p></li></ul></li><li><p>Improvement</p><ul><li>When a lagged peer replicated a lot of entries, it may be insufficient to commit the last entry it replicated. But it could be sufficient to commit some earlier entries.</li><li>We only need to commit the k-th largest index in <code>matchIndex</code>.</li></ul></li><li><p>My initial thought</p><ul><li>Track the replication state of each entry instead each peer.</li><li>But the entries are a lot more than peers causing higher time complexity to maintain when a lot of entries are by peers.</li></ul></li></ul></li><li><p><strong>What is the constraint of committing uncommitted entries of earlier terms?</strong></p><ul><li>A constraint on commit entries is that each leader can only commit entries added in its term. And by committing such entries, they also commit all entries before it. Hence the entries of earlier terms are committed indirectly.</li><li>But there is a corner case that a leader doesn’t receive any entry at the beginning of its term. And those uncommitted entries of earlier terms cannot be committed until the leader received its first entry.</li><li>My solution is that when a server becomes the leader, it will add an empty entry, and by this empty entry, those uncomitted entries can be committed.</li><li>But the test system of 6.824 didn’t consider this case. This implementation will cause all tests failed.</li></ul></li></ol><h2 id="2c-persistence"><a class="markdownIt-Anchor" href="#2c-persistence"></a> 2C: Persistence</h2><ol><li><code>persist()</code> is called only when <code>rf.currentTerm</code>, <code>rf.votedFor</code> or <code>rf.logs</code> is changed. And when they’re changed, the <code>rf.mu</code> lock must be hold by the caller of <code>persist()</code>. In order to make the states stored as soon as possible, I won’t release the lock util <code>persist()</code> is finished.</li><li><strong>When a server restarts, what information should it restore?</strong><ul><li>Naturally, it need to restore its <code>currentTerm</code>, <code>votedFor</code> and <code>logs</code> from the persisted state.</li><li>Then it need to set its <code>lastLogIndex</code> and <code>lastLogTerm</code> appropriately.</li><li>The <code>lastApplied</code>, <code>commitIndex</code> and <code>lastIncludedIndex</code> will be set to the index of the sentinel entry.<ul><li>Because the current state is the same state executed until the sentinel entry.</li><li>In the future, if the server finds that other peers have committed later entries, it need to re-execute those entries to achieve the same state.</li></ul></li><li>It should update its <code>lastApplied</code> to the last committed entry according to the commit state in each log entry.</li></ul></li><li>**How to invoke persist()? **<ul><li><code>persist()</code> is called only when <code>rf.currentTerm</code>, <code>rf.votedFor</code> or <code>rf.logs</code> is changed.</li><li>When they’re changed, the <code>rf.mu</code> lock must be hold by the caller of <code>persist()</code>. In order to make the states stored as soon as possible, I won’t release the lock util <code>persist()</code> is finished.</li><li>If it is possible to modify the three variables several times before communicate with outside, or release the lock, we just use a variable to mark whether need to persist, instead of really call <code>persist()</code> each time. And only call the <code>persist()</code> at the end.</li></ul></li></ol><h2 id="2d-log-compaction"><a class="markdownIt-Anchor" href="#2d-log-compaction"></a> 2D: Log compaction</h2><ol><li><strong>How to deal with those deleted entries when a server restarts?</strong><ul><li>When a server restores its state from <code>readPersist()</code>, we want it to re-execute those persisted logs.</li><li>But we don’t require to re-execute those deleted entries since we can get to the state of last deleted log by restore snapshot without execution.</li><li>The effect is the same as we have committed those missing entries. So we also need to modify the <code>lastApplied</code> and <code>commitIndex</code> to the last deleted log index before re-executing.</li></ul></li><li><strong>How to take a snapshot?</strong><ul><li>In this lab, the snapshot is naive. It simply stores all the log entries.</li><li>Hence, the server just need to set <code>lastIncludedIndex</code> and <code>lastIncludedTerm</code> appropriately, and remove all the snapshotted entries.</li><li>Also, if the log is empty after removal, we need to insert the sentinel entry back to the entry. Its command is still unimportant.</li></ul></li><li><strong>How to install a snapshot?</strong><ul><li>The snapshot data only contain commands in log entries, so we need to recover the log entries with the snapshot.<ul><li>Their indices and commands are easy to understand.</li><li>We only know the <code>lastIncludedterm</code>. Also these entries are already committed in leader. Thus no matter what will happen in the future, these entries will not be overwriten and no <code>AppendEntry</code> will need to compare with these entries except for the last one. Hence for convenient, I set all their terms to the <code>LastIncludedTerm</code>.</li><li>As aforementioned, these entries are already reflected in the snapshot. Thus, there is no need to re-commit them again.</li></ul></li><li>Then we need to determine whether the snapshot contains new information.<ul><li><code>FirstUncover</code> is to indicate the first entry in <code>logs</code> that is more up-to-date than the last entry in snapshot.<ul><li>If the snapshot contains new information not already in the recipient’s log, then <code>firstUncover == len(rf.logs)</code>.</li><li>If the snapshot describes a prefix of its log, then <code>firstUncover &lt; len(rf.logs)</code>, then we only need to delete the former entries.</li></ul></li><li>I thought that maybe I just need to compare <code>lastLogIndex</code> in server and <code>LastIncludedIndex</code> of snapshot, but this is not sufficient.<ul><li>Because some server need to discard the last few entries from ealier leaders, yet not in the logs of the current leader.</li><li>We need to remove the entries whose term is smaller than the <code>LastIncludedTerm</code> of snapshot while whose index is larger than <code>LastIncludedIndex</code> of snapshot.</li></ul></li></ul></li><li>If the snapshot contains new information<ul><li>We will discard the whole log entries, and insert a new sentinel entry with index equals to <code>LastIncludedIndex</code> and term equals to <code>LastIncludedTerm</code>.</li><li>Then <code>commitIndex</code> and <code>lastApplied</code> need to be updated to <code>LastIncludedIndex</code> since we won’t re-execute those new entries in snapshot.</li><li>It need to be persisted.</li></ul></li><li>If the snapshot describes only a prefix of logs, then discard the covered entries. But don’t discard those covered, yet uncommitted entries and need to leave one entry as sentinel.</li></ul></li><li>If PrevLog is already trimmed, we should find the entry with the same index as the sentinel. And make it the new PrevLog, only accept the entries following it.</li></ol><h1 id="lab-3-fault-tolerant-keyvalue-service"><a class="markdownIt-Anchor" href="#lab-3-fault-tolerant-keyvalue-service"></a> Lab 3: Fault-tolerant Key/Value Service</h1><ol><li><strong>How does Key/Value server execute command from clerk?</strong><ul><li>It will call the <code>Start()</code> function of its associated Raft server. It can safely execute the command until the Raft server commits that command.</li><li>Only the KV server associated with leader Raft server can successfully use <code>Start()</code> to append command to logs.</li><li>But there could be a situation that the network is partitioned, and the clerk connects to a partition leader whose log entry can never be successfully committed. So we need to set a timeout for each command, if it cannot commit in time, the clerk should be informed to find another server.</li></ul></li><li><strong>Can clerk read from follower?</strong><ul><li>In the design described above, clerks can only read or write through the leader, which can make leader the bottleneck of the whole system.</li><li>With another design, read-only operation can be executed through followers, thus providing a speedup for the Get operation.<ul><li>When a KV server received a Get operation request, it will request ReadIndex from the Raft leader server.</li><li>Then the raft leader server need to broadcast heartbeat to all followers to confirm that it is still the rightful leader.</li><li>When it heard from a majority followers, it can reply its last CommitIndex as the ReadIndex.</li><li>Then the KV server can execute the Get operation after it has applied at least as up-to-date as the ReadIndex.</li></ul></li><li>In the Raft protocol, a leader can only commit the entries appended in its term. Similarly, a leader can only grant ReadIndex pointing to an entry of its term. Or the result of read may become unlinearizable.<ul><li>Consider the case that a leader committed index of <em>x</em>, and granted a ReadIndex of <em>x</em> to its associated KV server. So the KV server returned the result up to index <em>x</em>. But it crashed before sending commit message to other followers. Then a new leader is elected who received a request for ReadIndex. It does not know anything about committing entry <em>x</em>, thus granting a ReadIndex lower than <em>x</em>. Hence the read will return a result unseeing the execution result of entry of index <em>x</em>, which is violated with the linearizablility scheme.</li><li>So the solution is to append an empty entry to the log if the leader hasn’t appended any entry in its term.</li></ul></li></ul></li><li><strong>How can we prevent re-execution of an executed command?</strong><ul><li>Each clerk needs to maintain a monotonically increasing index to mark the command it issued.</li><li>Each Key/Value server needs to track the highest index it has executed for each clerk.</li><li>When a Key/Value server receives a new command, it compares the index of the new command with the highest executed index of that clerk. If the command’s index is lower, it can know that this is an executed command, and return the result directly.</li></ul></li><li><strong>How many kind of error could occur when client issues a command?</strong><ul><li>For read-only operation, there could be a key error.</li><li>Except for the read-only operation with follower read, the client may connect to a follower who cannot append a command.</li><li>The client may connect to a server in a minority parition of servers.<ul><li>The PutAppend command is appended to the log but cannot commit.</li><li>For the read-only operation with follower read, it connects to its leader, but its leader cannot receive majority response. Hence it cannot acquire a ReadIndex.</li></ul></li><li>For read-only operation with follower read,<ul><li>The KV Server is associated with a leader, and its leader set a higher commit index when communicating with majority. But the Raft leader crashed before commit that entry, leaving the KV server keep waiting to apply as up-to-date as the ReadIndex.</li><li>The client may connect to a partition without leader, hence cannot acquire ReadIndex.</li></ul></li></ul></li><li><strong>What should be stored in a snapshot?</strong><ul><li>Of course, we need to store the state of all key-value pairs.</li><li>We also need to store the last index executed for each client so far, in order to be able to recognize duplicated commands even after crashed.</li><li>The index of last applied entry is also stored to prevent that the first command after recovery is a read-only operation.</li></ul></li><li><strong>What need to do to recover the state after crashed?</strong><ul><li>First, we need to install the latest snapshot persisted.</li><li>But that is not enough if only the KV server is crashed while the associated Raft server is still running since there might still have some committed entries which is not included in the snapshot, yet applied before crash. The KV server needs to acquire those committed entries to truely bring itself back to the state right before crash.</li></ul></li><li>Execution speed of Get operation:<ul><li>When running test without enabling snapshot:<ul><li>The time spent for each operation of the un-optimzied implementation will become slower as the number of operation grows. This is because the log of each Raft server becomes larger and larger and becomes slower to persist.</li><li>When executing the Get operation, the log of optimized implementation won’t increase. Hence it won’t slow down the execution.</li><li>When executing <em>3000</em> Get operations, the un-optimized implementation needs about <em>50 ms/op</em>, while the optimized implementation only needs <em>1.7 ms/op</em>, which is about <em>29</em> times speedup.</li></ul></li><li>When running test enabling snapshot:<ul><li>The time spent for the un-optimized implementation becomes stable since the log size is now stable. However, when only executing the Get operation, the oprimized implementation does not need the benefit of trimming logs.</li><li>When executing <em>3000</em> Get operations, the un-optimized imlementation need about <em>14.7 ms/op</em>, while the optimized imlementation is still <em>1.7 ms/op</em>, which is about <em>8.6</em> times speedup.</li></ul></li><li>I think that the speedup of optimized read-only scheme comes from two parts: follower concurrency that increased the total bandwidth between clients and servers, and the persisting time saved by eliminating Get operation entries from logs.</li></ul></li><li>Execution speed of PutAppend operation:<ul><li>When executing <em>1000</em> Put operations without enabling snapshot, both implementations needs about <em>29.5 ms/op</em>. Executing Append operations needs about the same amount of time.</li><li>When executing <em>1000</em> Put operations enabling snapshot, both implementations needs about <em>13.9 ms/op</em>. Executing Append operations needs about the same amount of time.</li><li>Thus, with snapshot enabled, it can achieve about <em>2.1</em> times speedup. I think the speedup mainly comes from the persisting time saved by shrinking log.</li></ul></li></ol><h1 id="lab-4-shardkv"><a class="markdownIt-Anchor" href="#lab-4-shardkv"></a> Lab 4: ShardKV</h1>]]></content>
      
      
      <categories>
          
          <category> Open Source Code </category>
          
          <category> 6.824 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Distributed System </tag>
            
            <tag> Distributed Storage </tag>
            
            <tag> Consensus Algorithm </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>COPS</title>
      <link href="/2023/09/26/Paper/Distributed/COPS/"/>
      <url>/2023/09/26/Paper/Distributed/COPS/</url>
      
        <content type="html"><![CDATA[<p>Paper: <a href="http://nil.csail.mit.edu/6.824/2020/papers/cops.pdf">Don’t Settle for Eventual: Scalable Causal Consistency for Wide-Area Storage with COPS</a></p><p><ul class="markdownIt-TOC"><li><a href="#purpose">Purpose</a></li><li><a href="#model">Model</a><ul><li><a href="#alps-systems">ALPS systems</a><ul><li><a href="#what-are-the-desirable-properties-of-alps-systems">What are the desirable properties of ALPS systems?</a></li><li><a href="#what-is-the-problem-of-linearizability">What is the problem of linearizability?</a></li></ul></li><li><a href="#causal-consistency">Causal+ consistency</a><ul><li><a href="#what-is-causal-consistency">What is causal consistency?</a></li><li><a href="#how-to-handle-conflicts">How to handle conflicts?</a></li><li><a href="#how-to-decide-which-write-is-the-last-write">How to decide which write is the last write?</a></li><li><a href="#what-are-other-consistency-models">What are other consistency models?</a></li><li><a href="#how-is-causal-ensured-in-cops">How is causal+ ensured in COPS?</a></li><li><a href="#why-previous-systems-cannot-provide-scalability">Why previous systems cannot provide scalability?</a></li></ul></li><li><a href="#cops-system">COPS system</a><ul><li><a href="#what-are-the-components-of-cops">What are the components of COPS?</a></li><li><a href="#what-consistency-is-achieved-in-cops">What consistency is achieved in COPS?</a></li><li><a href="#key-value-store">Key-value store</a><ul><li><a href="#what-is-stored-in-cops-storage">What is stored in COPS storage?</a></li><li><a href="#how-does-cops-support-scalability-in-kv-storage">How does COPS support scalability in KV-storage?</a></li></ul></li><li><a href="#client-library">Client library</a><ul><li><a href="#what-is-provided-in-the-client-api">What is provided in the client API?</a></li><li><a href="#what-is-the-context-in-library">What is the context in library?</a></li><li><a href="#what-does-cops-gt-store-in-context">What does COPS-GT store in context?</a></li><li><a href="#what-are-the-concerns-of-cops-gt-context">What are the concerns of COPS-GT context?</a></li><li><a href="#what-does-cops-store-in-context">What does COPS store in context?</a></li><li><a href="#how-does-cops-or-cops-gt-write-to-local-cluster">How does COPS (or COPS-GT) write to local cluster?</a></li><li><a href="#how-to-replica-writes-between-clusters">How to replica writes between clusters?</a></li><li><a href="#how-to-read-values-in-cops">How to read values in COPS?</a></li><li><a href="#why-does-cops-gt-need-to-proviced-get_trans-what-is-wrong-with-the-get-interface">Why does COPS-GT need to proviced get_trans? What is wrong with the get interface?</a></li><li><a href="#how-does-get_trans-work">How does get_trans work?</a></li></ul></li><li><a href="#garbage-collection">Garbage collection</a><ul><li><a href="#how-does-cops-gt-collect-version-garbage">How does COPS-GT collect version garbage?</a></li><li><a href="#how-does-cops-gt-collect-dependency-garbage">How does COPS-GT collect dependency garbage?</a></li><li><a href="#how-does-cops-collect-client-metadata-garbage">How does COPS collect client metadata garbage?</a></li></ul></li><li><a href="#fault-tolerance">Fault tolerance</a><ul><li><a href="#how-does-cops-handle-client-failures">How does COPS handle client failures?</a></li><li><a href="#how-does-cops-handle-key-value-node-failures">How does COPS handle key-value node failures?</a></li><li><a href="#what-will-happen-when-datacenter-failed">What will happen when datacenter failed?</a></li><li><a href="#how-does-cops-with-conflict-detection-cops-cd-detect-conflict">How does COPS with conflict detection (COPS-CD) detect conflict?</a></li></ul></li></ul></li></ul></li></ul></p><h1 id="purpose"><a class="markdownIt-Anchor" href="#purpose"></a> Purpose</h1><ol><li>Issues<ul><li>Systems often sacrifice strong consistency to achieve these goals, exposing inconsistencies to their clients and necessitating complex application logic.</li><li>The author referred to systems with these four properties—Availability, low Latency, Partition-tolerance, and high Scalability—as ALPS systems.</li><li>Eventually consistent systems may expose versions out of order.</li></ul></li><li>Contribution:<ul><li>The author identified and defined a consistency model—causal consistency with convergent conflict handling, or causal+ —that is the strongest achieved under ALPS systems.<ul><li>The convergent conflict handling component of causal+ consistency ensures that replicas never permanently diverge and that conflicting updates to the same key are dealt with identically at all sites.</li><li>When combined with causal consistency, this property ensures that clients see only progressively newer versions of keys.</li></ul></li><li>The scalability of Clusters of Order-Preserving Servers (COPS) system can enforce causal dependencies between keys stored across an entire cluster, rather than a single server like previous systems.</li><li>In COPS-GT, the author introduced get transactions in order to obtain a consistent view of multiple keys without locking or blocking.</li></ul></li></ol><h1 id="model"><a class="markdownIt-Anchor" href="#model"></a> Model</h1><h2 id="alps-systems"><a class="markdownIt-Anchor" href="#alps-systems"></a> ALPS systems</h2><h3 id="what-are-the-desirable-properties-of-alps-systems"><a class="markdownIt-Anchor" href="#what-are-the-desirable-properties-of-alps-systems"></a> What are the desirable properties of ALPS systems?</h3><ol><li><strong>Availability</strong>:<ul><li>All operations issued to the data store complete successfully.</li><li>No operation can block indefinitely or return an error signifying that data is unavailable.</li></ul></li><li><strong>Low Latency</strong>: Client operations complete “quickly.”<ul><li>Commercial service-level objectives suggest average performance of a few milliseconds and worse-case performance (i.e., 99.9th percentile) of 10s or 100s of milliseconds.</li></ul></li><li><strong>Partition Tolerance</strong>: The data store continues to operate under network partitions.</li><li><strong>High Scalability</strong>: The data store scales out linearly. Adding N resources to the system increases aggregate throughput and storage capacity by <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>O</mi><mo stretchy="false">(</mo><mi>N</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">O(N)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">O</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.10903em;">N</span><span class="mclose">)</span></span></span></span>.</li><li><strong>Stronger Consistency</strong>:<ul><li>Linearizability dictates that operations appear to take effect across the entire system at a single instance in time between the invocation and completion of the operation.</li><li>Eventual consistency models not only might subsequent reads not reflect the latest value, reads across multiple objects might reflect an incoherent mix of old and new values.</li></ul></li></ol><h3 id="what-is-the-problem-of-linearizability"><a class="markdownIt-Anchor" href="#what-is-the-problem-of-linearizability"></a> What is the problem of linearizability?</h3><ol><li>The CAP Theorem proves that a shared-data system that has availability and partition tolerance cannot achieve linearizability.</li><li>Low latency—defined as latency less than the maximum widearea delay between replicas—has also been proven incompatible with linearizability and sequential consistency.</li></ol><h2 id="causal-consistency"><a class="markdownIt-Anchor" href="#causal-consistency"></a> Causal+ consistency</h2><h3 id="what-is-causal-consistency"><a class="markdownIt-Anchor" href="#what-is-causal-consistency"></a> What is causal consistency?</h3><ol><li>Values are stored and retrieved from logical replicas, each of which hosts the entire key space.</li><li>The potential causality between operations denoted by <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>⇝</mo></mrow><annotation encoding="application/x-tex">\leadsto</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.37788em;vertical-align:0em;"></span><span class="mrel amsrm">⇝</span></span></span></span>:<ul><li><strong>Execution Thread</strong>: If <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>a</mi></mrow><annotation encoding="application/x-tex">a</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathnormal">a</span></span></span></span> and <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>b</mi></mrow><annotation encoding="application/x-tex">b</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathnormal">b</span></span></span></span> are two operations in a single thread of execution, then <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>a</mi><mo>⇝</mo><mi>b</mi></mrow><annotation encoding="application/x-tex">a \leadsto b</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathnormal">a</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel amsrm">⇝</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathnormal">b</span></span></span></span> if operation <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>a</mi></mrow><annotation encoding="application/x-tex">a</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathnormal">a</span></span></span></span> happens before operation <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>b</mi></mrow><annotation encoding="application/x-tex">b</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathnormal">b</span></span></span></span>.</li><li><strong>Gets From</strong>: If <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>a</mi></mrow><annotation encoding="application/x-tex">a</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathnormal">a</span></span></span></span> is a put operation and <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>b</mi></mrow><annotation encoding="application/x-tex">b</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathnormal">b</span></span></span></span> is a get operation that returns the value written by <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>a</mi></mrow><annotation encoding="application/x-tex">a</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathnormal">a</span></span></span></span>, then <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>a</mi><mo>⇝</mo><mi>b</mi></mrow><annotation encoding="application/x-tex">a \leadsto b</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathnormal">a</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel amsrm">⇝</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathnormal">b</span></span></span></span>.</li><li><strong>Transitivity</strong>: For operations <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>a</mi></mrow><annotation encoding="application/x-tex">a</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathnormal">a</span></span></span></span>, <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>b</mi></mrow><annotation encoding="application/x-tex">b</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathnormal">b</span></span></span></span>, and <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>c</mi></mrow><annotation encoding="application/x-tex">c</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathnormal">c</span></span></span></span>, if <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>a</mi><mo>⇝</mo><mi>b</mi></mrow><annotation encoding="application/x-tex">a \leadsto b</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathnormal">a</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel amsrm">⇝</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathnormal">b</span></span></span></span> and <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>b</mi><mo>⇝</mo><mi>c</mi></mrow><annotation encoding="application/x-tex">b \leadsto c</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathnormal">b</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel amsrm">⇝</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathnormal">c</span></span></span></span>, then <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>a</mi><mo>⇝</mo><mi>c</mi></mrow><annotation encoding="application/x-tex">a \leadsto c</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathnormal">a</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel amsrm">⇝</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathnormal">c</span></span></span></span>.</li></ul></li><li>Causal consistency requires that values returned from get operations at a replica are consistent with the order defined by <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>⇝</mo></mrow><annotation encoding="application/x-tex">\leadsto</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.37788em;vertical-align:0em;"></span><span class="mrel amsrm">⇝</span></span></span></span> (causality).<ul><li>It must appear the operation that writes a value occurs after all operations that causally precede it.</li><li>If <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>a</mi><mo>⇝̸</mo><mi>b</mi></mrow><annotation encoding="application/x-tex">a \not\leadsto b</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord mathnormal">a</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel"><span class="mord vbox"><span class="thinbox"><span class="rlap"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="inner"><span class="mrel"></span></span><span class="fix"></span></span></span></span></span></span><span class="base"><span class="strut" style="height:0.37788em;vertical-align:0em;"></span><span class="mrel amsrm">⇝</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathnormal">b</span></span></span></span> and <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>b</mi><mo>⇝̸</mo><mi>a</mi></mrow><annotation encoding="application/x-tex">b \not\leadsto a</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord mathnormal">b</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel"><span class="mord vbox"><span class="thinbox"><span class="rlap"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="inner"><span class="mrel"></span></span><span class="fix"></span></span></span></span></span></span><span class="base"><span class="strut" style="height:0.37788em;vertical-align:0em;"></span><span class="mrel amsrm">⇝</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathnormal">a</span></span></span></span>, then <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>a</mi></mrow><annotation encoding="application/x-tex">a</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathnormal">a</span></span></span></span> and <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>b</mi></mrow><annotation encoding="application/x-tex">b</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathnormal">b</span></span></span></span> are concurrent. Causal consistency does not order concurrent operations.</li></ul></li></ol><h3 id="how-to-handle-conflicts"><a class="markdownIt-Anchor" href="#how-to-handle-conflicts"></a> How to handle conflicts?</h3><ol><li>If <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>a</mi></mrow><annotation encoding="application/x-tex">a</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathnormal">a</span></span></span></span> and <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>b</mi></mrow><annotation encoding="application/x-tex">b</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathnormal">b</span></span></span></span> are both puts to the same key, then they are in conflict.<ul><li>Conflicts are unordered by causal consistency, and allow replicas to diverge forever.</li><li>Conflicts may represent an exceptional condition that requires special handling.</li></ul></li><li>Convergent conflict handling requires that all conflicting puts be handled in the same manner at all replicas, using a handler function <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>h</mi></mrow><annotation encoding="application/x-tex">h</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathnormal">h</span></span></span></span>.<ul><li>This handler function <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>h</mi></mrow><annotation encoding="application/x-tex">h</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathnormal">h</span></span></span></span> must be <strong>associative</strong> and <strong>commutative</strong>, so that replicas can handle conflicting writes in the order they receive them and that the results of these handlings will converge.<ul><li>The last-writer-wins rule (Thomas’s write rule): one of the conflicting writes as having occurred later and has it overwrite the “earlier” write.</li><li>The default COPS system avoids conflict detection using a last-writer-wins strategy. The “last” write is determined by comparing version numbers.</li><li>Another way is to mark them as conflicting and require their resolution by some other means.</li></ul></li></ul></li><li>All potential forms of convergent conflict handling avoid the first issue by ensuring that replicas reach the same result after exchanging operations.</li><li>the second issue with conflicts is only avoided by the use of more explicit conflict resolution procedures.<ul><li>These explicit procedures provide greater flexibility for applications, but require additional programmer complexity and/or performance overhead.</li></ul></li></ol><h3 id="how-to-decide-which-write-is-the-last-write"><a class="markdownIt-Anchor" href="#how-to-decide-which-write-is-the-last-write"></a> How to decide which write is the last write?</h3><ol><li>It uses last-write-win strategy. So the problem is how to decide which write is the last write.</li><li>The decision is made by attaching the current wall-clock time as version number on each put.<ul><li>Local shard server assigns <code>version number (v#) = time</code> when it receives client <code>put()</code></li><li>Remote datacenter receives <code>put(k, -, v#)</code><ul><li>If <code>v#</code> is larger than version of currently stored value for <code>k</code>, then it replaces the current value with new value, and update <code>v#</code>.</li><li>Otherwise, it just ignores new value.</li></ul></li></ul></li><li>If two <code>put(k)</code> happen at exactly the same time at different datacenters, we can break tie with a unique ID in the low bits of <code>v#</code>.</li><li>COPS uses Lamport clocks to assign <code>v#</code><ul><li>Each server implements a “Lamport clock” or “logical clock”<ul><li><code>Tmax = highest v# seen</code> (from self and others)</li><li><code>T = max(Tmax + 1, wall-clock time)</code></li></ul></li></ul></li><li>In the naive strategy, if one datacenter’s (or server’s) clock is fast by an hour, it will cause that datacenter’s values to win. In the worst case, it prevents any other update for an hour.<ul><li>But in  COPS, if some server has a fast clock, everyone who sees a version from that server will advance their Lamport clock.</li></ul></li></ol><h3 id="what-are-other-consistency-models"><a class="markdownIt-Anchor" href="#what-are-other-consistency-models"></a> What are other consistency models?</h3><ol><li><p>Linearizability (or strong consistency) maintains a global, real-time ordering.</p></li><li><p>Sequential consistency ensures at least a global ordering.</p></li><li><p>Causal consistency ensures partial orderings between dependent operations.</p></li><li><p>FIFO (PRAM) consistency only preserves the partial ordering of an execution thread, not between threads.</p></li><li><p>Per-key sequential consistency ensures that, for each individual key, all operations have a global order.</p></li><li><p>Eventual consistency, a “catch-all” term used today suggesting eventual convergence to some type of agreement.</p></li><li><p>The strength of those models is as shown below:</p><img src="/imgs/Distributed/COPS/models.png" width="50%"></li></ol><h3 id="how-is-causal-ensured-in-cops"><a class="markdownIt-Anchor" href="#how-is-causal-ensured-in-cops"></a> How is causal+ ensured in COPS?</h3><ol><li><p><strong>Progressing property</strong></p><ul><li><p>Different values a key has is referred as the versions of a key, which is denote <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi><mi>e</mi><msub><mi>y</mi><mrow><mi>v</mi><mi>e</mi><mi>r</mi><mi>s</mi><mi>i</mi><mi>o</mi><mi>n</mi></mrow></msub></mrow><annotation encoding="application/x-tex">key_{version}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord mathnormal" style="margin-right:0.03148em;">k</span><span class="mord mathnormal">e</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.03588em;">v</span><span class="mord mathnormal mtight">e</span><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span><span class="mord mathnormal mtight">s</span><span class="mord mathnormal mtight">i</span><span class="mord mathnormal mtight">o</span><span class="mord mathnormal mtight">n</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>.</p></li><li><p>In COPS, versions are assigned in a manner that ensures that if <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>x</mi><mi>i</mi></msub><mo>⇝</mo><msub><mi>y</mi><mi>j</mi></msub></mrow><annotation encoding="application/x-tex">x_i \leadsto y_j</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel amsrm">⇝</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.716668em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.311664em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span></span></span></span> then <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>i</mi><mo>&lt;</mo><mi>j</mi></mrow><annotation encoding="application/x-tex">i &lt; j</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69862em;vertical-align:-0.0391em;"></span><span class="mord mathnormal">i</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">&lt;</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.85396em;vertical-align:-0.19444em;"></span><span class="mord mathnormal" style="margin-right:0.05724em;">j</span></span></span></span>.</p></li><li><p>Once a replica in COPS returns version <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>i</mi></mrow><annotation encoding="application/x-tex">i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.65952em;vertical-align:0em;"></span><span class="mord mathnormal">i</span></span></span></span> of a key, <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>x</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">x_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>, causal+ consistency ensures it will then only return that version or a causally later version.</p></li><li><p>The handling of a conflict is causally later than the conflicting puts it resolves.</p><ul><li><p>Assume a replica first returns <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>x</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">x_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> and then <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>x</mi><mi>k</mi></msub></mrow><annotation encoding="application/x-tex">x_k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>, where <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>i</mi><mo mathvariant="normal">≠</mo><mi>k</mi></mrow><annotation encoding="application/x-tex">i \ne k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord mathnormal">i</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel"><span class="mrel"><span class="mord vbox"><span class="thinbox"><span class="rlap"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="inner"><span class="mrel"></span></span><span class="fix"></span></span></span></span></span><span class="mrel">=</span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.03148em;">k</span></span></span></span> and <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>x</mi><mi>i</mi></msub><mo>⇝̸</mo><msub><mi>x</mi><mi>k</mi></msub></mrow><annotation encoding="application/x-tex">x_i \not\leadsto x_k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel"><span class="mord vbox"><span class="thinbox"><span class="rlap"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="inner"><span class="mrel"></span></span><span class="fix"></span></span></span></span></span></span><span class="base"><span class="strut" style="height:0.37788em;vertical-align:0em;"></span><span class="mrel amsrm">⇝</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>.</p></li><li><p>Causal consistency ensures that if <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>x</mi><mi>k</mi></msub></mrow><annotation encoding="application/x-tex">x_k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> is returned after <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>x</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">x_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>, then <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>x</mi><mi>k</mi></msub><mo>⇝̸</mo><msub><mi>x</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">x_k \not\leadsto x_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel"><span class="mord vbox"><span class="thinbox"><span class="rlap"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="inner"><span class="mrel"></span></span><span class="fix"></span></span></span></span></span></span><span class="base"><span class="strut" style="height:0.37788em;vertical-align:0em;"></span><span class="mrel amsrm">⇝</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>, and so <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>x</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">x_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> and <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>x</mi><mi>k</mi></msub></mrow><annotation encoding="application/x-tex">x_k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> conflict.</p></li><li><p>But, if <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>x</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">x_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> and <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>x</mi><mi>k</mi></msub></mrow><annotation encoding="application/x-tex">x_k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> conflict, then convergent conflict handling ensures that as soon as both are present at a replica, their handling <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>h</mi><mo stretchy="false">(</mo><msub><mi>x</mi><mi>i</mi></msub><mo separator="true">,</mo><msub><mi>x</mi><mi>k</mi></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">h(x_i,x_k)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">h</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span>, which is causally after both, will be returned instead of either <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>x</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">x_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> or <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>x</mi><mi>k</mi></msub></mrow><annotation encoding="application/x-tex">x_k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>, which contradicts our assumption.</p></li></ul></li><li><p>Thus, each replica in COPS always returns non-decreasing versions of a key.</p></li></ul></li><li><p><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>y</mi><mi>j</mi></msub></mrow><annotation encoding="application/x-tex">y_j</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.716668em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.311664em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span></span></span></span> depends on <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>x</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">x_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> if and only if <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi><mi>u</mi><mi>t</mi><mo stretchy="false">(</mo><msub><mi>x</mi><mi>i</mi></msub><mo stretchy="false">)</mo><mo>⇝</mo><mi>p</mi><mi>u</mi><mi>t</mi><mo stretchy="false">(</mo><msub><mi>y</mi><mi>j</mi></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">put(x_i) \leadsto put(y_j)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">p</span><span class="mord mathnormal">u</span><span class="mord mathnormal">t</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel amsrm">⇝</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.036108em;vertical-align:-0.286108em;"></span><span class="mord mathnormal">p</span><span class="mord mathnormal">u</span><span class="mord mathnormal">t</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.311664em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span>.</p><ul><li>These dependencies are in essence the reverse of the causal ordering of writes.</li><li>COPS provides causal+ consistency during replication by writing a version only after writing all of its dependencies.</li></ul></li></ol><h3 id="why-previous-systems-cannot-provide-scalability"><a class="markdownIt-Anchor" href="#why-previous-systems-cannot-provide-scalability"></a> Why previous systems cannot provide scalability?</h3><ol><li><p>They all use a form of log serialization and exchange.</p><ul><li><p>All operations at a logical replica are written to a single log in serialized order, commonly marked with a version vector.</p></li><li><p>Log-exchange-based serialization inhibits replica scalability, as it relies on a single serialization point in each replica to establish ordering.</p></li><li><p>Either causal dependencies between keys are limited to the set of keys that can be stored on one node, or a single node (or replicated state machine) must provide a commit ordering and log for all operations across a cluster.</p></li></ul></li><li><p>In COPS, nodes in each datacenter are responsible for different partitions of the keyspace, but the system can track and enforce dependencies between keys stored on different nodes.</p><ul><li>COPS explicitly encodes dependencies in metadata associated with each key’s version.</li><li>When keys are replicated remotely, the receiving datacenter performs dependency checks before committing the incoming version.</li></ul></li></ol><h2 id="cops-system"><a class="markdownIt-Anchor" href="#cops-system"></a> COPS system</h2><h3 id="what-are-the-components-of-cops"><a class="markdownIt-Anchor" href="#what-are-the-components-of-cops"></a> What are the components of COPS?</h3><ol><li>Key-value store<ul><li>Each key-value pair has associated metadata.<ul><li>In COPS, this metadata is a version number.</li><li>In COPS-GT, it is both a version number and a list of dependencies (other keys and their respective versions).</li></ul></li><li>The key-value store exports three additional operations as part of its key-value interface: <code>get_by_version</code>, <code>put_after</code>, and <code>dep_check</code>.</li><li>For COPS-GT, the system keeps around old versions of key-value pairs, not just the most recent put, to ensure that it can provide get transactions.</li></ul></li><li>Client library<ul><li>The client library exports two main operations to applications: reads via <code>get</code> (in COPS) or <code>get_trans</code> (in COPS-GT), and writes via <code>put</code>.</li><li>The client library also maintains state about a client’s current dependencies through a <code>context</code> parameter in the client library API.</li></ul></li><li>A client of COPS is an application that uses the COPS client library to call directly into the COPS key-value store.</li><li>Clients communicate only with their local COPS cluster running in the same datacenter.</li></ol><h3 id="what-consistency-is-achieved-in-cops"><a class="markdownIt-Anchor" href="#what-consistency-is-achieved-in-cops"></a> What consistency is achieved in COPS?</h3><ol><li>Each local COPS cluster is set up as a linearizable (strongly consistent) key-value store.<ul><li>Linearizable systems can be implemented scalably by partitioning the keyspace into N linearizable partitions.</li><li>The composability of linearizability ensures that the resulting system as a whole remains linearizable.</li><li>Linearizability is acceptable locally because we expect very low latency and no partitions within a cluster.</li></ul></li><li>Replication between COPS clusters happens asynchronously to ensure low latency for client operations and availability in the face of external partitions.</li><li>The COPS design strives to provide causal+ consistency with resource and performance overhead similar to existing eventually consistent systems.<ul><li>COPS and COPS-GT need to minimize overhead of consistency-preserving replication<ul><li>A naive implementation, however, would require checks on all of a value’s dependencies.</li></ul></li><li>COPS-GT needs to minimize space requirements</li><li>COPS-GT needs to ensure fast <code>get_trans</code> operations<ul><li>A naive algorithm could block and/or take an unbounded number of get rounds to complete.</li></ul></li></ul></li></ol><h3 id="key-value-store"><a class="markdownIt-Anchor" href="#key-value-store"></a> Key-value store</h3><h4 id="what-is-stored-in-cops-storage"><a class="markdownIt-Anchor" href="#what-is-stored-in-cops-storage"></a> What is stored in COPS storage?</h4><ol><li>COPS must track the versions of written values, as well as their dependencies in the case of COPS-GT.</li><li>In COPS, the system stores the most recent version number and value for each key.</li><li>In COPS-GT, the system maps each key to a list of version entries, each consisting of <code>&lt;version, value, deps&gt;</code>.<ul><li>The deps field is a list of the version’s zero or more dependencies; each dependency is a <code>&lt;key, version&gt;</code> pair.</li></ul></li></ol><h4 id="how-does-cops-support-scalability-in-kv-storage"><a class="markdownIt-Anchor" href="#how-does-cops-support-scalability-in-kv-storage"></a> How does COPS support scalability in KV-storage?</h4><ol><li>It partitions the keyspace across a cluster’s nodes using consistent hashing.</li><li>Every key stored in COPS has one primary node in each cluster.<ul><li>The set of primary nodes for a key across all clusters are termed as the <strong>equivalent nodes</strong> for that key.</li><li>After a write completes locally, the primary node places it in a replication queue, from which it is sent asynchronously to remote equivalent nodes.</li><li>Those nodes, in turn, wait until the value’s dependencies are satisfied in their local cluster before locally committing the value.</li><li>This dependency checking mechanism ensures writes happen in a causally consistent order and reads never block.</li></ul></li><li>In practice, COPS’s consistent hashing assigns each node responsibility for a few different key ranges.<ul><li>Key ranges may have different sizes and node mappings in different datacenters</li><li>The total number of equivalent nodes with which a given node needs to communicate is proportional to the number of datacenters (i.e., communication is not all-to-all between nodes in different datacenters).</li></ul></li></ol><h3 id="client-library"><a class="markdownIt-Anchor" href="#client-library"></a> Client library</h3><h4 id="what-is-provided-in-the-client-api"><a class="markdownIt-Anchor" href="#what-is-provided-in-the-client-api"></a> What is provided in the client API?</h4><ol><li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>c</mi><mi>t</mi><mi>x</mi><mi mathvariant="normal">_</mi><mi>i</mi><mi>d</mi><mo>←</mo><mi>c</mi><mi>r</mi><mi>e</mi><mi>a</mi><mi>t</mi><mi>e</mi><mi>C</mi><mi>o</mi><mi>n</mi><mi>t</mi><mi>e</mi><mi>x</mi><mi>t</mi><mo stretchy="false">(</mo><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">ctx\_id\leftarrow createContext()</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.00444em;vertical-align:-0.31em;"></span><span class="mord mathnormal">c</span><span class="mord mathnormal">t</span><span class="mord mathnormal">x</span><span class="mord" style="margin-right:0.02778em;">_</span><span class="mord mathnormal">i</span><span class="mord mathnormal">d</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">←</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">c</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mord mathnormal">e</span><span class="mord mathnormal">a</span><span class="mord mathnormal">t</span><span class="mord mathnormal">e</span><span class="mord mathnormal" style="margin-right:0.07153em;">C</span><span class="mord mathnormal">o</span><span class="mord mathnormal">n</span><span class="mord mathnormal">t</span><span class="mord mathnormal">e</span><span class="mord mathnormal">x</span><span class="mord mathnormal">t</span><span class="mopen">(</span><span class="mclose">)</span></span></span></span></li><li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>b</mi><mi>o</mi><mi>o</mi><mi>l</mi><mo>←</mo><mi>d</mi><mi>e</mi><mi>l</mi><mi>e</mi><mi>t</mi><mi>e</mi><mi>C</mi><mi>o</mi><mi>n</mi><mi>t</mi><mi>e</mi><mi>x</mi><mi>t</mi><mo stretchy="false">(</mo><mi>c</mi><mi>t</mi><mi>x</mi><mi mathvariant="normal">_</mi><mi>i</mi><mi>d</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">bool\leftarrow deleteContext(ctx\_id)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathnormal">b</span><span class="mord mathnormal">o</span><span class="mord mathnormal">o</span><span class="mord mathnormal" style="margin-right:0.01968em;">l</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">←</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.06em;vertical-align:-0.31em;"></span><span class="mord mathnormal">d</span><span class="mord mathnormal">e</span><span class="mord mathnormal" style="margin-right:0.01968em;">l</span><span class="mord mathnormal">e</span><span class="mord mathnormal">t</span><span class="mord mathnormal">e</span><span class="mord mathnormal" style="margin-right:0.07153em;">C</span><span class="mord mathnormal">o</span><span class="mord mathnormal">n</span><span class="mord mathnormal">t</span><span class="mord mathnormal">e</span><span class="mord mathnormal">x</span><span class="mord mathnormal">t</span><span class="mopen">(</span><span class="mord mathnormal">c</span><span class="mord mathnormal">t</span><span class="mord mathnormal">x</span><span class="mord" style="margin-right:0.02778em;">_</span><span class="mord mathnormal">i</span><span class="mord mathnormal">d</span><span class="mclose">)</span></span></span></span></li><li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>b</mi><mi>o</mi><mi>o</mi><mi>l</mi><mo>←</mo><mi>p</mi><mi>u</mi><mi>t</mi><mo stretchy="false">(</mo><mi>k</mi><mi>e</mi><mi>y</mi><mo separator="true">,</mo><mi>v</mi><mi>a</mi><mi>l</mi><mi>u</mi><mi>e</mi><mo separator="true">,</mo><mi>c</mi><mi>t</mi><mi>x</mi><mi mathvariant="normal">_</mi><mi>i</mi><mi>d</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">bool\leftarrow put(key,value,ctx\_id)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathnormal">b</span><span class="mord mathnormal">o</span><span class="mord mathnormal">o</span><span class="mord mathnormal" style="margin-right:0.01968em;">l</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">←</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.06em;vertical-align:-0.31em;"></span><span class="mord mathnormal">p</span><span class="mord mathnormal">u</span><span class="mord mathnormal">t</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.03148em;">k</span><span class="mord mathnormal">e</span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">v</span><span class="mord mathnormal">a</span><span class="mord mathnormal" style="margin-right:0.01968em;">l</span><span class="mord mathnormal">u</span><span class="mord mathnormal">e</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal">c</span><span class="mord mathnormal">t</span><span class="mord mathnormal">x</span><span class="mord" style="margin-right:0.02778em;">_</span><span class="mord mathnormal">i</span><span class="mord mathnormal">d</span><span class="mclose">)</span></span></span></span></li><li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>v</mi><mi>a</mi><mi>l</mi><mi>u</mi><mi>e</mi><mo>←</mo><mi>g</mi><mi>e</mi><mi>t</mi><mo stretchy="false">(</mo><mi>k</mi><mi>e</mi><mi>y</mi><mo separator="true">,</mo><mi>c</mi><mi>t</mi><mi>x</mi><mi mathvariant="normal">_</mi><mi>i</mi><mi>d</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">value\leftarrow get(key,ctx\_id)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">v</span><span class="mord mathnormal">a</span><span class="mord mathnormal" style="margin-right:0.01968em;">l</span><span class="mord mathnormal">u</span><span class="mord mathnormal">e</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">←</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.06em;vertical-align:-0.31em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">g</span><span class="mord mathnormal">e</span><span class="mord mathnormal">t</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.03148em;">k</span><span class="mord mathnormal">e</span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal">c</span><span class="mord mathnormal">t</span><span class="mord mathnormal">x</span><span class="mord" style="margin-right:0.02778em;">_</span><span class="mord mathnormal">i</span><span class="mord mathnormal">d</span><span class="mclose">)</span></span></span></span> for COPS, or <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">⟨</mo><mi>v</mi><mi>a</mi><mi>l</mi><mi>u</mi><mi>e</mi><mi>s</mi><mo stretchy="false">⟩</mo><mo>←</mo><mi>g</mi><mi>e</mi><mi>t</mi><mi mathvariant="normal">_</mi><mi>t</mi><mi>r</mi><mi>a</mi><mi>n</mi><mi>s</mi><mo stretchy="false">(</mo><mo stretchy="false">⟨</mo><mi>k</mi><mi>e</mi><mi>y</mi><mi>s</mi><mo stretchy="false">⟩</mo><mo separator="true">,</mo><mi>c</mi><mi>t</mi><mi>x</mi><mi mathvariant="normal">_</mi><mi>i</mi><mi>d</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\langle values\rangle\leftarrow get\_trans(\langle keys\rangle,ctx\_id)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">⟨</span><span class="mord mathnormal" style="margin-right:0.03588em;">v</span><span class="mord mathnormal">a</span><span class="mord mathnormal" style="margin-right:0.01968em;">l</span><span class="mord mathnormal">u</span><span class="mord mathnormal">e</span><span class="mord mathnormal">s</span><span class="mclose">⟩</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">←</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.06em;vertical-align:-0.31em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">g</span><span class="mord mathnormal">e</span><span class="mord mathnormal">t</span><span class="mord" style="margin-right:0.02778em;">_</span><span class="mord mathnormal">t</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mord mathnormal">a</span><span class="mord mathnormal">n</span><span class="mord mathnormal">s</span><span class="mopen">(</span><span class="mopen">⟨</span><span class="mord mathnormal" style="margin-right:0.03148em;">k</span><span class="mord mathnormal">e</span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="mord mathnormal">s</span><span class="mclose">⟩</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal">c</span><span class="mord mathnormal">t</span><span class="mord mathnormal">x</span><span class="mord" style="margin-right:0.02778em;">_</span><span class="mord mathnormal">i</span><span class="mord mathnormal">d</span><span class="mclose">)</span></span></span></span> for COPS-GT<ul><li>COPS-GT provides <code>get_trans</code>, which returns a consistent view of multiple key-value pairs in a single call.</li></ul></li></ol><h4 id="what-is-the-context-in-library"><a class="markdownIt-Anchor" href="#what-is-the-context-in-library"></a> What is the context in library?</h4><ol><li>All functions take a context argument, which the library uses internally to track causal dependencies across each client’s operations.</li><li>The context defines the causal+ “thread of execution.” A single process may contain many separate threads of execution.</li><li>By separating different threads of execution, COPS avoids false dependencies that would result from intermixing them.</li></ol><h4 id="what-does-cops-gt-store-in-context"><a class="markdownIt-Anchor" href="#what-does-cops-gt-store-in-context"></a> What does COPS-GT store in context?</h4><ol><li><p>The client library in COPS-GT stores the client’s context in a table of <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">⟨</mo><mi>k</mi><mi>e</mi><mi>y</mi><mo separator="true">,</mo><mi>v</mi><mi>e</mi><mi>r</mi><mi>s</mi><mi>i</mi><mi>o</mi><mi>n</mi><mo separator="true">,</mo><mi>d</mi><mi>e</mi><mi>p</mi><mi>s</mi><mo stretchy="false">⟩</mo></mrow><annotation encoding="application/x-tex">\langle key, version, deps\rangle</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">⟨</span><span class="mord mathnormal" style="margin-right:0.03148em;">k</span><span class="mord mathnormal">e</span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">v</span><span class="mord mathnormal">e</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mord mathnormal">s</span><span class="mord mathnormal">i</span><span class="mord mathnormal">o</span><span class="mord mathnormal">n</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal">d</span><span class="mord mathnormal">e</span><span class="mord mathnormal">p</span><span class="mord mathnormal">s</span><span class="mclose">⟩</span></span></span></span> entries.</p><ul><li>Clients reference their context using a context ID (<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>c</mi><mi>t</mi><mi>x</mi><mi mathvariant="normal">_</mi><mi>i</mi><mi>d</mi></mrow><annotation encoding="application/x-tex">ctx\_id</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.00444em;vertical-align:-0.31em;"></span><span class="mord mathnormal">c</span><span class="mord mathnormal">t</span><span class="mord mathnormal">x</span><span class="mord" style="margin-right:0.02778em;">_</span><span class="mord mathnormal">i</span><span class="mord mathnormal">d</span></span></span></span>) in the API.</li></ul></li><li><p>When a client gets a key from the data store, the library adds this key and its causal dependencies to the context.</p></li><li><p>When a client puts a value, the library sets the put’s dependencies to the most recent version of each key in the current context.</p><ul><li>A successful put into the data store returns the version number v assigned to the written value.</li><li>The client library then adds this new entry, <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">⟨</mo><mi>k</mi><mi>e</mi><mi>y</mi><mo separator="true">,</mo><mi>v</mi><mo separator="true">,</mo><mi>D</mi><mo stretchy="false">⟩</mo></mrow><annotation encoding="application/x-tex">\langle key, v, D\rangle</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">⟨</span><span class="mord mathnormal" style="margin-right:0.03148em;">k</span><span class="mord mathnormal">e</span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">v</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">D</span><span class="mclose">⟩</span></span></span></span>, to the context.</li></ul></li></ol><h4 id="what-are-the-concerns-of-cops-gt-context"><a class="markdownIt-Anchor" href="#what-are-the-concerns-of-cops-gt-context"></a> What are the concerns of COPS-GT context?</h4><ol><li>The context therefore includes all values previously read or written in the client’s session, as well as all of those dependencies’ dependencies.</li><li>State requirements for storing these dependencies, both in the client library and in the data store.<ul><li>To mitigate the client and data-store state required to track dependencies, COPS-GT provides garbage collection.</li></ul></li><li>The number of potential checks that must occur when replicating writes between clusters, in order to ensure causal consistency.<ul><li>The dependencies that must be checked are termed the nearest dependencies.<ul><li>If the storage node committing a node determins that its direct dependencies are all committed, then it can infer that all former dependencies are also committed.</li><li>Hence, each dependency check only need to check nodes within <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1</mn></mrow><annotation encoding="application/x-tex">1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">1</span></span></span></span> step in the graph of causal dependencies.</li></ul></li><li>The nearest dependencies are sufficient for the key-value store to provide causal+ consistency.</li><li>The full dependency list is only needed to provide <code>get_trans</code> operations in COPS-GT.</li></ul></li></ol><h4 id="what-does-cops-store-in-context"><a class="markdownIt-Anchor" href="#what-does-cops-store-in-context"></a> What does COPS store in context?</h4><ol><li>It does not store or even retrieve the dependencies of any value it gets<ul><li>The retrieved value is nearer than any of its dependencies, rendering them unnecessary.</li><li>The COPS client library stores only <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">⟨</mo><mi>k</mi><mi>e</mi><mi>y</mi><mo separator="true">,</mo><mi>v</mi><mi>e</mi><mi>r</mi><mi>s</mi><mi>i</mi><mi>o</mi><mi>n</mi><mo stretchy="false">⟩</mo></mrow><annotation encoding="application/x-tex">\langle key, version\rangle</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">⟨</span><span class="mord mathnormal" style="margin-right:0.03148em;">k</span><span class="mord mathnormal">e</span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">v</span><span class="mord mathnormal">e</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mord mathnormal">s</span><span class="mord mathnormal">i</span><span class="mord mathnormal">o</span><span class="mord mathnormal">n</span><span class="mclose">⟩</span></span></span></span> entries.</li></ul></li><li>For a get operation, the retrieved <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">⟨</mo><mi>k</mi><mi>e</mi><mi>y</mi><mo separator="true">,</mo><mi>v</mi><mi>e</mi><mi>r</mi><mi>s</mi><mi>i</mi><mi>o</mi><mi>n</mi><mo stretchy="false">⟩</mo></mrow><annotation encoding="application/x-tex">\langle key, version\rangle</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">⟨</span><span class="mord mathnormal" style="margin-right:0.03148em;">k</span><span class="mord mathnormal">e</span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">v</span><span class="mord mathnormal">e</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mord mathnormal">s</span><span class="mord mathnormal">i</span><span class="mord mathnormal">o</span><span class="mord mathnormal">n</span><span class="mclose">⟩</span></span></span></span> is added to the context.</li><li>For a put operation, the library uses the current context as the nearest dependencies, clears the context, and then repopulates it with only this put.<ul><li>This put depends on all previous key-version pairs and thus is nearer than them.</li></ul></li></ol><h4 id="how-does-cops-or-cops-gt-write-to-local-cluster"><a class="markdownIt-Anchor" href="#how-does-cops-or-cops-gt-write-to-local-cluster"></a> How does COPS (or COPS-GT) write to local cluster?</h4><ol><li>All writes in COPS first go to the client’s local cluster and then propagate asynchronously to remote clusters.</li><li>The key-value store exports a single API call to provide both operations: <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">⟨</mo><mi>b</mi><mi>o</mi><mi>o</mi><mi>l</mi><mo separator="true">,</mo><mi>v</mi><mi>e</mi><mi>r</mi><mi>s</mi><mo stretchy="false">⟩</mo><mo>←</mo><mi>p</mi><mi>u</mi><mi>t</mi><mi mathvariant="normal">_</mi><mi>a</mi><mi>f</mi><mi>t</mi><mi>e</mi><mi>r</mi><mo stretchy="false">(</mo><mi>k</mi><mi>e</mi><mi>y</mi><mo separator="true">,</mo><mi>v</mi><mi>a</mi><mi>l</mi><mo separator="true">,</mo><mo stretchy="false">[</mo><mi>d</mi><mi>e</mi><mi>p</mi><mi>s</mi><mo stretchy="false">]</mo><mo separator="true">,</mo><mi>n</mi><mi>e</mi><mi>a</mi><mi>r</mi><mi>e</mi><mi>s</mi><mi>t</mi><mo separator="true">,</mo><mi>v</mi><mi>e</mi><mi>r</mi><mi>s</mi><mo>=</mo><mi mathvariant="normal">∅</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\langle bool,vers\rangle \leftarrow put\_after(key,val,[deps],nearest,vers=\empty)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">⟨</span><span class="mord mathnormal">b</span><span class="mord mathnormal">o</span><span class="mord mathnormal">o</span><span class="mord mathnormal" style="margin-right:0.01968em;">l</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">v</span><span class="mord mathnormal">e</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mord mathnormal">s</span><span class="mclose">⟩</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">←</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.06em;vertical-align:-0.31em;"></span><span class="mord mathnormal">p</span><span class="mord mathnormal">u</span><span class="mord mathnormal">t</span><span class="mord" style="margin-right:0.02778em;">_</span><span class="mord mathnormal">a</span><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="mord mathnormal">t</span><span class="mord mathnormal">e</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.03148em;">k</span><span class="mord mathnormal">e</span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">v</span><span class="mord mathnormal">a</span><span class="mord mathnormal" style="margin-right:0.01968em;">l</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mopen">[</span><span class="mord mathnormal">d</span><span class="mord mathnormal">e</span><span class="mord mathnormal">p</span><span class="mord mathnormal">s</span><span class="mclose">]</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal">n</span><span class="mord mathnormal">e</span><span class="mord mathnormal">a</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mord mathnormal">e</span><span class="mord mathnormal">s</span><span class="mord mathnormal">t</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">v</span><span class="mord mathnormal">e</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mord mathnormal">s</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord">∅</span><span class="mclose">)</span></span></span></span></li><li>When a client calls <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi><mi>u</mi><mi>t</mi><mo stretchy="false">(</mo><mi>k</mi><mi>e</mi><mi>y</mi><mo separator="true">,</mo><mi>v</mi><mi>a</mi><mi>l</mi><mo separator="true">,</mo><mi>c</mi><mi>t</mi><mi>x</mi><mi mathvariant="normal">_</mi><mi>i</mi><mi>d</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">put (key,val,ctx\_id)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.06em;vertical-align:-0.31em;"></span><span class="mord mathnormal">p</span><span class="mord mathnormal">u</span><span class="mord mathnormal">t</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.03148em;">k</span><span class="mord mathnormal">e</span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">v</span><span class="mord mathnormal">a</span><span class="mord mathnormal" style="margin-right:0.01968em;">l</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal">c</span><span class="mord mathnormal">t</span><span class="mord mathnormal">x</span><span class="mord" style="margin-right:0.02778em;">_</span><span class="mord mathnormal">i</span><span class="mord mathnormal">d</span><span class="mclose">)</span></span></span></span>,<ul><li>The library computes the complete set of dependencies deps, and identifies some of those dependency tuples as the value’s nearest ones.</li><li>The library then calls put after without the version argument (i.e., it sets <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>v</mi><mi>e</mi><mi>r</mi><mi>s</mi><mi>i</mi><mi>o</mi><mi>n</mi><mo>=</mo><mi mathvariant="normal">∅</mi></mrow><annotation encoding="application/x-tex">version=\empty</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.65952em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">v</span><span class="mord mathnormal">e</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mord mathnormal">s</span><span class="mord mathnormal">i</span><span class="mord mathnormal">o</span><span class="mord mathnormal">n</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.80556em;vertical-align:-0.05556em;"></span><span class="mord">∅</span></span></span></span>).</li><li>In COPS-GT, the library includes deps in the <code>put_after</code> call because dependencies must be stored with the value.</li><li>In COPS, the library only needs to include nearest and does not include deps.</li></ul></li><li>The key’s primary storage node in the local cluster assigns the key a version number and returns it to the client library.</li><li>Each client is restricted to a single outstanding put; this is necessary because later puts must know the version numbers of earlier puts so they may depend on them.</li><li>The put after operation ensures that val is committed to each cluster only after all of the entries in its dependency list have been written.<ul><li>In the client’s local cluster, this property holds automatically, as the local store provides linearizability.</li><li>If <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>y</mi></mrow><annotation encoding="application/x-tex">y</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span></span></span></span> depends on <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>x</mi></mrow><annotation encoding="application/x-tex">x</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathnormal">x</span></span></span></span>, then <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi><mi>u</mi><mi>t</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">put(x)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">p</span><span class="mord mathnormal">u</span><span class="mord mathnormal">t</span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mclose">)</span></span></span></span> must have been committed before <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi><mi>u</mi><mi>t</mi><mo stretchy="false">(</mo><mi>y</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">put(y)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">p</span><span class="mord mathnormal">u</span><span class="mord mathnormal">t</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="mclose">)</span></span></span></span> was issued.</li></ul></li></ol><h4 id="how-to-replica-writes-between-clusters"><a class="markdownIt-Anchor" href="#how-to-replica-writes-between-clusters"></a> How to replica writes between clusters?</h4><ol><li>After a write commits locally, the primary storage node asynchronously replicates that write to its equivalent nodes in different clusters using a stream of <code>put_after</code> operations.<ul><li>The primary node includes the key’s version number in the put after call.</li><li>The deps argument is included in COPS-GT, and not included in COPS.</li></ul></li><li>It requires the remote nodes receiving updates to commit an update only after its dependencies have been committed to the same cluster.<ul><li>A node that receives a put after request from another cluster must determine if the value’s nearest dependencies have already been satisfied locally.</li><li>It does so by issuing a check to the local nodes responsible for the those dependencies: <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>b</mi><mi>o</mi><mi>o</mi><mi>l</mi><mo>←</mo><mi>d</mi><mi>e</mi><mi>p</mi><mi mathvariant="normal">_</mi><mi>c</mi><mi>h</mi><mi>e</mi><mi>c</mi><mi>k</mi><mo stretchy="false">(</mo><mi>k</mi><mi>e</mi><mi>y</mi><mo separator="true">,</mo><mi>v</mi><mi>e</mi><mi>r</mi><mi>s</mi><mi>i</mi><mi>o</mi><mi>n</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">bool\leftarrow dep\_check(key, version)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathnormal">b</span><span class="mord mathnormal">o</span><span class="mord mathnormal">o</span><span class="mord mathnormal" style="margin-right:0.01968em;">l</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">←</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.06em;vertical-align:-0.31em;"></span><span class="mord mathnormal">d</span><span class="mord mathnormal">e</span><span class="mord mathnormal">p</span><span class="mord" style="margin-right:0.02778em;">_</span><span class="mord mathnormal">c</span><span class="mord mathnormal">h</span><span class="mord mathnormal">e</span><span class="mord mathnormal">c</span><span class="mord mathnormal" style="margin-right:0.03148em;">k</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.03148em;">k</span><span class="mord mathnormal">e</span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">v</span><span class="mord mathnormal">e</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mord mathnormal">s</span><span class="mord mathnormal">i</span><span class="mord mathnormal">o</span><span class="mord mathnormal">n</span><span class="mclose">)</span></span></span></span></li><li>The way that nearest dependencies are computed ensures that all dependencies have been satisfied before the value is committed, which in turn ensures causal consistency.</li></ul></li></ol><h4 id="how-to-read-values-in-cops"><a class="markdownIt-Anchor" href="#how-to-read-values-in-cops"></a> How to read values in COPS?</h4><ol><li>Reads are satisfied in the local cluster.</li><li>The library issues a read to the node responsible for the key in the local cluster: <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">⟨</mo><mi>v</mi><mi>a</mi><mi>l</mi><mi>u</mi><mi>e</mi><mo separator="true">,</mo><mi>v</mi><mi>e</mi><mi>r</mi><mi>s</mi><mi>i</mi><mi>o</mi><mi>n</mi><mo separator="true">,</mo><mi>d</mi><mi>e</mi><mi>p</mi><mi>s</mi><mo stretchy="false">⟩</mo><mo>←</mo><mi>g</mi><mi>e</mi><mi>t</mi><mi mathvariant="normal">_</mi><mi>b</mi><mi>y</mi><mi mathvariant="normal">_</mi><mi>v</mi><mi>e</mi><mi>r</mi><mi>s</mi><mi>i</mi><mi>o</mi><mi>n</mi><mo stretchy="false">(</mo><mi>k</mi><mi>e</mi><mi>y</mi><mo separator="true">,</mo><mi>v</mi><mi>e</mi><mi>r</mi><mi>s</mi><mi>i</mi><mi>o</mi><mi>n</mi><mo>=</mo><mi>L</mi><mi>A</mi><mi>T</mi><mi>E</mi><mi>S</mi><mi>T</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\langle value, version,deps\rangle\leftarrow get\_by\_version(key,version=LATEST)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">⟨</span><span class="mord mathnormal" style="margin-right:0.03588em;">v</span><span class="mord mathnormal">a</span><span class="mord mathnormal" style="margin-right:0.01968em;">l</span><span class="mord mathnormal">u</span><span class="mord mathnormal">e</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">v</span><span class="mord mathnormal">e</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mord mathnormal">s</span><span class="mord mathnormal">i</span><span class="mord mathnormal">o</span><span class="mord mathnormal">n</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal">d</span><span class="mord mathnormal">e</span><span class="mord mathnormal">p</span><span class="mord mathnormal">s</span><span class="mclose">⟩</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">←</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.06em;vertical-align:-0.31em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">g</span><span class="mord mathnormal">e</span><span class="mord mathnormal">t</span><span class="mord" style="margin-right:0.02778em;">_</span><span class="mord mathnormal">b</span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="mord" style="margin-right:0.02778em;">_</span><span class="mord mathnormal" style="margin-right:0.03588em;">v</span><span class="mord mathnormal">e</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mord mathnormal">s</span><span class="mord mathnormal">i</span><span class="mord mathnormal">o</span><span class="mord mathnormal">n</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.03148em;">k</span><span class="mord mathnormal">e</span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">v</span><span class="mord mathnormal">e</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mord mathnormal">s</span><span class="mord mathnormal">i</span><span class="mord mathnormal">o</span><span class="mord mathnormal">n</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">L</span><span class="mord mathnormal">A</span><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="mord mathnormal" style="margin-right:0.05764em;">E</span><span class="mord mathnormal" style="margin-right:0.05764em;">S</span><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="mclose">)</span></span></span></span></li><li>This read can request either the latest version of the key or a specific older one. Requesting a specific version is necessary to enable get transactions.</li><li>Upon receiving a response, the client library adds the <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">⟨</mo><mi>k</mi><mi>e</mi><mi>y</mi><mo separator="true">,</mo><mi>v</mi><mi>e</mi><mi>r</mi><mi>s</mi><mi>i</mi><mi>o</mi><mi>n</mi><mo separator="true">,</mo><mo stretchy="false">[</mo><mi>d</mi><mi>e</mi><mi>p</mi><mi>s</mi><mo stretchy="false">]</mo><mo stretchy="false">⟩</mo></mrow><annotation encoding="application/x-tex">\langle key,version,[deps]\rangle</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">⟨</span><span class="mord mathnormal" style="margin-right:0.03148em;">k</span><span class="mord mathnormal">e</span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">v</span><span class="mord mathnormal">e</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mord mathnormal">s</span><span class="mord mathnormal">i</span><span class="mord mathnormal">o</span><span class="mord mathnormal">n</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mopen">[</span><span class="mord mathnormal">d</span><span class="mord mathnormal">e</span><span class="mord mathnormal">p</span><span class="mord mathnormal">s</span><span class="mclose">]</span><span class="mclose">⟩</span></span></span></span> tuple to the client context, and returns value to the calling code.</li><li>The deps are stored only in COPS-GT, not in COPS.</li></ol><h4 id="why-does-cops-gt-need-to-proviced-get_trans-what-is-wrong-with-the-get-interface"><a class="markdownIt-Anchor" href="#why-does-cops-gt-need-to-proviced-get_trans-what-is-wrong-with-the-get-interface"></a> Why does COPS-GT need to proviced get_trans? What is wrong with the get interface?</h4><ol><li>Reading a set of dependent keys using a single-key get interface cannot ensure causal+ consistency, even though the data store itself is causal+ consistent.</li><li>It may have a “time-to-check-to-time-to-use” race condition, i.e. check operation and usage is not an atomic operation.</li><li>The standard way to achieve such a guarantee is to read and write all related keys in a transaction<ul><li>This requires a single serialization point for all grouped keys, which COPS avoids for greater scalability and simplicity.</li></ul></li></ol><h4 id="how-does-get_trans-work"><a class="markdownIt-Anchor" href="#how-does-get_trans-work"></a> How does get_trans work?</h4><ol><li><p>To retrieve multiple values in a causal+ consistent manner, a client calls get trans with the desired set of keys.</p></li><li><p>In the first round, the library issues n concurrent <code>get_by_version</code> operations to the local cluster, one for each key the client listed in <code>get_trans</code>.</p><ul><li><p>Because COPS-GT commits writes locally, the local data store guarantees that each of these explicitly listed keys’ dependencies are already satisfied</p></li><li><p>All listed keys have been written locally and reads on them will immediately return.</p></li><li><p>Each <code>get_by_version</code> operation returns a <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">⟨</mo><mi>v</mi><mi>a</mi><mi>l</mi><mi>u</mi><mi>e</mi><mo separator="true">,</mo><mi>v</mi><mi>e</mi><mi>r</mi><mi>s</mi><mi>i</mi><mi>o</mi><mi>n</mi><mo separator="true">,</mo><mi>d</mi><mi>e</mi><mi>p</mi><mi>s</mi><mo stretchy="false">⟩</mo></mrow><annotation encoding="application/x-tex">\langle value, version, deps\rangle</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">⟨</span><span class="mord mathnormal" style="margin-right:0.03588em;">v</span><span class="mord mathnormal">a</span><span class="mord mathnormal" style="margin-right:0.01968em;">l</span><span class="mord mathnormal">u</span><span class="mord mathnormal">e</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">v</span><span class="mord mathnormal">e</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mord mathnormal">s</span><span class="mord mathnormal">i</span><span class="mord mathnormal">o</span><span class="mord mathnormal">n</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal">d</span><span class="mord mathnormal">e</span><span class="mord mathnormal">p</span><span class="mord mathnormal">s</span><span class="mclose">⟩</span></span></span></span> tuple, where deps is a list of keys and versions.</p></li></ul></li><li><p>The client library then examines every dependency entry <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">⟨</mo><mi>k</mi><mi>e</mi><mi>y</mi><mo separator="true">,</mo><mi>v</mi><mi>e</mi><mi>r</mi><mi>s</mi><mi>i</mi><mi>o</mi><mi>n</mi><mo stretchy="false">⟩</mo></mrow><annotation encoding="application/x-tex">\langle key, version\rangle</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">⟨</span><span class="mord mathnormal" style="margin-right:0.03148em;">k</span><span class="mord mathnormal">e</span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">v</span><span class="mord mathnormal">e</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mord mathnormal">s</span><span class="mord mathnormal">i</span><span class="mord mathnormal">o</span><span class="mord mathnormal">n</span><span class="mclose">⟩</span></span></span></span>.</p><ul><li>The causal dependencies for that result are satisfied<ul><li>If either the client did not request the dependent key.</li><li>Or if it did, the version it retrieved was <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>≥</mo></mrow><annotation encoding="application/x-tex">≥</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7719400000000001em;vertical-align:-0.13597em;"></span><span class="mrel">≥</span></span></span></span> the version in the dependency list.</li></ul></li></ul></li><li><p>For all keys that are not satisfied, the library issues a second round of concurrent get by version operations.</p><ul><li>The version requested will be the newest version seen in any dependency list from the first round.</li><li>These versions satisfy all causal dependencies from the first round because they are <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>≥</mo></mrow><annotation encoding="application/x-tex">≥</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7719400000000001em;vertical-align:-0.13597em;"></span><span class="mrel">≥</span></span></span></span> the needed versions.</li><li>Because dependencies are transitive and these second-round versions are all depended on by versions retrieved in the first round, they do not introduce any new dependencies that need to be satisfied.</li></ul></li><li><p>The second round happens only when the client must read newer versions than those retrieved in the first round.</p><ul><li>This case occurs only if keys involved in the get transaction are updated during the first round.</li></ul></li></ol><h3 id="garbage-collection"><a class="markdownIt-Anchor" href="#garbage-collection"></a> Garbage collection</h3><h4 id="how-does-cops-gt-collect-version-garbage"><a class="markdownIt-Anchor" href="#how-does-cops-gt-collect-version-garbage"></a> How does COPS-GT collect version garbage?</h4><ol><li>The <code>get_trans</code> algorithm limits the number of versions needed to complete a get transaction.<ul><li>COPS-GT limits the total running time of get trans through a configurable parameter, <code>trans_time</code>.</li><li>If the timeout fires, the client library will restart the get trans call and satisfy the transaction with newer versions of the keys.</li></ul></li><li>After a new version of a key is written, COPS-GT only needs to keep the old version around for <code>trans_time</code> plus a small delta for clock skew.</li><li>The space overhead is bounded by the number of old versions that can be created within the <code>trans_time</code>.<ul><li>This number is determined by the maximum write throughput that the node can sustain.</li><li>This overhead is per-machine and does not grow with the cluster size or the number of datacenters.</li></ul></li></ol><h4 id="how-does-cops-gt-collect-dependency-garbage"><a class="markdownIt-Anchor" href="#how-does-cops-gt-collect-dependency-garbage"></a> How does COPS-GT collect dependency garbage?</h4><ol><li>COPS-GT can garbage collect these dependencies once the versions associated with old dependencies are no longer needed for correctness in get transaction operations.</li><li>After <code>trans_time</code> seconds after a value has been committed in all datacenters, COPS-GT can clean a value’s dependencies.<ul><li>To clean dependencies each remote datacenter notifies the originating datacenter when the write has committed and the timeout period has elapsed.</li><li>Once all datacenters confirm, the originating datacenter cleans its own dependencies and informs the others to do likewise.</li></ul></li><li>To minimize bandwidth devoted to cleaning dependencies, a replica only notifies the originating datacenter if this version of a key is the newest after <code>trans_time</code> seconds<ul><li>If it is not, there is no need to collect the dependencies because the entire version will be collected.</li></ul></li><li>Under normal operation, dependencies are garbage collected after <code>trans_time</code> plus a round-trip time.</li><li>During a partition, dependencies on the most recent versions of keys cannot be collected.</li></ol><h4 id="how-does-cops-collect-client-metadata-garbage"><a class="markdownIt-Anchor" href="#how-does-cops-collect-client-metadata-garbage"></a> How does COPS collect client metadata garbage?</h4><ol><li>The COPS client library tracks all operations during a client session (single thread of execution) using the ctx id passed with all operation.<ul><li>In both systems, each get since the last put adds another nearest dependency.</li><li>Additionally in COPS-GT, all new values and their dependencies returned in get trans operations and all put operations add normal dependencies.</li></ul></li><li>Clients need to track dependencies only until they are guaranteed to be satisfied everywhere.</li><li>Once a <code>put_after</code> commits successfully to all datacenters, COPS flags that key version as <em>never-depend</em>, in order to indicate that clients need not express a dependence upon it.<ul><li>The client library will immediately remove a never-depend item from the list of dependencies in the client context.</li><li>Anything that a never-depend key depended on must have been flagged never-depend, so it too can be garbage collected from the context.</li></ul></li><li>The COPS storage nodes remove unnecessary dependencies from <code>put_after</code> operations.<ul><li>When a node receives a <code>put_after</code>, it checks each item in the dependency list and removes items with version numbers older than a global checkpoint time.</li></ul></li></ol><h3 id="fault-tolerance"><a class="markdownIt-Anchor" href="#fault-tolerance"></a> Fault tolerance</h3><h4 id="how-does-cops-handle-client-failures"><a class="markdownIt-Anchor" href="#how-does-cops-handle-client-failures"></a> How does COPS handle client failures?</h4><ol><li>From the storage system’s perspective, if a client fails, it simply stops issuing new requests; no recovery is necessary.</li><li>From a client’s perspective, COPS’s dependency tracking makes it easier to handle failures of other clients, by ensuring properties such as referential integrity.</li></ol><h4 id="how-does-cops-handle-key-value-node-failures"><a class="markdownIt-Anchor" href="#how-does-cops-handle-key-value-node-failures"></a> How does COPS handle key-value node failures?</h4><ol><li><p>COPS can use any underlying faulttolerant linearizable key-value store.</p><ul><li>The author uses chain replication within a cluster to mask node failures.</li></ul></li><li><p>Dependency garbage collection follows a similar pattern of interlocking chains.</p><p>Version garbage collection is done locally on each node and can operate as in the single node case.</p><p>Calculation of the global checkpoint time, for client metadata garbage collection, operates normally with each tail updating its corresponding key range minimums.</p></li></ol><h4 id="what-will-happen-when-datacenter-failed"><a class="markdownIt-Anchor" href="#what-will-happen-when-datacenter-failed"></a> What will happen when datacenter failed?</h4><ol><li>Any put after operations that originated in the failed datacenter, but which were not yet copied out, will be lost.</li><li>The storage required for replication queues in the active datacenters will grow.<ul><li>They will be unable to send put after operations to the failed datacenter, and thus COPS will be unable to garbage collect those dependencies.</li><li>Solutions: Allow the queues to grow if the partition is likely to heal soon, or reconfigure COPS to no longer use the failed datacenter.</li></ul></li></ol><h4 id="how-does-cops-with-conflict-detection-cops-cd-detect-conflict"><a class="markdownIt-Anchor" href="#how-does-cops-with-conflict-detection-cops-cd-detect-conflict"></a> How does COPS with conflict detection (COPS-CD) detect conflict?</h4><ol><li>All put operations carry with them previous version metadata<ul><li>It indicates the most recent previous version of the key that was visible at the local cluster at the time of the write.</li></ul></li><li>All put operations now have an implicit dependency on that previous version<ul><li>This ensures that a new version will only be written after its previous version.</li></ul></li><li>COPS-CD has an applicationspecified convergent conflict handler that is invoked when a conflict is detected.<ul><li>A put operation <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi><mi>e</mi><mi>w</mi></mrow><annotation encoding="application/x-tex">new</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathnormal">n</span><span class="mord mathnormal">e</span><span class="mord mathnormal" style="margin-right:0.02691em;">w</span></span></span></span> to a key (with previous version <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi><mi>r</mi><mi>e</mi><mi>v</mi></mrow><annotation encoding="application/x-tex">prev</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord mathnormal">p</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mord mathnormal">e</span><span class="mord mathnormal" style="margin-right:0.03588em;">v</span></span></span></span>) is in conflict with the key’s current visible version <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>c</mi><mi>u</mi><mi>r</mi><mi>r</mi></mrow><annotation encoding="application/x-tex">curr</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathnormal">c</span><span class="mord mathnormal">u</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span></span></span></span>: <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi><mi>r</mi><mi>e</mi><mi>v</mi><mo mathvariant="normal">≠</mo><mi>c</mi><mi>u</mi><mi>r</mi><mi>r</mi></mrow><annotation encoding="application/x-tex">prev \neq curr</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord mathnormal">p</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mord mathnormal">e</span><span class="mord mathnormal" style="margin-right:0.03588em;">v</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel"><span class="mrel"><span class="mord vbox"><span class="thinbox"><span class="rlap"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="inner"><span class="mrel"></span></span><span class="fix"></span></span></span></span></span><span class="mrel">=</span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathnormal">c</span><span class="mord mathnormal">u</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span></span></span></span> if and only if <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi><mi>e</mi><mi>w</mi></mrow><annotation encoding="application/x-tex">new</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathnormal">n</span><span class="mord mathnormal">e</span><span class="mord mathnormal" style="margin-right:0.02691em;">w</span></span></span></span> and <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>c</mi><mi>u</mi><mi>r</mi><mi>r</mi></mrow><annotation encoding="application/x-tex">curr</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathnormal">c</span><span class="mord mathnormal">u</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span></span></span></span> conflict.</li></ul></li></ol>]]></content>
      
      
      <categories>
          
          <category> Paper Notebook </category>
          
          <category> Distributed System </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Distributed System </tag>
            
            <tag> Consistency Level </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Memcache</title>
      <link href="/2023/09/26/Paper/Distributed/Memcache/"/>
      <url>/2023/09/26/Paper/Distributed/Memcache/</url>
      
        <content type="html"><![CDATA[<p>Paper: <a href="http://nil.csail.mit.edu/6.824/2020/papers/memcache-fb.pdf">Scaling Memcache at Facebook</a></p><p><ul class="markdownIt-TOC"><li><a href="#purpose">Purpose</a></li><li><a href="#model">Model</a><ul><li><a href="#overview">Overview</a><ul><li><a href="#how-does-queries-carry-out-with-memcache">How does queries carry out with memcache?</a></li><li><a href="#how-does-writes-carry-out-with-memcache">How does writes carry out with memcache?</a></li><li><a href="#what-are-the-stages-of-problems-when-user-increasing">What are the stages of problems when user increasing?</a></li><li><a href="#what-are-the-consistent-requirements">What are the consistent requirements?</a></li></ul></li><li><a href="#in-a-cluster-latency-and-load">In a cluster: latency and load</a><ul><li><a href="#how-does-clients-communicate-with-memcached-servers">How does clients communicate with memcached servers?</a></li><li><a href="#how-to-handle-incast-congestion">How to handle incast congestion?</a></li><li><a href="#how-to-prevent-stale-sets-problem">How to prevent stale sets problem?</a></li><li><a href="#how-to-prevent-thundering-herds">How to prevent thundering herds?</a></li><li><a href="#how-to-prevent-hit-rates-decreasing-caused-by-different-client-access-patterns">How to prevent hit rates decreasing caused by different client access patterns?</a></li><li><a href="#how-to-handle-small-number-memcache-server-inaccessible-due-to-network-or-server-failure">How to handle small number memcache server inaccessible due to network or server failure?</a></li></ul></li><li><a href="#in-a-region-replication">In a region: replication</a><ul><li><a href="#what-is-the-problem-of-scaling-memcache">What is the problem of scaling memcache?</a></li><li><a href="#how-to-mitigate-the-poor-hit-rates-when-a-cold-cluster-starts-up">How to mitigate the poor hit rates when a cold cluster starts up?</a></li><li><a href="#how-to-solve-the-race-in-cold-cluster-warmup-caused-by-update-in-cold-cluster">How to solve the race in cold cluster warmup caused by update in cold cluster?</a></li></ul></li><li><a href="#across-regions-consistency">Across regions: consistency</a><ul><li><a href="#how-to-execute-a-write-operation">How to execute a write operation?</a></li></ul></li></ul></li></ul></p><h1 id="purpose"><a class="markdownIt-Anchor" href="#purpose"></a> Purpose</h1><ol><li><p>Issues:</p><ul><li>Users consume an order of magnitude more content than they create.<ul><li>This behavior results in a workload dominated by fetching data and suggests that caching can have significant advantages.</li></ul></li><li>Read operations fetch data from a variety of sources<ul><li>This heterogeneity requires a flexible caching strategy able to store data from disparate sources.</li></ul></li></ul></li><li><p>The requirement of a social network’s infrastructure?</p><ul><li><p>Allow near realtime communication</p></li><li><p>Aggregate content on-the-fly from multiple sources</p></li><li><p>Be able to access and update very popular shared content</p></li><li><p>Scale to process millions of user requests per second</p></li></ul></li><li><p>Memcached is an open-source implementation of an in-memory hash table, which provides low latency access to a shared storage pool at low cost.</p></li><li><p>Findings:</p><ul><li>While qualities like performance, efficiency, fault-tolerance, and consistency are important at all scales, at specific sizes some qualities require more effort to achieve than others.</li><li>The importance of finding an optimal communication schedule increases as the number of servers increase and networking becomes the bottleneck.</li></ul></li></ol><h1 id="model"><a class="markdownIt-Anchor" href="#model"></a> Model</h1><h2 id="overview"><a class="markdownIt-Anchor" href="#overview"></a> Overview</h2><h3 id="how-does-queries-carry-out-with-memcache"><a class="markdownIt-Anchor" href="#how-does-queries-carry-out-with-memcache"></a> How does queries carry out with memcache?</h3><ol><li>When a web server needs data, it first requests the value from memcache by providing a string key.</li><li>If the item addressed by that key is not cached, the web server retrieves the data from the database or other backend service and populates the cache with the key-value pair.</li></ol><img src="/imgs/Distributed/Memcache/read.png" width="30%"><h3 id="how-does-writes-carry-out-with-memcache"><a class="markdownIt-Anchor" href="#how-does-writes-carry-out-with-memcache"></a> How does writes carry out with memcache?</h3><ol><li>For write requests, the web server issues SQL statements to the database and then sends a delete request to memcache that invalidates any stale data.</li><li>We choose to delete cached data instead of updating it because deletes are idempotent.<ul><li>Consider two concurrent writes, there is no guarantee that the update operation is in the same order as database updates.</li><li>If database updates write A first, then write B while memcache set write B first then write A, the memcache would be inconsistent with database.</li></ul></li></ol><img src="/imgs/Distributed/Memcache/write.png" width="30%"><h3 id="what-are-the-stages-of-problems-when-user-increasing"><a class="markdownIt-Anchor" href="#what-are-the-stages-of-problems-when-user-increasing"></a> What are the stages of problems when user increasing?</h3><ol><li>At the beginning, there is no much users, the service can be provided with a single server running both scripts and database.</li><li>As the number of users growing, the first problem is usually that the server run out of CPU to execute scripts.<ul><li>Hence the solution is to use multiple servers to run scripts, and another server to run database.</li></ul></li><li>If the number of users keeps growing, the next problem is that the database run out of steam.<ul><li>The solution is usually using a distributed sharding database system. This is when all those consistent problem comes.</li></ul></li><li>However, the MySQL cannot process reads and writes fast. And if there are some keys being the hot zone, no matter how delicate we sharding, there is only one group for that key.<ul><li>The FaceBook uses memcache to solve this situation when most read requests are absorbed by memcache servers, only few are exposed to database servers.</li></ul></li></ol><h3 id="what-are-the-consistent-requirements"><a class="markdownIt-Anchor" href="#what-are-the-consistent-requirements"></a> What are the consistent requirements?</h3><ol><li>When user only reads data, they can barely notice the stale data for a few seconds, but not too long, like data from yesterday.</li><li>When users changed something, if they immediately try to read it, they should see the data they changed. There should not have any stale in this case.</li></ol><h2 id="in-a-cluster-latency-and-load"><a class="markdownIt-Anchor" href="#in-a-cluster-latency-and-load"></a> In a cluster: latency and load</h2><h3 id="how-does-clients-communicate-with-memcached-servers"><a class="markdownIt-Anchor" href="#how-does-clients-communicate-with-memcached-servers"></a> How does clients communicate with memcached servers?</h3><ol><li>Client logic is provided as two components: a library that can be embedded into applications or as a standalone proxy named <em>mcrouter</em>.<ul><li>This proxy presents a <em>memcached</em> server interface and routes the requests/replies to/from other servers.</li></ul></li><li><code>get</code> requests is relied on UDP to reduce latency and overhead.<ul><li>Each thread in the web server is allowed to directly communicate with <em>memcached</em> servers directly, bypassing <em>mcrouter</em>, without establishing and maintaining a connection thereby reducing the overhead.</li><li>The UDP implementation detects packets that are dropped or received out of order (using sequence numbers) and treats them as errors on the client side. It does not provide any mechanism to try to recover from them.</li></ul></li><li>For reliability, clients perform <code>set</code> and <code>delete</code> operations over TCP through an instance of <em>mcrouter</em> running on the same machine as the web server.<ul><li>For operations where we need to confirm a state change (<code>update</code>s and <code>delete</code>s) TCP alleviates the need to add a retry mechanism to our UDP implementation.</li></ul></li></ol><h3 id="how-to-handle-incast-congestion"><a class="markdownIt-Anchor" href="#how-to-handle-incast-congestion"></a> How to handle incast congestion?</h3><ol><li>Web servers have to routinely communicate with many memcached servers to satisfy a user request.<ul><li>As a result, all web servers communicate with every memcached server in a short period of time.</li><li>This all-to-all communication pattern can cause incast congestion or allow a single server to become the bottleneck for many web servers.</li></ul></li><li>Memcache clients implement flowcontrol mechanisms to limit incast congestion.<ul><li>Clients use a sliding window mechanism to control the number of outstanding requests.</li><li>The size of this sliding window grows slowly upon a successful request and shrinks when a request goes unanswered.</li><li>With lower window sizes, the application will have to dispatch more groups of memcache requests serially, increasing the duration of the web request.</li><li>As the window size gets too large, the number of simultaneous memcache requests causes incast congestion.</li></ul></li></ol><h3 id="how-to-prevent-stale-sets-problem"><a class="markdownIt-Anchor" href="#how-to-prevent-stale-sets-problem"></a> How to prevent stale sets problem?</h3><ol><li>A stale set occurs when a web server sets a value in <em>memcache</em> that does not reflect the latest value that should be cached.<ul><li>For example, when server A tried to read an entry <code>get(k)</code> and missed, it read a value <code>v1</code> from database. But before its <code>set(k, v1)</code> being executed, another server updated <code>k=v2</code> and executed <code>delete(k)</code>.</li><li>The problem is that after <code>delete(k)</code> is executed, there is no mechanism to prevent the stale <code>set(k, v1)</code> being executed. Hence a stale entry will be left in the <em>memcache</em> for indefinite long time.</li></ul></li><li>A memcached instance gives a lease to a client to set data back into the cache when that client experiences a cache miss.<ul><li>The lease is a 64-bit token bound to the specific key the client originally requested.</li><li>The client provides the lease token when setting the value in the cache.</li><li>Verification can fail if memcached has invalidated the lease token due to receiving a delete request for that item.</li></ul></li></ol><h3 id="how-to-prevent-thundering-herds"><a class="markdownIt-Anchor" href="#how-to-prevent-thundering-herds"></a> How to prevent thundering herds?</h3><ol><li>A thundering herd happens when a specific key undergoes heavy read and write activity.<ul><li>If one client updates database and deletes a key, lots of clients <code>get()</code> but miss causing that they all try to fetch from database and all <code>set()</code>.</li></ul></li><li>Each memcached server regulates the rate at which it returns lease tokens.<ul><li>Each memcached server only return a lease token every period of time.</li><li>Other cache misses during that period will receive a special notification telling the client to wait a shot amount of time.</li><li>Return a lease every period of time instead of only return to first cache miss is to prevent the first client failed to acquire data from database.</li></ul></li></ol><h3 id="how-to-prevent-hit-rates-decreasing-caused-by-different-client-access-patterns"><a class="markdownIt-Anchor" href="#how-to-prevent-hit-rates-decreasing-caused-by-different-client-access-patterns"></a> How to prevent hit rates decreasing caused by different client access patterns?</h3><ol><li>A cluster’s memcached servers are partitioned into separate pools.<ul><li>One pool (named <em>wildcard</em>) is designated as the default.</li><li>Separate pools are provided for keys whose residence in wildcard is problematic.</li></ul></li><li>Within some pools, replication can be used to improve the latency and efficiency.<ul><li>Choose to replicate a category of keys within a pool when<ul><li>The application routinely fetches many keys simultaneously</li><li>The entire data set fits in one or two memcached servers</li><li>The request rate is much higher than what a single server can manage</li></ul></li><li>Favor replication in this instance over further dividing the key space due to the following reasons:<ul><li>The difference in memcached overhead for retrieving 100 keys per request instead of 1 key is small.</li><li>Replicating can reduce the requests need to be processed by each server, while dividing the key space can only reduce the keys retrieved from each server and increase the number of requests.</li></ul></li></ul></li></ol><h3 id="how-to-handle-small-number-memcache-server-inaccessible-due-to-network-or-server-failure"><a class="markdownIt-Anchor" href="#how-to-handle-small-number-memcache-server-inaccessible-due-to-network-or-server-failure"></a> How to handle small number memcache server inaccessible due to network or server failure?</h3><ol><li><p>For small outages, it relies on an automated remediation system.</p><ul><li>These actions are not instant and can take up to a few minutes.</li><li>This duration is long enough to cause the aforementioned cascading failures.</li></ul></li><li><p>A small set of machines, named <em>Gutter</em>, takes over the responsibilities of a few failed servers.</p><ul><li><p>Gutter accounts for approximately 1% of the memcached servers in a cluster.</p></li><li><p>When a memcached client receives no response to its get request, the client assumes the server has failed and issues the request again to a special Gutter pool.</p></li><li><p>If this second request misses, the client will insert the appropriate key-value pair into the Gutter machine after querying the database.</p></li><li><p>Entries in Gutter expire quickly to obviate Gutter invalidations.</p></li><li><p>Gutter limits the load on backend services at the cost of slightly stale data.</p></li></ul></li><li><p>This design differs from an approach in which a client rehashes keys among the remaining memcached servers.</p><ul><li>The server that becomes responsible for this hot key might also become overloaded. By shunting load to idle servers we limit that risk.</li></ul></li></ol><h2 id="in-a-region-replication"><a class="markdownIt-Anchor" href="#in-a-region-replication"></a> In a region: replication</h2><h3 id="what-is-the-problem-of-scaling-memcache"><a class="markdownIt-Anchor" href="#what-is-the-problem-of-scaling-memcache"></a> What is the problem of scaling memcache?</h3><ol><li><p>In communication traffic:</p><ul><li><p>Highly requested items will only become more popular as more web servers are added to cope with increased user traffic.</p></li><li><p>Incast congestion also worsens as the number of memcached servers increases.</p></li><li><p>Split web and memcached servers into multiple <em>frontend</em> clusters.</p></li><li><p>These clusters, along with a storage cluster that contain the databases, define a region.</p></li></ul></li><li><p>The number of invalidations will increase</p><ul><li>The storage cluster is responsible for invalidating cached data to keep frontend clusters consistent with the authoritative versions.</li><li>As an optimization, a web server that modifies data also sends invalidations to its own cluster to provide read-after-write semantics for a single user request and reduce the amount of time stale data is present in its local cache.</li><li>Also batch invalidations can reduce packet rates.</li></ul></li><li><p>If users’ requests are randomly routed to all available frontend clusters then the cached data will be roughly the same across all the frontend clusters.</p><ul><li><p>Over-replicating the data can be memory inefficient, especially for large, rarely accessed items.</p></li><li><p>Reduce the number of replicas by having multiple frontend clusters share the same set of memcached servers which is call a regional pool.</p></li></ul></li></ol><h3 id="how-to-mitigate-the-poor-hit-rates-when-a-cold-cluster-starts-up"><a class="markdownIt-Anchor" href="#how-to-mitigate-the-poor-hit-rates-when-a-cold-cluster-starts-up"></a> How to mitigate the poor hit rates when a cold cluster starts up?</h3><ol><li>When we bring a new cluster online, an existing one fails, or perform scheduled maintenance the caches will have very poor hit rates diminishing the ability to insulate backend services.</li><li>A system called Cold Cluster Warmup mitigates this by allowing clients in the “cold cluster” (i.e. the frontend cluster that has an empty cache) to retrieve data from the “warm cluster” (i.e. a cluster that has caches with normal hit rates) rather than the persistent storage.</li><li>With this system cold clusters can be brought back to full capacity in a few hours instead of a few days.</li><li>The cold cluster warmup is turned off once the cold cluster’s hit rate stabilizes and the benefits diminish.</li></ol><h3 id="how-to-solve-the-race-in-cold-cluster-warmup-caused-by-update-in-cold-cluster"><a class="markdownIt-Anchor" href="#how-to-solve-the-race-in-cold-cluster-warmup-caused-by-update-in-cold-cluster"></a> How to solve the race in cold cluster warmup caused by update in cold cluster?</h3><ol><li>If a client in the cold cluster does a database update, and a subsequent request from another client retrieves the stale value from the warm cluster before the warm cluster has received the invalidation, that item will be indefinitely inconsistent in the cold cluster.</li><li>Memcached deletes support nonzero hold-off times that reject add operations for the specified hold-off time.<ul><li>By default, all deletes to the cold cluster are issued with a two second hold-off.</li><li>When a miss is detected in the cold cluster, the client re-requests the key from the warm cluster and adds it into the cold cluster.</li><li>The failure of the add indicates that newer data is available on the database and thus the client will refetch the value from the databases.</li></ul></li></ol><h2 id="across-regions-consistency"><a class="markdownIt-Anchor" href="#across-regions-consistency"></a> Across regions: consistency</h2><h3 id="how-to-execute-a-write-operation"><a class="markdownIt-Anchor" href="#how-to-execute-a-write-operation"></a> How to execute a write operation?</h3><ol><li><p>Of many regions, one region is designated to hold the master databases and the other regions to contain read-only replicas.</p></li><li><p>For writes from a master region:</p><ul><li><p>The storage cluster of each region will send invalidations after they have replicated data.</p></li><li><p>It avoids a race condition in which an invalidation arrives before the data has been replicated from the master region.</p></li></ul></li><li><p>For writes from a non-master region:</p><ul><li>The user’s next request could result in confusion if his recent change is missing.</li><li>Employ a remote marker mechanism to minimize the probability of reading stale data.<ul><li>The presence of the marker indicates that data in the local replica database are potentially stale and the query should be redirected to the master region.</li></ul></li><li>When a web server wishes to update data that affects a key <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi></mrow><annotation encoding="application/x-tex">k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.03148em;">k</span></span></span></span>, that server<ul><li>sets a remote marker <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>r</mi><mi>k</mi></msub></mrow><annotation encoding="application/x-tex">r_k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> in the region</li><li>performs the write to the master embedding <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi></mrow><annotation encoding="application/x-tex">k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.03148em;">k</span></span></span></span> and <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>r</mi><mi>k</mi></msub></mrow><annotation encoding="application/x-tex">r_k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> to be invalidated in the SQL statement</li><li>deletes <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi></mrow><annotation encoding="application/x-tex">k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.03148em;">k</span></span></span></span> in the local cluster</li></ul></li><li>On a subsequent request for <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi></mrow><annotation encoding="application/x-tex">k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.03148em;">k</span></span></span></span>,<ul><li>A web server will be unable to find the cached data</li><li>Check whether <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>r</mi><mi>k</mi></msub></mrow><annotation encoding="application/x-tex">r_k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> exists</li><li>Direct its query to the master or local region depending on the presence of <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>r</mi><mi>k</mi></msub></mrow><annotation encoding="application/x-tex">r_k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>.</li></ul></li><li>The remote markers are implemented by using a regional pool.</li><li>This mechanism may reveal stale information during concurrent modifications to the same key as one operation may delete a remote marker that should remain present for another in-flight operation.</li></ul></li></ol>]]></content>
      
      
      <categories>
          
          <category> Paper Notebook </category>
          
          <category> Distributed System </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Distributed System </tag>
            
            <tag> Cache System </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Spark</title>
      <link href="/2023/09/26/Paper/Distributed/Spark/"/>
      <url>/2023/09/26/Paper/Distributed/Spark/</url>
      
        <content type="html"><![CDATA[<p>Paper: <a href="http://nil.csail.mit.edu/6.824/2020/papers/zaharia-spark.pdf">Resilient Distributed Datasets: A Fault-Tolerant Abstraction for In-Memory Cluster Computing</a></p><p><ul class="markdownIt-TOC"><li><a href="#purpose">Purpose</a></li><li><a href="#model">Model</a><ul><li><a href="#rdds">RDDs</a><ul><li><a href="#what-is-rdd">What is RDD?</a></li><li><a href="#what-is-the-advantges-of-the-rdd-model-comparing-with-distributed-shared-memory-dsm">What is the advantges of the RDD model comparing with distributed shared memory (DSM)?</a></li><li><a href="#what-kind-of-applications-are-suited-for-rdds">What kind of applications are suited for RDDs?</a></li></ul></li><li><a href="#spark">Spark</a><ul><li><a href="#what-is-the-runtime-of-spark">What is the runtime of Spark?</a></li><li><a href="#what-is-spark-programming-interface-of-rdds">What is Spark programming interface of RDDs?</a></li><li><a href="#what-rdd-operations-are-supported-in-spark">What RDD operations are supported in Spark?</a></li><li><a href="#what-is-the-common-interface-of-each-rdd">What is the common interface of each RDD?</a></li><li><a href="#what-is-the-interface-of-representing-dependencies-between-rdds">What is the interface of representing dependencies between RDDs?</a></li></ul></li><li><a href="#implementation">Implementation</a><ul><li><a href="#how-does-spark-schedule-computations">How does Spark schedule computations?</a></li><li><a href="#how-does-spark-handle-task-failures">How does Spark handle task failures?</a></li><li><a href="#how-does-spark-manage-storage-of-persistent-rdds">How does Spark manage storage of persistent RDDs?</a></li><li><a href="#how-does-spark-evict-rdds-when-run-out-of-memory">How does Spark evict RDDs when run out of memory?</a></li><li><a href="#when-will-checkpointing-be-useful">When will checkpointing be useful?</a></li></ul></li></ul></li><li><a href="#experiement">Experiement</a></li></ul></p><h1 id="purpose"><a class="markdownIt-Anchor" href="#purpose"></a> Purpose</h1><ol><li><p>Contribution:</p><ul><li>Present Resilient Distributed Datasets (RDDs), a distributed memory abstraction that lets programmers perform in-memory computations on large clusters in a fault-tolerant manner.</li><li>RDDs provide an interface based on coarse-grained transformations (e.g., map, filter and join) that apply the same operation to many data items.</li></ul></li><li><p>Issues:</p><ul><li><p>Two types of applications that current computing frameworks handle inefficiently: iterative algorithms and interactive data mining tools.</p></li><li><p>Current frameworks lack abstractions for leveraging distributed memory.</p><ul><li>In most current frameworks, the only way to reuse data between computations is to write it to an external stable storage system.</li><li>This makes them inefficient for those that reuse intermediate results across multiple computations.</li><li>This incurs substantial overheads due to data replication, disk I/O, and serialization.</li></ul></li><li><p>There are some specialized frameworks developed for some applications that require data reuse. But they do not provide abstractions for more general reuse.</p></li><li><p>Both replicatint the data across machines or logging updates across machines are expensive for data-intensive workloads.</p></li></ul></li></ol><h1 id="model"><a class="markdownIt-Anchor" href="#model"></a> Model</h1><h2 id="rdds"><a class="markdownIt-Anchor" href="#rdds"></a> RDDs</h2><h3 id="what-is-rdd"><a class="markdownIt-Anchor" href="#what-is-rdd"></a> What is RDD?</h3><ol><li>An RDD is a read-only, partitioned collection of records.<ul><li>Although individual RDDs are immutable, it is possible to implement mutable state by having multiple RDDs to represent multiple versions of a dataset.</li></ul></li><li>RDDs can only be created through deterministic operations on either data in stable storage or other RDDs.<ul><li>These operations are called transformations to differentiate them from other operations on RDDs.</li></ul></li><li>An RDD has enough information about how it was derived from other datasets (its lineage) to compute its partitions from data in stable storage.<ul><li>A program cannot reference an RDD that it cannot reconstruct after a failure.</li><li>RDDs do not need to be materialized at all times.</li></ul></li><li>Users can control two other aspects of RDDs: persistence and partitioning.<ul><li>Users can indicate which RDDs they will reuse and choose a storage strategy for them.</li><li>They can also ask that an RDD’s elements be partitioned across machines based on a key in each record.</li></ul></li></ol><h3 id="what-is-the-advantges-of-the-rdd-model-comparing-with-distributed-shared-memory-dsm"><a class="markdownIt-Anchor" href="#what-is-the-advantges-of-the-rdd-model-comparing-with-distributed-shared-memory-dsm"></a> What is the advantges of the RDD model comparing with distributed shared memory (DSM)?</h3><ol><li><p>The main difference between RDDs and DSM is that RDDs can only be created (“written”) through coarsegrained transformations, while DSM allows reads and writes to each memory location.</p><ul><li>This restricts RDDs to applications that perform bulk writes, but allows for more efficient fault tolerance.</li><li>RDDs do not need to incur the overhead of checkpointing, as they can be recovered using lineage.</li><li>Only the lost partitions of an RDD need to be recomputed upon failure, and they can be recomputed in parallel on different nodes, without having to roll back the whole program.</li></ul></li><li><p>RDDs’ immutable nature lets a system mitigate slow nodes (stragglers) by running backup copies of slow tasks as in MapReduce.</p><ul><li>Backup tasks would be hard to implement with DSM, as the two copies of a task would access the same memory locations and interfere with each other’s updates.</li></ul></li><li><p>In bulk operations on RDDs, a runtime can schedule tasks based on data locality to improve performance.</p></li><li><p>RDDs degrade gracefully when there is not enough memory to store them, as long as they are only being used in scan-based operations.</p><p>Partitions that do not fit in RAM can be stored on disk and will provide similar performance to current data-parallel systems.</p></li></ol><h3 id="what-kind-of-applications-are-suited-for-rdds"><a class="markdownIt-Anchor" href="#what-kind-of-applications-are-suited-for-rdds"></a> What kind of applications are suited for RDDs?</h3><ol><li>RDDs are best suited for batch applications that apply the same operation to all elements of a dataset.<ul><li>RDDs can efficiently remember each transformation as one step in a lineage graph and can recover lost partitions without having to log large amounts of data.</li></ul></li><li>RDDs would be less suitable for applications that make asynchronous finegrained updates to shared state.</li></ol><h2 id="spark"><a class="markdownIt-Anchor" href="#spark"></a> Spark</h2><h3 id="what-is-the-runtime-of-spark"><a class="markdownIt-Anchor" href="#what-is-the-runtime-of-spark"></a> What is the runtime of Spark?</h3><ol><li>Developers write a <strong>driver</strong> program that connects to a cluster of <strong>workers</strong>.<ul><li>The driver defines one or more RDDs and invokes actions on them.</li><li>Spark code on the driver also tracks the RDDs’ lineage.</li></ul></li><li>The workers are long-lived processes that can store RDD partitions in RAM across operations.</li></ol><img src="/imgs/Distributed/Spark/runtime.png" width="30%"><h3 id="what-is-spark-programming-interface-of-rdds"><a class="markdownIt-Anchor" href="#what-is-spark-programming-interface-of-rdds"></a> What is Spark programming interface of RDDs?</h3><ol><li>Each dataset is represented as an object and transformations are invoked using methods on these objects.</li><li>Programmers start by defining one or more RDDs through transformations on data in stable storage.<ul><li>They can then use these RDDs in actions, which are operations that return a value to the application or export data to a storage system.</li></ul></li><li>Programmers can call a <code>persist()</code> method to indicate which RDDs they want to reuse in future operations.<ul><li>Spark keeps persistent RDDs in memory by default, but it can spill them to disk if there is not enough RAM.</li><li>Users can set a persistence priority on each RDD to specify which in-memory data should spill to disk first.</li><li>The user can call <code>persist</code> with a <code>RELIABLE</code> flag to reliably replicate some of the versions of RDDs to reduce fault recovery times.</li></ul></li></ol><h3 id="what-rdd-operations-are-supported-in-spark"><a class="markdownIt-Anchor" href="#what-rdd-operations-are-supported-in-spark"></a> What RDD operations are supported in Spark?</h3><ol><li>Users provide arguments to RDD operations by passing closures (function literals).</li><li>RDDs themselves are statically typed objects parametrized by an element type.</li><li>Transformations are <strong>lazy</strong> operations that define a new RDD.<ul><li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>m</mi><mi>a</mi><mi>p</mi><mo stretchy="false">(</mo><mi>f</mi><mo>:</mo><mi>T</mi><mo>⇒</mo><mi>U</mi><mo stretchy="false">)</mo><mo>:</mo><mi>R</mi><mi>D</mi><mi>D</mi><mo stretchy="false">[</mo><mi>T</mi><mo stretchy="false">]</mo><mo>⇒</mo><mi>R</mi><mi>D</mi><mi>D</mi><mo stretchy="false">[</mo><mi>U</mi><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">map(f: T\Rightarrow U): RDD[T]\Rightarrow RDD[U]</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">m</span><span class="mord mathnormal">a</span><span class="mord mathnormal">p</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">:</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">⇒</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">U</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">:</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="mord mathnormal" style="margin-right:0.02778em;">D</span><span class="mord mathnormal" style="margin-right:0.02778em;">D</span><span class="mopen">[</span><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="mclose">]</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">⇒</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="mord mathnormal" style="margin-right:0.02778em;">D</span><span class="mord mathnormal" style="margin-right:0.02778em;">D</span><span class="mopen">[</span><span class="mord mathnormal" style="margin-right:0.10903em;">U</span><span class="mclose">]</span></span></span></span></li><li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>f</mi><mi>i</mi><mi>l</mi><mi>t</mi><mi>e</mi><mi>r</mi><mo stretchy="false">(</mo><mi>f</mi><mo>:</mo><mi>T</mi><mo>⇒</mo><mi>B</mi><mi>o</mi><mi>o</mi><mi>l</mi><mo stretchy="false">)</mo><mo>:</mo><mi>R</mi><mi>D</mi><mi>D</mi><mo stretchy="false">[</mo><mi>T</mi><mo stretchy="false">]</mo><mo>⇒</mo><mi>R</mi><mi>D</mi><mi>D</mi><mo stretchy="false">[</mo><mi>T</mi><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">filter(f: T\Rightarrow Bool): RDD[T]\Rightarrow RDD[T]</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="mord mathnormal">i</span><span class="mord mathnormal" style="margin-right:0.01968em;">l</span><span class="mord mathnormal">t</span><span class="mord mathnormal">e</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">:</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">⇒</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.05017em;">B</span><span class="mord mathnormal">o</span><span class="mord mathnormal">o</span><span class="mord mathnormal" style="margin-right:0.01968em;">l</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">:</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="mord mathnormal" style="margin-right:0.02778em;">D</span><span class="mord mathnormal" style="margin-right:0.02778em;">D</span><span class="mopen">[</span><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="mclose">]</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">⇒</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="mord mathnormal" style="margin-right:0.02778em;">D</span><span class="mord mathnormal" style="margin-right:0.02778em;">D</span><span class="mopen">[</span><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="mclose">]</span></span></span></span></li><li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>f</mi><mi>l</mi><mi>a</mi><mi>t</mi><mi>M</mi><mi>a</mi><mi>p</mi><mo stretchy="false">(</mo><mi>f</mi><mo>:</mo><mi>T</mi><mo>⇒</mo><mi>S</mi><mi>e</mi><mi>q</mi><mo stretchy="false">[</mo><mi>U</mi><mo stretchy="false">]</mo><mo stretchy="false">)</mo><mo>:</mo><mi>R</mi><mi>D</mi><mi>D</mi><mo stretchy="false">[</mo><mi>T</mi><mo stretchy="false">]</mo><mo>⇒</mo><mi>R</mi><mi>D</mi><mi>D</mi><mo stretchy="false">[</mo><mi>U</mi><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">flatMap(f: T\Rightarrow Seq[U]): RDD[T]\Rightarrow RDD[U]</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="mord mathnormal" style="margin-right:0.01968em;">l</span><span class="mord mathnormal">a</span><span class="mord mathnormal">t</span><span class="mord mathnormal" style="margin-right:0.10903em;">M</span><span class="mord mathnormal">a</span><span class="mord mathnormal">p</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">:</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">⇒</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.05764em;">S</span><span class="mord mathnormal">e</span><span class="mord mathnormal" style="margin-right:0.03588em;">q</span><span class="mopen">[</span><span class="mord mathnormal" style="margin-right:0.10903em;">U</span><span class="mclose">]</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">:</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="mord mathnormal" style="margin-right:0.02778em;">D</span><span class="mord mathnormal" style="margin-right:0.02778em;">D</span><span class="mopen">[</span><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="mclose">]</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">⇒</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="mord mathnormal" style="margin-right:0.02778em;">D</span><span class="mord mathnormal" style="margin-right:0.02778em;">D</span><span class="mopen">[</span><span class="mord mathnormal" style="margin-right:0.10903em;">U</span><span class="mclose">]</span></span></span></span></li><li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>s</mi><mi>a</mi><mi>m</mi><mi>p</mi><mi>l</mi><mi>e</mi><mo stretchy="false">(</mo><mi>f</mi><mi>r</mi><mi>a</mi><mi>c</mi><mi>t</mi><mi>i</mi><mi>o</mi><mi>n</mi><mo>:</mo><mi>F</mi><mi>l</mi><mi>o</mi><mi>a</mi><mi>t</mi><mo stretchy="false">)</mo><mo>:</mo><mi>R</mi><mi>D</mi><mi>D</mi><mo stretchy="false">[</mo><mi>T</mi><mo stretchy="false">]</mo><mo>⇒</mo><mi>R</mi><mi>D</mi><mi>D</mi><mo stretchy="false">[</mo><mi>T</mi><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">sample(fraction: Float): RDD[T]\Rightarrow RDD[T]</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">s</span><span class="mord mathnormal">a</span><span class="mord mathnormal">m</span><span class="mord mathnormal">p</span><span class="mord mathnormal" style="margin-right:0.01968em;">l</span><span class="mord mathnormal">e</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mord mathnormal">a</span><span class="mord mathnormal">c</span><span class="mord mathnormal">t</span><span class="mord mathnormal">i</span><span class="mord mathnormal">o</span><span class="mord mathnormal">n</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">:</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">F</span><span class="mord mathnormal" style="margin-right:0.01968em;">l</span><span class="mord mathnormal">o</span><span class="mord mathnormal">a</span><span class="mord mathnormal">t</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">:</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="mord mathnormal" style="margin-right:0.02778em;">D</span><span class="mord mathnormal" style="margin-right:0.02778em;">D</span><span class="mopen">[</span><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="mclose">]</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">⇒</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="mord mathnormal" style="margin-right:0.02778em;">D</span><span class="mord mathnormal" style="margin-right:0.02778em;">D</span><span class="mopen">[</span><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="mclose">]</span></span></span></span> (Deterministic sampling)</li><li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>g</mi><mi>r</mi><mi>o</mi><mi>u</mi><mi>p</mi><mi>B</mi><mi>y</mi><mi>K</mi><mi>e</mi><mi>y</mi><mo stretchy="false">(</mo><mo stretchy="false">)</mo><mo>:</mo><mi>R</mi><mi>D</mi><mi>D</mi><mo stretchy="false">[</mo><mo stretchy="false">(</mo><mi>K</mi><mo separator="true">,</mo><mi>V</mi><mo stretchy="false">)</mo><mo stretchy="false">]</mo><mo>⇒</mo><mi>R</mi><mi>D</mi><mi>D</mi><mo stretchy="false">[</mo><mo stretchy="false">(</mo><mi>K</mi><mo separator="true">,</mo><mi>S</mi><mi>e</mi><mi>q</mi><mo stretchy="false">[</mo><mi>V</mi><mo stretchy="false">]</mo><mo stretchy="false">)</mo><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">groupByKey(): RDD[(K,V)]\Rightarrow RDD[(K,Seq[V])]</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">g</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mord mathnormal">o</span><span class="mord mathnormal">u</span><span class="mord mathnormal">p</span><span class="mord mathnormal" style="margin-right:0.05017em;">B</span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="mord mathnormal" style="margin-right:0.07153em;">K</span><span class="mord mathnormal">e</span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="mopen">(</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">:</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="mord mathnormal" style="margin-right:0.02778em;">D</span><span class="mord mathnormal" style="margin-right:0.02778em;">D</span><span class="mopen">[</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.07153em;">K</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal" style="margin-right:0.22222em;">V</span><span class="mclose">)</span><span class="mclose">]</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">⇒</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="mord mathnormal" style="margin-right:0.02778em;">D</span><span class="mord mathnormal" style="margin-right:0.02778em;">D</span><span class="mopen">[</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.07153em;">K</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal" style="margin-right:0.05764em;">S</span><span class="mord mathnormal">e</span><span class="mord mathnormal" style="margin-right:0.03588em;">q</span><span class="mopen">[</span><span class="mord mathnormal" style="margin-right:0.22222em;">V</span><span class="mclose">]</span><span class="mclose">)</span><span class="mclose">]</span></span></span></span></li><li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>r</mi><mi>e</mi><mi>d</mi><mi>u</mi><mi>c</mi><mi>e</mi><mi>B</mi><mi>y</mi><mi>K</mi><mi>e</mi><mi>y</mi><mo stretchy="false">(</mo><mi>f</mi><mo>:</mo><mo stretchy="false">(</mo><mi>V</mi><mo separator="true">,</mo><mi>V</mi><mo stretchy="false">)</mo><mo>⇒</mo><mi>V</mi><mo stretchy="false">)</mo><mo>:</mo><mi>R</mi><mi>D</mi><mi>D</mi><mo stretchy="false">[</mo><mo stretchy="false">(</mo><mi>K</mi><mo separator="true">,</mo><mi>V</mi><mo stretchy="false">)</mo><mo stretchy="false">]</mo><mo>⇒</mo><mi>R</mi><mi>D</mi><mi>D</mi><mo stretchy="false">[</mo><mo stretchy="false">(</mo><mi>K</mi><mo separator="true">,</mo><mi>V</mi><mo stretchy="false">)</mo><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">reduceByKey(f:(V,V)\Rightarrow V): RDD[(K,V)]\Rightarrow RDD[(K,V)]</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mord mathnormal">e</span><span class="mord mathnormal">d</span><span class="mord mathnormal">u</span><span class="mord mathnormal">c</span><span class="mord mathnormal">e</span><span class="mord mathnormal" style="margin-right:0.05017em;">B</span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="mord mathnormal" style="margin-right:0.07153em;">K</span><span class="mord mathnormal">e</span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">:</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.22222em;">V</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal" style="margin-right:0.22222em;">V</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">⇒</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.22222em;">V</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">:</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="mord mathnormal" style="margin-right:0.02778em;">D</span><span class="mord mathnormal" style="margin-right:0.02778em;">D</span><span class="mopen">[</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.07153em;">K</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal" style="margin-right:0.22222em;">V</span><span class="mclose">)</span><span class="mclose">]</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">⇒</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="mord mathnormal" style="margin-right:0.02778em;">D</span><span class="mord mathnormal" style="margin-right:0.02778em;">D</span><span class="mopen">[</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.07153em;">K</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal" style="margin-right:0.22222em;">V</span><span class="mclose">)</span><span class="mclose">]</span></span></span></span></li><li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>u</mi><mi>n</mi><mi>i</mi><mi>o</mi><mi>n</mi><mo stretchy="false">(</mo><mo stretchy="false">)</mo><mo>:</mo><mo stretchy="false">(</mo><mi>R</mi><mi>D</mi><mi>D</mi><mo stretchy="false">[</mo><mi>T</mi><mo stretchy="false">]</mo><mo separator="true">,</mo><mi>R</mi><mi>D</mi><mi>D</mi><mo stretchy="false">[</mo><mi>T</mi><mo stretchy="false">]</mo><mo stretchy="false">)</mo><mo>⇒</mo><mi>R</mi><mi>D</mi><mi>D</mi><mo stretchy="false">[</mo><mi>T</mi><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">union(): (RDD[T],RDD[T])\Rightarrow RDD[T]</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">u</span><span class="mord mathnormal">n</span><span class="mord mathnormal">i</span><span class="mord mathnormal">o</span><span class="mord mathnormal">n</span><span class="mopen">(</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">:</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="mord mathnormal" style="margin-right:0.02778em;">D</span><span class="mord mathnormal" style="margin-right:0.02778em;">D</span><span class="mopen">[</span><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="mclose">]</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="mord mathnormal" style="margin-right:0.02778em;">D</span><span class="mord mathnormal" style="margin-right:0.02778em;">D</span><span class="mopen">[</span><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="mclose">]</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">⇒</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="mord mathnormal" style="margin-right:0.02778em;">D</span><span class="mord mathnormal" style="margin-right:0.02778em;">D</span><span class="mopen">[</span><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="mclose">]</span></span></span></span></li><li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>j</mi><mi>o</mi><mi>i</mi><mi>n</mi><mo stretchy="false">(</mo><mo stretchy="false">)</mo><mo>:</mo><mo stretchy="false">(</mo><mi>R</mi><mi>D</mi><mi>D</mi><mo stretchy="false">[</mo><mo stretchy="false">(</mo><mi>K</mi><mo separator="true">,</mo><mi>V</mi><mo stretchy="false">)</mo><mo stretchy="false">]</mo><mo separator="true">,</mo><mi>R</mi><mi>D</mi><mi>D</mi><mo stretchy="false">[</mo><mo stretchy="false">(</mo><mi>K</mi><mo separator="true">,</mo><mi>W</mi><mo stretchy="false">)</mo><mo stretchy="false">]</mo><mo stretchy="false">)</mo><mo>⇒</mo><mi>R</mi><mi>D</mi><mi>D</mi><mo stretchy="false">[</mo><mo stretchy="false">(</mo><mi>K</mi><mo separator="true">,</mo><mo stretchy="false">(</mo><mi>V</mi><mo separator="true">,</mo><mi>W</mi><mo stretchy="false">)</mo><mo stretchy="false">)</mo><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">join():(RDD[(K,V)],RDD[(K,W)])\Rightarrow RDD[(K,(V,W))]</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.05724em;">j</span><span class="mord mathnormal">o</span><span class="mord mathnormal">i</span><span class="mord mathnormal">n</span><span class="mopen">(</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">:</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="mord mathnormal" style="margin-right:0.02778em;">D</span><span class="mord mathnormal" style="margin-right:0.02778em;">D</span><span class="mopen">[</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.07153em;">K</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal" style="margin-right:0.22222em;">V</span><span class="mclose">)</span><span class="mclose">]</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="mord mathnormal" style="margin-right:0.02778em;">D</span><span class="mord mathnormal" style="margin-right:0.02778em;">D</span><span class="mopen">[</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.07153em;">K</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="mclose">)</span><span class="mclose">]</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">⇒</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="mord mathnormal" style="margin-right:0.02778em;">D</span><span class="mord mathnormal" style="margin-right:0.02778em;">D</span><span class="mopen">[</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.07153em;">K</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.22222em;">V</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="mclose">)</span><span class="mclose">)</span><span class="mclose">]</span></span></span></span></li><li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>c</mi><mi>o</mi><mi>g</mi><mi>r</mi><mi>o</mi><mi>u</mi><mi>p</mi><mo stretchy="false">(</mo><mo stretchy="false">)</mo><mo>:</mo><mo stretchy="false">(</mo><mi>R</mi><mi>D</mi><mi>D</mi><mo stretchy="false">[</mo><mo stretchy="false">(</mo><mi>K</mi><mo separator="true">,</mo><mi>V</mi><mo stretchy="false">)</mo><mo stretchy="false">]</mo><mo separator="true">,</mo><mi>R</mi><mi>D</mi><mi>D</mi><mo stretchy="false">[</mo><mo stretchy="false">(</mo><mi>K</mi><mo separator="true">,</mo><mi>W</mi><mo stretchy="false">)</mo><mo stretchy="false">]</mo><mo stretchy="false">)</mo><mo>⇒</mo><mi>R</mi><mi>D</mi><mi>D</mi><mo stretchy="false">[</mo><mo stretchy="false">(</mo><mi>K</mi><mo separator="true">,</mo><mo stretchy="false">(</mo><mi>S</mi><mi>e</mi><mi>q</mi><mo stretchy="false">[</mo><mi>V</mi><mo stretchy="false">]</mo><mo separator="true">,</mo><mi>S</mi><mi>e</mi><mi>q</mi><mo stretchy="false">[</mo><mi>W</mi><mo stretchy="false">]</mo><mo stretchy="false">)</mo><mo stretchy="false">)</mo><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">cogroup():(RDD[(K,V)],RDD[(K,W)])\Rightarrow RDD[(K,(Seq[V],Seq[W]))]</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">c</span><span class="mord mathnormal">o</span><span class="mord mathnormal" style="margin-right:0.03588em;">g</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mord mathnormal">o</span><span class="mord mathnormal">u</span><span class="mord mathnormal">p</span><span class="mopen">(</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">:</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="mord mathnormal" style="margin-right:0.02778em;">D</span><span class="mord mathnormal" style="margin-right:0.02778em;">D</span><span class="mopen">[</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.07153em;">K</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal" style="margin-right:0.22222em;">V</span><span class="mclose">)</span><span class="mclose">]</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="mord mathnormal" style="margin-right:0.02778em;">D</span><span class="mord mathnormal" style="margin-right:0.02778em;">D</span><span class="mopen">[</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.07153em;">K</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="mclose">)</span><span class="mclose">]</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">⇒</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="mord mathnormal" style="margin-right:0.02778em;">D</span><span class="mord mathnormal" style="margin-right:0.02778em;">D</span><span class="mopen">[</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.07153em;">K</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.05764em;">S</span><span class="mord mathnormal">e</span><span class="mord mathnormal" style="margin-right:0.03588em;">q</span><span class="mopen">[</span><span class="mord mathnormal" style="margin-right:0.22222em;">V</span><span class="mclose">]</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal" style="margin-right:0.05764em;">S</span><span class="mord mathnormal">e</span><span class="mord mathnormal" style="margin-right:0.03588em;">q</span><span class="mopen">[</span><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="mclose">]</span><span class="mclose">)</span><span class="mclose">)</span><span class="mclose">]</span></span></span></span></li><li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>c</mi><mi>r</mi><mi>o</mi><mi>s</mi><mi>s</mi><mi>P</mi><mi>r</mi><mi>o</mi><mi>d</mi><mi>u</mi><mi>c</mi><mi>t</mi><mo stretchy="false">(</mo><mo stretchy="false">)</mo><mo>:</mo><mo stretchy="false">(</mo><mi>R</mi><mi>D</mi><mi>D</mi><mo stretchy="false">[</mo><mi>T</mi><mo stretchy="false">]</mo><mo separator="true">,</mo><mi>R</mi><mi>D</mi><mi>D</mi><mo stretchy="false">[</mo><mi>U</mi><mo stretchy="false">]</mo><mo stretchy="false">)</mo><mo>⇒</mo><mi>R</mi><mi>D</mi><mi>D</mi><mo stretchy="false">[</mo><mo stretchy="false">(</mo><mi>T</mi><mo separator="true">,</mo><mi>U</mi><mo stretchy="false">)</mo><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">crossProduct():(RDD[T],RDD[U])\Rightarrow RDD[(T,U)]</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">c</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mord mathnormal">o</span><span class="mord mathnormal">s</span><span class="mord mathnormal">s</span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mord mathnormal">o</span><span class="mord mathnormal">d</span><span class="mord mathnormal">u</span><span class="mord mathnormal">c</span><span class="mord mathnormal">t</span><span class="mopen">(</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">:</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="mord mathnormal" style="margin-right:0.02778em;">D</span><span class="mord mathnormal" style="margin-right:0.02778em;">D</span><span class="mopen">[</span><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="mclose">]</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="mord mathnormal" style="margin-right:0.02778em;">D</span><span class="mord mathnormal" style="margin-right:0.02778em;">D</span><span class="mopen">[</span><span class="mord mathnormal" style="margin-right:0.10903em;">U</span><span class="mclose">]</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">⇒</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="mord mathnormal" style="margin-right:0.02778em;">D</span><span class="mord mathnormal" style="margin-right:0.02778em;">D</span><span class="mopen">[</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">U</span><span class="mclose">)</span><span class="mclose">]</span></span></span></span></li><li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>m</mi><mi>a</mi><mi>p</mi><mi>V</mi><mi>a</mi><mi>l</mi><mi>u</mi><mi>e</mi><mi>s</mi><mo stretchy="false">(</mo><mi>f</mi><mo>:</mo><mi>V</mi><mo>⇒</mo><mi>W</mi><mo stretchy="false">)</mo><mo>:</mo><mi>R</mi><mi>D</mi><mi>D</mi><mo stretchy="false">[</mo><mo stretchy="false">(</mo><mi>K</mi><mo separator="true">,</mo><mi>V</mi><mo stretchy="false">)</mo><mo stretchy="false">]</mo><mo>⇒</mo><mi>R</mi><mi>D</mi><mi>D</mi><mo stretchy="false">[</mo><mo stretchy="false">(</mo><mi>K</mi><mo separator="true">,</mo><mi>W</mi><mo stretchy="false">)</mo><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">mapValues(f:V\Rightarrow W):RDD[(K,V)]\Rightarrow RDD[(K,W)]</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">m</span><span class="mord mathnormal">a</span><span class="mord mathnormal">p</span><span class="mord mathnormal" style="margin-right:0.22222em;">V</span><span class="mord mathnormal">a</span><span class="mord mathnormal" style="margin-right:0.01968em;">l</span><span class="mord mathnormal">u</span><span class="mord mathnormal">e</span><span class="mord mathnormal">s</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">:</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.22222em;">V</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">⇒</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">:</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="mord mathnormal" style="margin-right:0.02778em;">D</span><span class="mord mathnormal" style="margin-right:0.02778em;">D</span><span class="mopen">[</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.07153em;">K</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal" style="margin-right:0.22222em;">V</span><span class="mclose">)</span><span class="mclose">]</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">⇒</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="mord mathnormal" style="margin-right:0.02778em;">D</span><span class="mord mathnormal" style="margin-right:0.02778em;">D</span><span class="mopen">[</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.07153em;">K</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="mclose">)</span><span class="mclose">]</span></span></span></span> (Preserves partitioning)</li><li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>s</mi><mi>o</mi><mi>r</mi><mi>t</mi><mo stretchy="false">(</mo><mi>c</mi><mo>:</mo><mi>C</mi><mi>o</mi><mi>m</mi><mi>p</mi><mi>a</mi><mi>r</mi><mi>a</mi><mi>t</mi><mi>o</mi><mi>r</mi><mo stretchy="false">[</mo><mi>K</mi><mo stretchy="false">]</mo><mo stretchy="false">)</mo><mo>:</mo><mi>R</mi><mi>D</mi><mi>D</mi><mo stretchy="false">[</mo><mo stretchy="false">(</mo><mi>K</mi><mo separator="true">,</mo><mi>V</mi><mo stretchy="false">)</mo><mo stretchy="false">]</mo><mo>⇒</mo><mi>R</mi><mi>D</mi><mi>D</mi><mo stretchy="false">[</mo><mo stretchy="false">(</mo><mi>K</mi><mo separator="true">,</mo><mi>V</mi><mo stretchy="false">)</mo><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">sort(c:Comparator[K]):RDD[(K,V)]\Rightarrow RDD[(K,V)]</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">s</span><span class="mord mathnormal">o</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mord mathnormal">t</span><span class="mopen">(</span><span class="mord mathnormal">c</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">:</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.07153em;">C</span><span class="mord mathnormal">o</span><span class="mord mathnormal">m</span><span class="mord mathnormal">p</span><span class="mord mathnormal">a</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mord mathnormal">a</span><span class="mord mathnormal">t</span><span class="mord mathnormal">o</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mopen">[</span><span class="mord mathnormal" style="margin-right:0.07153em;">K</span><span class="mclose">]</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">:</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="mord mathnormal" style="margin-right:0.02778em;">D</span><span class="mord mathnormal" style="margin-right:0.02778em;">D</span><span class="mopen">[</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.07153em;">K</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal" style="margin-right:0.22222em;">V</span><span class="mclose">)</span><span class="mclose">]</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">⇒</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="mord mathnormal" style="margin-right:0.02778em;">D</span><span class="mord mathnormal" style="margin-right:0.02778em;">D</span><span class="mopen">[</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.07153em;">K</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal" style="margin-right:0.22222em;">V</span><span class="mclose">)</span><span class="mclose">]</span></span></span></span></li><li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi><mi>a</mi><mi>r</mi><mi>t</mi><mi>i</mi><mi>t</mi><mi>i</mi><mi>o</mi><mi>n</mi><mi>B</mi><mi>y</mi><mo stretchy="false">(</mo><mi>p</mi><mo>:</mo><mi>P</mi><mi>a</mi><mi>r</mi><mi>t</mi><mi>i</mi><mi>t</mi><mi>i</mi><mi>o</mi><mi>n</mi><mi>e</mi><mi>r</mi><mo stretchy="false">[</mo><mi>K</mi><mo stretchy="false">]</mo><mo stretchy="false">)</mo><mo>:</mo><mi>R</mi><mi>D</mi><mi>D</mi><mo stretchy="false">[</mo><mo stretchy="false">(</mo><mi>K</mi><mo separator="true">,</mo><mi>V</mi><mo stretchy="false">)</mo><mo stretchy="false">]</mo><mo>⇒</mo><mi>R</mi><mi>D</mi><mi>D</mi><mo stretchy="false">[</mo><mo stretchy="false">(</mo><mi>K</mi><mo separator="true">,</mo><mi>V</mi><mo stretchy="false">)</mo><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">partitionBy(p:Partitioner[K]):RDD[(K,V)]\Rightarrow RDD[(K,V)]</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">p</span><span class="mord mathnormal">a</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mord mathnormal">t</span><span class="mord mathnormal">i</span><span class="mord mathnormal">t</span><span class="mord mathnormal">i</span><span class="mord mathnormal">o</span><span class="mord mathnormal">n</span><span class="mord mathnormal" style="margin-right:0.05017em;">B</span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="mopen">(</span><span class="mord mathnormal">p</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">:</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="mord mathnormal">a</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mord mathnormal">t</span><span class="mord mathnormal">i</span><span class="mord mathnormal">t</span><span class="mord mathnormal">i</span><span class="mord mathnormal">o</span><span class="mord mathnormal">n</span><span class="mord mathnormal">e</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mopen">[</span><span class="mord mathnormal" style="margin-right:0.07153em;">K</span><span class="mclose">]</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">:</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="mord mathnormal" style="margin-right:0.02778em;">D</span><span class="mord mathnormal" style="margin-right:0.02778em;">D</span><span class="mopen">[</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.07153em;">K</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal" style="margin-right:0.22222em;">V</span><span class="mclose">)</span><span class="mclose">]</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">⇒</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="mord mathnormal" style="margin-right:0.02778em;">D</span><span class="mord mathnormal" style="margin-right:0.02778em;">D</span><span class="mopen">[</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.07153em;">K</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal" style="margin-right:0.22222em;">V</span><span class="mclose">)</span><span class="mclose">]</span></span></span></span></li></ul></li><li>Actions launch a computation to return a value to the program or write data to external storage.<ul><li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>c</mi><mi>o</mi><mi>u</mi><mi>n</mi><mi>t</mi><mo stretchy="false">(</mo><mo stretchy="false">)</mo><mo>:</mo><mi>R</mi><mi>D</mi><mi>D</mi><mo stretchy="false">[</mo><mi>T</mi><mo stretchy="false">]</mo><mo>⇒</mo><mi>L</mi><mi>o</mi><mi>n</mi><mi>g</mi><mo>:</mo></mrow><annotation encoding="application/x-tex">count(): RDD[T]\Rightarrow Long:</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">c</span><span class="mord mathnormal">o</span><span class="mord mathnormal">u</span><span class="mord mathnormal">n</span><span class="mord mathnormal">t</span><span class="mopen">(</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">:</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="mord mathnormal" style="margin-right:0.02778em;">D</span><span class="mord mathnormal" style="margin-right:0.02778em;">D</span><span class="mopen">[</span><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="mclose">]</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">⇒</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.8777699999999999em;vertical-align:-0.19444em;"></span><span class="mord mathnormal">L</span><span class="mord mathnormal">o</span><span class="mord mathnormal">n</span><span class="mord mathnormal" style="margin-right:0.03588em;">g</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">:</span></span></span></span> Returns the number of elements in the dataset</li><li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>c</mi><mi>o</mi><mi>l</mi><mi>l</mi><mi>e</mi><mi>c</mi><mi>t</mi><mo stretchy="false">(</mo><mo stretchy="false">)</mo><mo>:</mo><mi>R</mi><mi>D</mi><mi>D</mi><mo stretchy="false">[</mo><mi>T</mi><mo stretchy="false">]</mo><mo>⇒</mo><mi>S</mi><mi>e</mi><mi>q</mi><mo stretchy="false">[</mo><mi>T</mi><mo stretchy="false">]</mo><mo>:</mo></mrow><annotation encoding="application/x-tex">collect(): RDD[T]\Rightarrow Seq[T]:</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">c</span><span class="mord mathnormal">o</span><span class="mord mathnormal" style="margin-right:0.01968em;">l</span><span class="mord mathnormal" style="margin-right:0.01968em;">l</span><span class="mord mathnormal">e</span><span class="mord mathnormal">c</span><span class="mord mathnormal">t</span><span class="mopen">(</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">:</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="mord mathnormal" style="margin-right:0.02778em;">D</span><span class="mord mathnormal" style="margin-right:0.02778em;">D</span><span class="mopen">[</span><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="mclose">]</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">⇒</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.05764em;">S</span><span class="mord mathnormal">e</span><span class="mord mathnormal" style="margin-right:0.03588em;">q</span><span class="mopen">[</span><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="mclose">]</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">:</span></span></span></span> Returns the elements themselves</li><li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>r</mi><mi>e</mi><mi>d</mi><mi>u</mi><mi>c</mi><mi>e</mi><mo stretchy="false">(</mo><mi>f</mi><mo>:</mo><mo stretchy="false">(</mo><mi>T</mi><mo separator="true">,</mo><mi>T</mi><mo stretchy="false">)</mo><mo>⇒</mo><mi>T</mi><mo stretchy="false">)</mo><mo>:</mo><mi>R</mi><mi>D</mi><mi>D</mi><mo stretchy="false">[</mo><mi>T</mi><mo stretchy="false">]</mo><mo>⇒</mo><mi>T</mi></mrow><annotation encoding="application/x-tex">reduce(f:(T,T)\Rightarrow T): RDD[T]\Rightarrow T</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mord mathnormal">e</span><span class="mord mathnormal">d</span><span class="mord mathnormal">u</span><span class="mord mathnormal">c</span><span class="mord mathnormal">e</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">:</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">⇒</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">:</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="mord mathnormal" style="margin-right:0.02778em;">D</span><span class="mord mathnormal" style="margin-right:0.02778em;">D</span><span class="mopen">[</span><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="mclose">]</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">⇒</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">T</span></span></span></span></li><li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>l</mi><mi>o</mi><mi>o</mi><mi>k</mi><mi>u</mi><mi>p</mi><mo stretchy="false">(</mo><mi>k</mi><mo>:</mo><mi>K</mi><mo stretchy="false">)</mo><mo>:</mo><mi>R</mi><mi>D</mi><mi>D</mi><mo stretchy="false">[</mo><mo stretchy="false">(</mo><mi>K</mi><mo separator="true">,</mo><mi>V</mi><mo stretchy="false">)</mo><mo stretchy="false">]</mo><mo>⇒</mo><mi>S</mi><mi>e</mi><mi>q</mi><mo stretchy="false">[</mo><mi>V</mi><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">lookup(k:K):RDD[(K,V)]\Rightarrow Seq[V]</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.01968em;">l</span><span class="mord mathnormal">o</span><span class="mord mathnormal">o</span><span class="mord mathnormal" style="margin-right:0.03148em;">k</span><span class="mord mathnormal">u</span><span class="mord mathnormal">p</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.03148em;">k</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">:</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.07153em;">K</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">:</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="mord mathnormal" style="margin-right:0.02778em;">D</span><span class="mord mathnormal" style="margin-right:0.02778em;">D</span><span class="mopen">[</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.07153em;">K</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal" style="margin-right:0.22222em;">V</span><span class="mclose">)</span><span class="mclose">]</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">⇒</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.05764em;">S</span><span class="mord mathnormal">e</span><span class="mord mathnormal" style="margin-right:0.03588em;">q</span><span class="mopen">[</span><span class="mord mathnormal" style="margin-right:0.22222em;">V</span><span class="mclose">]</span></span></span></span> (On hash/range partitioned RDDs)</li><li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>s</mi><mi>a</mi><mi>v</mi><mi>e</mi><mo stretchy="false">(</mo><mi>p</mi><mi>a</mi><mi>t</mi><mi>h</mi><mo>:</mo><mi>S</mi><mi>t</mi><mi>r</mi><mi>i</mi><mi>n</mi><mi>g</mi><mo stretchy="false">)</mo><mo>:</mo></mrow><annotation encoding="application/x-tex">save(path:String):</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">s</span><span class="mord mathnormal">a</span><span class="mord mathnormal" style="margin-right:0.03588em;">v</span><span class="mord mathnormal">e</span><span class="mopen">(</span><span class="mord mathnormal">p</span><span class="mord mathnormal">a</span><span class="mord mathnormal">t</span><span class="mord mathnormal">h</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">:</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.05764em;">S</span><span class="mord mathnormal">t</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mord mathnormal">i</span><span class="mord mathnormal">n</span><span class="mord mathnormal" style="margin-right:0.03588em;">g</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">:</span></span></span></span> Outputs RDD to a storage system</li></ul></li></ol><h3 id="what-is-the-common-interface-of-each-rdd"><a class="markdownIt-Anchor" href="#what-is-the-common-interface-of-each-rdd"></a> What is the common interface of each RDD?</h3><ol><li>A set of partitions, which are atomic pieces of the dataset<ul><li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi><mi>a</mi><mi>r</mi><mi>t</mi><mi>i</mi><mi>t</mi><mi>i</mi><mi>o</mi><mi>n</mi><mi>e</mi><mi>r</mi><mo stretchy="false">(</mo><mo stretchy="false">)</mo><mo>:</mo></mrow><annotation encoding="application/x-tex">partitioner():</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">p</span><span class="mord mathnormal">a</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mord mathnormal">t</span><span class="mord mathnormal">i</span><span class="mord mathnormal">t</span><span class="mord mathnormal">i</span><span class="mord mathnormal">o</span><span class="mord mathnormal">n</span><span class="mord mathnormal">e</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mopen">(</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">:</span></span></span></span> Return metadata specifying whether the RDD is hash/range partitioned</li></ul></li><li>A set of dependencies on parent RDDs<ul><li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>d</mi><mi>e</mi><mi>p</mi><mi>e</mi><mi>n</mi><mi>d</mi><mi>e</mi><mi>n</mi><mi>c</mi><mi>i</mi><mi>e</mi><mi>s</mi><mo stretchy="false">(</mo><mo stretchy="false">)</mo><mo>:</mo></mrow><annotation encoding="application/x-tex">dependencies():</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">d</span><span class="mord mathnormal">e</span><span class="mord mathnormal">p</span><span class="mord mathnormal">e</span><span class="mord mathnormal">n</span><span class="mord mathnormal">d</span><span class="mord mathnormal">e</span><span class="mord mathnormal">n</span><span class="mord mathnormal">c</span><span class="mord mathnormal">i</span><span class="mord mathnormal">e</span><span class="mord mathnormal">s</span><span class="mopen">(</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">:</span></span></span></span> Return a list of dependencies</li></ul></li><li>A function for computing the dataset based on its parents<ul><li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>i</mi><mi>t</mi><mi>e</mi><mi>r</mi><mi>a</mi><mi>t</mi><mi>o</mi><mi>r</mi><mo stretchy="false">(</mo><mi>p</mi><mo separator="true">,</mo><mi>p</mi><mi>a</mi><mi>r</mi><mi>e</mi><mi>n</mi><mi>t</mi><mi>I</mi><mi>t</mi><mi>e</mi><mi>r</mi><mi>s</mi><mo stretchy="false">)</mo><mo>:</mo></mrow><annotation encoding="application/x-tex">iterator(p, parentIters):</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">i</span><span class="mord mathnormal">t</span><span class="mord mathnormal">e</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mord mathnormal">a</span><span class="mord mathnormal">t</span><span class="mord mathnormal">o</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mopen">(</span><span class="mord mathnormal">p</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal">p</span><span class="mord mathnormal">a</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mord mathnormal">e</span><span class="mord mathnormal">n</span><span class="mord mathnormal">t</span><span class="mord mathnormal" style="margin-right:0.07847em;">I</span><span class="mord mathnormal">t</span><span class="mord mathnormal">e</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mord mathnormal">s</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">:</span></span></span></span> Compute the elements of partition p given iterators for its parent partitions</li></ul></li><li>Metadata about its partitioning scheme and data placement<ul><li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi><mi>a</mi><mi>r</mi><mi>t</mi><mi>i</mi><mi>t</mi><mi>i</mi><mi>o</mi><mi>n</mi><mi>s</mi><mo stretchy="false">(</mo><mo stretchy="false">)</mo><mo>:</mo></mrow><annotation encoding="application/x-tex">partitions():</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">p</span><span class="mord mathnormal">a</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mord mathnormal">t</span><span class="mord mathnormal">i</span><span class="mord mathnormal">t</span><span class="mord mathnormal">i</span><span class="mord mathnormal">o</span><span class="mord mathnormal">n</span><span class="mord mathnormal">s</span><span class="mopen">(</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">:</span></span></span></span> Return a list of Partition objects</li><li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi><mi>r</mi><mi>e</mi><mi>f</mi><mi>e</mi><mi>r</mi><mi>r</mi><mi>e</mi><mi>d</mi><mi>L</mi><mi>o</mi><mi>c</mi><mi>a</mi><mi>t</mi><mi>i</mi><mi>o</mi><mi>n</mi><mi>s</mi><mo stretchy="false">(</mo><mi>p</mi><mo stretchy="false">)</mo><mo>:</mo></mrow><annotation encoding="application/x-tex">preferredLocations(p):</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">p</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mord mathnormal">e</span><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="mord mathnormal">e</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mord mathnormal">e</span><span class="mord mathnormal">d</span><span class="mord mathnormal">L</span><span class="mord mathnormal">o</span><span class="mord mathnormal">c</span><span class="mord mathnormal">a</span><span class="mord mathnormal">t</span><span class="mord mathnormal">i</span><span class="mord mathnormal">o</span><span class="mord mathnormal">n</span><span class="mord mathnormal">s</span><span class="mopen">(</span><span class="mord mathnormal">p</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">:</span></span></span></span> List nodes where partition <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi></mrow><annotation encoding="application/x-tex">p</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord mathnormal">p</span></span></span></span> can be accessed faster due to data locality</li></ul></li></ol><h3 id="what-is-the-interface-of-representing-dependencies-between-rdds"><a class="markdownIt-Anchor" href="#what-is-the-interface-of-representing-dependencies-between-rdds"></a> What is the interface of representing dependencies between RDDs?</h3><ol><li><p>Classify dependencies into two types:</p><ul><li>Narrow dependencies: each partition of the parent RDD is used by at most one partition of the child RDD.</li><li>Wide dependencies: multiple child partitions may depend on it.</li></ul></li><li><p>Narrow dependencies allow for pipelined execution on one cluster node, which can compute all the parent partitions.</p><p>Wide dependencies require data from all parent partitions to be available and to be shuffled across the nodes using a MapReducelike operation.</p></li><li><p>Recovery after a node failure is more efficient with a narrow dependency, as only the lost parent partitions need to be recomputed, and they can be recomputed in parallel on different nodes.</p><p>In a lineage graph with wide dependencies, a single failed node might cause the loss of some partition from all the ancestors of an RDD, requiring a complete re-execution.</p></li></ol><h2 id="implementation"><a class="markdownIt-Anchor" href="#implementation"></a> Implementation</h2><h3 id="how-does-spark-schedule-computations"><a class="markdownIt-Anchor" href="#how-does-spark-schedule-computations"></a> How does Spark schedule computations?</h3><ol><li><p>Whenever a user runs an action on an RDD, the scheduler examines that RDD’s lineage graph to build a DAG of stages to execute.</p><ul><li><p>Each stage contains as many pipelined transformations with narrow dependencies as possible.</p></li><li><p>The boundaries of the stages are the shuffle operations required for wide dependencies, or any already computed partitions that can short-circuit the computation of a parent RDD.</p></li></ul></li><li><p>The scheduler then launches tasks to compute missing partitions from each stage until it has computed the target RDD.</p><ul><li>The scheduler assigns tasks to machines based on data locality using delay scheduling.</li><li>If a task needs to process a partition that is available in memory on a node, we send it to that node.</li><li>Otherwise, if a task processes a partition for which the containing RDD provides preferred locations (e.g., an HDFS file), we send it to those.</li></ul></li></ol><h3 id="how-does-spark-handle-task-failures"><a class="markdownIt-Anchor" href="#how-does-spark-handle-task-failures"></a> How does Spark handle task failures?</h3><ol><li><p>For wide dependencies, it is possible that those alive workers have long passed the wide-dependent points and already discard intermediate results causing the stage become unavailable. In that case, all the dependencies need to be re-calculated, which is costly.</p></li><li><p>Hence, intermediate records are materialized on the nodes holding parent partitions to simplify fault recovery.</p><ul><li><p>If a task fails, it will be re-run on another node as long as its stage’s parents are still available.</p></li><li><p>If some stages have become unavailable, limited number of tasks to compute the missing partitions are resubmitted in parallel.</p></li></ul></li></ol><h3 id="how-does-spark-manage-storage-of-persistent-rdds"><a class="markdownIt-Anchor" href="#how-does-spark-manage-storage-of-persistent-rdds"></a> How does Spark manage storage of persistent RDDs?</h3><ol><li>In-memory storage as deserialized Java objects<ul><li>It provides the fastest performance, because the Java VM can access each RDD element natively.</li></ul></li><li>In-memory storage as serialized data<ul><li>It lets users choose a more memory-efficient representation than Java object graphs when space is limited, at the cost of lower performance.</li></ul></li><li>On-disk storage<ul><li>It is useful for RDDs that are too large to keep in RAM but costly to recompute on each use.</li></ul></li></ol><h3 id="how-does-spark-evict-rdds-when-run-out-of-memory"><a class="markdownIt-Anchor" href="#how-does-spark-evict-rdds-when-run-out-of-memory"></a> How does Spark evict RDDs when run out of memory?</h3><ol><li>LRU eviction policy is used at the level of RDDs.</li><li>Unless the LRU RDD is the same RDD as the one with the new partition.<ul><li>The old partition is kept in memory to prevent cycling partitions from the same RDD in and out.</li><li>This is important because most operations will run tasks over an entire RDD, so it is quite likely that the partition already in memory will be needed in the future.</li></ul></li></ol><h3 id="when-will-checkpointing-be-useful"><a class="markdownIt-Anchor" href="#when-will-checkpointing-be-useful"></a> When will checkpointing be useful?</h3><ol><li>Checkpointing is useful for RDDs with long lineage graphs containing wide dependencies.<ul><li>A node failure in the cluster may result in the loss of some slice of data from each parent RDD, requiring a full recomputation.</li></ul></li><li>For RDDs with narrow dependencies on data in stable storage, checkpointing may never be worthwhile.<ul><li>If a node fails, lost partitions from these RDDs can be recomputed in parallel on other nodes, at a fraction of the cost of replicating the whole RDD.</li></ul></li><li>The read-only nature of RDDs makes  them simpler to checkpoint than general shared memory.<ul><li>Consistency is not a concern, RDDs can be written out in the background without requiring program pauses or distributed snapshot schemes.</li></ul></li></ol><h1 id="experiement"><a class="markdownIt-Anchor" href="#experiement"></a> Experiement</h1><ol><li><p>The main contribution of this paper is improving the performance of iterative applications, hence the author measured the speedup of Spark against Hadoop.</p><ul><li><p>One scene of iterative applications is machine learning applications. The author choosed k-means and logistic regression to measure performance.</p><ul><li>The iteration time of k-means is dominated by computation.</li><li>Logistic regression is less compute-intensive and thus more sensitive to time spent in deserialization and I/O.</li><li>The time consumed should be reported for the first iteration and subsequent iterations separately as following:</li></ul><img src="/imgs/Distributed/Spark/ml-base.png" width="50%"></li><li><p>Another scene is PageRank algorithm.</p></li></ul></li><li><p>Hadoop ran slower due to several factors</p><ul><li>Minimum overhead of the Hadoop software stack<ul><li>It can be measured by running no-op Hadoop jobs.</li></ul></li><li>Overhead of HDFS while serving data<ul><li>HDFS performed multiple memory copies and a checksum to serve each block.</li><li>It can be seen by comparing the time of accessing in-memory HDFS and local file.</li></ul></li><li>Deserialization cost to convert binary records to usable in-memory Java objects<ul><li>It can be seen by comparing the time of access text input and binary input.</li></ul></li></ul><img src="/imgs/Distributed/Spark/hadoop.png" width=50%></li><li><p>The scalability is another concerned metrics. The result of machine learning algorithm is as shown below:</p><img src="/imgs/Distributed/Spark/ml-scale.png" width="50%"></li><li><p>Other important metric of the systems is failure fault recovery.</p><ul><li>The author measured the time consumed in each iteration while a node failed at the start of 6th iteration.</li></ul><img src="/imgs/Distributed/Spark/fault-recovery.png" width="50%"></li><li><p>Given that Spark makes the assumption that most RDDs will be stored in memory, the author also measured the performance when memory is limited.</p><ul><li>The performance degrades gracefully with less space.</li></ul><img src="/imgs/Distributed/Spark/mem-lim.png" width=50%></li><li><p>Given that Spark provides an interactive interpreter, the author also measured the response time thes of those queries.</p></li><li><p>To prove that RDD can support a wide class of applications, the author showed how to use RDDs to express exists programming models (e.g. MapReduce, SQL, Pregel)</p></li></ol>]]></content>
      
      
      <categories>
          
          <category> Paper Notebook </category>
          
          <category> Distributed System </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Distributed System </tag>
            
            <tag> Distributed Computation </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Spanner</title>
      <link href="/2023/09/26/Paper/Distributed/Spanner/"/>
      <url>/2023/09/26/Paper/Distributed/Spanner/</url>
      
        <content type="html"><![CDATA[<p>Paper: <a href="http://nil.csail.mit.edu/6.824/2020/papers/spanner.pdf">Spanner: Google’s Globally-Distributed Database</a></p><p><ul class="markdownIt-TOC"><li><a href="#purpose">Purpose</a></li><li><a href="#model">Model</a><ul><li><a href="#structure-of-implementation">Structure of implementation</a><ul><li><a href="#what-is-the-overview-of-spanner-server-organization">What is the overview of Spanner server organization?</a></li><li><a href="#what-is-the-zones-in-spanner">What is the zones in Spanner?</a></li><li><a href="#software-stack">Software stack</a><ul><li><a href="#how-does-spanner-manage-key-value-pairs">How does Spanner manage key-value pairs?</a></li><li><a href="#how-does-spanner-support-replication">How does Spanner support replication?</a></li><li><a href="#how-does-spanner-manage-lock-table">How does Spanner manage lock table?</a></li><li><a href="#how-does-spanner-manage-transactions">How does Spanner manage transactions?</a></li></ul></li><li><a href="#data-management">Data management</a><ul><li><a href="#how-does-spanner-manage-data-placement">How does Spanner manage data placement?</a></li><li><a href="#when-would-spanner-move-a-directory">When would Spanner move a directory?</a></li><li><a href="#how-does-spanner-move-a-directory">How does Spanner move a directory?</a></li><li><a href="#how-does-applications-specify-placement-of-data">How does applications specify placement of data?</a></li><li><a href="#what-is-the-data-model-of-spanner">What is the data model of Spanner?</a></li></ul></li></ul></li><li><a href="#truetime-api">TrueTime API</a><ul><li><a href="#how-does-truetime-api-represents-time">How does TrueTime API represents time?</a></li><li><a href="#how-is-truetime-api-implemented">How is TrueTime API implemented?</a></li><li><a href="#what-does-time-masters-need-to-do">What does time masters need to do?</a></li><li><a href="#what-does-daemons-need-to-do">What does daemons need to do?</a></li></ul></li><li><a href="#concurrency-control">Concurrency control</a><ul><li><a href="#how-does-spanner-manage-paxos-leader-leases">How does Spanner manage Paxos leader leases?</a></li><li><a href="#read-write-transactions">Read-write transactions</a><ul><li><a href="#how-does-spanner-assign-timestamps-to-rw-transactions">How does Spanner assign timestamps to RW transactions?</a></li><li><a href="#how-does-spanner-enfore-external-consistency-invariant">How does Spanner enfore external-consistency invariant?</a></li><li><a href="#how-does-spanner-handle-reads-within-rw-transactions">How does Spanner handle reads within RW transactions?</a></li><li><a href="#what-is-the-client-drive-two-phase-commit">What is the client drive two-phase commit?</a></li><li><a href="#how-to-perform-the-two-phase-commit">How to perform the two-phase commit?</a></li></ul></li><li><a href="#read-only-transactions">Read-only transactions</a><ul><li><a href="#what-kinds-of-ro-transactions-does-spanner-provide">What kinds of RO transactions does Spanner provide?</a></li><li><a href="#how-does-spanner-server-reads-given-its-timestamp">How does Spanner server reads given its timestamp?</a></li><li><a href="#how-to-optimize-for-the-safe-read-timestamp">How to optimize for the safe read timestamp?</a></li><li><a href="#how-to-perform-ro-transactions">How to perform RO transactions?</a></li><li><a href="#how-does-spanner-assign-timestamps-to-ro-transactions">How does Spanner assign timestamps to RO transactions?</a></li></ul></li></ul></li></ul></li><li><a href="#evaluation">Evaluation</a></li></ul></p><h1 id="purpose"><a class="markdownIt-Anchor" href="#purpose"></a> Purpose</h1><ol><li><p>Spanner’s main focus is managing cross-datacenter replicated data.</p></li><li><p>Problems of Bigtable:</p><ul><li><p>Bigtable can be difficult to use for those that have complex, evolving schemas, or those that want strong consistency in the presence of wide-area replication.</p></li><li><p>Many applications at Google have chosen to use Megastore because of its semi-relational data model and support for synchronous replication, despite its relatively poor write throughput.</p></li></ul></li><li><p>Spanner new features:</p><ul><li><p>Spanner has evolved from a Bigtable-like versioned key-value store into a temporal multi-version database.</p></li><li><p>Data is stored in schematized semi-relational tables</p><ul><li>Data is versioned, and each version is automatically timestamped with its commit time</li><li>Old versions of data are subject to configurable garbage-collection policies</li><li>Applications can read data at old timestamps.</li></ul></li></ul></li><li><p>Spanner assigns globally-meaningful commit timestamps to transactions.</p><ul><li>If a transaction <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>T</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">T_1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> commits before another transaction <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>T</mi><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">T_2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> starts, then <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>T</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">T_1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>’s commit timestamp is smaller than <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>T</mi><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">T_2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>’s.</li><li>Spanner provides externally consistent reads and writes, and globally-consistent reads across the database at a timestamp.</li></ul></li></ol><h1 id="model"><a class="markdownIt-Anchor" href="#model"></a> Model</h1><h2 id="structure-of-implementation"><a class="markdownIt-Anchor" href="#structure-of-implementation"></a> Structure of implementation</h2><h3 id="what-is-the-overview-of-spanner-server-organization"><a class="markdownIt-Anchor" href="#what-is-the-overview-of-spanner-server-organization"></a> What is the overview of Spanner server organization?</h3><ol><li>A Spanner deployment is called a universe.</li><li>Spanner is organized as a set of zones.<ul><li>A zone has one zonemaster and between one hundred and several thousand spanservers.</li><li>The zonemaster assigns data to spanservers; the spanservers serve data to clients.</li><li>The per-zone location proxies are used by clients to locate the spanservers assigned to serve their data.</li><li>The per-zone location proxies are used by clients to locate the spanservers assigned to serve their data.</li></ul></li><li>The universe master is primarily a console that displays status information about all the zones for interactive debugging.</li><li>The placement driver handles automated movement of data across zones on the timescale of minutes.<ul><li>The placement driver periodically communicates with the spanservers to find data that needs to be moved, either to meet updated replication constraints or to balance load.</li></ul></li><li>The universe master and the placement driver are currently singletons.</li></ol><img src="/imgs/Distributed/Spanner/structure.png" width="50%"><h3 id="what-is-the-zones-in-spanner"><a class="markdownIt-Anchor" href="#what-is-the-zones-in-spanner"></a> What is the zones in Spanner?</h3><ol><li>Each zone is the rough analog of a deployment of Bigtable servers.</li><li>Zones are the unit of administrative deployment. The set of zones is also the set of locations across which data can be replicated.</li><li>Zones can be added to or removed from a running system as new datacenters are brought into service and old ones are turned off, respectively.</li><li>Zones are also the unit of physical isolation. There may be one or more zones in a datacenter.</li></ol><h3 id="software-stack"><a class="markdownIt-Anchor" href="#software-stack"></a> Software stack</h3><img src="/imgs/Distributed/Spanner/software.png" width=50%><h4 id="how-does-spanner-manage-key-value-pairs"><a class="markdownIt-Anchor" href="#how-does-spanner-manage-key-value-pairs"></a> How does Spanner manage key-value pairs?</h4><ol><li>At the bottom, each spanserver is responsible for between 100 and 1000 instances of a data structure called a tablet.</li><li>A tablet is similar to Bigtable’s tablet abstraction, in that it implements a bag of the following mappings: <code>(key: string, timestamp: int64) → string</code></li><li>Unlike Bigtable, Spanner assigns timestamps to data, which is more like a multi-version database than a key-value store.</li><li>A tablet’s state is stored in set of B-tree-like files and a write-ahead log, all on a distributed file system called Colossus.</li></ol><h4 id="how-does-spanner-support-replication"><a class="markdownIt-Anchor" href="#how-does-spanner-support-replication"></a> How does Spanner support replication?</h4><ol><li>Each spanserver implements a single Paxos state machine on top of each tablet.<ul><li>Its Paxos implementation supports long-lived leaders with time-based leader leases, whose length defaults to 10 seconds.</li><li>The implementation logs every Paxos write twice: once in the tablet’s log, and once in the Paxos log. (made out of expediency, to be remedied eventually)</li><li>The implementation of Paxos is pipelined, so as to improve Spanner’s throughput in the presence of WAN latencies; but writes are applied by Paxos in order.</li></ul></li><li>The Paxos state machines are used to implement a consistently replicated bag of mappings.<ul><li>Each state machine stores its metadata and log in its corresponding tablet.</li><li>Writes must initiate the Paxos protocol at the leader; reads access state directly from the underlying tablet at any replica that is sufficiently up-to-date.</li></ul></li></ol><h4 id="how-does-spanner-manage-lock-table"><a class="markdownIt-Anchor" href="#how-does-spanner-manage-lock-table"></a> How does Spanner manage lock table?</h4><ol><li>At every replica that is a leader, each spanserver implements a lock table to implement concurrency control.</li><li>The lock table contains the state for two-phase locking: it maps ranges of keys to lock states.</li><li>Having a long-lived Paxos leader is critical to efficiently managing the lock table.</li></ol><h4 id="how-does-spanner-manage-transactions"><a class="markdownIt-Anchor" href="#how-does-spanner-manage-transactions"></a> How does Spanner manage transactions?</h4><ol><li><p>At every replica that is a leader, each spanserver also implements a transaction manager to support distributed transactions.</p><ul><li>The transaction manager is used to implement a <strong>participant leader</strong>; the other replicas in the group will be referred to as <strong>participant slaves</strong>.</li></ul></li><li><p>If a transaction involves only one Paxos group, it can bypass the transaction manager, since the lock table and Paxos together provide transactionality.</p></li><li><p>If a transaction involves more than one Paxos group, those groups’ leaders coordinate to perform twophase commit.</p><ul><li><p>One of the participant groups is chosen as the coordinator: the participant leader of that group will be referred to as the <strong>coordinator leader</strong>, and the slaves of that group as <strong>coordinator slaves</strong>.</p></li><li><p>The state of each transaction manager is stored in the underlying Paxos group.</p></li></ul></li></ol><h3 id="data-management"><a class="markdownIt-Anchor" href="#data-management"></a> Data management</h3><h4 id="how-does-spanner-manage-data-placement"><a class="markdownIt-Anchor" href="#how-does-spanner-manage-data-placement"></a> How does Spanner manage data placement?</h4><ol><li>A <strong>directory</strong> is a set of contiguous keys that share a common prefix.<ul><li>A directory is the unit of data placement. All data in a directory has the same replication configuration.</li><li>Directories can be moved while client operations are ongoing.</li><li>A Paxos group may contain multiple directories, i.e. a Spanner tablet is a container that may encapsulate multiple partitions of the row space.</li></ul></li><li>Spanner will shard a directory into multiple fragments if it grows too large.<ul><li>Fragments may be served from different Paxos groups.</li><li>Movedir actually moves fragments, and not whole directories, between groups.</li></ul></li></ol><h4 id="when-would-spanner-move-a-directory"><a class="markdownIt-Anchor" href="#when-would-spanner-move-a-directory"></a> When would Spanner move a directory?</h4><ol><li>To shed load from a Paxos group.</li><li>To put directories that are frequently accessed together into the same group.</li><li>To move a directory into a group that is closer to its accessors.</li></ol><h4 id="how-does-spanner-move-a-directory"><a class="markdownIt-Anchor" href="#how-does-spanner-move-a-directory"></a> How does Spanner move a directory?</h4><ol><li>Movedir is not implemented as a single transaction, so as to avoid blocking ongoing reads and writes on a bulky data move.</li><li>Instead, movedir registers the fact that it is starting to move data and moves the data in the background.</li><li>When it has moved all but a nominal amount of the data, it uses a transaction to atomically move that nominal amount and update the metadata for the two Paxos groups.</li></ol><h4 id="how-does-applications-specify-placement-of-data"><a class="markdownIt-Anchor" href="#how-does-applications-specify-placement-of-data"></a> How does applications specify placement of data?</h4><ol><li>A directory is also the smallest unit whose geographicreplication properties can be specified by an application.</li><li>Administrators control two dimensions: the number and types of replicas, and the geographic placement of those replicas.<ul><li>They create a menu of named options in these two dimensions.</li></ul></li><li>An application controls how data is replicated, by tagging each database and/or individual directories with a combination of those options.</li></ol><h4 id="what-is-the-data-model-of-spanner"><a class="markdownIt-Anchor" href="#what-is-the-data-model-of-spanner"></a> What is the data model of Spanner?</h4><ol><li><p>Spanner exposes the following set of data features to applications</p><ul><li>A data model based on schematized semi-relational tables</li><li>A query language</li><li>Generalpurpose transactions</li></ul></li><li><p>The application data model is layered on top of the directory-bucketed key-value mappings supported by the implementation.</p><ul><li><p>An application creates one or more databases in a universe.</p></li><li><p>Each database can contain an unlimited number of schematized tables.</p></li><li><p>Tables look like relational-database tables, with rows, columns, and versioned values.</p></li></ul></li><li><p>Every table is required to have an ordered set of one or more primary-key columns.</p><ul><li>The primary keys form the name for a row, and each table defines a mapping from the primary-key columns to the non-primary-key columns.</li><li>A row has existence only if some value (even if it is NULL) is defined for the row’s keys.</li></ul></li><li><p>Every Spanner database must be partitioned by clients into one or more hierarchies of tables.</p><ul><li>Each row in a directory table with key K, together with all of the rows in descendant tables that start with K in lexicographic order, forms a directory.</li></ul></li></ol><h2 id="truetime-api"><a class="markdownIt-Anchor" href="#truetime-api"></a> TrueTime API</h2><h3 id="how-does-truetime-api-represents-time"><a class="markdownIt-Anchor" href="#how-does-truetime-api-represents-time"></a> How does TrueTime API represents time?</h3><ol><li><p>TrueTime explicitly represents time as a <code>TTinterval</code>, which is an interval with bounded time uncertainty. The endpoints of a TTinterval are of type <code>TTstamp</code>.</p></li><li><p>The <code>TT.now()</code> method returns a <code>TTinterval</code>: <code>[earliest, latest]</code> that is guaranteed to contain the absolute time during which <code>TT.now()</code> was invoked.</p><ul><li>Denote the absolute time of an event e by the function <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>t</mi><mrow><mi>a</mi><mi>b</mi><mi>s</mi></mrow></msub><mo stretchy="false">(</mo><mi>e</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">t_{abs}(e)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathnormal">t</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">a</span><span class="mord mathnormal mtight">b</span><span class="mord mathnormal mtight">s</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathnormal">e</span><span class="mclose">)</span></span></span></span>.</li><li>TrueTime guarantees that for an invocation <code>tt = TT.now()</code>, <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>t</mi><mi>t</mi><mi mathvariant="normal">.</mi><mi>e</mi><mi>a</mi><mi>r</mi><mi>l</mi><mi>i</mi><mi>e</mi><mi>s</mi><mi>t</mi><mo>≤</mo><msub><mi>t</mi><mrow><mi>a</mi><mi>b</mi><mi>s</mi></mrow></msub><mo stretchy="false">(</mo><msub><mi>e</mi><mrow><mi>n</mi><mi>o</mi><mi>w</mi></mrow></msub><mo stretchy="false">)</mo><mo>≤</mo><mi>t</mi><mi>t</mi><mi mathvariant="normal">.</mi><mi>l</mi><mi>a</mi><mi>t</mi><mi>e</mi><mi>s</mi><mi>t</mi></mrow><annotation encoding="application/x-tex">tt.earliest ≤ t_{abs}(e_{now}) ≤ tt.latest</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83041em;vertical-align:-0.13597em;"></span><span class="mord mathnormal">t</span><span class="mord mathnormal">t</span><span class="mord">.</span><span class="mord mathnormal">e</span><span class="mord mathnormal">a</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mord mathnormal" style="margin-right:0.01968em;">l</span><span class="mord mathnormal">i</span><span class="mord mathnormal">e</span><span class="mord mathnormal">s</span><span class="mord mathnormal">t</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">≤</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathnormal">t</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">a</span><span class="mord mathnormal mtight">b</span><span class="mord mathnormal mtight">s</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">e</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">n</span><span class="mord mathnormal mtight">o</span><span class="mord mathnormal mtight" style="margin-right:0.02691em;">w</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">≤</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathnormal">t</span><span class="mord mathnormal">t</span><span class="mord">.</span><span class="mord mathnormal" style="margin-right:0.01968em;">l</span><span class="mord mathnormal">a</span><span class="mord mathnormal">t</span><span class="mord mathnormal">e</span><span class="mord mathnormal">s</span><span class="mord mathnormal">t</span></span></span></span>, where <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>e</mi><mrow><mi>n</mi><mi>o</mi><mi>w</mi></mrow></msub></mrow><annotation encoding="application/x-tex">e_{now}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">e</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">n</span><span class="mord mathnormal mtight">o</span><span class="mord mathnormal mtight" style="margin-right:0.02691em;">w</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> is the invocation event.</li></ul></li><li><p><code>TT.after(t)</code> returns <code>true</code> if t has definitely passed.</p><p><code>TT.before(t)</code> returns <code>true</code> if t has definitely not arrived.</p></li></ol><h3 id="how-is-truetime-api-implemented"><a class="markdownIt-Anchor" href="#how-is-truetime-api-implemented"></a> How is TrueTime API implemented?</h3><ol><li>TrueTime is implemented by a set of <strong>time master</strong> machines per datacenter and a <strong>timeslave daemon</strong> per machine.</li><li>The majority of masters have GPS receivers with dedicated antennas.<ul><li>These masters are separated physically to reduce the effects of antenna failures, radio interference, and spoofing.</li></ul></li><li>The remaining masters (which we refer to as <strong>Armageddon masters</strong>) are equipped with atomic clocks.</li></ol><h3 id="what-does-time-masters-need-to-do"><a class="markdownIt-Anchor" href="#what-does-time-masters-need-to-do"></a> What does time masters need to do?</h3><ol><li><p>All masters’ time references are regularly compared against each other.</p></li><li><p>Each master also cross-checks the rate at which its reference advances time against its own local clock, and evicts itself if there is substantial divergence.</p></li><li><p>Between synchronizations,</p><ul><li><p>Armageddon masters advertise a slowly increasing time uncertainty that is derived from conservatively applied worst-case clock drift.</p></li><li><p>GPS masters advertise uncertainty that is typically close to zero.</p></li></ul></li></ol><h3 id="what-does-daemons-need-to-do"><a class="markdownIt-Anchor" href="#what-does-daemons-need-to-do"></a> What does daemons need to do?</h3><ol><li>Every daemon polls a variety of masters to reduce vulnerability to errors from any one master.<ul><li>Some are GPS masters chosen from nearby datacenters</li><li>The rest are GPS masters from farther datacenters, as well as some Armageddon masters.</li></ul></li><li>Daemons apply a variant of Marzullo’s algorithm to detect and reject liars, and synchronize the local machine clocks to the non-liars.</li><li>To protect against broken local clocks, machines that exhibit frequency excursions larger than the worstcase bound derived from component specifications and operating environment are evicted.</li><li>Between synchronizations,<ul><li>A daemon advertises a slowly increasing time uncertainty. <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>ϵ</mi></mrow><annotation encoding="application/x-tex">\epsilon</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathnormal">ϵ</span></span></span></span> is derived from conservatively applied worst-case local clock drift.</li><li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>ϵ</mi></mrow><annotation encoding="application/x-tex">\epsilon</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathnormal">ϵ</span></span></span></span> also depends on time-master uncertainty and communication delay to the time masters.</li></ul></li></ol><h2 id="concurrency-control"><a class="markdownIt-Anchor" href="#concurrency-control"></a> Concurrency control</h2><h3 id="how-does-spanner-manage-paxos-leader-leases"><a class="markdownIt-Anchor" href="#how-does-spanner-manage-paxos-leader-leases"></a> How does Spanner manage Paxos leader leases?</h3><ol><li>Spanner depends on the <strong>disjointness invariant</strong>: for each Paxos group, each Paxos leader’s lease interval is disjoint from every other leader’s.</li><li>The Spanner implementation permits a Paxos leader to abdicate by releasing its slaves from their lease votes.<ul><li>To preserve the disjointness invariant, Spanner constrains when abdication is permissible.</li><li>Define <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>s</mi><mrow><mi>m</mi><mi>a</mi><mi>x</mi></mrow></msub></mrow><annotation encoding="application/x-tex">s_{max}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">m</span><span class="mord mathnormal mtight">a</span><span class="mord mathnormal mtight">x</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> to be the maximum timestamp used by a leader. Before abdicating, a leader must wait until <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>T</mi><mi>T</mi><mi mathvariant="normal">.</mi><mi>a</mi><mi>f</mi><mi>t</mi><mi>e</mi><mi>r</mi><mo stretchy="false">(</mo><msub><mi>s</mi><mrow><mi>m</mi><mi>a</mi><mi>x</mi></mrow></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">TT.after(s_{max})</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="mord">.</span><span class="mord mathnormal">a</span><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="mord mathnormal">t</span><span class="mord mathnormal">e</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">m</span><span class="mord mathnormal mtight">a</span><span class="mord mathnormal mtight">x</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span> is true.</li></ul></li></ol><h3 id="read-write-transactions"><a class="markdownIt-Anchor" href="#read-write-transactions"></a> Read-write transactions</h3><h4 id="how-does-spanner-assign-timestamps-to-rw-transactions"><a class="markdownIt-Anchor" href="#how-does-spanner-assign-timestamps-to-rw-transactions"></a> How does Spanner assign timestamps to RW transactions?</h4><ol><li>For a given transaction, Spanner assigns it the timestamp that Paxos assigns to the Paxos write that represents the transaction commit.</li><li><strong>Monotonicity invariant</strong>: within each Paxos group, Spanner assigns timestamps to Paxos writes in monotonically increasing order, even across leaders.<ul><li>This invariant is enforced across leaders by making use of the disjointness invariant: a leader must only assign timestamps within the interval of its leader lease.</li><li>Whenever a timestamp <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>s</mi></mrow><annotation encoding="application/x-tex">s</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathnormal">s</span></span></span></span> is assigned, <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>s</mi><mrow><mi>m</mi><mi>a</mi><mi>x</mi></mrow></msub></mrow><annotation encoding="application/x-tex">s_{max}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">m</span><span class="mord mathnormal mtight">a</span><span class="mord mathnormal mtight">x</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> is advanced to s to preserve disjointness.</li></ul></li></ol><h4 id="how-does-spanner-enfore-external-consistency-invariant"><a class="markdownIt-Anchor" href="#how-does-spanner-enfore-external-consistency-invariant"></a> How does Spanner enfore external-consistency invariant?</h4><ol><li><p><strong>External-consistency invariant</strong>: if the start of a transaction <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>T</mi><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">T_2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> occurs after the commit of a transaction <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>T</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">T_1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>, then the commit timestamp of <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>T</mi><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">T_2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> must be greater than the commit timestamp of <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>T</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">T_1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>.</p></li><li><p>Define the start and commit events for a transaction <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>T</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">T_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> by <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msubsup><mi>e</mi><mi>i</mi><mrow><mi>s</mi><mi>t</mi><mi>a</mi><mi>r</mi><mi>t</mi></mrow></msubsup></mrow><annotation encoding="application/x-tex">e^{start}_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.05222em;vertical-align:-0.258664em;"></span><span class="mord"><span class="mord mathnormal">e</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.7935559999999999em;"><span style="top:-2.441336em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">s</span><span class="mord mathnormal mtight">t</span><span class="mord mathnormal mtight">a</span><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span><span class="mord mathnormal mtight">t</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.258664em;"><span></span></span></span></span></span></span></span></span></span> and <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msubsup><mi>e</mi><mi>i</mi><mrow><mi>c</mi><mi>o</mi><mi>m</mi><mi>m</mi><mi>i</mi><mi>t</mi></mrow></msubsup></mrow><annotation encoding="application/x-tex">e^{commit}_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.0833279999999998em;vertical-align:-0.258664em;"></span><span class="mord"><span class="mord mathnormal">e</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.824664em;"><span style="top:-2.441336em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">c</span><span class="mord mathnormal mtight">o</span><span class="mord mathnormal mtight">m</span><span class="mord mathnormal mtight">m</span><span class="mord mathnormal mtight">i</span><span class="mord mathnormal mtight">t</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.258664em;"><span></span></span></span></span></span></span></span></span></span> ; and the commit timestamp of a transaction <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>T</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">T_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> by <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>s</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">s_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>. The invariant becomes <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>t</mi><mrow><mi>a</mi><mi>b</mi><mi>s</mi></mrow></msub><mo stretchy="false">(</mo><msubsup><mi>e</mi><mn>1</mn><mrow><mi>c</mi><mi>o</mi><mi>m</mi><mi>m</mi><mi>i</mi><mi>t</mi></mrow></msubsup><mo stretchy="false">)</mo><mo>&lt;</mo><msub><mi>t</mi><mrow><mi>a</mi><mi>b</mi><mi>s</mi></mrow></msub><mo stretchy="false">(</mo><msubsup><mi>e</mi><mn>2</mn><mrow><mi>s</mi><mi>t</mi><mi>a</mi><mi>r</mi><mi>t</mi></mrow></msubsup><mo stretchy="false">)</mo><mo>⇒</mo><msub><mi>s</mi><mn>1</mn></msub><mo>&lt;</mo><msub><mi>s</mi><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">t_{abs}(e^{commit}_1 ) &lt; t_{abs}(e^{start}_2 ) \Rightarrow s_1 &lt; s_2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.0746639999999998em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathnormal">t</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">a</span><span class="mord mathnormal mtight">b</span><span class="mord mathnormal mtight">s</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">e</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.824664em;"><span style="top:-2.4518920000000004em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">c</span><span class="mord mathnormal mtight">o</span><span class="mord mathnormal mtight">m</span><span class="mord mathnormal mtight">m</span><span class="mord mathnormal mtight">i</span><span class="mord mathnormal mtight">t</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.24810799999999997em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">&lt;</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.043556em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathnormal">t</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">a</span><span class="mord mathnormal mtight">b</span><span class="mord mathnormal mtight">s</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">e</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.7935559999999999em;"><span style="top:-2.4518920000000004em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">s</span><span class="mord mathnormal mtight">t</span><span class="mord mathnormal mtight">a</span><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span><span class="mord mathnormal mtight">t</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.24810799999999997em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">⇒</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.6891em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">&lt;</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>.</p></li><li><p>Define the arrival event of the commit request at the coordinator leader for a write <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>T</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">T_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> to be <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msubsup><mi>e</mi><mi>i</mi><mrow><mi>s</mi><mi>e</mi><mi>r</mi><mi>v</mi><mi>e</mi><mi>r</mi></mrow></msubsup></mrow><annotation encoding="application/x-tex">e^{server}_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.923056em;vertical-align:-0.258664em;"></span><span class="mord"><span class="mord mathnormal">e</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.664392em;"><span style="top:-2.441336em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">s</span><span class="mord mathnormal mtight">e</span><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span><span class="mord mathnormal mtight" style="margin-right:0.03588em;">v</span><span class="mord mathnormal mtight">e</span><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.258664em;"><span></span></span></span></span></span></span></span></span></span>.</p></li><li><p>The protocol for executing transactions and assigning timestamps obeys two rules</p><ul><li><strong>Start</strong>: The coordinator leader for a write <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>T</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">T_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> assigns a commit timestamp <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>s</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">s_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> no less than the value of <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>T</mi><mi>T</mi><mi mathvariant="normal">.</mi><mi>n</mi><mi>o</mi><mi>w</mi><mo stretchy="false">(</mo><mo stretchy="false">)</mo><mi mathvariant="normal">.</mi><mi>l</mi><mi>a</mi><mi>t</mi><mi>e</mi><mi>s</mi><mi>t</mi></mrow><annotation encoding="application/x-tex">TT.now().latest</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="mord">.</span><span class="mord mathnormal">n</span><span class="mord mathnormal">o</span><span class="mord mathnormal" style="margin-right:0.02691em;">w</span><span class="mopen">(</span><span class="mclose">)</span><span class="mord">.</span><span class="mord mathnormal" style="margin-right:0.01968em;">l</span><span class="mord mathnormal">a</span><span class="mord mathnormal">t</span><span class="mord mathnormal">e</span><span class="mord mathnormal">s</span><span class="mord mathnormal">t</span></span></span></span>, computed after <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msubsup><mi>e</mi><mi>i</mi><mrow><mi>s</mi><mi>e</mi><mi>r</mi><mi>v</mi><mi>e</mi><mi>r</mi></mrow></msubsup></mrow><annotation encoding="application/x-tex">e^{server}_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.923056em;vertical-align:-0.258664em;"></span><span class="mord"><span class="mord mathnormal">e</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.664392em;"><span style="top:-2.441336em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">s</span><span class="mord mathnormal mtight">e</span><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span><span class="mord mathnormal mtight" style="margin-right:0.03588em;">v</span><span class="mord mathnormal mtight">e</span><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.258664em;"><span></span></span></span></span></span></span></span></span></span> .</li><li><strong>Commit Wait</strong>: The coordinator leader ensures that clients cannot see any data committed by <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>T</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">T_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> until <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>T</mi><mi>T</mi><mi mathvariant="normal">.</mi><mi>a</mi><mi>f</mi><mi>t</mi><mi>e</mi><mi>r</mi><mo stretchy="false">(</mo><msub><mi>s</mi><mi>i</mi></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">TT.after(s_i)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="mord">.</span><span class="mord mathnormal">a</span><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="mord mathnormal">t</span><span class="mord mathnormal">e</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span> is true.<ul><li>Commit wait ensures that <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>s</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">s_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> is less than the absolute commit time of <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>T</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">T_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>, or <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>s</mi><mi>i</mi></msub><mo>&lt;</mo><msub><mi>t</mi><mrow><mi>a</mi><mi>b</mi><mi>s</mi></mrow></msub><mo stretchy="false">(</mo><msubsup><mi>e</mi><mi>i</mi><mrow><mi>c</mi><mi>o</mi><mi>m</mi><mi>m</mi><mi>i</mi><mi>t</mi></mrow></msubsup><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">s_i &lt; t_{abs}(e^{commit}_i )</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6891em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">&lt;</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.0833279999999998em;vertical-align:-0.258664em;"></span><span class="mord"><span class="mord mathnormal">t</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">a</span><span class="mord mathnormal mtight">b</span><span class="mord mathnormal mtight">s</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">e</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.824664em;"><span style="top:-2.441336em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">c</span><span class="mord mathnormal mtight">o</span><span class="mord mathnormal mtight">m</span><span class="mord mathnormal mtight">m</span><span class="mord mathnormal mtight">i</span><span class="mord mathnormal mtight">t</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.258664em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span>.</li></ul></li></ul></li><li><p>Proof:</p><img src="/imgs/Distributed/Spanner/ec_invariant.png" width="50%"></li></ol><h4 id="how-does-spanner-handle-reads-within-rw-transactions"><a class="markdownIt-Anchor" href="#how-does-spanner-handle-reads-within-rw-transactions"></a> How does Spanner handle reads within RW transactions?</h4><ol><li>Reads in a transaction do not see the effects of the transaction’s writes.<ul><li>Writes that occur in a transaction are buffered at the client until commit.</li><li>A read returns the timestamps of any data read, and uncommitted writes have not yet been assigned timestamps.</li></ul></li><li>Reads within read-write transactions use wound-wait to avoid deadlocks.<ul><li>When Transaction <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>T</mi><mi>n</mi></msub></mrow><annotation encoding="application/x-tex">T_n</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">n</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> requests a data item currently held by <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>T</mi><mi>k</mi></msub></mrow><annotation encoding="application/x-tex">T_k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>, <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>T</mi><mi>n</mi></msub></mrow><annotation encoding="application/x-tex">T_n</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">n</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> is allowed to wait only if it has a timestamp larger than that of <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>T</mi><mi>k</mi></msub></mrow><annotation encoding="application/x-tex">T_k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>, otherwise <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>T</mi><mi>k</mi></msub></mrow><annotation encoding="application/x-tex">T_k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> is killed (i.e. <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>T</mi><mi>k</mi></msub></mrow><annotation encoding="application/x-tex">T_k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> is wounded by <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>T</mi><mi>n</mi></msub></mrow><annotation encoding="application/x-tex">T_n</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">n</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>).</li><li>This scheme allows the younger transaction requesting a lock to “wait” if the older transaction already holds a lock, but forces the younger one to be suspended (“wound”) if the older transaction requests a lock on an item already held by the younger one.</li></ul></li></ol><h4 id="what-is-the-client-drive-two-phase-commit"><a class="markdownIt-Anchor" href="#what-is-the-client-drive-two-phase-commit"></a> What is the client drive two-phase commit?</h4><ol><li>The client issues reads to the leader replica of the appropriate group, which acquires read locks and then reads the most recent data.</li><li>While a client transaction remains open, it sends keepalive messages to prevent participant leaders from timing out its transaction.</li><li>When a client has completed all reads and buffered all writes, it begins two-phase commit.<ul><li>The client chooses a coordinator group.</li><li>Then it sends a commit message to each participant’s leader with the identity of the coordinator and any buffered writes.</li></ul></li><li>Having the client drive two-phase commit avoids sending data twice across wide-area links.</li></ol><h4 id="how-to-perform-the-two-phase-commit"><a class="markdownIt-Anchor" href="#how-to-perform-the-two-phase-commit"></a> How to perform the two-phase commit?</h4><ol><li>A non-coordinator-participant leader,<ul><li>It first acquires write locks.</li><li>It then chooses a prepare timestamp that must be larger than any timestamps it has assigned to previous transactions, and logs a prepare record through Paxos.</li><li>Each participant then notifies the coordinator of its prepare timestamp.</li></ul></li><li>The coordinator leader,<ul><li>It also first acquires write locks, but skips the prepare phase.</li><li>It chooses a timestamp for the entire transaction after hearing from all other participant leaders.</li><li>The commit timestamp s must be<ul><li>Greater or equal to all prepare timestamps,</li><li>Greater than <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>T</mi><mi>T</mi><mi mathvariant="normal">.</mi><mi>n</mi><mi>o</mi><mi>w</mi><mo stretchy="false">(</mo><mo stretchy="false">)</mo><mi mathvariant="normal">.</mi><mi>l</mi><mi>a</mi><mi>t</mi><mi>e</mi><mi>s</mi><mi>t</mi></mrow><annotation encoding="application/x-tex">TT.now().latest</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="mord">.</span><span class="mord mathnormal">n</span><span class="mord mathnormal">o</span><span class="mord mathnormal" style="margin-right:0.02691em;">w</span><span class="mopen">(</span><span class="mclose">)</span><span class="mord">.</span><span class="mord mathnormal" style="margin-right:0.01968em;">l</span><span class="mord mathnormal">a</span><span class="mord mathnormal">t</span><span class="mord mathnormal">e</span><span class="mord mathnormal">s</span><span class="mord mathnormal">t</span></span></span></span> at the time the coordinator received its commit message,</li><li>Greater than any timestamps the leader has assigned to previous transactions.</li><li>The coordinator leader logs a commit record through Paxos, or an abort if it timed out while waiting on the other participants.</li></ul></li></ul></li><li>Before allowing any coordinator replica to apply the commit record, the coordinator leader waits until <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>T</mi><mi>T</mi><mi mathvariant="normal">.</mi><mi>a</mi><mi>f</mi><mi>t</mi><mi>e</mi><mi>r</mi><mo stretchy="false">(</mo><mi>s</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">TT.after(s)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="mord">.</span><span class="mord mathnormal">a</span><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="mord mathnormal">t</span><span class="mord mathnormal">e</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mopen">(</span><span class="mord mathnormal">s</span><span class="mclose">)</span></span></span></span>.<ul><li>This wait is typically overlapped with Paxos communication.</li></ul></li><li>After commit wait, the coordinator sends the commit timestamp to the client and all other participant leaders.</li><li>Each participant leader logs the transaction’s outcome through Paxos. All participants apply at the same timestamp and then release locks.</li></ol><h3 id="read-only-transactions"><a class="markdownIt-Anchor" href="#read-only-transactions"></a> Read-only transactions</h3><h4 id="what-kinds-of-ro-transactions-does-spanner-provide"><a class="markdownIt-Anchor" href="#what-kinds-of-ro-transactions-does-spanner-provide"></a> What kinds of RO transactions does Spanner provide?</h4><ol><li>A read-only transaction is a kind of transaction that has the performance benefits of snapshot isolation.<ul><li>Reads in a read-only transaction execute at a system-chosen timestamp without locking, so that incoming writes are not blocked.</li></ul></li><li>A snapshot read is a read in the past that executes without locking.<ul><li>A client can specify a timestamp for a snapshot read.</li><li>Or they can provide an upper bound on the desired timestamp’s staleness and let Spanner choose a timestamp.</li></ul></li><li>For both read-only transactions and snapshot reads<ul><li>The execution of the reads in a read-only transaction can proceed on any replica that is sufficiently up-to-date.</li><li>Commit is inevitable once a timestamp has been chosen, unless the data at that timestamp has been garbagecollected.<ul><li>Clients can avoid buffering results inside a retry loop.</li><li>When a server fails, clients can internally continue the query on a different server by repeating the timestamp and the current read position.</li></ul></li></ul></li></ol><h4 id="how-does-spanner-server-reads-given-its-timestamp"><a class="markdownIt-Anchor" href="#how-does-spanner-server-reads-given-its-timestamp"></a> How does Spanner server reads given its timestamp?</h4><ol><li>Every replica tracks a value called safe time <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>t</mi><mrow><mi>s</mi><mi>a</mi><mi>f</mi><mi>e</mi></mrow></msub></mrow><annotation encoding="application/x-tex">t_{safe}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.9011879999999999em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord mathnormal">t</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361079999999999em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">s</span><span class="mord mathnormal mtight">a</span><span class="mord mathnormal mtight" style="margin-right:0.10764em;">f</span><span class="mord mathnormal mtight">e</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span></span></span></span> which is the maximum timestamp at which a replica is up-to-date.</li><li>Each Paxos state machine has a safe time <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msubsup><mi>t</mi><mrow><mi>s</mi><mi>a</mi><mi>f</mi><mi>e</mi></mrow><mrow><mi>P</mi><mi>a</mi><mi>x</mi><mi>o</mi><mi>s</mi></mrow></msubsup></mrow><annotation encoding="application/x-tex">t^{Paxos}_{safe}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.2605469999999999em;vertical-align:-0.4192159999999999em;"></span><span class="mord"><span class="mord mathnormal">t</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8413309999999999em;"><span style="top:-2.4168920000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">s</span><span class="mord mathnormal mtight">a</span><span class="mord mathnormal mtight" style="margin-right:0.10764em;">f</span><span class="mord mathnormal mtight">e</span></span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em;">P</span><span class="mord mathnormal mtight">a</span><span class="mord mathnormal mtight">x</span><span class="mord mathnormal mtight">o</span><span class="mord mathnormal mtight">s</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.4192159999999999em;"><span></span></span></span></span></span></span></span></span></span>.<ul><li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msubsup><mi>t</mi><mrow><mi>s</mi><mi>a</mi><mi>f</mi><mi>e</mi></mrow><mrow><mi>P</mi><mi>a</mi><mi>x</mi><mi>o</mi><mi>s</mi></mrow></msubsup></mrow><annotation encoding="application/x-tex">t^{Paxos}_{safe}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.2605469999999999em;vertical-align:-0.4192159999999999em;"></span><span class="mord"><span class="mord mathnormal">t</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8413309999999999em;"><span style="top:-2.4168920000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">s</span><span class="mord mathnormal mtight">a</span><span class="mord mathnormal mtight" style="margin-right:0.10764em;">f</span><span class="mord mathnormal mtight">e</span></span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em;">P</span><span class="mord mathnormal mtight">a</span><span class="mord mathnormal mtight">x</span><span class="mord mathnormal mtight">o</span><span class="mord mathnormal mtight">s</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.4192159999999999em;"><span></span></span></span></span></span></span></span></span></span> is the timestamp of the highest-applied Paxos write.</li><li>Because timestamps increase monotonically and writes are applied in order, writes will no longer occur at or below <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msubsup><mi>t</mi><mrow><mi>s</mi><mi>a</mi><mi>f</mi><mi>e</mi></mrow><mrow><mi>P</mi><mi>a</mi><mi>x</mi><mi>o</mi><mi>s</mi></mrow></msubsup></mrow><annotation encoding="application/x-tex">t^{Paxos}_{safe}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.2605469999999999em;vertical-align:-0.4192159999999999em;"></span><span class="mord"><span class="mord mathnormal">t</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8413309999999999em;"><span style="top:-2.4168920000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">s</span><span class="mord mathnormal mtight">a</span><span class="mord mathnormal mtight" style="margin-right:0.10764em;">f</span><span class="mord mathnormal mtight">e</span></span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em;">P</span><span class="mord mathnormal mtight">a</span><span class="mord mathnormal mtight">x</span><span class="mord mathnormal mtight">o</span><span class="mord mathnormal mtight">s</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.4192159999999999em;"><span></span></span></span></span></span></span></span></span></span> with respect to Paxos.</li></ul></li><li>Each transaction manager has a safe time <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msubsup><mi>t</mi><mrow><mi>s</mi><mi>a</mi><mi>f</mi><mi>e</mi></mrow><mrow><mi>T</mi><mi>M</mi></mrow></msubsup></mrow><annotation encoding="application/x-tex">t^{TM}_{safe}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.2605469999999999em;vertical-align:-0.4192159999999999em;"></span><span class="mord"><span class="mord mathnormal">t</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8413309999999999em;"><span style="top:-2.4168920000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">s</span><span class="mord mathnormal mtight">a</span><span class="mord mathnormal mtight" style="margin-right:0.10764em;">f</span><span class="mord mathnormal mtight">e</span></span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em;">T</span><span class="mord mathnormal mtight" style="margin-right:0.10903em;">M</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.4192159999999999em;"><span></span></span></span></span></span></span></span></span></span>.<ul><li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msubsup><mi>t</mi><mrow><mi>s</mi><mi>a</mi><mi>f</mi><mi>e</mi></mrow><mrow><mi>T</mi><mi>M</mi></mrow></msubsup></mrow><annotation encoding="application/x-tex">t^{TM}_{safe}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.2605469999999999em;vertical-align:-0.4192159999999999em;"></span><span class="mord"><span class="mord mathnormal">t</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8413309999999999em;"><span style="top:-2.4168920000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">s</span><span class="mord mathnormal mtight">a</span><span class="mord mathnormal mtight" style="margin-right:0.10764em;">f</span><span class="mord mathnormal mtight">e</span></span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em;">T</span><span class="mord mathnormal mtight" style="margin-right:0.10903em;">M</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.4192159999999999em;"><span></span></span></span></span></span></span></span></span></span> is <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal">∞</mi></mrow><annotation encoding="application/x-tex">\infty</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord">∞</span></span></span></span> at a replica if there are zero prepared (but not committed) transactions, i.e. transactions in between the two phases of two-phase commit.</li><li>If there are any such transactions, then the state affected by those transactions is indeterminate.<ul><li>A participant replica does not know yet whether such transactions will commit.</li><li>The commit protocol ensures that every participant knows a lower bound on a prepared transaction’s timestamp.</li><li>Every participant leader (for a group <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>g</mi></mrow><annotation encoding="application/x-tex">g</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">g</span></span></span></span>) for a transaction <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>T</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">T_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> assigns a prepare timestamp <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msubsup><mi>s</mi><mrow><mi>i</mi><mo separator="true">,</mo><mi>g</mi></mrow><mrow><mi>p</mi><mi>r</mi><mi>e</mi><mi>p</mi><mi>a</mi><mi>r</mi><mi>e</mi></mrow></msubsup></mrow><annotation encoding="application/x-tex">s^{prepare}_{i,g}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.1952720000000001em;vertical-align:-0.412972em;"></span><span class="mord"><span class="mord mathnormal">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.7823em;"><span style="top:-2.4231360000000004em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight" style="margin-right:0.03588em;">g</span></span></span></span><span style="top:-3.1809080000000005em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">p</span><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span><span class="mord mathnormal mtight">e</span><span class="mord mathnormal mtight">p</span><span class="mord mathnormal mtight">a</span><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span><span class="mord mathnormal mtight">e</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.412972em;"><span></span></span></span></span></span></span></span></span></span> to its prepare record.</li><li>The coordinator leader ensures that the transaction’s commit timestamp <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>s</mi><mi>i</mi></msub><mo>≥</mo><msubsup><mi>s</mi><mrow><mi>i</mi><mo separator="true">,</mo><mi>g</mi></mrow><mrow><mi>p</mi><mi>r</mi><mi>e</mi><mi>p</mi><mi>a</mi><mi>r</mi><mi>e</mi></mrow></msubsup></mrow><annotation encoding="application/x-tex">s_i ≥ s^{prepare}_{i,g}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7859700000000001em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">≥</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.1952720000000001em;vertical-align:-0.412972em;"></span><span class="mord"><span class="mord mathnormal">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.7823em;"><span style="top:-2.4231360000000004em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight" style="margin-right:0.03588em;">g</span></span></span></span><span style="top:-3.1809080000000005em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">p</span><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span><span class="mord mathnormal mtight">e</span><span class="mord mathnormal mtight">p</span><span class="mord mathnormal mtight">a</span><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span><span class="mord mathnormal mtight">e</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.412972em;"><span></span></span></span></span></span></span></span></span></span> over all participant groups <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>g</mi></mrow><annotation encoding="application/x-tex">g</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">g</span></span></span></span>.</li><li>For every replica in a group <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>g</mi></mrow><annotation encoding="application/x-tex">g</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">g</span></span></span></span>, over all transactions <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>T</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">T_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> prepared at <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>g</mi></mrow><annotation encoding="application/x-tex">g</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">g</span></span></span></span>, <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msubsup><mi>t</mi><mrow><mi>s</mi><mi>a</mi><mi>f</mi><mi>e</mi></mrow><mrow><mi>T</mi><mi>M</mi></mrow></msubsup><mo>=</mo><mi>m</mi><mi>i</mi><msub><mi>n</mi><mi>i</mi></msub><mo stretchy="false">(</mo><msubsup><mi>s</mi><mrow><mi>i</mi><mo separator="true">,</mo><mi>g</mi></mrow><mrow><mi>p</mi><mi>r</mi><mi>e</mi><mi>p</mi><mi>a</mi><mi>r</mi><mi>e</mi></mrow></msubsup><mo stretchy="false">)</mo><mtext>−</mtext><mn>1</mn></mrow><annotation encoding="application/x-tex">t^{TM}_{safe} = min_i(s^{prepare}_{i,g}) − 1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.2605469999999999em;vertical-align:-0.4192159999999999em;"></span><span class="mord"><span class="mord mathnormal">t</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8413309999999999em;"><span style="top:-2.4168920000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">s</span><span class="mord mathnormal mtight">a</span><span class="mord mathnormal mtight" style="margin-right:0.10764em;">f</span><span class="mord mathnormal mtight">e</span></span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em;">T</span><span class="mord mathnormal mtight" style="margin-right:0.10903em;">M</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.4192159999999999em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.1952720000000001em;vertical-align:-0.412972em;"></span><span class="mord mathnormal">m</span><span class="mord mathnormal">i</span><span class="mord"><span class="mord mathnormal">n</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.7823em;"><span style="top:-2.4231360000000004em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight" style="margin-right:0.03588em;">g</span></span></span></span><span style="top:-3.1809080000000005em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">p</span><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span><span class="mord mathnormal mtight">e</span><span class="mord mathnormal mtight">p</span><span class="mord mathnormal mtight">a</span><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span><span class="mord mathnormal mtight">e</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.412972em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mord">−</span><span class="mord">1</span></span></span></span> over all transactions prepared at <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>g</mi></mrow><annotation encoding="application/x-tex">g</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">g</span></span></span></span>.</li></ul></li></ul></li><li>Define <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>t</mi><mrow><mi>s</mi><mi>a</mi><mi>f</mi><mi>e</mi></mrow></msub><mo>=</mo><mi>m</mi><mi>i</mi><mi>n</mi><mo stretchy="false">(</mo><msubsup><mi>t</mi><mrow><mi>s</mi><mi>a</mi><mi>f</mi><mi>e</mi></mrow><mrow><mi>P</mi><mi>a</mi><mi>x</mi><mi>o</mi><mi>s</mi></mrow></msubsup><mo separator="true">,</mo><msubsup><mi>t</mi><mrow><mi>s</mi><mi>a</mi><mi>f</mi><mi>e</mi></mrow><mrow><mi>T</mi><mi>M</mi></mrow></msubsup><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">t_{safe} = min(t^{Paxos}_{safe} , t^{TM}_{safe})</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.9011879999999999em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord mathnormal">t</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361079999999999em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">s</span><span class="mord mathnormal mtight">a</span><span class="mord mathnormal mtight" style="margin-right:0.10764em;">f</span><span class="mord mathnormal mtight">e</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.2605469999999999em;vertical-align:-0.4192159999999999em;"></span><span class="mord mathnormal">m</span><span class="mord mathnormal">i</span><span class="mord mathnormal">n</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">t</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8413309999999999em;"><span style="top:-2.4168920000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">s</span><span class="mord mathnormal mtight">a</span><span class="mord mathnormal mtight" style="margin-right:0.10764em;">f</span><span class="mord mathnormal mtight">e</span></span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em;">P</span><span class="mord mathnormal mtight">a</span><span class="mord mathnormal mtight">x</span><span class="mord mathnormal mtight">o</span><span class="mord mathnormal mtight">s</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.4192159999999999em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathnormal">t</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8413309999999999em;"><span style="top:-2.4168920000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">s</span><span class="mord mathnormal mtight">a</span><span class="mord mathnormal mtight" style="margin-right:0.10764em;">f</span><span class="mord mathnormal mtight">e</span></span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em;">T</span><span class="mord mathnormal mtight" style="margin-right:0.10903em;">M</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.4192159999999999em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span>. A replica can satisfy a read at a timestamp <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>t</mi></mrow><annotation encoding="application/x-tex">t</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.61508em;vertical-align:0em;"></span><span class="mord mathnormal">t</span></span></span></span> if <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>t</mi><mo>≤</mo><msub><mi>t</mi><mrow><mi>s</mi><mi>a</mi><mi>f</mi><mi>e</mi></mrow></msub></mrow><annotation encoding="application/x-tex">t ≤ t_{safe}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7719400000000001em;vertical-align:-0.13597em;"></span><span class="mord mathnormal">t</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">≤</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.9011879999999999em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord mathnormal">t</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361079999999999em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">s</span><span class="mord mathnormal mtight">a</span><span class="mord mathnormal mtight" style="margin-right:0.10764em;">f</span><span class="mord mathnormal mtight">e</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span></span></span></span>.</li></ol><h4 id="how-to-optimize-for-the-safe-read-timestamp"><a class="markdownIt-Anchor" href="#how-to-optimize-for-the-safe-read-timestamp"></a> How to optimize for the safe read timestamp?</h4><ol><li><p>No reads can occur at timestamps later than <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msubsup><mi>t</mi><mrow><mi>s</mi><mi>a</mi><mi>f</mi><mi>e</mi></mrow><mrow><mi>T</mi><mi>M</mi></mrow></msubsup></mrow><annotation encoding="application/x-tex">t^{TM}_{safe}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.2605469999999999em;vertical-align:-0.4192159999999999em;"></span><span class="mord"><span class="mord mathnormal">t</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8413309999999999em;"><span style="top:-2.4168920000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">s</span><span class="mord mathnormal mtight">a</span><span class="mord mathnormal mtight" style="margin-right:0.10764em;">f</span><span class="mord mathnormal mtight">e</span></span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em;">T</span><span class="mord mathnormal mtight" style="margin-right:0.10903em;">M</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.4192159999999999em;"><span></span></span></span></span></span></span></span></span></span>, even if the reads do not conflict with the transaction.</p><ul><li><p>Can be removed by augmenting <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msubsup><mi>t</mi><mrow><mi>s</mi><mi>a</mi><mi>f</mi><mi>e</mi></mrow><mrow><mi>T</mi><mi>M</mi></mrow></msubsup></mrow><annotation encoding="application/x-tex">t^{TM}_{safe}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.2605469999999999em;vertical-align:-0.4192159999999999em;"></span><span class="mord"><span class="mord mathnormal">t</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8413309999999999em;"><span style="top:-2.4168920000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">s</span><span class="mord mathnormal mtight">a</span><span class="mord mathnormal mtight" style="margin-right:0.10764em;">f</span><span class="mord mathnormal mtight">e</span></span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em;">T</span><span class="mord mathnormal mtight" style="margin-right:0.10903em;">M</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.4192159999999999em;"><span></span></span></span></span></span></span></span></span></span> with a fine-grained mapping from key ranges to preparedtransaction timestamps.</p></li><li><p>This information can be stored in the lock table, which already maps key ranges to lock metadata.</p></li><li><p>When a read arrives, it only needs to be checked against the fine-grained safe time for key ranges with which the read conflicts.</p></li></ul></li><li><p><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msubsup><mi>t</mi><mrow><mi>s</mi><mi>a</mi><mi>f</mi><mi>e</mi></mrow><mrow><mi>P</mi><mi>a</mi><mi>x</mi><mi>o</mi><mi>s</mi></mrow></msubsup></mrow><annotation encoding="application/x-tex">t^{Paxos}_{safe}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.2605469999999999em;vertical-align:-0.4192159999999999em;"></span><span class="mord"><span class="mord mathnormal">t</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8413309999999999em;"><span style="top:-2.4168920000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">s</span><span class="mord mathnormal mtight">a</span><span class="mord mathnormal mtight" style="margin-right:0.10764em;">f</span><span class="mord mathnormal mtight">e</span></span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em;">P</span><span class="mord mathnormal mtight">a</span><span class="mord mathnormal mtight">x</span><span class="mord mathnormal mtight">o</span><span class="mord mathnormal mtight">s</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.4192159999999999em;"><span></span></span></span></span></span></span></span></span></span> cannot advance in the absence of Paxos writes. A snapshot read at <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>t</mi></mrow><annotation encoding="application/x-tex">t</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.61508em;vertical-align:0em;"></span><span class="mord mathnormal">t</span></span></span></span> cannot execute at Paxos groups whose last write happened before <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>t</mi></mrow><annotation encoding="application/x-tex">t</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.61508em;vertical-align:0em;"></span><span class="mord mathnormal">t</span></span></span></span>.</p><ul><li>Spanner addresses this problem by taking advantage of the disjointness of leader-lease intervals.</li><li>Each Paxos leader advances <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msubsup><mi>t</mi><mrow><mi>s</mi><mi>a</mi><mi>f</mi><mi>e</mi></mrow><mrow><mi>P</mi><mi>a</mi><mi>x</mi><mi>o</mi><mi>s</mi></mrow></msubsup></mrow><annotation encoding="application/x-tex">t^{Paxos}_{safe}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.2605469999999999em;vertical-align:-0.4192159999999999em;"></span><span class="mord"><span class="mord mathnormal">t</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8413309999999999em;"><span style="top:-2.4168920000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">s</span><span class="mord mathnormal mtight">a</span><span class="mord mathnormal mtight" style="margin-right:0.10764em;">f</span><span class="mord mathnormal mtight">e</span></span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em;">P</span><span class="mord mathnormal mtight">a</span><span class="mord mathnormal mtight">x</span><span class="mord mathnormal mtight">o</span><span class="mord mathnormal mtight">s</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.4192159999999999em;"><span></span></span></span></span></span></span></span></span></span> by keeping a threshold above which future writes’ timestamps will occur.<ul><li>It maintains a mapping <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>M</mi><mi>i</mi><mi>n</mi><mi>N</mi><mi>e</mi><mi>x</mi><mi>t</mi><mi>T</mi><mi>S</mi><mo stretchy="false">(</mo><mi>n</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">MinNextTS(n)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">M</span><span class="mord mathnormal">i</span><span class="mord mathnormal">n</span><span class="mord mathnormal" style="margin-right:0.10903em;">N</span><span class="mord mathnormal">e</span><span class="mord mathnormal">x</span><span class="mord mathnormal">t</span><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="mord mathnormal" style="margin-right:0.05764em;">S</span><span class="mopen">(</span><span class="mord mathnormal">n</span><span class="mclose">)</span></span></span></span> from Paxos sequence number <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi></mrow><annotation encoding="application/x-tex">n</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathnormal">n</span></span></span></span> to the minimum timestamp that may be assigned to Paxos sequence number <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi><mo>+</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">n + 1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.66666em;vertical-align:-0.08333em;"></span><span class="mord mathnormal">n</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">1</span></span></span></span>.</li><li>A replica can advance <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msubsup><mi>t</mi><mrow><mi>s</mi><mi>a</mi><mi>f</mi><mi>e</mi></mrow><mrow><mi>P</mi><mi>a</mi><mi>x</mi><mi>o</mi><mi>s</mi></mrow></msubsup></mrow><annotation encoding="application/x-tex">t^{Paxos}_{safe}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.2605469999999999em;vertical-align:-0.4192159999999999em;"></span><span class="mord"><span class="mord mathnormal">t</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8413309999999999em;"><span style="top:-2.4168920000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">s</span><span class="mord mathnormal mtight">a</span><span class="mord mathnormal mtight" style="margin-right:0.10764em;">f</span><span class="mord mathnormal mtight">e</span></span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em;">P</span><span class="mord mathnormal mtight">a</span><span class="mord mathnormal mtight">x</span><span class="mord mathnormal mtight">o</span><span class="mord mathnormal mtight">s</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.4192159999999999em;"><span></span></span></span></span></span></span></span></span></span> to <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>M</mi><mi>i</mi><mi>n</mi><mi>N</mi><mi>e</mi><mi>x</mi><mi>t</mi><mi>T</mi><mi>S</mi><mo stretchy="false">(</mo><mi>n</mi><mo stretchy="false">)</mo><mtext>−</mtext><mn>1</mn></mrow><annotation encoding="application/x-tex">MinNextTS(n) − 1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">M</span><span class="mord mathnormal">i</span><span class="mord mathnormal">n</span><span class="mord mathnormal" style="margin-right:0.10903em;">N</span><span class="mord mathnormal">e</span><span class="mord mathnormal">x</span><span class="mord mathnormal">t</span><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="mord mathnormal" style="margin-right:0.05764em;">S</span><span class="mopen">(</span><span class="mord mathnormal">n</span><span class="mclose">)</span><span class="mord">−</span><span class="mord">1</span></span></span></span> when it has applied through <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi></mrow><annotation encoding="application/x-tex">n</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathnormal">n</span></span></span></span>.</li></ul></li><li>A single leader can enforce its <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>M</mi><mi>i</mi><mi>n</mi><mi>N</mi><mi>e</mi><mi>x</mi><mi>t</mi><mi>T</mi><mi>S</mi><mo stretchy="false">(</mo><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">MinNextTS()</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">M</span><span class="mord mathnormal">i</span><span class="mord mathnormal">n</span><span class="mord mathnormal" style="margin-right:0.10903em;">N</span><span class="mord mathnormal">e</span><span class="mord mathnormal">x</span><span class="mord mathnormal">t</span><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="mord mathnormal" style="margin-right:0.05764em;">S</span><span class="mopen">(</span><span class="mclose">)</span></span></span></span> promises easily.<ul><li>The timestamps promised by <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>M</mi><mi>i</mi><mi>n</mi><mi>N</mi><mi>e</mi><mi>x</mi><mi>t</mi><mi>T</mi><mi>S</mi><mo stretchy="false">(</mo><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">MinNextTS()</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">M</span><span class="mord mathnormal">i</span><span class="mord mathnormal">n</span><span class="mord mathnormal" style="margin-right:0.10903em;">N</span><span class="mord mathnormal">e</span><span class="mord mathnormal">x</span><span class="mord mathnormal">t</span><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="mord mathnormal" style="margin-right:0.05764em;">S</span><span class="mopen">(</span><span class="mclose">)</span></span></span></span> lie within a leader’s lease, the disjointness invariant enforces <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>M</mi><mi>i</mi><mi>n</mi><mi>N</mi><mi>e</mi><mi>x</mi><mi>t</mi><mi>T</mi><mi>S</mi><mo stretchy="false">(</mo><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">MinNextTS()</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">M</span><span class="mord mathnormal">i</span><span class="mord mathnormal">n</span><span class="mord mathnormal" style="margin-right:0.10903em;">N</span><span class="mord mathnormal">e</span><span class="mord mathnormal">x</span><span class="mord mathnormal">t</span><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="mord mathnormal" style="margin-right:0.05764em;">S</span><span class="mopen">(</span><span class="mclose">)</span></span></span></span> promises across leaders.</li><li>If a leader wishes to advance MinNextTS() beyond the end of its leader lease, it must first extend its lease.</li></ul></li><li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>s</mi><mrow><mi>m</mi><mi>a</mi><mi>x</mi></mrow></msub></mrow><annotation encoding="application/x-tex">s_{max}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">m</span><span class="mord mathnormal mtight">a</span><span class="mord mathnormal mtight">x</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> is always advanced to the highest value in <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>M</mi><mi>i</mi><mi>n</mi><mi>N</mi><mi>e</mi><mi>x</mi><mi>t</mi><mi>T</mi><mi>S</mi><mo stretchy="false">(</mo><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">MinNextTS()</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">M</span><span class="mord mathnormal">i</span><span class="mord mathnormal">n</span><span class="mord mathnormal" style="margin-right:0.10903em;">N</span><span class="mord mathnormal">e</span><span class="mord mathnormal">x</span><span class="mord mathnormal">t</span><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="mord mathnormal" style="margin-right:0.05764em;">S</span><span class="mopen">(</span><span class="mclose">)</span></span></span></span> to preserve disjointness.</li></ul></li></ol><h4 id="how-to-perform-ro-transactions"><a class="markdownIt-Anchor" href="#how-to-perform-ro-transactions"></a> How to perform RO transactions?</h4><ol><li>A read-only transaction executes in two phases<ul><li>Assign a timestamp <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>s</mi><mrow><mi>r</mi><mi>e</mi><mi>a</mi><mi>d</mi></mrow></msub></mrow><annotation encoding="application/x-tex">s_{read}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span><span class="mord mathnormal mtight">e</span><span class="mord mathnormal mtight">a</span><span class="mord mathnormal mtight">d</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span></li><li>Then execute the transaction’s reads as snapshot reads at sread.</li><li>The snapshot reads can execute at any replicas that are sufficiently up-to-date.</li></ul></li><li>The simple assignment of <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>s</mi><mrow><mi>r</mi><mi>e</mi><mi>a</mi><mi>d</mi></mrow></msub><mo>=</mo><mi>T</mi><mi>T</mi><mi mathvariant="normal">.</mi><mi>n</mi><mi>o</mi><mi>w</mi><mo stretchy="false">(</mo><mo stretchy="false">)</mo><mi mathvariant="normal">.</mi><mi>l</mi><mi>a</mi><mi>t</mi><mi>e</mi><mi>s</mi><mi>t</mi></mrow><annotation encoding="application/x-tex">s_{read} = TT.now().latest</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span><span class="mord mathnormal mtight">e</span><span class="mord mathnormal mtight">a</span><span class="mord mathnormal mtight">d</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="mord">.</span><span class="mord mathnormal">n</span><span class="mord mathnormal">o</span><span class="mord mathnormal" style="margin-right:0.02691em;">w</span><span class="mopen">(</span><span class="mclose">)</span><span class="mord">.</span><span class="mord mathnormal" style="margin-right:0.01968em;">l</span><span class="mord mathnormal">a</span><span class="mord mathnormal">t</span><span class="mord mathnormal">e</span><span class="mord mathnormal">s</span><span class="mord mathnormal">t</span></span></span></span><ul><li>At any time after a transaction starts, it preserves external consistency by an argument analogous to that presented for writes.</li><li>Such a timestamp may require the execution of the data reads at <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>s</mi><mrow><mi>r</mi><mi>e</mi><mi>a</mi><mi>d</mi></mrow></msub></mrow><annotation encoding="application/x-tex">s_{read}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span><span class="mord mathnormal mtight">e</span><span class="mord mathnormal mtight">a</span><span class="mord mathnormal mtight">d</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> to block if <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>t</mi><mrow><mi>s</mi><mi>a</mi><mi>f</mi><mi>e</mi></mrow></msub></mrow><annotation encoding="application/x-tex">t_{safe}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.9011879999999999em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord mathnormal">t</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361079999999999em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">s</span><span class="mord mathnormal mtight">a</span><span class="mord mathnormal mtight" style="margin-right:0.10764em;">f</span><span class="mord mathnormal mtight">e</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span></span></span></span> has not advanced sufficiently.</li></ul></li><li>To reduce the chances of blocking, Spanner should assign the oldest timestamp that preserves external consistency.</li></ol><h4 id="how-does-spanner-assign-timestamps-to-ro-transactions"><a class="markdownIt-Anchor" href="#how-does-spanner-assign-timestamps-to-ro-transactions"></a> How does Spanner assign timestamps to RO transactions?</h4><ol><li>Assigning a timestamp requires a negotiation phase between all of the Paxos groups that are involved in the reads.</li><li>Spanner requires a scope expression for every read-only transaction, which is an expression that summarizes the keys that will be read by the entire transaction.</li><li>If the scope’s values are served by a single Paxos group<ul><li>The client issues the read-only transaction to that group’s leader. That leader assigns <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>s</mi><mrow><mi>r</mi><mi>e</mi><mi>a</mi><mi>d</mi></mrow></msub></mrow><annotation encoding="application/x-tex">s_{read}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span><span class="mord mathnormal mtight">e</span><span class="mord mathnormal mtight">a</span><span class="mord mathnormal mtight">d</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> and executes the read.</li><li>Define <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>L</mi><mi>a</mi><mi>s</mi><mi>t</mi><mi>T</mi><mi>S</mi><mo stretchy="false">(</mo><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">LastTS()</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">L</span><span class="mord mathnormal">a</span><span class="mord mathnormal">s</span><span class="mord mathnormal">t</span><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="mord mathnormal" style="margin-right:0.05764em;">S</span><span class="mopen">(</span><span class="mclose">)</span></span></span></span> to be the timestamp of the last committed write at a Paxos group.</li><li>If there are no prepared transactions, the assignment <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>s</mi><mrow><mi>r</mi><mi>e</mi><mi>a</mi><mi>d</mi></mrow></msub><mo>=</mo><mi>L</mi><mi>a</mi><mi>s</mi><mi>t</mi><mi>T</mi><mi>S</mi><mo stretchy="false">(</mo><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">s_{read} = LastTS()</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span><span class="mord mathnormal mtight">e</span><span class="mord mathnormal mtight">a</span><span class="mord mathnormal mtight">d</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">L</span><span class="mord mathnormal">a</span><span class="mord mathnormal">s</span><span class="mord mathnormal">t</span><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="mord mathnormal" style="margin-right:0.05764em;">S</span><span class="mopen">(</span><span class="mclose">)</span></span></span></span> trivially satisfies external consistency: the transaction will see the result of the last write, and therefore be ordered after it.</li></ul></li><li>If the scope’s values are served by multiple Paxos groups<ul><li>The most complicated option is to do a round of communication with all of the groups’s leaders to negotiate <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>s</mi><mrow><mi>r</mi><mi>e</mi><mi>a</mi><mi>d</mi></mrow></msub></mrow><annotation encoding="application/x-tex">s_{read}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span><span class="mord mathnormal mtight">e</span><span class="mord mathnormal mtight">a</span><span class="mord mathnormal mtight">d</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> based on <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>L</mi><mi>a</mi><mi>s</mi><mi>t</mi><mi>T</mi><mi>S</mi><mo stretchy="false">(</mo><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">LastTS()</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">L</span><span class="mord mathnormal">a</span><span class="mord mathnormal">s</span><span class="mord mathnormal">t</span><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="mord mathnormal" style="margin-right:0.05764em;">S</span><span class="mopen">(</span><span class="mclose">)</span></span></span></span>.</li><li>A simpler choice is that the client avoids a negotiation round, and just has its reads execute at <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>s</mi><mrow><mi>r</mi><mi>e</mi><mi>a</mi><mi>d</mi></mrow></msub><mo>=</mo><mi>T</mi><mi>T</mi><mi mathvariant="normal">.</mi><mi>n</mi><mi>o</mi><mi>w</mi><mo stretchy="false">(</mo><mo stretchy="false">)</mo><mi mathvariant="normal">.</mi><mi>l</mi><mi>a</mi><mi>t</mi><mi>e</mi><mi>s</mi><mi>t</mi></mrow><annotation encoding="application/x-tex">s_{read} = TT.now().latest</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span><span class="mord mathnormal mtight">e</span><span class="mord mathnormal mtight">a</span><span class="mord mathnormal mtight">d</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="mord">.</span><span class="mord mathnormal">n</span><span class="mord mathnormal">o</span><span class="mord mathnormal" style="margin-right:0.02691em;">w</span><span class="mopen">(</span><span class="mclose">)</span><span class="mord">.</span><span class="mord mathnormal" style="margin-right:0.01968em;">l</span><span class="mord mathnormal">a</span><span class="mord mathnormal">t</span><span class="mord mathnormal">e</span><span class="mord mathnormal">s</span><span class="mord mathnormal">t</span></span></span></span>.</li></ul></li><li>If a transaction has just committed, a non-conflicting read-only transaction must still be assigned <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>s</mi><mrow><mi>r</mi><mi>e</mi><mi>a</mi><mi>d</mi></mrow></msub></mrow><annotation encoding="application/x-tex">s_{read}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span><span class="mord mathnormal mtight">e</span><span class="mord mathnormal mtight">a</span><span class="mord mathnormal mtight">d</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> so as to follow that transaction.<ul><li>This weakness can be remedied by augmenting <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>L</mi><mi>a</mi><mi>s</mi><mi>t</mi><mi>T</mi><mi>S</mi><mo stretchy="false">(</mo><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">LastTS()</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">L</span><span class="mord mathnormal">a</span><span class="mord mathnormal">s</span><span class="mord mathnormal">t</span><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="mord mathnormal" style="margin-right:0.05764em;">S</span><span class="mopen">(</span><span class="mclose">)</span></span></span></span> with a fine-grained mapping from key ranges to commit timestamps in the lock table.</li><li>When a read-only transaction arrives, its timestamp can be assigned by taking the maximum value of <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>L</mi><mi>a</mi><mi>s</mi><mi>t</mi><mi>T</mi><mi>S</mi><mo stretchy="false">(</mo><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">LastTS()</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">L</span><span class="mord mathnormal">a</span><span class="mord mathnormal">s</span><span class="mord mathnormal">t</span><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="mord mathnormal" style="margin-right:0.05764em;">S</span><span class="mopen">(</span><span class="mclose">)</span></span></span></span> for the key ranges with which the transaction conflicts, unless there is a conflicting prepared transaction.</li></ul></li></ol><h1 id="evaluation"><a class="markdownIt-Anchor" href="#evaluation"></a> Evaluation</h1><ol><li><p>For the performance experiment, the author tested for the two common benchmarks: latency and throughput.</p><ul><li><p>For the latency experiments, clients issued sufficiently few operations so as to avoid queuing at the servers.</p></li><li><p>For the throughput experiments, clients issued sufficiently many operations so as to saturate the servers’ CPUs.</p></li><li><p>The result is as shown below. 1D means one replica with commit wait disabled.</p></li><li><p>As the number of replicas increases,</p><ul><li>The latency stays roughly constant with less standard deviation because Paxos executes in parallel at a group’s replicas, hence the latency to achieve a quorum becomes less sensitive to slowness at one slave replica.</li></ul><img src="/imgs/Distributed/Spanner/performance.png" width="75%"></li></ul></li><li><p>The author also tested the scalability of two-phase commit.</p><img src="/imgs/Distributed/Spanner/2pc.png" width=50%></li><li><p>The availability after server failure is another important metric.</p><ul><li><p>Non-leader killing has no effect on read throughput.</p></li><li><p>Killing leaders while giving time to handoff leadership to a different zone has a minor effect aroung <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>3</mn><mo>−</mo><mn>4</mn><mi mathvariant="normal">%</mi></mrow><annotation encoding="application/x-tex">3-4\%</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.72777em;vertical-align:-0.08333em;"></span><span class="mord">3</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.80556em;vertical-align:-0.05556em;"></span><span class="mord">4</span><span class="mord">%</span></span></span></span>.</p></li><li><p>Killing leaders with no warning has a severe effect: the rate of completion drops almost to <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>0</mn></mrow><annotation encoding="application/x-tex">0</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">0</span></span></span></span>.</p><img src="/imgs/Distributed/Spanner/availability.png" width="50%"></li></ul></li><li><p>The uncertainty of TrueTime would affect the reliability of Spanner.</p></li></ol>]]></content>
      
      
      <categories>
          
          <category> Paper Notebook </category>
          
          <category> Distributed System </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Database System </tag>
            
            <tag> Distributed System </tag>
            
            <tag> Distributed Database </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>2-Phase Commit</title>
      <link href="/2023/09/26/Paper/Distributed/2-Phase-Commit/"/>
      <url>/2023/09/26/Paper/Distributed/2-Phase-Commit/</url>
      
        <content type="html"><![CDATA[<p><ul class="markdownIt-TOC"><li><a href="#before-or-after-atomicity">Before-or-After Atomicity</a><ul><li><a href="#what-is-before-or-after-atomicity">What is before-or-after atomicity?</a></li><li><a href="#what-is-the-problem-of-before-or-after-atomicity">What is the problem of before-or-after atomicity?</a></li><li><a href="#what-kind-of-coordination-is-correct">What kind of coordination is correct?</a></li></ul></li><li><a href="#locking-disciplines">Locking disciplines</a><ul><li><a href="#simple-locking">Simple locking</a><ul><li><a href="#what-are-the-rules-of-simple-locking">What are the rules of simple locking?</a></li><li><a href="#what-are-lock-point-and-lock-set-of-a-transaction">What are lock point and lock set of a transaction?</a></li><li><a href="#how-can-we-implement-lock-manager">How can we implement lock manager?</a></li><li><a href="#how-to-argue-the-correctness-of-simple-locking">How to argue the correctness of simple locking?</a></li></ul></li><li><a href="#two-phase-locking">Two-phase locking</a><ul><li><a href="#what-are-the-rules-of-two-phase-locking">What are the rules of two-phase locking?</a></li><li><a href="#how-can-we-implement-lock-manager-2">How can we implement lock manager?</a></li><li><a href="#how-does-locks-interact-with-log-based-recovery">How does locks interact with log-based recovery?</a></li></ul></li><li><a href="#distributed-two-phase-commit">Distributed two-phase commit</a><ul><li><a href="#what-is-correct-in-multi-site-transaction">What is correct in multi-site transaction?</a></li><li><a href="#what-is-the-problem-of-multi-site-transaction">What is the problem of multi-site transaction?</a></li><li><a href="#what-is-the-steps-of-distributed-two-phase-commit-protocol">What is the steps of distributed two-phase commit protocol?</a></li><li><a href="#how-to-handle-the-lost-delayed-or-duplicated-message-problem">How to handle the lost, delayed, or duplicated message problem?</a></li><li><a href="#how-does-a-worker-site-recover-from-crashes">How does a worker site recover from crashes?</a></li><li><a href="#how-can-we-optimize-the-protocol">How can we optimize the protocol?</a></li></ul></li></ul></li></ul></p><h1 id="before-or-after-atomicity"><a class="markdownIt-Anchor" href="#before-or-after-atomicity"></a> Before-or-After Atomicity</h1><h2 id="what-is-before-or-after-atomicity"><a class="markdownIt-Anchor" href="#what-is-before-or-after-atomicity"></a> What is before-or-after atomicity?</h2><ol><li><p>Before-or-after property states that several actions that concurrently operate on the same data should not interfere with one another.</p></li><li><p>Concurrent actions have the before-or-after property if their effect from the point of view of their invokers is the same as if the actions occurred either completely before or completely after one another.</p></li></ol><h2 id="what-is-the-problem-of-before-or-after-atomicity"><a class="markdownIt-Anchor" href="#what-is-the-problem-of-before-or-after-atomicity"></a> What is the problem of before-or-after atomicity?</h2><ol><li>The programmer does not necessarily know the identities of all the other actions that might touch the shared vari­ able.</li><li>This lack of knowledge can make it problematic to coordinate actions by explicit program steps.</li><li>Instead, what the programmer needs is an automatic, implicit mechanism that ensures proper handling of every shared variable.</li></ol><h2 id="what-kind-of-coordination-is-correct"><a class="markdownIt-Anchor" href="#what-kind-of-coordination-is-correct"></a> What kind of coordination is correct?</h2><ol><li>Coordination among concurrent actions can be considered to be correct if every result is guaranteed to be one that could have been obtained by some purely serial application of those same actions.</li><li>As long as the intermediate states are not visible above the implementing layer, and the system is guaranteed to end up in one of the acceptable final states, we can declare the coordination to be correct.</li></ol><h1 id="locking-disciplines"><a class="markdownIt-Anchor" href="#locking-disciplines"></a> Locking disciplines</h1><h2 id="simple-locking"><a class="markdownIt-Anchor" href="#simple-locking"></a> Simple locking</h2><h3 id="what-are-the-rules-of-simple-locking"><a class="markdownIt-Anchor" href="#what-are-the-rules-of-simple-locking"></a> What are the rules of simple locking?</h3><ol><li>Each transaction must acquire a lock for every shared data object it intends to read or write before doing any actual reading and writing.</li><li>It may release its locks only after the transaction installs its last update and commits or completely restores the data and aborts.</li><li>Applications that discover which objects need to be read by reading other shared data objects have no alter­ native but to lock every object that they might need to read.</li></ol><h3 id="what-are-lock-point-and-lock-set-of-a-transaction"><a class="markdownIt-Anchor" href="#what-are-lock-point-and-lock-set-of-a-transaction"></a> What are lock point and lock set of a transaction?</h3><ol><li><em>Lock point</em>: the first instant at which it has acquired all of its locks.</li><li><em>Lock set</em>: The collection of locks it has acquired when it reaches its lock point.</li></ol><h3 id="how-can-we-implement-lock-manager"><a class="markdownIt-Anchor" href="#how-can-we-implement-lock-manager"></a> How can we implement lock manager?</h3><ol><li><p>Acquire locks</p><ul><li><p>Each transaction supply its intended lock set as an argu­ment to the <strong>begin_transaction</strong> operation, which acquires all of the locks of the lock set, if necessary waiting for them to become available.</p><ul><li>Interpose itself on all calls to read data and to log changes, to verify that they refer to variables that are in the lock set.</li></ul></li></ul></li><li><p>Release locks</p><ul><li>Intercept the call to <em>commit</em> or <em>abort</em> (or, if the application uses roll-forward recovery, to log an <em>END</em> record) at which time it auto­matically releases all of the locks of the lock set.</li></ul></li></ol><h3 id="how-to-argue-the-correctness-of-simple-locking"><a class="markdownIt-Anchor" href="#how-to-argue-the-correctness-of-simple-locking"></a> How to argue the correctness of simple locking?</h3><ol><li>Imagine that an all-seeing outside observer maintains an ordered list to which it adds each transaction identifier as soon as the transaction reaches its lock point and removes it from the list when it begins to release its locks.</li><li>Each transaction has agreed not to read or write anything until that transaction has been added to the observer’s list.</li><li>Since no data object can appear in the lock sets of two transactions, no data object in any transaction’s lock set appears in the lock set of the transaction preceding it in the list, and by induction to any transaction earlier in the list.</li><li>Thus all of this transaction’s input values are the same as they will be when the preceding transaction in the list commits or aborts.</li><li>The same argument applies to the transaction before the preceding one, so all inputs to any trans­ action are identical to the inputs that would be available if all the transactions ahead of it in the list ran serially, in the order of the list.</li><li>Thus the simple locking discipline ensures that this transaction runs completely after the preceding one and completely before the next one.</li><li>Concurrent transactions will produce results as if they had been serialized in the order that they reached their lock points.</li></ol><h2 id="two-phase-locking"><a class="markdownIt-Anchor" href="#two-phase-locking"></a> Two-phase locking</h2><h3 id="what-are-the-rules-of-two-phase-locking"><a class="markdownIt-Anchor" href="#what-are-the-rules-of-two-phase-locking"></a> What are the rules of two-phase locking?</h3><ol><li>It avoids the requirement that a transaction must know in advance which locks to acquire.</li><li>The twophase locking discipline allows a transaction to acquire locks as it proceeds, and the trans­ action may read or write a data object as soon as it acquires a lock on that object.</li><li>The primary constraint is that the transaction may not release any locks until it passes its lock point.</li><li>The transaction can release a lock on an object that it only reads any time after it reaches its lock point if it will never need to read that object again, even to abort.</li></ol><h3 id="how-can-we-implement-lock-manager-2"><a class="markdownIt-Anchor" href="#how-can-we-implement-lock-manager-2"></a> How can we implement lock manager?</h3><ol><li>Intercept all calls to read and write data; it acquires a lock (perhaps having to wait) on the first use of each shared variable.</li><li>As with simple locking, it then holds the locks until it intercepts the call to <em>commit</em>, <em>abort</em>, or log the <em>END</em> record of the transaction, at which time it releases them all at once.</li></ol><h3 id="how-does-locks-interact-with-log-based-recovery"><a class="markdownIt-Anchor" href="#how-does-locks-interact-with-log-based-recovery"></a> How does locks interact with log-based recovery?</h3><ol><li><p>Whether locks themselves are data objects for which changes should be logged?</p><ul><li><p>At the completion of crash recovery there should be no pending transactions because any transactions that were pending at the time of the crash should have been rolled back by the recovery procedure, and recov­ ery does not allow any new transactions to begin until it completes.</p></li><li><p>Since locks exist only to coordinate pending transactions, it would clearly be an error if there were locks still set when crash recovery is complete.</p></li><li><p>Locks belong in vol­atile storage, where they will automatically disappear on a crash, rather than in non­-volatile storage, where the recovery procedure would have to hunt them down to release them.</p></li></ul></li><li><p>whether or not the log-based recovery algorithm will construct a correct system state?</p><ul><li>The transactions that were not complete at the instant of the crash had nonoverlapping lock sets at the moment that the lock values vanished.</li><li>Those particular actions can safely be redone or undone without con­ cern for before-or-after atomicity during recovery.</li><li>The locks created a particular serialization of the transactions and the log has captured that serialization.</li><li>Since <em>RECOVER</em> performs <em>UNDO</em> actions in reverse order as specified in the log, and it per­ forms <em>REDO</em> actions in forward order, again as specified in the log, <em>RECOVER</em> reconstructs exactly that same serialization.</li></ul></li></ol><h2 id="distributed-two-phase-commit"><a class="markdownIt-Anchor" href="#distributed-two-phase-commit"></a> Distributed two-phase commit</h2><h3 id="what-is-correct-in-multi-site-transaction"><a class="markdownIt-Anchor" href="#what-is-correct-in-multi-site-transaction"></a> What is correct in multi-site transaction?</h3><ol><li>Correctness of the multiple-site ato­ micity protocol will be achieved if all the sites commit or if all the sites abort.</li><li>It is failed if some sites commit their part of a multiple-site transaction while others abort their part of that same transaction.</li></ol><h3 id="what-is-the-problem-of-multi-site-transaction"><a class="markdownIt-Anchor" href="#what-is-the-problem-of-multi-site-transaction"></a> What is the problem of multi-site transaction?</h3><ol><li>The coordinator has created a higher-layer transaction and each of the workers is to perform a transaction that is nested in the higher-layer transaction.</li><li>The complication is that the coordinator and workers cannot reliably communicate.</li><li>The problem thus reduces to constructing a reliable distributed version of the two-phase commit protocol. We can do that by applying persistent senders and duplicate suppression.</li></ol><h3 id="what-is-the-steps-of-distributed-two-phase-commit-protocol"><a class="markdownIt-Anchor" href="#what-is-the-steps-of-distributed-two-phase-commit-protocol"></a> What is the steps of distributed two-phase commit protocol?</h3><ol><li><p>Beginning</p><ul><li><p>The coordinator creates a top-layer outcome record for the overall transaction.</p></li><li><p>It persistently sends the content of sub-transactions to each site, referring to the same transaction, respectively.</p></li><li><p>A worker site, upon receiving a request, checks for duplicates and then creates a transaction of its own, but it makes the transaction a nested one, with its superior being the coordinator’s original transaction.</p></li><li><p>Then the worker site goes about doing the pre-commit part of the requested action, reporting back to coordinator that this much has gone well.</p></li></ul></li><li><p>Two-phase commit</p><ul><li>Phase one:<ul><li>The coordinatior , upon collecting a complete set of such responses then moves to the two-phase commit part of the transaction, by sending <code>PREPARE</code> messages to each worker site.</li><li>Each worker site, upon receiving this message, commits—but only tentatively—or aborts.</li><li>Having created durable tentative versions (or logged to journal storage its planned updates) and having recorded an outcome record saying that it is <code>PREPARED</code> either to commit or abort, worker sites persistently sends a response to coorinator of commit or abort.</li><li>If all workers send PREPARED messages, phase one of the two-phase commit is complete.</li><li>If any worker responds with an abort message, or doesn’t respond at all, the coordinator has the usual choice of aborting the entire transaction or perhaps trying a different worker site to carry out that component transaction.</li></ul></li><li>Phase two:<ul><li>The coordinator commits the entire transaction by marking its own outcome record <code>COMMITTED</code>.</li><li>It sends a completion message back to each worker site.</li><li>Each worker site, upon receiving such a message, changes its state from <code>PREPARED</code> to <code>COM­MITTED</code>, performs any needed post-commit actions, and exits.</li></ul></li></ul></li></ol><h3 id="how-to-handle-the-lost-delayed-or-duplicated-message-problem"><a class="markdownIt-Anchor" href="#how-to-handle-the-lost-delayed-or-duplicated-message-problem"></a> How to handle the lost, delayed, or duplicated message problem?</h3><ol><li>If coordinator doesn’t receive a response of ready message of some sub-transaction request from one or more of the workers in a reasonable time she resends the message to the non-responding workers as many times as necessary to elicit a response.</li><li>If a worker site receives a duplicate request of <code>PREPARE</code> from coordinator, its persistent sender sends back a duplicate of the <code>PREPARED</code> or <code>ABORTED</code> response.</li><li>If the coordinator goes down before the coordinator sends final <code>COMMITTED</code> message in phase-two, all of the workers must wait until it recovers; in this protocol, the coordinator is a single point of failure.</li><li>The coordinator must remem­ ber, reliably and for an indefinite time, the outcome of this transaction.<ul><li>If a completion message does not arrive in a reasonable period of time, the persistent sender at the worker site will resend its <code>PREPARED</code> message.</li><li>Whenever the coordinator receives a duplicate <code>PREPARED</code> message, it simply sends back the current state of the outcome record for the named transaction.</li></ul></li></ol><h3 id="how-does-a-worker-site-recover-from-crashes"><a class="markdownIt-Anchor" href="#how-does-a-worker-site-recover-from-crashes"></a> How does a worker site recover from crashes?</h3><ol><li>It must classify any <code>PREPARED</code> transaction as a tentative win­ner that it should restore to the <code>PREPARED</code> state.</li><li>If the worker is using locks for before-or-after atomicity, the recovery procedure must reacquire any locks the PREPARED transaction was holding at the time of the failure.</li><li>The recovery procedure must restart the persistent sender, to learn the current status of the higher-layer transaction.</li><li>If the worker site uses version histories, only the last step, restarting the persistent sender, is required.</li><li>If worker site crashes after sending <code>PREPARED</code> before receiving <code>COMMIT</code>, other servers will actually commit. So we want server recovery as <code>PREPARED</code>. So before sending <code>PREPARED</code>, servers need to make their log durable.</li></ol><h3 id="how-can-we-optimize-the-protocol"><a class="markdownIt-Anchor" href="#how-can-we-optimize-the-protocol"></a> How can we optimize the protocol?</h3><ol><li>The initial RPC request and response could also carry the PREPARE and PREPARED messages, respectively.<ul><li>Once a worker sends a <code>PREPARED</code> message, it loses the ability to unilaterally abort, and it must remain on the knife edge awaiting instructions from the coordinator.</li><li>To minimize this wait, it is usually preferable to delay the <code>PREPARE</code>/<code>PREPARED</code> message pair until the coordinator knows that the other workers seem to be in a position to do their parts.</li></ul></li><li>Have a fourth acknowl­ edgment message from the worker sites to the coordinator.<ul><li>Once all acknowledgments are in, the coordinator can then safely discard its outcome record, since every worker site is known to have gotten the word.</li></ul></li><li>Presumed commit: The coordi­nator answers any inquiry about a non-existent outcome record by sending a <code>COMMITTED</code> response.<ul><li>The coordinator commits by destroying the out­ come record, so a fourth acknowledgment message from every worker is unnecessary.</li><li>The coor­dinator can persistently ask for acknowledgment of aborted transactions, and discard the outcome record after all these acknowledgments are in.</li></ul></li></ol>]]></content>
      
      
      <categories>
          
          <category> Paper Notebook </category>
          
          <category> Distributed System </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Concurrency Control </tag>
            
            <tag> Distributed System </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Aurora</title>
      <link href="/2023/09/26/Paper/Distributed/Aurora/"/>
      <url>/2023/09/26/Paper/Distributed/Aurora/</url>
      
        <content type="html"><![CDATA[<p>Paper: <a href="http://nil.csail.mit.edu/6.824/2020/papers/aurora.pdf">Amazon Aurora: Design Considerations for High Throughput Cloud-Native Relational Databases</a></p><p><ul class="markdownIt-TOC"><li><a href="#purpose">Purpose</a></li><li><a href="#model">Model</a><ul><li><a href="#background-conceptions-of-aws">Background conceptions of AWS</a></li><li><a href="#durability-at-scale">Durability at scale</a><ul><li><a href="#how-does-aurora-tolerate-failures">How does Aurora tolerate failures?</a></li><li><a href="#how-does-aurora-shrink-the-window-of-vulnerability">How does Aurora shrink the window of vulnerability?</a></li><li><a href="#what-are-the-problems-of-io-volume-of-mirrored-mysql">What are the problems of I/O volume of mirrored MySQL?</a></li><li><a href="#how-does-aurora-reduce-network-traffic">How does Aurora reduce network traffic?</a></li><li><a href="#logs">Logs</a></li><li><a href="#how-does-aurora-decide-what-is-completed-and-what-is-durable">How does Aurora decide what is completed and what is durable?</a></li><li><a href="#how-does-the-database-and-storage-interact">How does the database and storage interact?</a></li><li><a href="#how-does-the-database-write-data">How does the database write data?</a></li><li><a href="#how-does-the-database-commit-transactions">How does the database commit transactions?</a></li><li><a href="#where-does-the-database-read">Where does the database read?</a></li><li><a href="#how-does-the-database-read">How does the database read?</a></li><li><a href="#how-does-the-database-replicate">How does the database replicate?</a></li><li><a href="#how-does-the-database-perform-undo-and-redo">How does the database perform undo and redo?</a></li><li><a href="#how-does-the-database-reestablish-runtime-state">How does the database reestablish runtime state?</a></li></ul></li></ul></li></ul></p><h1 id="purpose"><a class="markdownIt-Anchor" href="#purpose"></a> Purpose</h1><ol><li>Aurora is a relational database service for OLTP workloads.</li><li>Issue:<ul><li>In modern distributed cloud services, resilience and scalability are increasingly achieved by decoupling compute from storage and by replicating storage across multiple nodes.</li><li>The central constraint in high throughput data processing has moved from compute and storage to the network.</li></ul></li><li>Contribution:<ul><li>Build storage as an independent fault-tolerant and self-healing service across multiple data-centers.<ul><li>Protect the database from performance variance and transient or permanent failures at either the networking or storage tiers.</li></ul></li><li>Only write redo log records to storage<ul><li>Reduce network IOPS by an order of magnitude.</li><li>When bottleneck removed, the scalability of the system is greatly improved. And they can aggressively optimize numerous other points of contention.</li></ul></li><li>Move some of the most complex and critical functions (backup and redo recovery) from one-time expensive operations in the database engine to continuous asynchronous operations amortized across a large distributed fleet.<ul><li>This yields near-instant crash recovery without checkpointing as well as inexpensive backups that do not interfere with foreground processing.</li></ul></li><li>Also, it achieves consensus on durable state across numerous storage nodes using an efficient asynchronous scheme, avoiding expensive and chatty recovery protocols.</li></ul></li></ol><h1 id="model"><a class="markdownIt-Anchor" href="#model"></a> Model</h1><h2 id="background-conceptions-of-aws"><a class="markdownIt-Anchor" href="#background-conceptions-of-aws"></a> Background conceptions of AWS</h2><h2 id="durability-at-scale"><a class="markdownIt-Anchor" href="#durability-at-scale"></a> Durability at scale</h2><h3 id="how-does-aurora-tolerate-failures"><a class="markdownIt-Anchor" href="#how-does-aurora-tolerate-failures"></a> How does Aurora tolerate failures?</h3><ol><li>It uses a quorum-based voting protocol. The oridinary quorum voting protocol is as followed:<ul><li>If each of the <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>V</mi></mrow><annotation encoding="application/x-tex">V</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.22222em;">V</span></span></span></span> copies of a replicated data item is assigned a vote, a read must obtain quorum of <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>V</mi><mi>r</mi></msub></mrow><annotation encoding="application/x-tex">V_r</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.22222em;">V</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:-0.22222em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> votes while a write must obtain quorum of <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>V</mi><mi>w</mi></msub></mrow><annotation encoding="application/x-tex">V_w</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.22222em;">V</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:-0.22222em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.02691em;">w</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> votes.</li><li>Each read must be aware of the most recent write, formulated as <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>V</mi><mi>r</mi></msub><mo>+</mo><msub><mi>V</mi><mi>w</mi></msub><mo>&gt;</mo><mi>V</mi></mrow><annotation encoding="application/x-tex">V_r + V_w &gt; V</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.22222em;">V</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:-0.22222em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.22222em;">V</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:-0.22222em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.02691em;">w</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">&gt;</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.22222em;">V</span></span></span></span>.</li><li>Each write must be aware of the most recent write to avoid conflicting writes, formulated as <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>V</mi><mi>w</mi></msub><mo>&gt;</mo><mi>V</mi><mi mathvariant="normal">/</mi><mn>2</mn></mrow><annotation encoding="application/x-tex">V_w &gt; V/2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.22222em;">V</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:-0.22222em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.02691em;">w</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">&gt;</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.22222em;">V</span><span class="mord">/</span><span class="mord">2</span></span></span></span>.</li></ul></li><li>The failure of each Availability Zone (AZ) is independent.<ul><li>For a common setting <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>V</mi><mo>=</mo><mn>3</mn></mrow><annotation encoding="application/x-tex">V=3</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.22222em;">V</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">3</span></span></span></span>, <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>V</mi><mi>r</mi></msub><mo>=</mo><mn>2</mn></mrow><annotation encoding="application/x-tex">V_r=2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.22222em;">V</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:-0.22222em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">2</span></span></span></span>, <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>V</mi><mi>w</mi></msub><mo>=</mo><mn>2</mn></mrow><annotation encoding="application/x-tex">V_w=2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.22222em;">V</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:-0.22222em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.02691em;">w</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">2</span></span></span></span>, we can set <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>3</mn></mrow><annotation encoding="application/x-tex">3</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">3</span></span></span></span> replicas in different AZs to be tolerant to large-scale events in addition to the smaller individual failures.</li><li>However, the failure of an AZ will break quorum for any of the replicas that concurrently have failures in another AZ.</li><li>While the individual failures of replicas in each of the AZs are uncorrelated, the failure of an AZ is a correlated failure of all disks and nodes in that AZ.</li></ul></li><li>Quorum protocol of Aurora:<ul><li>Replicate each data item <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>6</mn></mrow><annotation encoding="application/x-tex">6</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">6</span></span></span></span> ways across <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>3</mn></mrow><annotation encoding="application/x-tex">3</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">3</span></span></span></span> AZs with <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>2</mn></mrow><annotation encoding="application/x-tex">2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">2</span></span></span></span> copies of each item in each AZ.</li><li>Use a quorum model with <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>6</mn></mrow><annotation encoding="application/x-tex">6</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">6</span></span></span></span> votes (<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>V</mi><mo>=</mo><mn>6</mn></mrow><annotation encoding="application/x-tex">V = 6</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.22222em;">V</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">6</span></span></span></span>), a write quorum of <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>4</mn><mi mathvariant="normal">/</mi><mn>6</mn></mrow><annotation encoding="application/x-tex">4/6</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord">4</span><span class="mord">/</span><span class="mord">6</span></span></span></span> (<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>V</mi><mi>w</mi></msub><mo>=</mo><mn>4</mn></mrow><annotation encoding="application/x-tex">V_w = 4</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.22222em;">V</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:-0.22222em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.02691em;">w</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">4</span></span></span></span>), and a read quorum of <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>3</mn><mi mathvariant="normal">/</mi><mn>6</mn></mrow><annotation encoding="application/x-tex">3/6</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord">3</span><span class="mord">/</span><span class="mord">6</span></span></span></span> (<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>V</mi><mi>r</mi></msub><mo>=</mo><mn>3</mn></mrow><annotation encoding="application/x-tex">V_r = 3</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.22222em;">V</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:-0.22222em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">3</span></span></span></span>).</li><li>It can lose a single AZ and one additional node (<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>A</mi><mi>Z</mi><mo>+</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">AZ+1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.76666em;vertical-align:-0.08333em;"></span><span class="mord mathnormal">A</span><span class="mord mathnormal" style="margin-right:0.07153em;">Z</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">1</span></span></span></span>) without losing read availability, and lose any two nodes, including a single AZ failure and maintain write availability.</li></ul></li></ol><h3 id="how-does-aurora-shrink-the-window-of-vulnerability"><a class="markdownIt-Anchor" href="#how-does-aurora-shrink-the-window-of-vulnerability"></a> How does Aurora shrink the window of vulnerability?</h3><ol><li>To provide sufficient durability in this model, one must ensure the probability of a double fault on uncorrelated failures, represented by Mean Time to Failure (MTTF), is sufficiently low over the time it takes to repair one of these failures, Mean Time to Repair (MTTR).</li><li>It is difficult, past a point, to reduce the probability of MTTF on independent failures.</li><li>Focus on reducing MTTR<ul><li>Partition the database volume into small fixed size segments, currently <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>10</mn></mrow><annotation encoding="application/x-tex">10</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">1</span><span class="mord">0</span></span></span></span>GB in size.<ul><li>These are each replicated <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>6</mn></mrow><annotation encoding="application/x-tex">6</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">6</span></span></span></span> ways into Protection Groups (PGs) so that each PG consists of six  segments, organized across <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>3</mn></mrow><annotation encoding="application/x-tex">3</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">3</span></span></span></span> AZs, with two segments in each AZ.</li><li>A storage volume is a concatenated set of PGs, physically implemented using a large fleet of storage nodes that are provisioned as virtual hosts with attached SSDs using Amazon Elastic Compute Cloud (EC2).</li><li>The PGs that constitute a volume are allocated as the volume grows.</li></ul></li><li>Segments are now unit of independent background noise failure and repair. The system monitor and automatically repair faults as part of service.</li></ul></li></ol><h3 id="what-are-the-problems-of-io-volume-of-mirrored-mysql"><a class="markdownIt-Anchor" href="#what-are-the-problems-of-io-volume-of-mirrored-mysql"></a> What are the problems of I/O volume of mirrored MySQL?</h3><img src="/imgs/Distributed/Aurora/MySQL.png" width="50%"><ol><li>The engine needs to write various types of data:<ul><li>The redo log, the binary (statement) log that is archived to Amazon Simple Storage Service (S3) in order to support point-in-time restores</li><li>The modified data pages, a second temporary write of the data page (double-write) to prevent torn pages, and finally the metadata (FRM) files.</li></ul></li><li>Steps 1, 3, and 5 are sequential and synchronous.<ul><li>Latency is additive because many writes are sequential.</li><li>Even on asynchronous writes, one must wait for the slowest operation, leaving the system at the mercy of outliers.</li><li>From a distributed system perspective, this model can be viewed as having a 4/4 write quorum, and is vulnerable to failures and outlier performance.</li></ul></li><li>User operations that are a result of OLTP applications cause many different types of writes often representing the same information in multiple ways.</li></ol><h3 id="how-does-aurora-reduce-network-traffic"><a class="markdownIt-Anchor" href="#how-does-aurora-reduce-network-traffic"></a> How does Aurora reduce network traffic?</h3><ol><li><p>The only writes that cross the network are redo log records. The log applicator is pushed to the storage tier where it can be used to generate database pages in background or on demand.</p></li><li><p>Generating each page from the complete chain of its modifications from the beginning of time is prohibitively expensive.</p><ul><li>Continually materialize database pages in the background to avoid regenerating them from scratch on demand every time.</li><li>As far as the engine is concerned, the log is the database, and any pages that the storage system materializes are simply a cache of log applications.</li></ul></li><li><p>The primary only writes log records to the storage service and streams those log records as well as metadata updates to the replica instances.</p><img src="/imgs/Distributed/Aurora/NetworkIO.png" width=50%></li><li><p>The storage node involves the following steps:</p><ul><li>(1) receive log record and add to an in-memory queue</li><li>(2) persist record on disk and acknowledge</li><li>(3) organize records and identify gaps in the log since some batches may be lost</li><li>(4) gossip with peers to fill in gaps</li><li>(5) coalesce log records into new data pages</li><li>(6) periodically stage log and new pages to S3</li><li>(7) periodically garbage collect old versions</li><li>(8) periodically validate CRC codes on pages</li><li>Each of the steps above asynchronous, and only steps (1) and (2) are in the foreground path potentially impacting latency.</li></ul><img src="/imgs/Distributed/Aurora/StorageNode.png" width="50%"></li></ol><h3 id="logs"><a class="markdownIt-Anchor" href="#logs"></a> Logs</h3><h3 id="how-does-aurora-decide-what-is-completed-and-what-is-durable"><a class="markdownIt-Anchor" href="#how-does-aurora-decide-what-is-completed-and-what-is-durable"></a> How does Aurora decide what is completed and what is durable?</h3><ol><li>At a high level, The system maintains points of consistency and durability, and continually advances these points as it receives acknowledgements for outstanding storage requests.</li><li>The logic for tracking partially completed transactions and undoing them is kept in the database engine, just as if it were writing to simple disks.<br />Upon restart, before the database is allowed to access the storage volume, the storage service does its own recovery which is focused not on user-level transactions, but on making sure that the database sees a uniform view of storage despite its distributed nature.</li><li>Completeness:<ul><li><em>Log Sequence Number (LSN)</em>: Each log record has an associated LSN that is a monotonically increasing value generated by the database.</li><li><em>Volume Complete LSN (VCL)</em>: The storage service determines the highest LSN for which it can guarantee availability of all prior log records.</li><li>During storage recovery, every log record with an LSN larger than the VCL must be truncated.</li></ul></li><li>Durability:<ul><li><em>Consistency Point LSNs (CPL)</em>: The database can further constrain a subset of points that are allowable for truncation by tagging log records</li><li><em>Volume Durable LSN (VDL)</em>: the highest CPL that is smaller than or equal to VCL and truncate all log records with LSN greater than the VDL.</li><li>A CPL can be thought of as delineating some limited form of storage system transaction that must be accepted in order.</li></ul></li></ol><h3 id="how-does-the-database-and-storage-interact"><a class="markdownIt-Anchor" href="#how-does-the-database-and-storage-interact"></a> How does the database and storage interact?</h3><ol><li>Each database-level transaction is broken up into multiple mini-transactions (MTRs) that are ordered and must be performed atomically.</li><li>Each mini-transaction is composed of multiple contiguous log records (as many as needed).</li><li>The final log record in a mini-transaction is a CPL.</li><li>On recovery, the database talks to the storage service to establish the durable point of each PG and uses that to establish the VDL and then issue commands to truncate the log records above VDL.</li></ol><h3 id="how-does-the-database-write-data"><a class="markdownIt-Anchor" href="#how-does-the-database-write-data"></a> How does the database write data?</h3><ol><li>Database view:<ul><li>As the database receives acknowledgements to establish the write quorum for each batch of log records, it advances the current VDL.</li><li>The database allocates a unique ordered LSN for each redo log record of each transaction that is no greater than the sum of the current VDL and the LSN Allocation Limit (LAL).</li><li>This limit ensures that the database does not get too far ahead of the storage system and introduces back-pressure that can throttle the incoming writes if the storage or network cannot keep up.</li></ul></li><li>PG view:<ul><li>Each segment of each PG only sees a subset of log records in the volume that affect the pages residing on that segment.</li><li>Each log record contains a backlink that identifies the previous log record for that PG to track the point of completeness of the log records that have reached each segment.</li><li><em>Segment Complete LSN (SCL)</em>: Identifies the greatest LSN below which all log records of the PG have been received, established through backlinks.</li><li>The SCL is used by the storage nodes when they gossip with each other in order to find and exchange log records that they are missing.</li></ul></li></ol><h3 id="how-does-the-database-commit-transactions"><a class="markdownIt-Anchor" href="#how-does-the-database-commit-transactions"></a> How does the database commit transactions?</h3><ol><li>When a client commits a transaction, the thread handling the commit request sets the transaction aside by recording its “commit LSN” as part of a separate list of transactions waiting on commit and moves on to perform other work.</li><li>Completing a commit, if and only if, the latest VDL is greater than or equal to the transaction’s commit LSN.</li><li>As the VDL advances, the database identifies qualifying transactions that are waiting to be committed and uses a dedicated thread to send commit acknowledgements to waiting clients.</li></ol><h3 id="where-does-the-database-read"><a class="markdownIt-Anchor" href="#where-does-the-database-read"></a> Where does the database read?</h3><ol><li>Pages are served from the buffer cache and only result in a storage IO request if the page in question is not present in the cache.</li><li>While the Aurora database does not write out pages on cache eviction (or anywhere else), it enforces a similar guarantee: a page in the buffer cache must always be of the latest version.<ul><li><em>Page LSN</em>: identify the log record associated with the latest change to the page</li><li>Evict a page from the cache only if its page LSN is greater than or equal to the VDL.</li><li>Hence, all changes in the page have been hardened in the log, and on a cache miss, it is sufficient to request a version of the page as of the current VDL to get its latest durable version.</li></ul></li></ol><h3 id="how-does-the-database-read"><a class="markdownIt-Anchor" href="#how-does-the-database-read"></a> How does the database read?</h3><ol><li>When reading a page from disk, the database establishes a read-point, representing the VDL at the time the request was issued.</li><li>The database can then select a storage node that is complete with respect to the read point, knowing that it will therefore receive an up to date version.</li><li>Protection Group Min Read Point LSN (PGMRPL): represents that all the log records of the PG below it are unnecessary.<ul><li>If there are read replicas, the writer gossips with them to establish the per-PG Minimum Read Point LSN across all nodes.</li><li>A storage node segment is guaranteed that there will be no read page requests with a read-point that is lower than the PGMRPL.</li><li>Each storage node is aware of the PGMRPL from the database and can, therefore, advance the materialized pages on disk by coalescing the older log records and then safely garbage collecting them.</li></ul></li></ol><h3 id="how-does-the-database-replicate"><a class="markdownIt-Anchor" href="#how-does-the-database-replicate"></a> How does the database replicate?</h3><ol><li>A single writer and up to 15 read replicas can all mount a single shared storage volume.</li><li>To minimize lag, the log stream generated by the writer and sent to the storage nodes is also sent to all read replicas.</li><li>In the reader, the database consumes this log stream by considering each log record in turn.<ul><li>If the log record refers to a page in the reader’s buffer cache, it uses the log applicator to apply the specified redo operation to the page in the cache.</li><li>Otherwise it simply discards the log record.</li><li>The replicas consume log records asynchronously from the perspective of the writer, which acknowledges user commits independent of the replica.</li><li>The only log records that will be applied are those whose LSN is less than or equal to the VDL.<br />The log records that are part of a single mini-transaction are applied atomically in the replica’s cache to ensure that the replica sees a consistent view of all database objects.</li></ul></li></ol><h3 id="how-does-the-database-perform-undo-and-redo"><a class="markdownIt-Anchor" href="#how-does-the-database-perform-undo-and-redo"></a> How does the database perform undo and redo?</h3><ol><li>The same redo log applicator is used in the forward processing path as well as on recovery where it operates synchronously and in the foreground while the database is offline.</li><li>The redo log applicator is decoupled from the database and operates on storage nodes, in parallel, and all the time in the background. Once the database starts up it performs volume recovery in collaboration with the storage service.</li><li>Undo recovery can happen when the database is online after the system builds the list of these in-flight transactions from the undo segments.</li></ol><h3 id="how-does-the-database-reestablish-runtime-state"><a class="markdownIt-Anchor" href="#how-does-the-database-reestablish-runtime-state"></a> How does the database reestablish runtime state?</h3><ol><li>It contacts for each PG, a read quorum of segments which is sufficient to guarantee discovery of any data that could have reached a write quorum.</li><li>Once the database has established a read quorum for every PG it can recalculate the VDL above which data is truncated by generating a truncation range that annuls every log record after the new VDL, up to and including an end LSN which the database can prove is at least as high as the highest possible outstanding log record that could ever have been seen.</li><li>The database infers this upper bound because it allocates LSNs, and limits how far allocation can occur above VDL (the 10 million limit described earlier).</li><li>The truncation ranges are versioned with epoch numbers, and written durably to the storage service so that there is no confusion over the durability of truncations in case recovery is interrupted and restarted.</li></ol>]]></content>
      
      
      <categories>
          
          <category> Paper Notebook </category>
          
          <category> Distributed System </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Distributed System </tag>
            
            <tag> Communication </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>CRAQ</title>
      <link href="/2023/09/26/Paper/Distributed/CRAQ/"/>
      <url>/2023/09/26/Paper/Distributed/CRAQ/</url>
      
        <content type="html"><![CDATA[<p>Paper: <a href="http://nil.csail.mit.edu/6.824/2020/papers/craq.pdf">Object Storage on CRAQ High-throughput chain replication for read-mostly workloads</a></p><p><ul class="markdownIt-TOC"><li><a href="#purpose">Purpose</a></li><li><a href="#model">Model</a><ul><li><a href="#related">Related</a><ul><li><a href="#what-is-object-based-storage">What is object-based storage?</a></li><li><a href="#what-is-strong-consistency-and-eventual-consistency">What is strong consistency and eventual consistency?</a></li><li><a href="#chain-replication">Chain replication</a><ul><li><a href="#what-is-chain-replication">What is chain replication?</a></li><li><a href="#what-is-the-problem-of-basic-chain-replication">What is the problem of basic chain replication?</a></li><li><a href="#how-does-cr-handle-client-requests">How does CR handle client requests?</a></li><li><a href="#why-cr-cannot-provide-read-from-intermediate-nodes">Why CR cannot provide read from intermediate nodes?</a></li></ul></li></ul></li><li><a href="#craq-system-model">CRAQ System Model</a><ul><li><a href="#how-does-craq-handle-write-requests">How does CRAQ handle write requests?</a></li><li><a href="#how-does-craq-handle-read-requests-to-guarantee-strong-consistency">How does CRAQ handle read requests to guarantee strong consistency?</a></li><li><a href="#in-what-scenarios-does-craq-out-performs-basic-cr">In what scenarios does CRAQ out-performs basic CR?</a></li><li><a href="#how-does-craq-support-eventual-consistency">How does CRAQ support eventual consistency?</a></li><li><a href="#how-does-craq-recover-from-failure">How does CRAQ recover from failure?</a></li><li><a href="#how-does-craq-manage-configuration">How does CRAQ manage configuration?</a></li><li><a href="#how-does-craq-handle-transient-failure-eg-partition-failure">How does CRAQ handle transient failure (e.g. partition failure)?</a></li><li><a href="#how-should-craq-choose-nodes-within-a-datacenter">How should CRAQ choose nodes within a Datacenter?</a></li><li><a href="#how-does-craq-support-mini-transaction-of-single-key-operations">How does CRAQ support mini-transaction of single-key operations?</a></li><li><a href="#how-does-craq-lower-write-latency-with-multicast">How does CRAQ lower write latency with multicast?</a></li><li><a href="#how-does-craq-use-zookeeper-to-manage-configuration">How does CRAQ use ZooKeeper to manage configuration?</a></li><li><a href="#how-does-nodes-communicate-with-each-other">How does nodes communicate with each other?</a></li></ul></li></ul></li><li><a href="#evaluation">Evaluation</a></li></ul></p><h1 id="purpose"><a class="markdownIt-Anchor" href="#purpose"></a> Purpose</h1><ol><li>Issue: many commercially-deployed systems sacrifice stronger consistency properties in the desire for greater availability and higher throughput.</li><li>Contribution:<ul><li>This system is an improvement on Chain Replication, maintains strong consistency while greatly improving read throughput by enabling any chain node to handle read operations.<ul><li>By distributing load across all object replicas, CRAQ scales linearly with chain size without increasing consistency coordination.</li></ul></li><li>CRAQ’s design naturally supports eventual-consistency among read operations for lower-latency reads during write contention and degradation to read-only behavior during transient partitions.<ul><li>CRAQ allows applications to specify the maximum staleness acceptable for read operations.</li></ul></li><li>Leveraging these load-balancing properties, we describe a wide-area system design for building CRAQ chains across geographically-diverse clusters that preserves strong locality properties.</li></ul></li></ol><h1 id="model"><a class="markdownIt-Anchor" href="#model"></a> Model</h1><h2 id="related"><a class="markdownIt-Anchor" href="#related"></a> Related</h2><h3 id="what-is-object-based-storage"><a class="markdownIt-Anchor" href="#what-is-object-based-storage"></a> What is object-based storage?</h3><ol><li>Object-based storage: Supported by key-value databases, data is presented to applications as entire units.</li><li>Object stores support two basic primitives: read (or query) operations return the data block stored under an object name, and write (or update) operations change the state of a single object.</li><li>Object stores are better suited for flat namespaces, such as in key-value databases, as opposed to hierarchical directory structures where file systems are better.</li><li>Object stores simplify the process of supporting whole-object modifications.<br />Typically only need to reason about the ordering of modifications to a specific object, as opposed to the entire storage system.<br />Significantly cheaper to provide consistency guarantees per object instead of across all operations and/or objects.</li></ol><h3 id="what-is-strong-consistency-and-eventual-consistency"><a class="markdownIt-Anchor" href="#what-is-strong-consistency-and-eventual-consistency"></a> What is strong consistency and eventual consistency?</h3><ol><li><p>Strong consistency guarantees that all read and write operations to an object are executed in some sequential order, and that a read to an object always sees the latest written value.</p></li><li><p>Eventual consistency implies that</p><ul><li><p>Writes to an object are still applied in a sequential order on all nodes, but eventually-consistent reads to different nodes can return stale data for some period of inconsistency.</p></li><li><p>However, read operations will never return an older version than the latest committed write.</p></li><li><p>A client will also see monotonic read consistency if it maintains a session with a particular node.</p></li></ul></li><li><p>The Eventual consistency is still different from the guarantees from ZooKeeper or Raft. In ZooKeeper or Raft, clients only see monotonic read consistency even if they cross sessions with different servers.</p></li></ol><h3 id="chain-replication"><a class="markdownIt-Anchor" href="#chain-replication"></a> Chain replication</h3><h4 id="what-is-chain-replication"><a class="markdownIt-Anchor" href="#what-is-chain-replication"></a> What is chain replication?</h4><ol><li>It organizes all nodes storing an object in a chain, where the chain tail handles all read requests, and the chain head handles all write requests,  as shown below:<br /><img src="/imgs/Distributed/CRAQ/basicCR.png" alt="" /></li><li>Writes propagate down the chain before the client is acknowledged, thus providing a simple ordering of all object operations, and hence strong consistency, at the tail.</li><li>The lack of any complex or multi-round protocols yields simplicity, good throughput, and easy recovery.</li></ol><h4 id="what-is-the-problem-of-basic-chain-replication"><a class="markdownIt-Anchor" href="#what-is-the-problem-of-basic-chain-replication"></a> What is the problem of basic chain replication?</h4><ol><li>All reads for an object must go to the same node, leading to potential hotspots.</li><li>Multiple chains can be constructed across a cluster of nodes for better load balancing via consistent hashing or a more centralized directory approach.</li><li>But these algorithms might still find load imbalances if particular objects are disproportionally popular.<br />All reads to a chain may then be handled by a potentially-distant node, namely the chain’s tail.</li></ol><h4 id="how-does-cr-handle-client-requests"><a class="markdownIt-Anchor" href="#how-does-cr-handle-client-requests"></a> How does CR handle client requests?</h4><ol><li>The <em>head</em> of the chain handles all write operations from clients.<ul><li>When a write operation is received by a node, it is propagated to the next node in the chain.</li><li>Once the write reaches the tail node, it has been applied to all replicas in the chain, and it is considered committed.</li><li>When the tail commits the write, a reply is sent to the client. The CR paper describes the tail sending a message directly back to the client.</li></ul></li><li>The tail node handles all read operations, so only values which are committed can be returned by a read.</li><li>The simple topology of CR makes write operations cheaper than in other protocols offering strong consistency.<br />Multiple concurrent writes can be pipelined down the chain, with transmission costs equally spread over all nodes.</li></ol><h4 id="why-cr-cannot-provide-read-from-intermediate-nodes"><a class="markdownIt-Anchor" href="#why-cr-cannot-provide-read-from-intermediate-nodes"></a> Why CR cannot provide read from intermediate nodes?</h4><ol><li>The reading result can violate the strong consistency.</li><li>Concurrent reads to different nodes could see different writes as they are in the process of propagating down the chain.</li></ol><h2 id="craq-system-model"><a class="markdownIt-Anchor" href="#craq-system-model"></a> CRAQ System Model</h2><h3 id="how-does-craq-handle-write-requests"><a class="markdownIt-Anchor" href="#how-does-craq-handle-write-requests"></a> How does CRAQ handle write requests?</h3><ol><li>A node in CRAQ can store multiple versions of an object, each including a monotonically-increasing version number and an additional attribute whether the version is clean or dirty. All versions are initially marked as clean.</li><li>When a node receives a new version of an object via a write being propagated down the chain, the node appends this latest version to its list for the object.<ul><li>If the node is not the tail, it marks the version as dirty, and propagates the write to its successor.</li><li>Otherwise, if the node is the tail, it marks the version as clean, at which time we call the object version (write) as committed.</li><li>The tail node can then notify all other nodes of the commit by sending an acknowledgement backwards through the chain.</li></ul></li><li>When an acknowledgement message for an object version arrives at a node, the node marks the object version as clean. The node can then delete all prior versions of the object.</li><li>If the node has exactly one version for an object, the object is implicitly in the clean state; otherwise, the object is dirty and the properlyordered version must be retrieved from the chain tail.</li></ol><h3 id="how-does-craq-handle-read-requests-to-guarantee-strong-consistency"><a class="markdownIt-Anchor" href="#how-does-craq-handle-read-requests-to-guarantee-strong-consistency"></a> How does CRAQ handle read requests to guarantee strong consistency?</h3><ol><li>When a node receives a read request for an object, if the latest known version of the requested object is clean, the node returns this value.</li><li>If the latest version number of the object requested is dirty, the node contacts the tail and asks for the tail’s last committed version number (a version query). The node then returns that version of the object.</li><li>The tail could commit a new version between when it replied to the version request and when the intermediate node sends a reply to the client.<br />This does not violate strong consistency, as read operations are serialized with respect to the tail.</li></ol><p><img src="/imgs/Distributed/CRAQ/read.png" alt="" /></p><h3 id="in-what-scenarios-does-craq-out-performs-basic-cr"><a class="markdownIt-Anchor" href="#in-what-scenarios-does-craq-out-performs-basic-cr"></a> In what scenarios does CRAQ out-performs basic CR?</h3><ol><li>In read-mostly workloads, most of the read requests handled solely by the C − 1 non-tail nodes (as clean reads), and thus throughput in these scenarios scales linearly with chain size C.</li><li>In write-heavy workloads, most read requests to non-tail nodes as dirty. But these version queries are lighter-weight than full reads, allowing the tail to process them at a much higher rate before it becomes saturated.</li></ol><h3 id="how-does-craq-support-eventual-consistency"><a class="markdownIt-Anchor" href="#how-does-craq-support-eventual-consistency"></a> How does CRAQ support eventual consistency?</h3><ol><li><p>It allows read operations to a chain node to return the newest object version known to it.</p></li><li><p>It can also support eventual consistency with maximum-bounded inconsistency.</p><ul><li>The limit imposed can be based on time (relative to a node’s local clock) or on absolute version numbers.</li></ul></li><li><p>If the chain is still available, this inconsistency is actually in terms of the returned version being newer than the last committed one.</p><p>If the system is partitioned and the node cannot participate in writes, the version may be older than the current committed one.</p></li></ol><h3 id="how-does-craq-recover-from-failure"><a class="markdownIt-Anchor" href="#how-does-craq-recover-from-failure"></a> How does CRAQ recover from failure?</h3><ol><li>Each chain node needs to know its predecessor and successor, as well as the chain head and tail.</li><li>When a head fails, its immediate successor takes over as the new chain head; likewise, the tail’s predecessor takes over when the tail fails.</li><li>If intermediate node fails, drop it from chain, predecessor may need to re-send recent writes since write request pipeline may have been broken from the failure server.</li></ol><h3 id="how-does-craq-manage-configuration"><a class="markdownIt-Anchor" href="#how-does-craq-manage-configuration"></a> How does CRAQ manage configuration?</h3><ol><li>An object’s identifier consists of both a chain identifier and a key identifier.</li><li>Applications can specify their requirements in multiple ways:<ul><li>Implicit Datacenters &amp; Global Chain Size <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">{</mo><mi>n</mi><mi>u</mi><mi>m</mi><mi mathvariant="normal">_</mi><mi>d</mi><mi>a</mi><mi>t</mi><mi>a</mi><mi>c</mi><mi>e</mi><mi>n</mi><mi>t</mi><mi>e</mi><mi>r</mi><mi>s</mi><mo separator="true">,</mo><mi>c</mi><mi>h</mi><mi>a</mi><mi>i</mi><mi>n</mi><mi mathvariant="normal">_</mi><mi>s</mi><mi>i</mi><mi>z</mi><mi>e</mi><mo stretchy="false">}</mo></mrow><annotation encoding="application/x-tex">\{num\_datacenters, chain\_size\}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.06em;vertical-align:-0.31em;"></span><span class="mopen">{</span><span class="mord mathnormal">n</span><span class="mord mathnormal">u</span><span class="mord mathnormal">m</span><span class="mord" style="margin-right:0.02778em;">_</span><span class="mord mathnormal">d</span><span class="mord mathnormal">a</span><span class="mord mathnormal">t</span><span class="mord mathnormal">a</span><span class="mord mathnormal">c</span><span class="mord mathnormal">e</span><span class="mord mathnormal">n</span><span class="mord mathnormal">t</span><span class="mord mathnormal">e</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mord mathnormal">s</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal">c</span><span class="mord mathnormal">h</span><span class="mord mathnormal">a</span><span class="mord mathnormal">i</span><span class="mord mathnormal">n</span><span class="mord" style="margin-right:0.02778em;">_</span><span class="mord mathnormal">s</span><span class="mord mathnormal">i</span><span class="mord mathnormal" style="margin-right:0.04398em;">z</span><span class="mord mathnormal">e</span><span class="mclose">}</span></span></span></span>.<ul><li>To determine exactly which datacenters store the chain, consistent hashing is used with unique datacenter identifiers.</li></ul></li><li>Explicit Datacenters &amp; Global Chain Size <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">{</mo><mi>c</mi><mi>h</mi><mi>a</mi><mi>i</mi><mi>n</mi><mi mathvariant="normal">_</mi><mi>s</mi><mi>i</mi><mi>z</mi><mi>e</mi><mo separator="true">,</mo><mi>d</mi><msub><mi>c</mi><mn>1</mn></msub><mo separator="true">,</mo><mi>d</mi><msub><mi>c</mi><mn>2</mn></msub><mo separator="true">,</mo><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mo separator="true">,</mo><mi>d</mi><msub><mi>c</mi><mi>N</mi></msub><mo stretchy="false">}</mo></mrow><annotation encoding="application/x-tex">\{chain\_size, dc_1, dc_2, ..., dc_N\}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.06em;vertical-align:-0.31em;"></span><span class="mopen">{</span><span class="mord mathnormal">c</span><span class="mord mathnormal">h</span><span class="mord mathnormal">a</span><span class="mord mathnormal">i</span><span class="mord mathnormal">n</span><span class="mord" style="margin-right:0.02778em;">_</span><span class="mord mathnormal">s</span><span class="mord mathnormal">i</span><span class="mord mathnormal" style="margin-right:0.04398em;">z</span><span class="mord mathnormal">e</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal">d</span><span class="mord"><span class="mord mathnormal">c</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal">d</span><span class="mord"><span class="mord mathnormal">c</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord">.</span><span class="mord">.</span><span class="mord">.</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal">d</span><span class="mord"><span class="mord mathnormal">c</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.32833099999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em;">N</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">}</span></span></span></span><ul><li>The order of the chain is the same as specified with head within <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>d</mi><msub><mi>c</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">dc_1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.84444em;vertical-align:-0.15em;"></span><span class="mord mathnormal">d</span><span class="mord"><span class="mord mathnormal">c</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> and tail within <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>d</mi><msub><mi>c</mi><mi>N</mi></msub></mrow><annotation encoding="application/x-tex">dc_N</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.84444em;vertical-align:-0.15em;"></span><span class="mord mathnormal">d</span><span class="mord"><span class="mord mathnormal">c</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.32833099999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em;">N</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>.</li><li>To determine which nodes within a datacenter store objects assigned to the chain, consistent hashing is used on the chain identifier.</li><li>Each datacenter <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>d</mi><msub><mi>c</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">dc_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.84444em;vertical-align:-0.15em;"></span><span class="mord mathnormal">d</span><span class="mord"><span class="mord mathnormal">c</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> has a node which connects to the tail of datacenter <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>d</mi><msub><mi>c</mi><mrow><mi>i</mi><mtext>−</mtext><mn>1</mn></mrow></msub></mrow><annotation encoding="application/x-tex">dc_{i−1}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.902771em;vertical-align:-0.208331em;"></span><span class="mord mathnormal">d</span><span class="mord"><span class="mord mathnormal">c</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.311664em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mord mtight">−</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.208331em;"><span></span></span></span></span></span></span></span></span></span> and a node which connects to the head of datacenter <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>d</mi><msub><mi>c</mi><mrow><mi>i</mi><mo>+</mo><mn>1</mn></mrow></msub></mrow><annotation encoding="application/x-tex">dc_{i+1}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.902771em;vertical-align:-0.208331em;"></span><span class="mord mathnormal">d</span><span class="mord"><span class="mord mathnormal">c</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.311664em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mbin mtight">+</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.208331em;"><span></span></span></span></span></span></span></span></span></span>.</li><li><code>chain_size</code> being <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>0</mn></mrow><annotation encoding="application/x-tex">0</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">0</span></span></span></span> indicates that the chain should use all nodes within each datacenter.</li></ul></li><li>Explicit Datacenter Chain Sizes <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">{</mo><mi>d</mi><msub><mi>c</mi><mn>1</mn></msub><mo separator="true">,</mo><mi>c</mi><mi>h</mi><mi>a</mi><mi>i</mi><mi>n</mi><mi mathvariant="normal">_</mi><mi>s</mi><mi>i</mi><mi>z</mi><msub><mi>e</mi><mn>1</mn></msub><mo separator="true">,</mo><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mo separator="true">,</mo><mi>d</mi><msub><mi>c</mi><mi>N</mi></msub><mo separator="true">,</mo><mi>c</mi><mi>h</mi><mi>a</mi><mi>i</mi><mi>n</mi><mi mathvariant="normal">_</mi><mi>s</mi><mi>i</mi><mi>z</mi><msub><mi>e</mi><mi>N</mi></msub><mo stretchy="false">}</mo></mrow><annotation encoding="application/x-tex">\{dc_1, chain\_size_1, ..., dc_N, chain\_size_N\}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.06em;vertical-align:-0.31em;"></span><span class="mopen">{</span><span class="mord mathnormal">d</span><span class="mord"><span class="mord mathnormal">c</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal">c</span><span class="mord mathnormal">h</span><span class="mord mathnormal">a</span><span class="mord mathnormal">i</span><span class="mord mathnormal">n</span><span class="mord" style="margin-right:0.02778em;">_</span><span class="mord mathnormal">s</span><span class="mord mathnormal">i</span><span class="mord mathnormal" style="margin-right:0.04398em;">z</span><span class="mord"><span class="mord mathnormal">e</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord">.</span><span class="mord">.</span><span class="mord">.</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal">d</span><span class="mord"><span class="mord mathnormal">c</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.32833099999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em;">N</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal">c</span><span class="mord mathnormal">h</span><span class="mord mathnormal">a</span><span class="mord mathnormal">i</span><span class="mord mathnormal">n</span><span class="mord" style="margin-right:0.02778em;">_</span><span class="mord mathnormal">s</span><span class="mord mathnormal">i</span><span class="mord mathnormal" style="margin-right:0.04398em;">z</span><span class="mord"><span class="mord mathnormal">e</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.32833099999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em;">N</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">}</span></span></span></span><ul><li>This allows for non-uniformity in chain load balancing.</li><li>The chain nodes within each datacenter are chosen in the same manner as the previous method, and <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>c</mi><mi>h</mi><mi>a</mi><mi>i</mi><mi>n</mi><mi mathvariant="normal">_</mi><mi>s</mi><mi>i</mi><mi>z</mi><msub><mi>e</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">chain\_size_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.00444em;vertical-align:-0.31em;"></span><span class="mord mathnormal">c</span><span class="mord mathnormal">h</span><span class="mord mathnormal">a</span><span class="mord mathnormal">i</span><span class="mord mathnormal">n</span><span class="mord" style="margin-right:0.02778em;">_</span><span class="mord mathnormal">s</span><span class="mord mathnormal">i</span><span class="mord mathnormal" style="margin-right:0.04398em;">z</span><span class="mord"><span class="mord mathnormal">e</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> can also be set to <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>0</mn></mrow><annotation encoding="application/x-tex">0</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">0</span></span></span></span>.</li></ul></li></ul></li></ol><h3 id="how-does-craq-handle-transient-failure-eg-partition-failure"><a class="markdownIt-Anchor" href="#how-does-craq-handle-transient-failure-eg-partition-failure"></a> How does CRAQ handle transient failure (e.g. partition failure)?</h3><ol><li>In methods 2 and 3 above, <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>d</mi><msub><mi>c</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">dc_1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.84444em;vertical-align:-0.15em;"></span><span class="mord mathnormal">d</span><span class="mord"><span class="mord mathnormal">c</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> can be set as a master datacenter.<ul><li>If a datacenter is the master for a chain, writes to the chain will only be accepted by that datacenter during transient failures.</li></ul></li><li>When a master is not defined,<ul><li>Writes will only continue in a partition if the partition contains a majority of the nodes in the global chain.</li><li>The minority partition will become read-only for maximumbounded inconsistent read operations.</li></ul></li></ol><h3 id="how-should-craq-choose-nodes-within-a-datacenter"><a class="markdownIt-Anchor" href="#how-should-craq-choose-nodes-within-a-datacenter"></a> How should CRAQ choose nodes within a Datacenter?</h3><ol><li>In CRAQ’s current implementation, we place chains within a datacenter using consistent hashing, mapping potentially many chain identifiers to a single head node.</li><li>Another approach is to use the membership management service as a directory service in assigning and storing randomized chain membership, i.e., each chain can include some random set of server nodes.<ul><li>This approach improves the potential for parallel system recovery.</li><li>But it would increase centralization and state, and require storing more metadata information in the coordination service.</li></ul></li></ol><h3 id="how-does-craq-support-mini-transaction-of-single-key-operations"><a class="markdownIt-Anchor" href="#how-does-craq-support-mini-transaction-of-single-key-operations"></a> How does CRAQ support mini-transaction of single-key operations?</h3><ol><li>For Prepend/Append and Increment/Decrement operations,<ul><li>The head of the chain storing the key’s object can simply apply the operation to the latest version of the object, even if the latest version is dirty, and then propagate a full replacement write down the chain.</li><li>If these operations are frequent, the head can buffer the requests and batch the updates. These enhancements would be much more expensive using a traditional two-phase-commit protocol.</li></ul></li><li>For the test-and-set operation,<ul><li>The head of the chain checks if its most recent committed version number equals the version number specified in the operation.</li><li>If there are no outstanding uncommitted versions of the object, the head accepts the operation and propagates an update down the chain.</li><li>If there are outstanding writes, we simply reject the test-and-set operation, and clients are careful to back off their request rate if continuously rejected.</li></ul></li><li>The optimistic two-phase protocol need only be implemented with the chain heads, not all involved nodes.<ul><li>The chain heads can lock any keys involved in the minitransaction until it is fully committed.</li><li>It reduces the write throughput of CRAQ as writes to the same object can no longer be pipelined.</li></ul></li></ol><h3 id="how-does-craq-lower-write-latency-with-multicast"><a class="markdownIt-Anchor" href="#how-does-craq-lower-write-latency-with-multicast"></a> How does CRAQ lower write latency with multicast?</h3><ol><li>Within a datacenter, this would take the form of a network-layer multicast protocol, while application-layer multicast protocols may be better-suited for wide-area chains.</li><li>No ordering or reliability guarantees are required from these multicast protocols.</li><li>The actual value can be multicast to the entire chain. Then, only a small metadata message needs to be propagated down the chain to ensure that all replicas have received a write before the tail.</li><li>If a node does not receive the multicast for any reason, the node can fetch the object from its predecessor after receiving the write commit message and before further propagating the commit message.</li><li>When the tail receives a propagated write request, a multicast acknowledgment message can be sent to the multicast group instead of propagating it backwards along the chain.</li></ol><h3 id="how-does-craq-use-zookeeper-to-manage-configuration"><a class="markdownIt-Anchor" href="#how-does-craq-use-zookeeper-to-manage-configuration"></a> How does CRAQ use ZooKeeper to manage configuration?</h3><ol><li><p>During initialization, a CRAQ node creates an ephemeral file in <code>/nodes/dc_name/node_id</code>.</p><ul><li><p>The content of the file contains the node’s IP address and port number.</p></li><li><p>CRAQ nodes can query <code>/nodes/dc_name</code> to determine the membership list for its datacenter. They creates a watch on the children list of <code>/nodes/dc_name</code>.</p></li></ul></li><li><p>When a CRAQ node receives a request to create a new chain, a file is created in <code>/chains/chain_id</code>.</p><ul><li>The chain’s placement strategy determines the contents of the file, but it only includes this chain configuration information, not the list of a chain’s current nodes.</li><li>Instead of letting nodes register their membership for each chain they belong to (<em>i.e.</em>, chain metadata explicitly names the chain’s current members), any node participating in the chain will query the chain file and place a watch on it.</li><li>This is based on the assumption that the number of chains will generally be at least an order of magnitude larger than the number of nodes in the system, or that chain dynamism may be significantly greater than nodes joining or leaving the system.</li></ul></li></ol><h3 id="how-does-nodes-communicate-with-each-other"><a class="markdownIt-Anchor" href="#how-does-nodes-communicate-with-each-other"></a> How does nodes communicate with each other?</h3><ol><li>The nodes within each datacenter organize themselves into a one-hop DHT using the identifiers generated when joining the system.<ul><li>A node’s chain predecessor and successor, the head node and the tail node are defined as its predecessor and successor in the DHT ring.</li></ul></li><li>All RPC-based communication between nodes, or between nodes and clients, is over TCP connections.<ul><li>Each node maintains a pool of connected TCP connections with its chain’s predecessor, successor, and tail.</li><li>For chains that span across multiple datacenters, the last node of one datacenter maintains a connection to the first node of its successor datacenter.</li><li>Any node that maintains a connection to a node outside of its datacenter must also place a watch on the node list of the external datacenter.</li></ul></li></ol><h1 id="evaluation"><a class="markdownIt-Anchor" href="#evaluation"></a> Evaluation</h1><ol><li><p>The main contribution is that it support read from intermediate nodes. So the author measured the read throughput of CRAQ and compared it with basic CR.</p><p><img src="/imgs/Distributed/CRAQ/4.png" alt="" /><img src="/imgs/Distributed/CRAQ/6.png" alt="" /></p></li><li><p>The author also tested the factors affecting read throughput, i.e. number of clients, number of nodes, and writes.</p><p><img src="/imgs/Distributed/CRAQ/5.png" alt="" /><img src="/imgs/Distributed/CRAQ/7.png" alt="" /></p></li><li><p>Another important test in distributed system is that how long does the system take to recover, and how do they perform during the failure.</p><p><img src="/imgs/Distributed/CRAQ/10-13.png" alt="" /></p></li></ol>]]></content>
      
      
      <categories>
          
          <category> Paper Notebook </category>
          
          <category> Distributed System </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Distributed System </tag>
            
            <tag> Distributed Storage </tag>
            
            <tag> Consensus Algorithm </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Zookeeper</title>
      <link href="/2023/09/26/Paper/Distributed/Zookeeper/"/>
      <url>/2023/09/26/Paper/Distributed/Zookeeper/</url>
      
        <content type="html"><![CDATA[<p>Paper: <a href="http://nil.csail.mit.edu/6.824/2020/papers/zookeeper.pdf">ZooKeeper: Wait-free coordination for Internet-scale systems</a></p><p><ul class="markdownIt-TOC"><li><a href="#purpose">Purpose</a></li><li><a href="#model">Model</a><ul><li><a href="#zookeeper-service-overview">ZooKeeper service overview</a><ul><li><a href="#how-does-client-interact-with-zookeeper-server">How does client interact with ZooKeeper server?</a></li><li><a href="#what-are-the-flags-of-znodes">What are the flags of znodes?</a></li><li><a href="#what-are-the-differences-between-znodes-and-files-in-file-system">What are the differences between znodes and files in file system?</a></li><li><a href="#what-does-zookeeper-guarantee">What does ZooKeeper guarantee?</a></li><li><a href="#how-to-change-configuration">How to change configuration?</a></li><li><a href="#how-should-a-client-read-configurations">How should a client read configurations?</a></li></ul></li><li><a href="#implement-primitives">Implement primitives</a><ul><li><a href="#how-does-zookeeper-manage-configuration">How does ZooKeeper manage configuration?</a></li><li><a href="#how-does-zookeeper-manage-rendezvous">How does ZooKeeper manage rendezvous?</a></li><li><a href="#how-does-zookeeper-manage-group-mambership">How does ZooKeeper manage group mambership?</a></li><li><a href="#how-does-zookeeper-manage-mini-transaction">How does ZooKeeper manage Mini-transaction?</a></li><li><a href="#how-does-zookeeper-implement-simple-locks">How does ZooKeeper implement simple locks?</a></li><li><a href="#how-does-zookeeper-implement-simple-locks-without-herd-effect">How does ZooKeeper implement simple locks without herd effect?</a></li><li><a href="#how-does-zookeeper-implement-readwrite-locks">How does ZooKeeper implement Read/Write locks?</a></li><li><a href="#what-is-the-difference-between-zookeeper-locks-and-thread-mutex-locks">What is the difference between ZooKeeper locks and thread mutex locks?</a></li><li><a href="#how-does-zookeeper-implementa-double-barrier">How does ZooKeeper implementa double barrier?</a></li></ul></li><li><a href="#implementation-of-zookeeper">Implementation of ZooKeeper</a><ul><li><a href="#how-does-zookeeper-serve-requests">How does ZooKeeper serve requests?</a></li><li><a href="#how-does-zookeeper-manage-database">How does ZooKeeper manage database?</a></li><li><a href="#how-does-request-processor-handle-write-requests">How does request processor handle write requests?</a></li><li><a href="#how-does-servers-reach-agreement">How does servers reach agreement?</a></li><li><a href="#how-does-zookeeper-take-snapshot">How does ZooKeeper take snapshot?</a></li><li><a href="#how-does-zookeeper-handle-sync">How does ZooKeeper handle sync()</a></li><li><a href="#how-does-zookeeper-ensure-to-serve-data-at-least-as-update-as-last-server-served-that-data">How does ZooKeeper ensure to serve data at least as update as last server served that data?</a></li><li><a href="#how-to-detect-client-session-failures">How to detect client session failures?</a></li></ul></li></ul></li><li><a href="#evaluation-and-results">Evaluation and results</a></li></ul></p><h1 id="purpose"><a class="markdownIt-Anchor" href="#purpose"></a> Purpose</h1><ol><li>Contribution<ul><li>Moved away from implementing specific primitives on the server side<ul><li>Opted for exposing an API that enables application developers to implement their own primitives.</li><li>It enables new primitives without requiring changes to the service core.</li></ul></li><li>Moved away from blocking primitives.<ul><li>Manipulate simple wait-free data objects organized hierarchically as in file systems.</li></ul></li><li>Provide a per client guarantee of FIFO execution of requests and linearizability for all writes.<ul><li>Read requests are satisfied by local servers.</li></ul></li></ul></li><li>Features<ul><li>Provide a simple and high performance kernel for building more complex coordination primitives at the client.</li><li>Incorporates elements from group messaging, shared registers, and distributed lock services in a replicated, centralized service.</li><li>It has the wait-free aspects of shared registers with an event-driven mechanism.</li><li>Using a simple pipelined architecture that allows us to have hundreds or thousands of requests outstanding while still achieving low latency.</li><li>With asynchronous operations, a client is able to have multiple outstanding operations at a time.</li><li>Enables caching data on the client side with ZooKeeper watches to avoid the problem of delayed update caused by slow or faulty client.</li></ul></li></ol><h1 id="model"><a class="markdownIt-Anchor" href="#model"></a> Model</h1><h2 id="zookeeper-service-overview"><a class="markdownIt-Anchor" href="#zookeeper-service-overview"></a> ZooKeeper service overview</h2><p>Znode: an in-memory data node in the ZooKeeper data<br />Data tree: a hierarchical namespace to organize znodes</p><h3 id="how-does-client-interact-with-zookeeper-server"><a class="markdownIt-Anchor" href="#how-does-client-interact-with-zookeeper-server"></a> How does client interact with ZooKeeper server?</h3><ol><li><p>Clients submit requests to ZooKeeper through a client API using a ZooKeeper client library.</p><ul><li><code>create(path, data, flags)</code>: returns the name of the new znode</li><li><code>delete(path, version)</code>: Deletes the znode path if that znode is at the expected version.</li><li><code>exists(path, watch)</code>: The watch flag enables a client to set a watch on the znode.</li><li><code>getData(path, watch)</code>: Returns the data and meta-data, such as version information, associated with the znode. ZooKeeper does not set the watch if the znode does not exist.</li><li><code>setData(path, data, version)</code>: Writes data[] to znode path if the version number is the current version of the znode.</li><li><code>getChildren(path, watch)</code></li><li><code>sync(path)</code>: Waits for all updates pending at the start of the operation to propagate to the server that the client is connected to. The path is currently ignored.</li></ul></li><li><p>All methods have both a synchronous and an asynchronous version available through the API.</p></li><li><p>If the actual version number of the znode does not match the expected version number the update fails with an unexpected version error.<br />If the version number is −1, it does not perform version checking.</p></li><li><p>The client library also manages the network connections between the client and ZooKeeper servers.</p></li></ol><h3 id="what-are-the-flags-of-znodes"><a class="markdownIt-Anchor" href="#what-are-the-flags-of-znodes"></a> What are the flags of znodes?</h3><ol><li><em>Regular</em>: Clients manipulate regular znodes by creating and deleting them explicitly</li><li><em>Ephemeral</em>: Clients create such znodes, and they either delete them explicitly, or let the system remove them automatically when the session that creates them terminates</li><li><em>Sequential</em>: Those znodes in the same parent znode have a monotonically increasing counter appended to its name. The newer znode has larger sequence value.</li><li><em>Watch</em><ul><li>A read operation with a watch flag set completes as normal except that the server promises to notify the client when the information returned has changed.</li><li>Watches are one-time triggers associated with a session; they are unregistered once triggered or the session closes.</li><li>Watches indicate that a change has happened, but do not provide the change.</li><li>Session events, such as connection loss events, are also sent to watch callbacks so that clients know that watch events may be delayed.</li></ul></li></ol><h3 id="what-are-the-differences-between-znodes-and-files-in-file-system"><a class="markdownIt-Anchor" href="#what-are-the-differences-between-znodes-and-files-in-file-system"></a> What are the differences between znodes and files in file system?</h3><ol><li><p>Znodes map to abstractions of the client application, typically corresponding to meta-data used for coordination purposes.</p></li><li><p>Znodes allow clients to store some information that can be used for meta-data or configuration in a distributed computation, like the leadership of a replica group can be stored to a known location.</p></li><li><p>ZooKeeper does not use handles to access znodes. Each request instead includes the full path of the znode being operated on.</p><ul><li><p>It simplifies the API (no <code>open()</code> or <code>close()</code> methods)</p></li><li><p>It also eliminates extra state that the server would need to maintain.</p></li></ul></li></ol><h3 id="what-does-zookeeper-guarantee"><a class="markdownIt-Anchor" href="#what-does-zookeeper-guarantee"></a> What does ZooKeeper guarantee?</h3><ol><li><p>This definition of its linearizability is called A-linearizability (asynchronous linearizability) that allows a client to have multiple outstanding operations.</p><ul><li><p><em>Linearizable writes</em>: all requests that update the state of ZooKeeper are serializable and respect precedence.</p></li><li><p><em>FIFO client order</em>: all requests from a given client are executed in the order that they were sent by the client.</p></li></ul></li><li><p>A-linearizability can choose to guarantee no specific order for outstanding operations of the same client or to guarantee FIFO order.</p></li><li><p>A system that satisfies A-linearizability also satisfies linearizability. Because only update requests are A-linearizable, ZooKeeper processes read requests locally at each replica.</p></li></ol><h3 id="how-to-change-configuration"><a class="markdownIt-Anchor" href="#how-to-change-configuration"></a> How to change configuration?</h3><ol><li><p>Two requirements:</p><ul><li>As the new leader starts making changes, we do not want other processes to start using the configuration that is being changed.</li><li>If the new leader dies before the configuration has been fully updated, we do not want the processes to use this partial configuration.</li></ul></li><li><p>The new leader can designate a path as the ready znode; other processes will only use the configuration when that znode exists.</p><ul><li>The new leader makes the configuration change by deleting ready, updating the various configuration znodes, and creating ready.</li><li>All of these changes can be pipelined and issued asynchronously to quickly update the configuration state given the FIFO client order guarantee.</li></ul></li></ol><h3 id="how-should-a-client-read-configurations"><a class="markdownIt-Anchor" href="#how-should-a-client-read-configurations"></a> How should a client read configurations?</h3><ol><li><p>If a client sees the ready exists before the new leader starts to make a change, it could read the partial configuration in progress and cannot notice anything.</p><ul><li>The client need to set the watch flag when they check the existence of the ready znode.</li><li>Then it will see a notification informing the client of the change before it can read any of the new configuration.</li></ul></li><li><p>If A changes the shared configuration in ZooKeeper and tells B of the change through the shared communication channel, B would expect to see the change when it re-reads the configuration.</p><ul><li>If B’s ZooKeeper replica is slightly behind A’s, it may not see the new configuration.</li><li>B can make sure that it sees the most up-to-date information by issuing a write before re-reading the configuration.</li><li><code>sync</code> causes a server to apply all pending write requests before processing the read without the overhead of a full write.</li></ul></li></ol><h2 id="implement-primitives"><a class="markdownIt-Anchor" href="#implement-primitives"></a> Implement primitives</h2><h3 id="how-does-zookeeper-manage-configuration"><a class="markdownIt-Anchor" href="#how-does-zookeeper-manage-configuration"></a> How does ZooKeeper manage configuration?</h3><ol><li>Configuration is stored in a znode, <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>z</mi><mi>c</mi></msub></mrow><annotation encoding="application/x-tex">z_c</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.04398em;">z</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:-0.04398em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">c</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>.</li><li>Processes start up with the full pathname of <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>z</mi><mi>c</mi></msub></mrow><annotation encoding="application/x-tex">z_c</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.04398em;">z</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:-0.04398em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">c</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>. Starting processes obtain their configuration by reading zc with the watch flag set to true.</li><li>If the configuration in <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>z</mi><mi>c</mi></msub></mrow><annotation encoding="application/x-tex">z_c</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.04398em;">z</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:-0.04398em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">c</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> is ever updated, the processes are notified and read the new configuration, again setting the watch flag to true.</li></ol><h3 id="how-does-zookeeper-manage-rendezvous"><a class="markdownIt-Anchor" href="#how-does-zookeeper-manage-rendezvous"></a> How does ZooKeeper manage rendezvous?</h3><ol><li>Use a rendezvous znode, <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>z</mi><mi>r</mi></msub></mrow><annotation encoding="application/x-tex">z_r</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.04398em;">z</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:-0.04398em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>, which is an node created by the client.</li><li>The client passes the full pathname of <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>z</mi><mi>r</mi></msub></mrow><annotation encoding="application/x-tex">z_r</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.04398em;">z</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:-0.04398em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> as a startup parameter of the master and worker processes.</li><li>When the master starts, it fills in <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>z</mi><mi>r</mi></msub></mrow><annotation encoding="application/x-tex">z_r</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.04398em;">z</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:-0.04398em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> with information about addresses and ports it is using.</li><li>When workers start, they read <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>z</mi><mi>r</mi></msub></mrow><annotation encoding="application/x-tex">z_r</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.04398em;">z</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:-0.04398em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> with watch set to true.<ul><li>If <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>z</mi><mi>r</mi></msub></mrow><annotation encoding="application/x-tex">z_r</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.04398em;">z</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:-0.04398em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> has not been filled in yet, the worker waits to be notified when <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>z</mi><mi>r</mi></msub></mrow><annotation encoding="application/x-tex">z_r</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.04398em;">z</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:-0.04398em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> is updated.</li><li>If <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>z</mi><mi>r</mi></msub></mrow><annotation encoding="application/x-tex">z_r</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.04398em;">z</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:-0.04398em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> is an ephemeral node, master and worker processes can watch for <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>z</mi><mi>r</mi></msub></mrow><annotation encoding="application/x-tex">z_r</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.04398em;">z</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:-0.04398em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> to be deleted and clean themselves up when the client ends.</li></ul></li></ol><h3 id="how-does-zookeeper-manage-group-mambership"><a class="markdownIt-Anchor" href="#how-does-zookeeper-manage-group-mambership"></a> How does ZooKeeper manage group mambership?</h3><ol><li><p>Designate a znode, <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>z</mi><mi>g</mi></msub></mrow><annotation encoding="application/x-tex">z_g</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.716668em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.04398em;">z</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.15139200000000003em;"><span style="top:-2.5500000000000003em;margin-left:-0.04398em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03588em;">g</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span></span></span></span> to represent the group.</p></li><li><p>When a process member of the group starts, it creates an <code>ephemeral</code> child znode under <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>z</mi><mi>g</mi></msub></mrow><annotation encoding="application/x-tex">z_g</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.716668em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.04398em;">z</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.15139200000000003em;"><span style="top:-2.5500000000000003em;margin-left:-0.04398em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03588em;">g</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span></span></span></span>. Processes may put process information in the data of the child znode.</p></li><li><p>If each process has a unique name or identifier, then that name is used as the name of the child znode; otherwise, the process creates the znode with the <code>SEQUENTIAL</code> flag to obtain a unique name assignment.</p></li></ol><h3 id="how-does-zookeeper-manage-mini-transaction"><a class="markdownIt-Anchor" href="#how-does-zookeeper-manage-mini-transaction"></a> How does ZooKeeper manage Mini-transaction?</h3><ol><li>In a mini-transaction, we want the <code>getData</code> and <code>setData</code> to be atomic.</li><li>ZooKeeper can support mini-transaction using version number.</li></ol><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">while</span> <span class="literal">true</span>:</span><br><span class="line">X, v = <span class="title function_ invoke__">getData</span>(K)</span><br><span class="line">  <span class="keyword">if</span> <span class="title function_ invoke__">setData</span>(K, X+<span class="number">1</span>, v):</span><br><span class="line"><span class="keyword">break</span></span><br></pre></td></tr></table></figure><h3 id="how-does-zookeeper-implement-simple-locks"><a class="markdownIt-Anchor" href="#how-does-zookeeper-implement-simple-locks"></a> How does ZooKeeper implement simple locks?</h3><ol><li><p>The lock is represented by a znode. To acquire a lock, a client tries to create the designated znode with the <code>EPHEMERAL</code> flag.</p></li><li><p>If the create succeeds, the client holds the lock. Otherwise, the client can read the znode with the watch flag set to be notified if the current leader dies.</p></li><li><p>A client releases the lock when it dies or explicitly deletes the znode.</p></li><li><p>Other clients that are waiting for a lock try again to acquire a lock once they observe the znode being deleted.</p></li></ol><h3 id="how-does-zookeeper-implement-simple-locks-without-herd-effect"><a class="markdownIt-Anchor" href="#how-does-zookeeper-implement-simple-locks-without-herd-effect"></a> How does ZooKeeper implement simple locks without herd effect?</h3><ol><li><p>Herd effect of simple locks: If there are many clients waiting to acquire a lock, they will all vie for the lock when it is released even though only one client can acquire the lock.</p></li><li><p>Define a lock znode l to implement such locks. Line up all the clients requesting the lock and each client obtains the lock in order of request arrival.</p><ul><li>Use the <code>SEQUENTIAL</code> flag to order the client’s attempt to acquire the lock with respect to all other attempts.</li><li>If the client’s znode has the lowest sequence number, the client holds the lock.</li><li>Otherwise, the client waits for deletion of the znode that either has the lock or will receive the lock before this client’s znode.</li></ul></li><li><p>By only watching the znode that precedes the client’s znode, the herd effect can be avoided by only waking up one process when a lock is released or a lock request is abandoned.</p></li><li><p>Once the znode being watched by the client goes away, the client must check if it now holds the lock.</p><ul><li>The previous lock request may have been abandoned and there is a znode with a lower sequence number still waiting for or holding the lock.</li></ul></li><li><p>Releasing a lock is as simple as deleting the znode n that represents the lock request.</p></li><li><p>We can see by browsing the ZooKeeper data the amount of lock contention, break locks, and debug locking problems.</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Lock</span></span><br><span class="line">n = create(l + “/lock-”, EPHEMERAL|SEQUENTIAL)</span><br><span class="line">C = getChildren(l, <span class="literal">false</span>)</span><br><span class="line"><span class="keyword">if</span> n is lowest znode in C, <span class="built_in">exit</span></span><br><span class="line">p = znode in C ordered just before n</span><br><span class="line"><span class="keyword">if</span> exists(p, <span class="literal">true</span>) wait <span class="keyword">for</span> watch event</span><br><span class="line"><span class="keyword">goto</span> <span class="number">2</span></span><br><span class="line"></span><br><span class="line"><span class="comment">//Unlock</span></span><br><span class="line">delete(n)</span><br></pre></td></tr></table></figure></li></ol><h3 id="how-does-zookeeper-implement-readwrite-locks"><a class="markdownIt-Anchor" href="#how-does-zookeeper-implement-readwrite-locks"></a> How does ZooKeeper implement Read/Write locks?</h3><ol><li><p>The write locks is similar to the simple locks since they are all exclusive.</p></li><li><p>Since read locks may be shared, and only earlier write lock znodes prevent the client from obtaining a read lock, read locks only need to check that no lower write znode.</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Write lock</span></span><br><span class="line">n = create(l + “/write-”, EPHEMERAL|SEQUENTIAL)</span><br><span class="line">C = getChildren(l, <span class="literal">false</span>)</span><br><span class="line"><span class="keyword">if</span> n is lowest znode in C, <span class="built_in">exit</span></span><br><span class="line">p = znode in C ordered just before n</span><br><span class="line"><span class="keyword">if</span> exists(p, <span class="literal">true</span>) wait <span class="keyword">for</span> event</span><br><span class="line"><span class="keyword">goto</span> <span class="number">2</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// Read Lock</span></span><br><span class="line">n = create(l + “/read-”, EPHEMERAL|SEQUENTIAL)</span><br><span class="line">C = getChildren(l, <span class="literal">false</span>)</span><br><span class="line"><span class="keyword">if</span> no write znodes lower than n in C, <span class="built_in">exit</span></span><br><span class="line">p = write znode in C ordered just before n</span><br><span class="line"><span class="keyword">if</span> exists(p, <span class="literal">true</span>) wait <span class="keyword">for</span> event</span><br><span class="line"><span class="keyword">goto</span> <span class="number">3</span></span><br></pre></td></tr></table></figure></li></ol><h3 id="what-is-the-difference-between-zookeeper-locks-and-thread-mutex-locks"><a class="markdownIt-Anchor" href="#what-is-the-difference-between-zookeeper-locks-and-thread-mutex-locks"></a> What is the difference between ZooKeeper locks and thread mutex locks?</h3><ol><li>In ZooKeeper lock, if lock holder fails, system automatically releases locks. So locks are not really enforcing atomicity of other activities.</li><li>To make writes atomic, use “ready” trick or mini-transactions.</li><li>For master/leader election, new leader must inspect state and clean up.</li><li>Or use soft locks like MapReduce, for performance but not correctness. Only one worker will do each task, and each task is OK to be done twice.</li></ol><h3 id="how-does-zookeeper-implementa-double-barrier"><a class="markdownIt-Anchor" href="#how-does-zookeeper-implementa-double-barrier"></a> How does ZooKeeper implementa double barrier?</h3><ol><li>Double barriers enable clients to synchronize the beginning and the end of a computation.<ul><li>Enter barrier: At the beginning, a client need to wait until the number of waiting clients exceeds the threshold before it can execute the computation.</li><li>Leave barrier: At the end, a client need to wait until the number of finished clients exceeds the threshold before it can exit.</li></ul></li><li>Represent a barrier in ZooKeeper with a znode, referred to as <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>b</mi></mrow><annotation encoding="application/x-tex">b</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathnormal">b</span></span></span></span>.</li><li>Every process <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi></mrow><annotation encoding="application/x-tex">p</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord mathnormal">p</span></span></span></span> registers with <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>b</mi></mrow><annotation encoding="application/x-tex">b</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathnormal">b</span></span></span></span> on entry by creating a znode as a child of <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>b</mi></mrow><annotation encoding="application/x-tex">b</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathnormal">b</span></span></span></span>, and unregisters when it is ready to leave by removing the child.<ul><li>Processes can enter the barrier when the number of child znodes of <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>b</mi></mrow><annotation encoding="application/x-tex">b</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathnormal">b</span></span></span></span> exceeds the barrier threshold.</li><li>Processes can leave the barrier when all of the processes have removed their children.</li></ul></li><li>We use watches to efficiently wait for enter and exit conditions to be satisfied.<ul><li>To enter, processes watch for the existence of a ready child of b that will be created by the process that causes the number of children to exceed the barrier threshold.</li><li>To leave, processes watch for a particular child to disappear and only check the exit condition once that znode has been removed.</li></ul></li></ol><h2 id="implementation-of-zookeeper"><a class="markdownIt-Anchor" href="#implementation-of-zookeeper"></a> Implementation of ZooKeeper</h2><h3 id="how-does-zookeeper-serve-requests"><a class="markdownIt-Anchor" href="#how-does-zookeeper-serve-requests"></a> How does ZooKeeper serve requests?</h3><ol><li>Upon receiving a request, a server prepares it for execution in request processor.</li><li>If a write request requires coordination among the servers, they use atomic broadcast to reach an agreement , and finally servers commit changes to the ZooKeeper database fully replicated across all servers of the ensemble.<ul><li>When a server processes a write request, it also sends out and clears notifications relative to any watch that corresponds to that update.</li><li>Only the server that a client is connected to tracks and triggers notifications for that client.</li><li>Servers process writes in order and do not process other writes or reads concurrently. This ensures strict succession of notifications.</li></ul></li><li>In the case of read requests, a server simply reads the state of the local database and generates a response to the request.<ul><li>Each read request is processed and tagged with a <em>zxid</em> that corresponds to the last transaction seen by the server.</li><li><em>Zxid</em> defines the partial order of the read requests with respect to the write requests.</li><li>For applications that require that ZooKeeper do not serve stale data, they can call <code>sync()</code> followed by the read operation.</li></ul></li></ol><h3 id="how-does-zookeeper-manage-database"><a class="markdownIt-Anchor" href="#how-does-zookeeper-manage-database"></a> How does ZooKeeper manage database?</h3><ol><li>The replicated database is an in-memory database containing the entire data tree.</li><li>Each znode in the tree stores a maximum of 1MB of data by default, but this maximum value is a configuration parameter that can be changed in specific cases.</li><li>For recoverability,<ul><li>Efficiently log updates to disk, and we force writes to be on the disk media before they are applied to the in-memory database.</li><li>A replay log (a write-ahead log) of committed operations is kept and periodically generate snapshots of the in-memory database.</li></ul></li></ol><h3 id="how-does-request-processor-handle-write-requests"><a class="markdownIt-Anchor" href="#how-does-request-processor-handle-write-requests"></a> How does request processor handle write requests?</h3><ol><li>When the leader receives a write request, it calculates what the state of the system will be when the write is applied and transforms it into a transaction that captures this new state.</li><li>The future state must be calculated because there may be outstanding transactions that have not yet been applied to the database.</li></ol><h3 id="how-does-servers-reach-agreement"><a class="markdownIt-Anchor" href="#how-does-servers-reach-agreement"></a> How does servers reach agreement?</h3><ol><li>All requests that update ZooKeeper state are forwarded to the leader.</li><li>The leader executes the request and broadcasts the change to the ZooKeeper state through Zab.<ul><li>Zab uses by default simple majority quorums to decide on a proposal, so Zab and thus ZooKeeper can only work if a majority of servers are correct.</li><li>Zab guarantees that changes broadcast by a leader are delivered in the order they were sent and all changes from previous leaders are delivered to an established leader before it broadcasts its own changes.</li><li>Because idempotent transactions is used, multiple delivery is acceptable as long as they are delivered in order.</li><li>ZooKeeper requires Zab to redeliver at least all messages that were delivered after the start of the last snapshot.</li></ul></li><li>The server that receives the client request responds to the client when it delivers the corresponding state change.</li><li>Use TCP for transport so message order is maintained by the network.</li></ol><h3 id="how-does-zookeeper-take-snapshot"><a class="markdownIt-Anchor" href="#how-does-zookeeper-take-snapshot"></a> How does ZooKeeper take snapshot?</h3><ol><li>ZooKeeper snapshots is called fuzzy snapshots since we do not lock the ZooKeeper state to take the snapshot.<br />Instead, we do a depth first scan of the tree atomically reading each znode’s data and meta-data and writing them to disk.</li><li>Since the resulting fuzzy snapshot may have applied some subset of the state changes delivered during the generation of the snapshot, the result may not correspond to the state of ZooKeeper at any point in time.</li><li>However, since state changes are idempotent, we can apply them twice as long as we apply the state changes in order.</li></ol><h3 id="how-does-zookeeper-handle-sync"><a class="markdownIt-Anchor" href="#how-does-zookeeper-handle-sync"></a> How does ZooKeeper handle sync()</h3><ol><li>It does not need to atomically broadcast sync as using a leader-based algorithm, and it simply places the <code>sync</code> operation at the end of the queue of requests between the leader and the server executing the call to sync.</li><li>The follower must be sure that the leader is still the leader.<ul><li>If there are pending transactions that commit, then the server does not suspect the leader.</li><li>If the pending queue is empty, the leader needs to issue a null transaction to commit and orders the <code>sync</code> after that transaction.</li><li>Hence, when the leader is under load, no extra broadcast traffic is generated.</li><li>Timeouts are set such that leaders realize they are not leaders before followers abandon them, so it does not issue the null transaction.</li></ul></li></ol><h3 id="how-does-zookeeper-ensure-to-serve-data-at-least-as-update-as-last-server-served-that-data"><a class="markdownIt-Anchor" href="#how-does-zookeeper-ensure-to-serve-data-at-least-as-update-as-last-server-served-that-data"></a> How does ZooKeeper ensure to serve data at least as update as last server served that data?</h3><ol><li>Check the last zxid of the client against its last zxid.</li><li>If the client has a more recent view than the server, the server does not reestablish the session with the client until the server has caught up.</li></ol><h3 id="how-to-detect-client-session-failures"><a class="markdownIt-Anchor" href="#how-to-detect-client-session-failures"></a> How to detect client session failures?</h3><ol><li>The leader determines that there has been a failure if no other server receives anything from a client session within the session timeout.</li><li>If the client sends requests frequently enough, then there is no need to send any other message.<br />Otherwise, the client sends heartbeat messages during periods of low activity.</li><li>If the client cannot communicate with a server to send a request or heartbeat, it connects to a different ZooKeeper server to re-establish its session.</li><li>To prevent the session from timing out, the ZooKeeper client library sends a heartbeat after the session has been idle for <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>s</mi><mi mathvariant="normal">/</mi><mn>3</mn></mrow><annotation encoding="application/x-tex">s/3</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">s</span><span class="mord">/</span><span class="mord">3</span></span></span></span> ms and switch to a new server if it has not heard from a server for <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>2</mn><mi>s</mi><mi mathvariant="normal">/</mi><mn>3</mn></mrow><annotation encoding="application/x-tex">2s/3</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord">2</span><span class="mord mathnormal">s</span><span class="mord">/</span><span class="mord">3</span></span></span></span> ms, where <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>s</mi></mrow><annotation encoding="application/x-tex">s</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathnormal">s</span></span></span></span> is the session timeout in milliseconds.</li></ol><h1 id="evaluation-and-results"><a class="markdownIt-Anchor" href="#evaluation-and-results"></a> Evaluation and results</h1><ol><li><p>To show the scalability of the system, the author varied the number of servers that make up the ZooKeeper service, but always kept the number of clients the same.</p><p>The throughput performance of a saturated system as the ratio of reads to writes vary is as shown below.</p><img src="/imgs/Distributed/ZooKeeper/Throughput.png"></li><li><p>There are two reasons for write requests taking longer than read requests.</p><ul><li>First, write requests must go through atomic broadcast, which requires some extra processing and adds latency to requests.</li><li>The other reason for longer processing of write requests is that servers must ensure that transactions are logged to non-volatile store before sending acknowledgments back to the leader.</li></ul></li><li><p>The atomic broadcast protocol does most of the work of the system and thus limits the performance of ZooKeeper more than any other component.</p><p>To benchmark its performance the author simulates clients by generating the transactions directly at the leader, so there is no client connections or client requests and replies.</p><p>The result is as shown below:</p><img src="/imgs/Distributed/ZooKeeper/AtomicBroadcast.png"></li><li><p>The author also tested the throughput of the system when occurring different failure events.</p><p>The events are: ① Failure and recovery of a follower; ② Failure and recovery of a different follower; ③ Failure of the leader; ④Failure of two followers (a, b) in the first two marks, and recovery at the third mark ©; ⑤ Failure of the leader; ⑥Recovery of the leader.</p><img src="/imgs/Distributed/ZooKeeper/Failures.png"></li><li><p>To assess the latency of requests, the author creates a worker process that simply sends a create, waits for it to finish, sends an asynchronous delete of the new node, and then starts the next create.</p><p>Then the throughput can be calculated by dividing the number of create requests completed by the total time it took for all the workers to complete.</p><img src="/imgs/Distributed/ZooKeeper/Latency.png"></li><li><p>The author also measured the performance of primitives implemented with ZooKeeper. They measured the performance of barriers.</p><p>The time to process all barriers increase roughly linearly with the number of barriers, showing that concurrent access to the same part of the data tree did not produce any unexpected delay</p><p>Latency increases proportionally to the number of clients. This is a consequence of not saturating the ZooKeeper service due to clients waiting on other clients.</p><img src="/imgs/Distributed/ZooKeeper/Barrier.png"></li></ol>]]></content>
      
      
      <categories>
          
          <category> Paper Notebook </category>
          
          <category> Distributed System </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Distributed System </tag>
            
            <tag> Distributed Storage </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Raft</title>
      <link href="/2023/09/26/Paper/Distributed/Raft/"/>
      <url>/2023/09/26/Paper/Distributed/Raft/</url>
      
        <content type="html"><![CDATA[<p>Paper: <a href="http://nil.csail.mit.edu/6.824/2020/papers/raft-extended.pdf">In Search of an Understandable Consensus Algorithm</a></p><p><ul class="markdownIt-TOC"><li><a href="#abstract">Abstract</a></li><li><a href="#purpose">Purpose</a></li><li><a href="#model">Model</a><ul><li><a href="#basics">Basics</a><ul><li><a href="#how-does-raft-implements-consensus-overall">How does Raft implements consensus overall?</a></li><li><a href="#what-are-the-states-of-each-server">What are the states of each server?</a></li><li><a href="#how-to-divide-the-terms">How to divide the terms?</a></li><li><a href="#how-does-terms-change">How does terms change?</a></li><li><a href="#how-does-raft-handle-follower-and-candidate-crashes">How does Raft handle follower and candidate crashes?</a></li><li><a href="#states-stored-on-servers">States stored on servers</a></li></ul></li><li><a href="#leader-election">Leader election</a><ul><li><a href="#how-does-the-servers-states-transit">How does the servers states transit?</a></li><li><a href="#how-to-elect-a-leader">How to elect a leader?</a></li><li><a href="#how-is-the-election-held">How is the election held?</a></li><li><a href="#how-to-determine-that-a-server-loses-the-election">How to determine that a server loses the election?</a></li><li><a href="#how-to-handle-a-split-vote">How to handle a split vote?</a></li><li><a href="#how-to-ensure-that-the-leader-of-any-given-term-contains-all-of-the-entries-committed-in-previous-terms">How to ensure that the leader of any given term contains all of the entries committed in previous terms?</a></li><li><a href="#what-is-the-limitation-of-broadcast-time-and-election-timeout">What is the limitation of broadcast time and election timeout?</a></li><li><a href="#requestvote-rpc">RequestVote RPC</a></li></ul></li><li><a href="#log-replication">Log replication</a><ul><li><a href="#how-are-client-requests-handled">How are client requests handled?</a></li><li><a href="#what-is-stored-in-a-log-entry">What is stored in a log entry?</a></li><li><a href="#how-to-apply-a-log-entry-to-the-state-machines">How to apply a log entry to the state machines?</a></li><li><a href="#how-to-determine-the-consistency-between-logs">How to determine the consistency between logs?</a></li><li><a href="#how-to-check-the-consistency-in-appendentries-rpcs">How to check the consistency in AppendEntries RPCs?</a></li><li><a href="#what-kinds-of-inconsistency-may-incur">What kinds of inconsistency may incur?</a></li><li><a href="#how-does-leader-handle-follower-inconsistencies">How does leader handle follower inconsistencies?</a></li><li><a href="#how-does-appendentries-rpc-perform-consistency-check">How does AppendEntries RPC perform consistency check?</a></li><li><a href="#how-to-handle-uncommited-entries-from-previous-leaders">How to handle uncommited entries from previous leaders?</a></li><li><a href="#appendentries-rpc">AppendEntries RPC</a></li></ul></li><li><a href="#log-compaction">Log compaction</a><ul><li><a href="#how-does-raft-compact-logs">How does Raft compact logs?</a></li><li><a href="#how-to-handle-the-appendentries-that-requires-compated-entries">How to handle the AppendEntries that requires compated entries?</a></li><li><a href="#how-to-install-the-snapshot-from-leader">How to install the snapshot from leader?</a></li><li><a href="#when-should-a-server-to-snapshot">When should a server to snapshot?</a></li><li><a href="#how-to-reduce-the-delays-of-normal-operations-caused-by-a-snapshot">How to reduce the delays of normal operations caused by a snapshot?</a></li><li><a href="#installsnapshot-rpc">InstallSnapshot RPC</a></li></ul></li><li><a href="#client-interaction">Client interaction</a><ul><li><a href="#how-does-client-find-cluster-leader">How does client find cluster leader?</a></li><li><a href="#how-to-prevent-raft-execute-a-command-multiple-times">How to prevent Raft execute a command multiple times?</a></li><li><a href="#how-to-prevent-returning-stale-date-to-a-read-only-operation">How to prevent returning stale date to a read-only operation?</a></li></ul></li></ul></li><li><a href="#experiements-and-results">Experiements and results</a></li><li><a href="#reproduce-and-unmentioned-parts">Reproduce and unmentioned parts</a></li></ul></p><h1 id="abstract"><a class="markdownIt-Anchor" href="#abstract"></a> Abstract</h1><ol><li><strong>Main idea</strong>: Understandability also matters for an algorithm to be implemented and deployed. Separate leader election and log replication parts in consensus to increase understandability. Linearizability are provided by restricting entries accepted by followers and client commands are executed only once.</li><li><strong>Key findings</strong>: The key of the correctness of the system is that committed entries are durable in all nodes. Based on Log Matching property and Leader Append-Only property, we can easily induct it. Another corner case to be noticed is that leaders commit entries of previous terms only by committing entries from its own term.</li><li><strong>The system</strong>: The elected leaders are restricted to be at least as up-to-date as majority nodes, and only leaders can append entries from clients.</li><li><strong>Evaluation</strong>: The authors evaluated the understandability againsted Paxos and the performance of electing leaders are measured.</li></ol><h1 id="purpose"><a class="markdownIt-Anchor" href="#purpose"></a> Purpose</h1><ol><li>Enhance the understandability of Paxos<ul><li>Raft separates the key elements of consensus, such as leader election, log replication, and safety</li><li>It enforces a stronger degree of coherency to reduce the number of states that must be considered</li></ul></li><li>Novel features: strong leader, leader election, membership changes.</li><li><strong>What is the common properties of consensus algorithms?</strong><ul><li>Safety: never returning an incorrect result under all non-Byzantine conditions, including network delays, partitions, and packet loss, duplication, and reordering.</li><li>Available as long as any majority of the servers are operational and can communicate with each other and with clients.</li><li>They do not depend on timing to ensure the consistency of the logs: faulty clocks and extreme message delays can, at worst, cause availability problems.</li><li>A command can complete as soon as a majority of the cluster has responded to a single round of remote procedure calls; a minority of slow servers need not impact overall system performance.</li></ul></li></ol><h1 id="model"><a class="markdownIt-Anchor" href="#model"></a> Model</h1><h2 id="basics"><a class="markdownIt-Anchor" href="#basics"></a> Basics</h2><h3 id="how-does-raft-implements-consensus-overall"><a class="markdownIt-Anchor" href="#how-does-raft-implements-consensus-overall"></a> How does Raft implements consensus overall?</h3><ol><li>First electing a distinguished leader, then giving the leader complete responsibility for managing the replicated log.</li><li>The leader accepts log entries from clients, replicates them on other servers, and tells servers when it is safe to apply log entries to their state machines.</li><li>A leader can fail or become disconnected from the other servers, in which case a new leader is elected.</li></ol><h3 id="what-are-the-states-of-each-server"><a class="markdownIt-Anchor" href="#what-are-the-states-of-each-server"></a> What are the states of each server?</h3><ol><li>At any given time each server is in one of three states: leader, follower, or candidate.</li><li>In normal operation there is exactly one leader and all of the other servers are followers.</li><li>Followers are passive: they issue no requests on their own but simply respond to requests from leaders and candidates.</li><li>The leader handles all client requests. If a client contacts a follower, the follower redirects it to the leader.</li><li>The candidate is used to elect a new leader.</li></ol><h3 id="how-to-divide-the-terms"><a class="markdownIt-Anchor" href="#how-to-divide-the-terms"></a> How to divide the terms?</h3><ol><li>Terms are numbered with consecutive integers. Each election begins a new term.</li><li>If an election results in a split vote, the term will end with no leader; a new term with a new election will begin shortly.</li><li>Terms act as a logical clock in Raft, and they allow servers to detect obsolete information such as stale leaders.</li></ol><h3 id="how-does-terms-change"><a class="markdownIt-Anchor" href="#how-does-terms-change"></a> How does terms change?</h3><ol><li>Each server stores a current term number, which increases monotonically over time.</li><li>Current terms are exchanged whenever servers communicate; if one server’s current term is smaller than the other’s, then it updates its current term to the larger value.</li><li>If a candidate or leader discovers that its term is out of date, it immediately reverts to follower state.</li><li>If a server receives a request with a stale term number, it rejects the request.</li></ol><h3 id="how-does-raft-handle-follower-and-candidate-crashes"><a class="markdownIt-Anchor" href="#how-does-raft-handle-follower-and-candidate-crashes"></a> How does Raft handle follower and candidate crashes?</h3><ol><li>If a follower or candidate crashes, then future <code>RequestVote</code> and <code>AppendEntries</code> RPCs sent to it will fail. Raft handles these failures by retrying indefinitely.</li><li>If a server crashes after completing an RPC but before responding, then it will receive the same RPC again after it restarts. Raft RPCs are idempotent, i.e. servers will ignore the RPCs that is already handled, so this causes no harm.</li></ol><h3 id="states-stored-on-servers"><a class="markdownIt-Anchor" href="#states-stored-on-servers"></a> States stored on servers</h3><ol><li>Persistent state on all servers: These states need to be updated on stable storage before responding to RPCs, i.e. communicating with outside.<ul><li><code>currentTerm</code>: latest term server has seen (initialized to 0 on first boot, increases monotonically)</li><li><code>votedFor</code>: candidateId that received vote in current term (or <code>null</code> if none)</li><li><code>log[]</code>: log entries</li></ul></li><li>Volatile state on all servers:<ul><li><code>commitIndex</code>: index of highest log entry known to be committed (initialized to 0, increases monotonically)</li><li><code>lastApplied</code>: index of highest log entry applied to state machine (initialized to 0, increases monotonically)</li></ul></li><li>Volatile state on leaders: These states need to be reinitialized after election<ul><li><code>nextIndex[]</code>: for each server, index of the next log entry to send to that server (initialized to leader last log index + 1)</li><li><code>matchIndex[]</code>: for each server, index of highest log entry known to be replicated on server (initialized to 0, increases monotonically)</li></ul></li></ol><h2 id="leader-election"><a class="markdownIt-Anchor" href="#leader-election"></a> Leader election</h2><h3 id="how-does-the-servers-states-transit"><a class="markdownIt-Anchor" href="#how-does-the-servers-states-transit"></a> How does the servers states transit?</h3><ol><li>When servers start up, they begin as followers. A server remains in follower state as long as it receives valid RPCs from a leader or candidate.</li><li>Leaders send periodic heartbeats (<code>AppendEntries</code> RPCs that carry no log entries) to all followers in order to maintain their authority.</li><li>If a follower receives no communication over a period of time called the election timeout, then it assumes there is no viable leader and become a candidate to initiate a new election.</li><li>A candidate that receives votes from a majority of the full cluster becomes the new leader.<br /><img src="/imgs/Distributed/Raft/01.png" alt="" /></li></ol><h3 id="how-to-elect-a-leader"><a class="markdownIt-Anchor" href="#how-to-elect-a-leader"></a> How to elect a leader?</h3><ol><li>To begin an election, a follower increments its current term and transitions to candidate state.</li><li>It then votes for itself and issues <code>RequestVote</code> RPCs in parallel to each of the other servers in the cluster.</li><li>Candidate continues in this state until one of three things happens<ul><li>It wins the election</li><li>Another server establishes itself as leader</li><li>A period of time goes by with no winner.</li></ul></li></ol><h3 id="how-is-the-election-held"><a class="markdownIt-Anchor" href="#how-is-the-election-held"></a> How is the election held?</h3><ol><li>Each server will vote for at most one candidate in a given term, on a first-come-first-served basis to ensure that at most one candidate can win the election for a particular term.</li><li>A candidate wins an election if it receives votes from a majority of the servers in the full cluster for the same term.</li><li>Once a candidate wins an election, it becomes leader. It then sends heartbeat messages to all of the other servers to establish its authority and prevent new elections.</li></ol><h3 id="how-to-determine-that-a-server-loses-the-election"><a class="markdownIt-Anchor" href="#how-to-determine-that-a-server-loses-the-election"></a> How to determine that a server loses the election?</h3><ol><li>A candidate may receive an <code>AppendEntries</code> RPC from another server claiming to be leader.</li><li>If the leader’s term is at least as large as the candidate’s current term, then the candidate recognizes the leader as legitimate and returns to follower state.</li><li>If the term in the RPC is smaller than the candidate’s current term, then the candidate rejects the RPC and continues in candidate state.</li></ol><h3 id="how-to-handle-a-split-vote"><a class="markdownIt-Anchor" href="#how-to-handle-a-split-vote"></a> How to handle a split vote?</h3><ol><li>If many followers become candidates at the same time, votes could be split so that no candidate obtains a majority.</li><li>Each candidate will time out and start a new election by incrementing its term and initiating another round of RequestVote RPCs.</li><li>Raft uses randomized election timeouts to ensure that split votes are rare and that they are resolved quickly.<ul><li>Election timeouts are chosen randomly from a fixed interval at the start of an election, and it waits for that timeout to elapse before starting the next election.</li><li>In most cases only a single server will time out; it wins the election and sends heartbeats before any other servers time out.</li></ul></li></ol><h3 id="how-to-ensure-that-the-leader-of-any-given-term-contains-all-of-the-entries-committed-in-previous-terms"><a class="markdownIt-Anchor" href="#how-to-ensure-that-the-leader-of-any-given-term-contains-all-of-the-entries-committed-in-previous-terms"></a> How to ensure that the leader of any given term contains all of the entries committed in previous terms?</h3><ol><li>A candidate must contact a majority of the cluster in order to be elected, which means that every committed entry must be present in at least one of those servers.</li><li>If the candidate’s log is at least as up-to-date as any other log in that majority, then it will hold all the committed entries.</li><li>In the <code>RequestVote</code> RPC, the voter denies its vote if its own log is more up-to-date than that of the candidate.</li><li>Raft determines which of two logs is more up-to-date by comparing the index and term of the last entries in the logs.<ul><li>If the logs have last entries with different terms, then the log with the later term is more up-to-date.</li><li>If the logs end with the same term, then whichever log is longer is more up-to-date.</li></ul></li></ol><h3 id="what-is-the-limitation-of-broadcast-time-and-election-timeout"><a class="markdownIt-Anchor" href="#what-is-the-limitation-of-broadcast-time-and-election-timeout"></a> What is the limitation of broadcast time and election timeout?</h3><ol><li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>b</mi><mi>r</mi><mi>o</mi><mi>a</mi><mi>d</mi><mi>c</mi><mi>a</mi><mi>s</mi><mi>t</mi><mi>T</mi><mi>i</mi><mi>m</mi><mi>e</mi><mo>≪</mo><mi>e</mi><mi>l</mi><mi>e</mi><mi>c</mi><mi>t</mi><mi>i</mi><mi>o</mi><mi>n</mi><mi>T</mi><mi>i</mi><mi>m</mi><mi>e</mi><mi>o</mi><mi>u</mi><mi>t</mi><mo>≪</mo><mi>M</mi><mi>T</mi><mi>B</mi><mi>F</mi></mrow><annotation encoding="application/x-tex">broadcastTime\ll electionTimeout\ll MTBF</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.73354em;vertical-align:-0.0391em;"></span><span class="mord mathnormal">b</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mord mathnormal">o</span><span class="mord mathnormal">a</span><span class="mord mathnormal">d</span><span class="mord mathnormal">c</span><span class="mord mathnormal">a</span><span class="mord mathnormal">s</span><span class="mord mathnormal">t</span><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="mord mathnormal">i</span><span class="mord mathnormal">m</span><span class="mord mathnormal">e</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">≪</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.73354em;vertical-align:-0.0391em;"></span><span class="mord mathnormal">e</span><span class="mord mathnormal" style="margin-right:0.01968em;">l</span><span class="mord mathnormal">e</span><span class="mord mathnormal">c</span><span class="mord mathnormal">t</span><span class="mord mathnormal">i</span><span class="mord mathnormal">o</span><span class="mord mathnormal">n</span><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="mord mathnormal">i</span><span class="mord mathnormal">m</span><span class="mord mathnormal">e</span><span class="mord mathnormal">o</span><span class="mord mathnormal">u</span><span class="mord mathnormal">t</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">≪</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">M</span><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="mord mathnormal" style="margin-right:0.05017em;">B</span><span class="mord mathnormal" style="margin-right:0.13889em;">F</span></span></span></span></li><li>BbroadcastTime is the average time it takes a server to send RPCs in parallel to every server in the cluster and receive their responses. electionTimeout is the election timeout. MTBF is the average time between failures for a single server.</li><li>The broadcast time should be an order of magnitude less than the election timeout so that leaders can reliably send the heartbeat messages required to keep followers from starting elections.</li><li>The election timeout should be a few orders of magnitude less than MTBF so that the system makes steady progress.</li></ol><h3 id="requestvote-rpc"><a class="markdownIt-Anchor" href="#requestvote-rpc"></a> RequestVote RPC</h3><ol><li>This is invoked by candidates to gather votes.</li><li>Arguments:<ul><li><code>term</code>: candidate’s term</li><li><code>candidateId</code>: candidate requesting vote</li><li><code>lastLogIndex</code>: index of candidate’s last log entry</li><li><code>lastLogTerm</code>: term of candidate’s last log entry</li></ul></li><li>Results:<ul><li><code>term</code>: currentTerm, for candidate to update itself</li><li><code>voteGranted</code>: true means candidate received vote</li></ul></li><li>Receiver implementation:<ul><li>Reply <code>false</code> if <code>term &lt; currentTerm</code></li><li>If votedFor is <code>null</code> or <code>candidateId</code>, and candidate’s log is at least as up-to-date as receiver’s log, grant vote</li></ul></li></ol><h2 id="log-replication"><a class="markdownIt-Anchor" href="#log-replication"></a> Log replication</h2><h3 id="how-are-client-requests-handled"><a class="markdownIt-Anchor" href="#how-are-client-requests-handled"></a> How are client requests handled?</h3><ol><li>Each client request contains a command to be executed by the replicated state machines.</li><li>The leader appends the command to its log as a new entry, then issues <code>AppendEntries</code> RPCs in parallel to each of the other servers to replicate the entry.</li><li>When the entry has been safely replicated, the leader applies the entry to its state machine and returns the result of that execution to the client.</li><li>If followers crash or run slowly, or if network packets are lost, the leader retries <code>AppendEntries</code> RPCs indefinitely (even after it has responded to the client) until all followers eventually store all log entries.</li></ol><h3 id="what-is-stored-in-a-log-entry"><a class="markdownIt-Anchor" href="#what-is-stored-in-a-log-entry"></a> What is stored in a log entry?</h3><ol><li>A command for state machine</li><li>A term number when entry was received by leader.</li><li>An index to identify its position in the log. The index of the first log is 1.</li></ol><h3 id="how-to-apply-a-log-entry-to-the-state-machines"><a class="markdownIt-Anchor" href="#how-to-apply-a-log-entry-to-the-state-machines"></a> How to apply a log entry to the state machines?</h3><ol><li>The leader decides when it is safe to apply a log entry to the state machines.<ul><li>Such an entry is called <code>committed</code>.</li><li>Raft guarantees that committed entries are durable and will eventually be executed by all of the available state machines.</li></ul></li><li>A log entry is committed once the leader that created the entry has replicated it on a majority of the servers.</li><li>It also commits all preceding entries in the leader’s log, including entries created by previous leaders.</li><li>The leader keeps track of the highest index it knows to be committed, and it includes that index in future <code>AppendEntries</code> RPCs, including heartbeats, so that the other servers eventually find out that they should commit some new entries.</li><li>Once a follower learns that a log entry is committed, it applies the entry to its local state machine in log order.</li></ol><h3 id="how-to-determine-the-consistency-between-logs"><a class="markdownIt-Anchor" href="#how-to-determine-the-consistency-between-logs"></a> How to determine the consistency between logs?</h3><ol><li><strong>Log Matching property</strong>: If two logs contain an entry with the same index and term, then the logs are identical in all entries up through the given index.</li><li>The Log Matching property is maintained through the following properties:<ul><li>If two entries in different logs have the same index and term, then they store the same command.</li><li>If two entries in different logs have the same index and term, then the logs are identical in all preceding entries.</li></ul></li></ol><h3 id="how-to-check-the-consistency-in-appendentries-rpcs"><a class="markdownIt-Anchor" href="#how-to-check-the-consistency-in-appendentries-rpcs"></a> How to check the consistency in AppendEntries RPCs?</h3><ol><li>When sending an <code>AppendEntries</code> RPC, the leader includes the index and term of the entry in its log that immediately precedes the new entries.</li><li>If the follower does not find an entry in its log with the same index and term, then it refuses the new entries.</li></ol><h3 id="what-kinds-of-inconsistency-may-incur"><a class="markdownIt-Anchor" href="#what-kinds-of-inconsistency-may-incur"></a> What kinds of inconsistency may incur?</h3><ol><li>Leader crashes can leave the logs inconsistent. The old leader may not have fully replicated all of the entries in its log.</li><li>A follower may be missing entries that are present on the leader, it may have extra entries that are not present on the leader, or both.</li></ol><h3 id="how-does-leader-handle-follower-inconsistencies"><a class="markdownIt-Anchor" href="#how-does-leader-handle-follower-inconsistencies"></a> How does leader handle follower inconsistencies?</h3><ol><li><strong>Leader Append-Only</strong> property: a leader never overwrites or deletes entries in its log.</li><li>The leader handles inconsistencies by forcing the followers’ logs to duplicate its own. Namely, conflicting entries in follower logs will be overwritten with entries from the leader’s log.</li><li>The leader must find the latest log entry where the two logs agree, delete any entries in the follower’s log after that point, and send the follower all of the leader’s entries after that point.</li><li>All of these actions happen in response to the consistency check performed by AppendEntries RPCs.</li><li>A leader does not need to take any special actions to restore log consistency when it comes to power. It just begins normal operation, and the logs automatically converge in response to failures of the AppendEntries consistency check.</li></ol><h3 id="how-does-appendentries-rpc-perform-consistency-check"><a class="markdownIt-Anchor" href="#how-does-appendentries-rpc-perform-consistency-check"></a> How does AppendEntries RPC perform consistency check?</h3><ol><li>The leader maintains a nextIndex for each follower. When a leader first comes to power, it initializes all nextIndex values to the index just after the last one in its log, i.e. assuming all followers are as up-to-date as itself.</li><li>If a follower’s log is inconsistent with the leader’s, the consistency check will fail in the next <code>AppendEntries</code> RPC.</li><li>After a rejection, the leader decrements nextIndex and retries the <code>AppendEntries</code> RPC.</li><li>Eventually <code>nextIndex</code> will reach a point where the leader and follower logs match. When this happens, <code>AppendEntries</code> will succeed, which removes any conflicting entries in the follower’s log and appends entries from the leader’s log (if any).</li><li>Once <code>AppendEntries</code> succeeds, the follower’s log is consistent with the leader’s, and it will remain that way for the rest of the term.</li></ol><h3 id="how-to-handle-uncommited-entries-from-previous-leaders"><a class="markdownIt-Anchor" href="#how-to-handle-uncommited-entries-from-previous-leaders"></a> How to handle uncommited entries from previous leaders?</h3><ol><li>If a leader crashes before committing an entry, future leaders will attempt to finish replicating the entry.</li><li>A leader cannot immediately conclude that an entry from a previous term <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>t</mi><mi>e</mi><mi>r</mi><msub><mi>m</mi><mi>p</mi></msub></mrow><annotation encoding="application/x-tex">term_p</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.9011879999999999em;vertical-align:-0.286108em;"></span><span class="mord mathnormal">t</span><span class="mord mathnormal">e</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mord"><span class="mord mathnormal">m</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.15139200000000003em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">p</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span></span></span></span> is committed once it is stored on a majority of servers.<ul><li>There could have other entries in a <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>t</mi><mi>e</mi><mi>r</mi><msub><mi>m</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">term_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.76508em;vertical-align:-0.15em;"></span><span class="mord mathnormal">t</span><span class="mord mathnormal">e</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mord"><span class="mord mathnormal">m</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> between <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>t</mi><mi>e</mi><mi>r</mi><msub><mi>m</mi><mi>p</mi></msub></mrow><annotation encoding="application/x-tex">term_p</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.9011879999999999em;vertical-align:-0.286108em;"></span><span class="mord mathnormal">t</span><span class="mord mathnormal">e</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mord"><span class="mord mathnormal">m</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.15139200000000003em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">p</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span></span></span></span> and the leader’s current term <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>t</mi><mi>e</mi><mi>r</mi><msub><mi>m</mi><mi>c</mi></msub></mrow><annotation encoding="application/x-tex">term_c</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.76508em;vertical-align:-0.15em;"></span><span class="mord mathnormal">t</span><span class="mord mathnormal">e</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mord"><span class="mord mathnormal">m</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">c</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>.</li><li>If nothing in the leaders current term has reached agreement, after the leader dies, that server with <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>t</mi><mi>e</mi><mi>r</mi><msub><mi>m</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">term_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.76508em;vertical-align:-0.15em;"></span><span class="mord mathnormal">t</span><span class="mord mathnormal">e</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mord"><span class="mord mathnormal">m</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> may become the new leader, and it can overwrite entries of <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>t</mi><mi>e</mi><mi>r</mi><msub><mi>m</mi><mi>p</mi></msub></mrow><annotation encoding="application/x-tex">term_p</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.9011879999999999em;vertical-align:-0.286108em;"></span><span class="mord mathnormal">t</span><span class="mord mathnormal">e</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mord"><span class="mord mathnormal">m</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.15139200000000003em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">p</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span></span></span></span> although those entries are committed since <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>t</mi><mi>e</mi><mi>r</mi><msub><mi>m</mi><mi>i</mi></msub><mo>&gt;</mo><mi>t</mi><mi>e</mi><mi>r</mi><msub><mi>m</mi><mi>p</mi></msub></mrow><annotation encoding="application/x-tex">term_i&gt;term_p</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.76508em;vertical-align:-0.15em;"></span><span class="mord mathnormal">t</span><span class="mord mathnormal">e</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mord"><span class="mord mathnormal">m</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">&gt;</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.9011879999999999em;vertical-align:-0.286108em;"></span><span class="mord mathnormal">t</span><span class="mord mathnormal">e</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mord"><span class="mord mathnormal">m</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.15139200000000003em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">p</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span></span></span></span></li></ul></li><li>Raft never commits log entries from previous terms by counting replicas.</li><li>Only log entries from the leader’s current term are committed by counting replicas; once an entry from the current term has been committed in this way, then all prior entries are committed indirectly because of the Log Matching Property.</li></ol><h3 id="appendentries-rpc"><a class="markdownIt-Anchor" href="#appendentries-rpc"></a> AppendEntries RPC</h3><ol><li>This is invoked by leader to replicate log entries; also used as heartbeat.</li><li>Arguments:<ul><li><code>term</code>: leader’s term</li><li><code>leaderId</code>: so follower can redirect clients</li><li><code>prevLogIndex</code>: index of log entry immediately preceding new ones.</li><li><code>prevLogTerm</code>: term of <code>prevLogIndex</code> entry</li><li><code>entries[]</code>: log entries to store (empty for hearbeat; may send more than one for efficiency)</li><li><code>leaderCommit</code>: leader’s <code>commitIndex</code></li></ul></li><li>Results:<ul><li><code>term</code>: <code>currentTerm</code>, for leader to update itself</li><li><code>success</code>: true if follower contrained entry matching <code>prevLogIndex</code> and <code>prevLogTerm</code></li></ul></li><li>Receiver implementation:<ul><li>Reply <code>false</code> if <code>term &lt; currentTerm</code></li><li>Reply <code>false</code> if log doesn’t contrain an entry at <code>prevLogIndex</code> whose term matches <code>prevLogTerm</code></li><li>If an existing entry conflicts with a new one (same index but different terms), delete the existing entry and all that follow it.</li><li>Append any new entries not already in the log.</li><li>If <code>leaderCommit &gt; commitIndex</code>, set <code>commitIndex = min(leaderCommit, index of last new entry)</code>.</li></ul></li></ol><h2 id="log-compaction"><a class="markdownIt-Anchor" href="#log-compaction"></a> Log compaction</h2><h3 id="how-does-raft-compact-logs"><a class="markdownIt-Anchor" href="#how-does-raft-compact-logs"></a> How does Raft compact logs?</h3><ol><li>In snapshotting, the entire current system state is written to a snapshot on stable storage.</li><li>Once a server completes writing a snapshot, it may delete all log entries up through the last included index, as well as any prior snapshot.</li><li>Each server takes snapshots independently, covering just the committed entries in its log.</li><li>Data still only flows from leaders to followers, just followers can now reorganize their data.</li></ol><h3 id="how-to-handle-the-appendentries-that-requires-compated-entries"><a class="markdownIt-Anchor" href="#how-to-handle-the-appendentries-that-requires-compated-entries"></a> How to handle the AppendEntries that requires compated entries?</h3><ol><li>Raft also includes a small amount of metadata in the snapshot.<ul><li>The <code>last included index</code> is the index of the last entry in the log that the snapshot replaces (the last entry the state machine had applied).</li><li>The <code>last included term</code> is the term of this entry.</li></ul></li><li>When the leader has already discarded the next log entry that it needs to send to a follower.</li><li>This situation is unlikely in normal operation: a follower that has kept up with the leader would already have this entry. However, an exceptionally slow follower or a new server joining the cluster would not.</li></ol><h3 id="how-to-install-the-snapshot-from-leader"><a class="markdownIt-Anchor" href="#how-to-install-the-snapshot-from-leader"></a> How to install the snapshot from leader?</h3><ol><li>The leader uses a new RPC called <code>InstallSnapshot</code> to send snapshots to followers that are too far behind.</li><li>When a follower receives a snapshot with this RPC, it must decide what to do with its existing log entries.</li><li>If the snapshot contains new information not already in the recipient’s log<ul><li>The follower discards its entire log</li><li>It is all superseded by the snapshot and may possibly have uncommitted entries that conflict with the snapshot.</li></ul></li><li>If instead the follower receives a snapshot that describes a prefix of its log<ul><li>This could be due to retransmission or by mistake.</li><li>Log entries covered by the snapshot are deleted but entries following the snapshot are still valid and must be retained.</li></ul></li></ol><h3 id="when-should-a-server-to-snapshot"><a class="markdownIt-Anchor" href="#when-should-a-server-to-snapshot"></a> When should a server to snapshot?</h3><ol><li>If a server snapshots too often, it wastes disk bandwidth and energy; if it snapshots too infrequently, it risks exhausting its storage capacity, and it increases the time required to replay the log during restarts.</li><li>One simple strategy is to take a snapshot when the log reaches a fixed size in bytes.</li><li>If this size is set to be significantly larger than the expected size of a snapshot, then the disk bandwidth overhead for snapshotting will be small.</li></ol><h3 id="how-to-reduce-the-delays-of-normal-operations-caused-by-a-snapshot"><a class="markdownIt-Anchor" href="#how-to-reduce-the-delays-of-normal-operations-caused-by-a-snapshot"></a> How to reduce the delays of normal operations caused by a snapshot?</h3><ol><li>The solution is to use copy-on-write techniques so that new updates can be accepted without impacting the snapshot being written.</li><li>The operating system’s copy-on-write support (e.g., fork on Linux) can be used to create an in-memory snapshot of the entire state machine.</li></ol><h3 id="installsnapshot-rpc"><a class="markdownIt-Anchor" href="#installsnapshot-rpc"></a> InstallSnapshot RPC</h3><ol><li>This is invoked by leader to send chunks of snapshot to a follower. Leaders always send chunks in order.</li><li>Arguments:<ul><li><code>term</code>: leader’s term</li><li><code>leaderId</code>: so follower can redirect clients</li><li><code>lastIncludedIndex</code>: the snapshot replaces all entries up through and including this index</li><li><code>lastIncludedTerm</code>: term of <code>lastIncludedIndex</code></li><li><code>offset</code>: byte offset where chunk is positioned in the snapshot file<ul><li>The whole snapshot file may be large, and hence divided into several chunks.</li></ul></li><li><code>data[]</code>: raw bytes of the snapshot chunk, starting at offset</li><li><code>done</code>: <code>true</code> if this is the last chunk</li></ul></li><li>Results:<ul><li><code>term</code>: <code>currentTerm</code>, for leader to update itself</li></ul></li><li>Receiver implementation:<ul><li>Reply immediately if <code>term &lt; currentTerm</code></li><li>Create new snapshot file if first chunk (offset is 0)</li><li>Write data into snapshot file at given offset</li><li>Reply and wait for more data chunks if done is <code>false</code>.</li><li>Save snapshot file, discard any existing or partial snapshot with smaller index</li><li>If existing log entry has same index and term as snapshot’s last included entry, retain log entries following it and reply</li><li>Discard the entire log</li><li>Reset state machine using snapshot contents (and load snapshot’s cluster configuration)</li></ul></li></ol><h2 id="client-interaction"><a class="markdownIt-Anchor" href="#client-interaction"></a> Client interaction</h2><h3 id="how-does-client-find-cluster-leader"><a class="markdownIt-Anchor" href="#how-does-client-find-cluster-leader"></a> How does client find cluster leader?</h3><ol><li>When a client first starts up<ul><li>It connects to a randomly-chosen server.</li><li>If the client’s first choice is not the leader, that server will reject the client’s request and supply information about the most recent leader it has heard from.</li></ul></li><li>If the leader crashes<ul><li>Client requests will time out.</li><li>Clients then try again with randomly-chosen servers.</li></ul></li></ol><h3 id="how-to-prevent-raft-execute-a-command-multiple-times"><a class="markdownIt-Anchor" href="#how-to-prevent-raft-execute-a-command-multiple-times"></a> How to prevent Raft execute a command multiple times?</h3><ol><li>Our goal for Raft is to implement linearizable semantics, i.e. each operation appears to execute instantaneously, exactly once, at some point between its invocation and its response.<ul><li>One case of executing a command multiple times is that if the leader crashes after committing the log entry but before responding to the client, the client will retry the command with a new leader, causing it to be executed a second time.</li></ul></li><li>The solution is for clients to assign unique serial numbers to every command.</li><li>Then, the state machine tracks the latest serial number processed for each client, along with the associated response.</li><li>If it receives a command whose serial number has already been executed, it responds immediately without re-executing the request.</li></ol><h3 id="how-to-prevent-returning-stale-date-to-a-read-only-operation"><a class="markdownIt-Anchor" href="#how-to-prevent-returning-stale-date-to-a-read-only-operation"></a> How to prevent returning stale date to a read-only operation?</h3><ol><li>The reason for stale reading is that the leader responding to the request might have been superseded by a newer leader of which it is unaware.</li><li>A leader must have the latest information on which entries are committed.<ul><li>The Leader Completeness Property guarantees that a leader has all committed entries, but at the start of its term, it may not know which those are.</li><li>To find out, it needs to commit an entry from its term.</li><li>Raft handles this by having each leader commit a blank <em>no-op</em> entry into the log at the start of its term.</li></ul></li><li>A leader must check whether it has been deposed before processing a read-only request, since its information may be stale if a more recent leader has been elected).<ul><li>Raft handles this by having the leader exchange heartbeat messages with a majority of the cluster before responding to read-only requests.</li><li>Alternatively, the leader could rely on the heartbeat mechanism to provide a form of lease, but this would rely on timing for safety (it assumes bounded clock skew).</li></ul></li></ol><h1 id="experiements-and-results"><a class="markdownIt-Anchor" href="#experiements-and-results"></a> Experiements and results</h1><ol><li>The main goal of Raft is to propose a consensus algorithm which is easier to understand than Paxos. Hence the author measured the understandability of this model through scores of learning students.</li><li>A most important measure of a new system is its correctness. The author proved the correctness of Raft with a formal specification.</li><li>Finally, the author also measured the performance of Raft, which is similar to other consensus algorithms.</li><li>The election timeout will effect the performance of the system through the performance of leader election. Hence, the author measured how will the randomization and base election timeout effect the performance.<ul><li>A small amount of randomization in the election timeout is enough to avoid split votes in elections. Using more randomness improves worst-case behavior.</li><li>Downtime can be reduced by reducing the election timeout.<ul><li>However, lowering the timeouts beyond 12 - 14 ms violates Raft’s timing requirement: leaders have difficulty broadcasting heartbeats before other servers start new elections. This can cause unnecessary leader changes and lower overall system availability.</li><li>The author recommends using a conservative election timeout such as 150–300ms; such timeouts are unlikely to cause unnecessary leader changes and will still provide good availability.</li></ul></li><li><img src="/imgs/Distributed/Raft/02.png" style="zoom:33%;" /></li></ul></li></ol><h1 id="reproduce-and-unmentioned-parts"><a class="markdownIt-Anchor" href="#reproduce-and-unmentioned-parts"></a> Reproduce and unmentioned parts</h1><p>Reference to the Lab 2, 3 and 4 of MIT 6.824.</p>]]></content>
      
      
      <categories>
          
          <category> Paper Notebook </category>
          
          <category> Distributed System </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Distributed System </tag>
            
            <tag> Distributed Storage </tag>
            
            <tag> Consensus Algorithm </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Fault Tolerance VM</title>
      <link href="/2023/09/26/Paper/Distributed/Fault-Tolerance-VM/"/>
      <url>/2023/09/26/Paper/Distributed/Fault-Tolerance-VM/</url>
      
        <content type="html"><![CDATA[<p>Paper: <a href="http://nil.csail.mit.edu/6.824/2020/papers/vm-ft.pdf">The Design of a Practical System for Fault-Tolerance Virtual Machines</a></p><p><ul class="markdownIt-TOC"><li><a href="#purpose">Purpose</a></li><li><a href="#model">Model</a><ul><li><a href="#ft-design">FT design</a><ul><li><a href="#primary-backup-structure">Primary-backup structure</a><ul><li><a href="#what-is-the-usual-way-to-implement-fault-tolerance-via-primarybackup-approach">What is the usual way to implement fault-tolerance via primary/backup approach?</a></li><li><a href="#what-is-the-difference-between-physical-servers-and-vm-in-state-machine-level">What is the difference between physical servers and VM in state machine level?</a></li><li><a href="#what-is-the-basic-structure-of-ft-vms">What is the basic structure of FT VMs?</a></li></ul></li><li><a href="#ft-protocol">FT protocol</a><ul><li><a href="#how-does-vmware-backup-vm-replay">How does VMware backup VM replay?</a></li><li><a href="#what-if-the-backup-vm-executes-in-a-way-different-from-the-primary-vm">What if the backup VM executes in a way different from the primary VM?</a></li><li><a href="#will-the-output-rule-affect-vm-eg-stop-its-execution">Will the Output Rule affect VM, e.g. stop its execution?</a></li><li><a href="#what-is-the-subtleties-of-executing-disk-reads-on-the-backup-vm">What is the subtleties of executing disk reads on the backup VM?</a></li></ul></li><li><a href="#detecting-and-responding-to-failure">Detecting and responding to failure</a><ul><li><a href="#how-to-handle-duplicate-outputs">How to handle duplicate outputs?</a></li><li><a href="#how-to-handle-backup-vm-failure">How to handle backup VM failure?</a></li><li><a href="#how-to-handle-primary-vm-failure">How to handle primary VM failure?</a></li><li><a href="#after-a-failover-how-will-the-new-primary-vm-communicate-with-external-world">After a failover, how will the new primary VM communicate with external world?</a></li><li><a href="#how-to-detect-failure-of-primary-or-backup-vms">How to detect failure of primary or backup VMs?</a></li><li><a href="#how-to-avoid-split-brain-problems">How to avoid split-brain problems?</a></li></ul></li><li><a href="#alternative-non-shared-disk">Alternative: Non-shared disk</a><ul><li><a href="#what-is-the-difference-between-non-shared-disk-and-shared-disk">What is the difference between non-shared disk and shared disk?</a></li><li><a href="#in-what-case-non-shared-disk-will-be-useful">In what case non-shared disk will be useful?</a></li><li><a href="#what-is-the-disadvantage-of-non-shared-disk">What is the disadvantage of non-shared disk?</a></li><li><a href="#how-to-solve-the-split-brain-situation">How to solve the split-brain situation?</a></li></ul></li></ul></li><li><a href="#implementation">Implementation</a><ul><li><a href="#starting-and-restarting">Starting and restarting</a><ul><li><a href="#what-requirements-need-to-be-satisfied-by-the-startup-mechanism">What requirements need to be satisfied by the startup mechanism?</a></li><li><a href="#how-to-implement-the-startup-mechanism">How to implement the startup mechanism?</a></li><li><a href="#how-to-choose-a-server-on-which-to-run-the-backup-vm">How to choose a server on which to run the backup VM?</a></li></ul></li><li><a href="#logging-channel">Logging channel</a><ul><li><a href="#how-to-control-primary-sending-log-entries-and-backup-receiving-entries">How to control primary sending log entries, and backup receiving entries?</a></li><li><a href="#what-if-the-log-buffer-of-the-primary-is-full">What if the log buffer of the primary is full?</a></li><li><a href="#what-is-the-main-cause-of-the-buffer-of-primary-being-full">What is the main cause of the buffer of primary being full?</a></li><li><a href="#how-to-prevent-the-backup-vm-from-getting-too-far-behind-the-primary">How to prevent the backup VM from getting too far behind the primary?</a></li></ul></li><li><a href="#special-operations">Special operations</a><ul><li><a href="#how-to-deal-with-control-operations">How to deal with control operations?</a></li><li><a href="#how-to-implement-the-vmotion-for-primary-and-backup-vms">How to implement the VMotion for primary and backup VMs?</a></li></ul></li><li><a href="#issues-for-disk-ios">Issues for disk IOs</a><ul><li><a href="#how-many-kind-of-races-may-occur">How many kind of races may occur?</a></li><li><a href="#how-to-solve-the-non-determinism-caused-by-several-io-operations">How to solve the non-determinism caused by several IO operations?</a></li><li><a href="#how-to-solve-the-non-determinism-caused-by-io-operations-and-applicationos">How to solve the non-determinism caused by IO operations and application/OS?</a></li><li><a href="#how-the-newly-promoted-primary-vm-handle-those-outstanding-ios">How the newly-promoted primary VM handle those outstanding IOs?</a></li></ul></li><li><a href="#issues-for-network-io">Issues for network IO</a><ul><li><a href="#how-to-solve-the-non-determinism-caused-by-asynchronous-updates">How to solve the non-determinism caused by asynchronous updates?</a></li><li><a href="#how-can-we-optimize-the-network-performance-while-running-ft">How can we optimize the network performance while running FT?</a></li></ul></li></ul></li></ul></li><li><a href="#experiments-and-results">Experiments and results</a></li></ul></p><h1 id="purpose"><a class="markdownIt-Anchor" href="#purpose"></a> Purpose</h1><ol><li>Contribution<ul><li>This paper implemented a system providing fault tolerance virtual machine (VM) based on the approach of replicating the execution of a primary VM vis a backup VM on another server. The system automatically restores redundancy after faulure.</li><li>It reduces performance of real applications by less than 10%. The data bandwidth needed to keep the primary and secondary VM executing in lockstep is less than 20 Mb/s for several real applications, which allows for the possibility of implementing fault tolerance over longer distance.</li><li>The system automatically restores redundancy after a failure by starting a new backup viretual machine on any available server in the local cluster.</li></ul></li><li>Limitation<ul><li>Only support uni-processor VMs. Recording and replaying the execution of a multi-processor VM have significant performance issues because nearly every access to shared memory can be a non-deterministic operation.</li><li>Only attempt to deal with fail-stop failure, which are server failures that can be detected before the failing server causes an incorrect externally visible action.</li></ul></li><li>Challenges<ul><li>Correctly capturing all the input and non-determinism necessary to ensure deterministic execution of a backup virtual machine.</li><li>Correctly applying the inputs and non-determinism to the backup virtual machine.</li><li>Doing so in a manner that doesn’t degrade performance.</li></ul></li></ol><h1 id="model"><a class="markdownIt-Anchor" href="#model"></a> Model</h1><h2 id="ft-design"><a class="markdownIt-Anchor" href="#ft-design"></a> FT design</h2><h3 id="primary-backup-structure"><a class="markdownIt-Anchor" href="#primary-backup-structure"></a> Primary-backup structure</h3><h4 id="what-is-the-usual-way-to-implement-fault-tolerance-via-primarybackup-approach"><a class="markdownIt-Anchor" href="#what-is-the-usual-way-to-implement-fault-tolerance-via-primarybackup-approach"></a> What is the usual way to implement fault-tolerance via primary/backup approach?</h4><ol><li><p>The backup server is always available to take over is the primary server fails.</p><ul><li>The problem is that the state of the backup server must be kept nearly identical to the primary server at all times. We say that the two VMs are in virtual lock-step.</li></ul></li><li><p>One way is to ship changes to all state of the primary. The bandwidth needed to send can be very large.</p></li><li><p>Another method is the state-machine approach.</p><ul><li><p>The idea is to model the servers as deterministic state machcines that are kept in sync by starting them from the same initial state and ensuring that they receive the same input requests in the same order.</p></li><li><p>Some operations are not deterministic. Extra coordination must be used to ensure that they receive a primary and backup are kept in sync.</p></li><li><p>The extra information is far less than the amount of state (mainly memory updates) that is changing in the primary.</p></li></ul></li></ol><h4 id="what-is-the-difference-between-physical-servers-and-vm-in-state-machine-level"><a class="markdownIt-Anchor" href="#what-is-the-difference-between-physical-servers-and-vm-in-state-machine-level"></a> What is the difference between physical servers and VM in state machine level?</h4><ol><li><p>Implementing coordication to ensure deterministic execution of physical servers is difficult, particularly as processor frequencies increase.</p></li><li><p>VM running on top of a hypervisor can be considered a well-defined state machine.</p></li><li><p>VMs still have non-deterministic operations. Hypervisor is able to capture all the necessary information about non-deterministic operations on the primary VM and to replay these operations correctly on the backup VM.</p></li></ol><h4 id="what-is-the-basic-structure-of-ft-vms"><a class="markdownIt-Anchor" href="#what-is-the-basic-structure-of-ft-vms"></a> What is the basic structure of FT VMs?</h4><ol><li><p>The virtual disks for the VMs are on shared storage, and accessible to the primary and backup VM for input and output.</p></li><li><p>Only the primary VM advertises its presence on the network, so all network inputs come to the primary VM. So does all other inputs.</p></li><li><p>All inputs, including incoming network packets, disk reads, keyboard and mouse, only come to the primary VM. And  the primary VM sends all inputs it received to the backup VM via a network connection known as the logging channel.</p><img src="/imgs/Distributed/FTVM/01.png" style="zoom:33%;" /></li></ol><h3 id="ft-protocol"><a class="markdownIt-Anchor" href="#ft-protocol"></a> FT protocol</h3><h4 id="how-does-vmware-backup-vm-replay"><a class="markdownIt-Anchor" href="#how-does-vmware-backup-vm-replay"></a> How does VMware backup VM replay?</h4><ol><li>VMware deterministic replay records the inputs of a VM and all possible non-determinism associated with the VM execution in a stream of log entries written to a log file.</li><li>For non-deterministic operations, sufficient infomation is logged to allow the operation to be reproduced with the same state change and output.</li><li>For non-deterministic events such as timer or IO completion interrupts, the exact instruction at which the event occurred is also recorded. During replay, the event is delivered at the same point in the instruction stream.</li><li>VMware deterministic replay has no need to use epochs where non-deterministic events are only delievered at the end. Each interrupt is recorded as it occurs and effciently delivered at the appropriate instruction while being replayed.</li><li>Instead of writing the log entries to disk, we send them to the backup VM via the logging channel. The backup VM replays the entries in real time.</li></ol><h4 id="what-if-the-backup-vm-executes-in-a-way-different-from-the-primary-vm"><a class="markdownIt-Anchor" href="#what-if-the-backup-vm-executes-in-a-way-different-from-the-primary-vm"></a> What if the backup VM executes in a way different from the primary VM?</h4><ol><li><p>The <em>Output Requirement</em>: if the backup VM ever takes over after a failure of the primary, the backup VM will continue executing in a way that is entirely consistent with all outputs that the primary VM has sent to the external world.</p></li><li><p>The Output Requirement can be ensured by</p><ul><li><p>delaying any external output (typically a network packet) until the backup VM has received all information that will allow it to replay execution at least to the point of that output operation.</p></li><li><p>One necessary condition is that the backup VM must have received all log entries generated prior to the output operation.</p></li></ul></li><li><p>If we create a special log entry at each output operation. Then, the Output Requirement may be enforced by the Output Rule.</p><ul><li><em>Output Rule</em>: the primary VM may not send an output to the external world, until the backup VM has received and acknowledged the log entry associated with the operation producing the output.</li></ul></li></ol><h4 id="will-the-output-rule-affect-vm-eg-stop-its-execution"><a class="markdownIt-Anchor" href="#will-the-output-rule-affect-vm-eg-stop-its-execution"></a> Will the Output Rule affect VM, e.g. stop its execution?</h4><ol><li>It does not say anything about stopping the execution of the primary VM. We need only delay the sending of the output, but the VM itself can continue execution.</li><li>Since operating systems do non-blocking network and disk outputs with asynchronous interrupts to indicate completion, the VM can easily continue execution and will not necessarily be immediately affected by the delay in the output.</li></ol><h4 id="what-is-the-subtleties-of-executing-disk-reads-on-the-backup-vm"><a class="markdownIt-Anchor" href="#what-is-the-subtleties-of-executing-disk-reads-on-the-backup-vm"></a> What is the subtleties of executing disk reads on the backup VM?</h4><ol><li><p>By default, the primary VM will send the results of the disk read to the backup VM via the logging channel.</p></li><li><p>Executing disk read on the backup VM can greatly reduce the traffic on the logging channel for workloads that do a lot of disk reads. It may also slow down the backup VM’s execution.</p></li><li><p>Some extra work must be done to deal with failed disk read operations.</p><ul><li><p>If the primary succeeds while the backup fails, the backup needs to keep retrying until succeess.</p></li><li><p>If the backup succeeds while the primary fails, the contents of the target memory must be sent to the backup via the logging channel, since the contents of memory will be undetermined and not necessarily replicated by a successful disk read by the backup VM.</p></li></ul></li><li><p>If the primary VM does a read to a particular disk location followed fairly soon by a write to the same disk location, then the disk write must be delayed until the backup VM has executed the first disk read.</p></li></ol><h3 id="detecting-and-responding-to-failure"><a class="markdownIt-Anchor" href="#detecting-and-responding-to-failure"></a> Detecting and responding to failure</h3><h4 id="how-to-handle-duplicate-outputs"><a class="markdownIt-Anchor" href="#how-to-handle-duplicate-outputs"></a> How to handle duplicate outputs?</h4><ol><li>We cannot guarantee that all outputs are produced exactly once in a failover situation.</li><li>The network infrastructure (e.g. TCP) is designed to deal with lost packets and duplicate packets.</li></ol><h4 id="how-to-handle-backup-vm-failure"><a class="markdownIt-Anchor" href="#how-to-handle-backup-vm-failure"></a> How to handle backup VM failure?</h4><p>The primary VM will go live, i.e. leave recording mode, stop sending entries on the logging channel and start executing normally.</p><h4 id="how-to-handle-primary-vm-failure"><a class="markdownIt-Anchor" href="#how-to-handle-primary-vm-failure"></a> How to handle primary VM failure?</h4><ol><li>The backup VM will continue replaying its execution from the log entries until it has consumed the last log entry.</li><li>The backup VM will stop replaying mode and start executing as a normal VM. The backup VM has been promoted to the primary VM, and is now missing a backup VM.</li></ol><h4 id="after-a-failover-how-will-the-new-primary-vm-communicate-with-external-world"><a class="markdownIt-Anchor" href="#after-a-failover-how-will-the-new-primary-vm-communicate-with-external-world"></a> After a failover, how will the new primary VM communicate with external world?</h4><ol><li>VMware FT automatically advertises the MAC address of the new primary VM on the network, so that physical network switches will know  on what server that new primary VM is located.</li><li>The newly promoted primary VM may need to reissue some disk IOs.</li></ol><h4 id="how-to-detect-failure-of-primary-or-backup-vms"><a class="markdownIt-Anchor" href="#how-to-detect-failure-of-primary-or-backup-vms"></a> How to detect failure of primary or backup VMs?</h4><ol><li>VMware FT uses UDP heartbeating between servers that are running fault-tolerant VMs to detect when a server may have crashed.</li><li>In addition, VMware FT monitors the logging traffic that is sent from the primary to the backup VM and the acknowledgments sent from the backup VM to the primary VM. Because of regular timer interrupts, the logging traffic should be regular and never stop for a functioning guest OS.</li></ol><h4 id="how-to-avoid-split-brain-problems"><a class="markdownIt-Anchor" href="#how-to-avoid-split-brain-problems"></a> How to avoid split-brain problems?</h4><ol><li>When either a primary or backup VM wants to go live, it executes an atomic test-and-set operation on the shared virtual disk.</li><li>If the operation succeeds, the VM is allowed to go live.</li><li>If the operation fails, then the other VM must have already gone live, so the current VM actually halts itself (“commits suicide”).</li></ol><h3 id="alternative-non-shared-disk"><a class="markdownIt-Anchor" href="#alternative-non-shared-disk"></a> Alternative: Non-shared disk</h3><h4 id="what-is-the-difference-between-non-shared-disk-and-shared-disk"><a class="markdownIt-Anchor" href="#what-is-the-difference-between-non-shared-disk-and-shared-disk"></a> What is the difference between non-shared disk and shared disk?</h4><ol><li>In shared disk, any write to the shared disk is considered a communication to external world. Writes to the shared disk must be delayed.</li><li>In non-shared disk, the virtual disks are essentially considered part of the internal state of each VM. Disk writes of the primary do not have to be delayed according to the Output Rule.</li></ol><h4 id="in-what-case-non-shared-disk-will-be-useful"><a class="markdownIt-Anchor" href="#in-what-case-non-shared-disk-will-be-useful"></a> In what case non-shared disk will be useful?</h4><ol><li>Shared storage is not accessible to the primary and backup VMs.</li><li>This may be the case because shared storage is unavailable or too expensive, or because the servers running the primary and backup VMs are far apart.</li></ol><h4 id="what-is-the-disadvantage-of-non-shared-disk"><a class="markdownIt-Anchor" href="#what-is-the-disadvantage-of-non-shared-disk"></a> What is the disadvantage of non-shared disk?</h4><ol><li>The two copies of the virtual disks must be explicitly synced up in some manner when fault tolerance is first enabled.</li><li>The disks can get out of sync after a failure, so they must be explicitly resynced when the backup VM is restarted after a failure.</li></ol><h4 id="how-to-solve-the-split-brain-situation"><a class="markdownIt-Anchor" href="#how-to-solve-the-split-brain-situation"></a> How to solve the split-brain situation?</h4><ol><li><p>There may be no shared storage to use for dealing with it. The system could use some other external tiebreaker.</p><ul><li>A third-party server that both servers can talk to.</li></ul></li><li><p>If the servers are part of a cluster with more than two nodes, the system could alternatively use a majority algorithm.</p><ul><li>A VM would only be allowed to go live if it is running on a server that is part of a communication sub-cluster that contains a majority of the original nodes.</li></ul></li></ol><h2 id="implementation"><a class="markdownIt-Anchor" href="#implementation"></a> Implementation</h2><h3 id="starting-and-restarting"><a class="markdownIt-Anchor" href="#starting-and-restarting"></a> Starting and restarting</h3><h4 id="what-requirements-need-to-be-satisfied-by-the-startup-mechanism"><a class="markdownIt-Anchor" href="#what-requirements-need-to-be-satisfied-by-the-startup-mechanism"></a> What requirements need to be satisfied by the startup mechanism?</h4><ol><li>We also want to use it to restart a backup VM after a failure. Hence, this mechanism must be usable for a running primary VM that is in an arbitrary state.</li><li>We would prefer that the mechanism does not significantly disrupt that execution of the primary VM.</li></ol><h4 id="how-to-implement-the-startup-mechanism"><a class="markdownIt-Anchor" href="#how-to-implement-the-startup-mechanism"></a> How to implement the startup mechanism?</h4><ol><li>VMware FT adapted a modified VMware VMotion that allows the migration of a running VM from one server to another server with minimal disruption. However, after migration, the VMotion will destroy the local VM.</li><li>The FT VMotion clones a VM to a remote host rather than migrating it without destroying the local VM.</li><li>The FT VMotion also sets up a logging channel, and causes the source VM to enter logging mode as the primary, and the destination VM to enter replay mode as the new backup.</li></ol><h4 id="how-to-choose-a-server-on-which-to-run-the-backup-vm"><a class="markdownIt-Anchor" href="#how-to-choose-a-server-on-which-to-run-the-backup-vm"></a> How to choose a server on which to run the backup VM?</h4><ol><li>The primary Vm informs the clustering service that it needs a new backup.</li><li>The clustering service determines the best server on which to run the backup VM based on resource usage and other constraints and invokes an FT VMotion to create the new backup VM.</li><li>VMware FT typically can re-establish VM redundancy within minutes of a server failure, all without any noticeable interruption in the execution of a fault-tolerant VM.</li></ol><h3 id="logging-channel"><a class="markdownIt-Anchor" href="#logging-channel"></a> Logging channel</h3><h4 id="how-to-control-primary-sending-log-entries-and-backup-receiving-entries"><a class="markdownIt-Anchor" href="#how-to-control-primary-sending-log-entries-and-backup-receiving-entries"></a> How to control primary sending log entries, and backup receiving entries?</h4><ol><li>The hypervisors maintain a large buffer for logging entries for the primary and backup VMs.</li><li>The contents of the primary’s log buffer are flushed out to the logging channel as soon as possible, and log entries are read into the backup’s log buffer from the logging channel as soon as they arrive.</li><li>The backup sends acknowledgments back to the primary each time that it reads some log entries from the network into its log buffer.</li></ol><h4 id="what-if-the-log-buffer-of-the-primary-is-full"><a class="markdownIt-Anchor" href="#what-if-the-log-buffer-of-the-primary-is-full"></a> What if the log buffer of the primary is full?</h4><ol><li>It must stop execution until log entries can be flushed out.</li><li>This stop in execution is a natural flow-control mechanism that slows down the primary VM when it is producing log entries at too fast a rate.</li><li>This pause can affect clients of the VM, and we must minimize the possibility that the primary log buffer fills up.</li></ol><h4 id="what-is-the-main-cause-of-the-buffer-of-primary-being-full"><a class="markdownIt-Anchor" href="#what-is-the-main-cause-of-the-buffer-of-primary-being-full"></a> What is the main cause of the buffer of primary being full?</h4><ol><li>One biggest reason is that the backup VM is executing too slowly and therefore sonsuming log entries too slowly.</li><li>In general, the backup VM must be able to replay an execution at roughly the same speed as sthe primary VM is recording the execution.</li><li>The overhead of recording and replaying in VMware deterministic replay is roughly the same.</li><li>If the server hosting the backup VM is heavily loaded with other VMs (and hence overcommitted on resources), the backup VM may not be able to get enough CPU and memory resources to execute as fast as the primary VM.</li></ol><h4 id="how-to-prevent-the-backup-vm-from-getting-too-far-behind-the-primary"><a class="markdownIt-Anchor" href="#how-to-prevent-the-backup-vm-from-getting-too-far-behind-the-primary"></a> How to prevent the backup VM from getting too far behind the primary?</h4><ol><li>When sending acknowledgments, we also send additional information to determine the real-time execution lag between the primary and backup VMs.</li><li>Typically the execution lag is less than 100 milliseconds.</li><li>If the backup VM starts having a significant execution lag (e.g. more than 1 second), VMware FT starts slowing down the primary VM by informing the scheduler to give it a slightly smally amount of CPU.</li><li>Such slowdowns are very rare, and typically happen only when the system is under extreme stress.</li></ol><h3 id="special-operations"><a class="markdownIt-Anchor" href="#special-operations"></a> Special operations</h3><h4 id="how-to-deal-with-control-operations"><a class="markdownIt-Anchor" href="#how-to-deal-with-control-operations"></a> How to deal with control operations?</h4><ol><li><p>Most control operations shouls be applied to both machines.</p><ul><li><p>If the primary VM is explicitly powered off, the backup VM should be stopped as well, and not attempt to go live.</p></li><li><p>Any resource management change on the primary should be applied to the backup.</p></li></ul></li><li><p>The only operation that can be done independently on the primary and backup VMs is VMotion.</p><ul><li><p>The primary and backup VMs can be VMotioned independently to other hosts.</p></li><li><p>VMware FT ensures that neither VM is moved to the server where the other VM is.</p></li></ul></li></ol><h4 id="how-to-implement-the-vmotion-for-primary-and-backup-vms"><a class="markdownIt-Anchor" href="#how-to-implement-the-vmotion-for-primary-and-backup-vms"></a> How to implement the VMotion for primary and backup VMs?</h4><ol><li><p>For a normal VMotion, it requires that all outstanding disk IOs be quiesced just as the final switchover on the VMotion occurs.</p></li><li><p>For a primary VM,</p><ul><li><p>The quiescing is easily handled by waiting until the physical IOs completeand delivering these completions to the VM.</p></li><li><p>The backup VM must disconnect from the source primary and re-connect to the destination primary at the appropriate time.</p></li></ul></li><li><p>For a backup VM,</p><ul><li><p>There is no easy way to cause all IOs to be completed at any required point, since the backup VM must replay the primary VM’s execution and complete IOs at the same execution point.</p></li><li><p>When a backup VM is at the final switchover point for a VMotion, it requests via the logging channel that the primary VM temporarily quiesce all its IOs.</p></li></ul></li></ol><h3 id="issues-for-disk-ios"><a class="markdownIt-Anchor" href="#issues-for-disk-ios"></a> Issues for disk IOs</h3><h4 id="how-many-kind-of-races-may-occur"><a class="markdownIt-Anchor" href="#how-many-kind-of-races-may-occur"></a> How many kind of races may occur?</h4><ol><li><p>The first kind is caused by several IO operations.</p><ul><li><p>One reason is that disk operations are non-blocking and can execute in parallel. Simultaneous disk operations access the same disk location causing races.</p></li><li><p>The other reason is that DMA directly to/from the memory of the VM. Simultaneous disk operations access the same memory pages.</p></li></ul></li><li><p>The second kind is caused by IO operations and non-IO operations.</p><ul><li>The disk operations directly access the memory of a VM via DMA. Hence a disk operation accesses the same memory pages as an aplication or OS in a VM causing races.</li></ul></li></ol><h4 id="how-to-solve-the-non-determinism-caused-by-several-io-operations"><a class="markdownIt-Anchor" href="#how-to-solve-the-non-determinism-caused-by-several-io-operations"></a> How to solve the non-determinism caused by several IO operations?</h4><p>We should detect any such IO races, and force such racing disk operations to execute sequentially in the same way on the primary and backup.</p><h4 id="how-to-solve-the-non-determinism-caused-by-io-operations-and-applicationos"><a class="markdownIt-Anchor" href="#how-to-solve-the-non-determinism-caused-by-io-operations-and-applicationos"></a> How to solve the non-determinism caused by IO operations and application/OS?</h4><ol><li><p>We need to set up page protection termporarily on pages that are targets of disk operations.</p></li><li><p>The page protections result in a trap if the VM happens to make an access to a page that is also the target of an outstanding disk operation, and the VM can be paused until the disk operation completes.</p></li><li><p>Changing MMU protections on pages is expensive, we use bounce buffers.</p><ul><li><p>A bounce buffer is a temporary buffer that has the same size as the memory being accessed by a disk operation.</p></li><li><p>A disk read operation is modified to read the specified data to the bounce buffer, and the data is copied to guest memory only as the IO completion is delivered.</p></li><li><p>For a disk write operation, the data to besent is first copied to the bounce buffer, and the disk write is modified to write data from the bounce buffer.</p></li></ul></li><li><p>The bounce buffer can slow down disk operations, but noticeable performance loss is not seen.</p></li></ol><h4 id="how-the-newly-promoted-primary-vm-handle-those-outstanding-ios"><a class="markdownIt-Anchor" href="#how-the-newly-promoted-primary-vm-handle-those-outstanding-ios"></a> How the newly-promoted primary VM handle those outstanding IOs?</h4><ol><li>There is no way for the newly-promoted primary VM to be sure if the disk IOs were issued to the disk or completed  successfully.</li><li>We could send an error completion that indicates that each IO failed, since it is acceptable to return an error even if the IO completed successfully. However, the guest OS might not respond well to errors from its local disk.</li><li>We can re-issue the pending IOs during the go-live process of the backup VM. Because we have eliminated all races and all IOs specify derectly which memory and disk blocks are accessed, these disk operations can be re-issued even if they have already completed successfully.</li></ol><h3 id="issues-for-network-io"><a class="markdownIt-Anchor" href="#issues-for-network-io"></a> Issues for network IO</h3><h4 id="how-to-solve-the-non-determinism-caused-by-asynchronous-updates"><a class="markdownIt-Anchor" href="#how-to-solve-the-non-determinism-caused-by-asynchronous-updates"></a> How to solve the non-determinism caused by asynchronous updates?</h4><ol><li><p>In normal VM, the hypervisor asynchronously updating the state of the virtual machine’s network device.</p></li><li><p>For FT</p><ul><li><p>The code that asynchronously updates VM ring buffers with incoming packets has been modified to force the guest to trap to the hypervisor, where it can log the updates and then apply them to the VM.</p></li><li><p>The code that normally pull packets out of transmit queues asynchronously is diabled, and instead transmits are done through a trap to the hypervisor.</p></li></ul></li></ol><h4 id="how-can-we-optimize-the-network-performance-while-running-ft"><a class="markdownIt-Anchor" href="#how-can-we-optimize-the-network-performance-while-running-ft"></a> How can we optimize the network performance while running FT?</h4><ol><li><p>Reduce VM trapand interrupts with clustering optimizations.</p><ul><li><p>When the VM is streaming data at a sufficient bit rate, the hypervisor can do one transmit trap per group of packets and, in the best case, zero traps, since it can transmit the packets as part of receiving new packets.</p></li><li><p>The hypervisor can reduce the number of interrupts to the VM for incoming packets by only posting the interrupt for a group of packets.</p></li></ul></li><li><p>Reduce the delay for transmitted packets.</p><ul><li><p>The key is to reduce the time required to send a log message to the backup and get an acknowledgment.</p></li><li><p>It is ensured that sending and receiving log entries and acknowledgments can all be done without any thread context switch.</p></li><li><p>The VMware vSphere hypervisor allows functions to be registered with the TCP stack that will be called from a deferred-execution context (similar to a tasklet in Linux) whenever TCP data is received.</p></li><li><p>When the primary VM enqueues a packet to be transmitted, we force an immediate log flush of the associated output log entry by scheduling a defferred-execution context to do the flush.</p></li></ul></li></ol><h1 id="experiments-and-results"><a class="markdownIt-Anchor" href="#experiments-and-results"></a> Experiments and results</h1><p>One important banchmark is the performance ratio between non-FT and FT systems and logging bandwidth between primary and backup. The performance ratio can show how efficient the FT protocol is, and logging bandwidth is usually a bottleneck of the system. The author measured them all as the following table. We can see that FT protocol only decreases the performance by less than 10%</p><img src="/imgs/Distributed/FTVM/02.png" style="zoom:30%;" /><p>The typical idle logging bandwidth is 0.5-1.5 Mbits/sec. The idle bandwidth is largely the result of recording the delivery of timer interrupts. For a VM with an active workload, the logging bandwidth is dominated by the network and disk inputs that must be sent to the backup - the network packets that are received and the disk blocks that are read from disk. Hence the logging bandwidth can be much higher than those measured in table for applications that have very high network receive or disk read bandwidth. For these kinds of applications, the bandwidth of the logging channel could be a bottleneck.</p><p>The author also measured the bandwidth of logging channels with different capacities, as shown below. When FT is enabled for receive workloads, the loging bandwidth is very large, since all incomming network packets must be sent on the logging channel. When FT is enabled for transmit workloads, the logging bandwidth is much lower. Overall, FT can limit network bandwidths significantly at very high transmit and receive rates, but high absolute rates are still achievable.</p><img src="/imgs/Distributed/FTVM/03.png" style="zoom:30%;" />]]></content>
      
      
      <categories>
          
          <category> Paper Notebook </category>
          
          <category> Distributed System </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Distributed System </tag>
            
            <tag> Fault Tolerance </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>GFS</title>
      <link href="/2023/09/26/Paper/Distributed/GFS/"/>
      <url>/2023/09/26/Paper/Distributed/GFS/</url>
      
        <content type="html"><![CDATA[<p>Paper: <a href="http://nil.csail.mit.edu/6.824/2020/papers/gfs.pdf">The Google File System</a></p><p><ul class="markdownIt-TOC"><li><a href="#purpose">Purpose</a></li><li><a href="#model">Model</a><ul><li><a href="#overview">Overview</a><ul><li><a href="#what-operations-are-supported">What operations are supported?</a></li><li><a href="#architecture">Architecture</a><ul><li><a href="#what-does-the-system-consist-of">What does the system consist of?</a></li><li><a href="#what-does-master-need-to-do">What does master need to do?</a></li><li><a href="#how-to-prevent-the-master-becoming-a-bottleneck">How to prevent the master becoming a bottleneck?</a></li><li><a href="#what-is-the-advantage-of-large-chunk-size">What is the advantage of large chunk size?</a></li><li><a href="#what-is-the-disadvantage-of-large-chunk-size">What is the disadvantage of large chunk size?</a></li><li><a href="#when-will-hot-spots-problem-emerge">When will hot spots problem emerge?</a></li></ul></li><li><a href="#consistency">Consistency</a><ul><li><a href="#how-do-we-define-a-file-region-being-consistent-or-defined">How do we define a file region being consistent or defined?</a></li><li><a href="#how-many-consistency-rules-should-be-considered">How many consistency rules should be considered?</a></li><li><a href="#how-do-gfs-guarantees-the-second-rule">How do GFS guarantees the second rule?</a></li><li><a href="#what-is-the-side-effect-of-clients-caching-chunk-locations">What is the side-effect of clients caching chunk locations?</a></li></ul></li></ul></li><li><a href="#data-mutation">Data mutation</a><ul><li><a href="#control-data-flow">Control &amp; data flow</a><ul><li><a href="#how-do-we-minimize-management-overhead-at-the-master-of-data-mutation">How do we minimize management overhead at the master of data mutation?</a></li><li><a href="#what-does-leases-change">What does leases change?</a></li><li><a href="#how-does-the-control-flow">How does the control flow?</a></li><li><a href="#how-does-primary-and-secondary-servers-write-data">How does primary and secondary servers write data?</a></li><li><a href="#what-would-the-system-do-if-write-fails">What would the system do if write fails?</a></li><li><a href="#what-if-a-write-is-large-or-straddles-a-chunk-boundary">What if a write is large or straddles a chunk boundary?</a></li><li><a href="#how-to-prevent-primary-become-bottleneck-of-pushing-data">How to prevent primary become bottleneck of pushing data?</a></li><li><a href="#how-to-minimize-latency-of-pushing-data">How to minimize latency of pushing data?</a></li></ul></li><li><a href="#write-and-record-append">Write and record append</a><ul><li><a href="#what-is-the-difference-between-write-and-record-append">What is the difference between write and record append?</a></li><li><a href="#how-does-typical-writing-happen">How does typical writing happen?</a></li><li><a href="#how-does-readers-deal-with-occasional-padding-and-duplicates">How does readers deal with occasional padding and duplicates?</a></li></ul></li><li><a href="#atomic-record-appends">Atomic record appends</a><ul><li><a href="#what-if-appending-causes-the-current-chunk-to-exceed-the-maximum-size">What if appending causes the current chunk to exceed the maximum size?</a></li><li><a href="#what-if-appending-fails-at-some-chunkservers">What if appending fails at some chunkservers?</a></li></ul></li><li><a href="#snapshot">Snapshot</a><ul><li><a href="#what-does-snapshot-do">What does snapshot do?</a></li><li><a href="#how-does-snapshot-be-implemented">How does snapshot be implemented?</a></li><li><a href="#how-does-clients-write-a-chunk-after-snapshot">How does clients write a chunk after snapshot?</a></li></ul></li></ul></li><li><a href="#master">Master</a><ul><li><a href="#basic-operations">Basic operations</a><ul><li><a href="#how-does-client-communicate-with-master-specifically">How does client communicate with master specifically?</a></li><li><a href="#what-metadata-does-master-need-to-store">What metadata does master need to store?</a></li><li><a href="#how-to-persist">How to persist?</a></li><li><a href="#how-does-gfs-manage-namespace">How does GFS manage namespace?</a></li><li><a href="#how-does-gfs-design-locking-scheme">How does GFS design locking scheme?</a></li></ul></li><li><a href="#replica-management">Replica management</a><ul><li><a href="#how-to-place-replicas">How to place replicas?</a></li><li><a href="#what-factors-are-considered-when-create-a-new-chunk">What factors are considered when create a new chunk?</a></li><li><a href="#what-if-the-number-of-available-replicas-of-a-chunk-falls-below-a-user-specified-goal">What if the number of available replicas of a chunk falls below a user-specified goal?</a></li><li><a href="#what-if-cloning-traffic-from-overwhelming-client-traffic">What if cloning traffic from overwhelming client traffic?</a></li><li><a href="#how-to-keep-the-placement-of-replicas-in-balance">How to keep the placement of replicas in balance?</a></li></ul></li><li><a href="#deletion">Deletion</a><ul><li><a href="#how-to-delete-a-file">How to delete a file?</a></li><li><a href="#what-are-the-advantages-and-disadvantages-of-lazy-deletion-over-eager-deletion">What are the advantages and disadvantages of lazy deletion over eager deletion?</a></li><li><a href="#how-to-address-the-issues-of-reusing">How to address the issues of reusing?</a></li><li><a href="#how-to-handle-the-possible-stale-replicas">How to handle the possible stale replicas?</a></li></ul></li></ul></li><li><a href="#fault-tolerance">Fault tolerance</a><ul><li><a href="#how-to-handle-master-failure">How to handle master failure?</a></li><li><a href="#why-cannot-recover-data-using-other-chunk-replicas-why-each-chunkserver-must-independently-verify-the-integrity">Why cannot recover data using other chunk replicas? Why each chunkserver must independently verify the integrity?</a></li><li><a href="#how-to-ensure-data-integrity">How to ensure data integrity?</a></li><li><a href="#how-to-read-data-with-checksum">How to read data with checksum?</a></li><li><a href="#how-to-write-data-with-checksum">How to write data with checksum?</a></li><li><a href="#what-is-included-in-the-diagnostic-logs">What is included in the diagnostic logs?</a></li></ul></li><li><a href="#other-parts-unmentioned">Other parts (unmentioned)</a><ul><li><a href="#to-sum-up-what-is-the-metadata-of-master-and-where-are-they">To sum up, what is the metadata of master, and where are they?</a></li><li><a href="#what-is-the-cause-of-split-brain-how-to-solve-it">What is the cause of split brain? How to solve it?</a></li><li><a href="#why-gfs-doesnt-overwrite-those-failed-records-immediately-but-leaving-padding-and-duplicates">Why GFS doesn’t overwrite those failed records immediately, but leaving padding and duplicates?</a></li><li><a href="#gfs-is-a-weak-consistency-system-how-can-we-upgrade-it-to-a-strong-consistency-system">GFS is a weak consistency system, how can we upgrade it to a strong consistency system?</a></li></ul></li></ul></li><li><a href="#experiments-and-results">Experiments and results</a><ul><li><a href="#micro-benchmarks">Micro-benchmarks</a><ul><li><a href="#read">Read</a></li><li><a href="#write">Write</a></li><li><a href="#record-append">Record append</a></li></ul></li><li><a href="#real-world-clusters">Real world clusters</a></li></ul></li></ul></p><h1 id="purpose"><a class="markdownIt-Anchor" href="#purpose"></a> Purpose</h1><ol><li>Contribution: provides fault tolerance while running on inexpensive commodity hardware, and it delivers high aggregate performance to a large number of clients.</li><li>Difference points in design space<ul><li>This system integreted constant monitoring, error detection, fault tolerance, and automatic recovery.</li><li>Files are huge by traditional standards. Design assumptions and parameters such as I/O operation and block sizes have to be revisited.</li><li>Most files are mutated by appending new data rather than overwriting existing data. Random writes within a file are practically non-existent. Once written, the files are only read, and often only seuqentially.</li></ul></li></ol><h1 id="model"><a class="markdownIt-Anchor" href="#model"></a> Model</h1><h2 id="overview"><a class="markdownIt-Anchor" href="#overview"></a> Overview</h2><h3 id="what-operations-are-supported"><a class="markdownIt-Anchor" href="#what-operations-are-supported"></a> What operations are supported?</h3><ol><li>Usual operations: <code>create</code>, <code>delete</code>, <code>open</code>, <code>close</code>, <code>read</code>, and <code>write</code></li><li><code>snapshot</code>: creates a copy of a file or a directory tree at low cost</li><li><code>record append</code>: allows multiple clients to append data to the same file concurrently while guaranteeing the atomicity</li></ol><h3 id="architecture"><a class="markdownIt-Anchor" href="#architecture"></a> Architecture</h3><img src="/imgs/Distributed/GFS/01.png" style="zoom:33%;" /><h4 id="what-does-the-system-consist-of"><a class="markdownIt-Anchor" href="#what-does-the-system-consist-of"></a> What does the system consist of?</h4><ol><li>Consist of a signle <em>master</em> and multiple <em>chunkservers</em> and is accessed by multiple <em>clients</em>.</li><li>Files are divided into fixed-size chunks. Each chunk is identified by an immutable and globally unique 64 bit <em>chunk handle</em> assigned by the master at the timeof chunk creation.</li><li>Chunkservers store chunks on local disks as Linux files and read or write chunk data specified by a chunk handle and byte range. Each chunk is replicated on multiple chunkservers, three by default.</li><li>Neither the client nor the chunkserver caches file data. Caches offer little benefit while causing coherence issues. But clients do cache metadata.</li></ol><h4 id="what-does-master-need-to-do"><a class="markdownIt-Anchor" href="#what-does-master-need-to-do"></a> What does master need to do?</h4><ol><li><p>The master maintains all file system metadata, and controls system-wide activities.</p><ul><li><p>Metadata includes namespace, access control information, the mapping from files to chunks, and the current locations of chunks.</p></li><li><p>System-wide activities includes chunk lease management, garbage collection of orphaned chunks, and chunk migration between chunkservers.</p></li></ul></li><li><p>The master periodically comminicates with each chunkserver in HeartBeat messages to give it instructions and collect its state.</p></li><li><p>Clients interact with the master for metadata operations, but all data-bearing communication goes directly to the chunkservers.</p></li></ol><h4 id="how-to-prevent-the-master-becoming-a-bottleneck"><a class="markdownIt-Anchor" href="#how-to-prevent-the-master-becoming-a-bottleneck"></a> How to prevent the master becoming a bottleneck?</h4><ol><li><p>The idea is to minimize its involvement in reads and writes.</p></li><li><p>A client asks the master which chunkservers it should contact, and caches this information for a limited time and interacts with the chunkservers directly for subsequent operations.</p></li></ol><h4 id="what-is-the-advantage-of-large-chunk-size"><a class="markdownIt-Anchor" href="#what-is-the-advantage-of-large-chunk-size"></a> What is the advantage of large chunk size?</h4><ol><li><p>Reduce clients’ need to interact with the master because reads and writes on the same chunk require only one initial request to the master for chunk location information.</p></li><li><p>Reduce network overhead by keeping a persistent TCP connection to the chunkserver over an extended period of time.</p></li><li><p>Reduce the size of the metadata stored on the master.</p></li></ol><h4 id="what-is-the-disadvantage-of-large-chunk-size"><a class="markdownIt-Anchor" href="#what-is-the-disadvantage-of-large-chunk-size"></a> What is the disadvantage of large chunk size?</h4><ol><li><p>Wasting space due to internal fragmentation. This can be eased through lazy space allocation.</p></li><li><p>A small file consists of a small number of chunks, perhaps just one. The chunkservers storing those chunks may become hot spots if many clients are accessing the same file. This have not been a major issue.</p></li></ol><h4 id="when-will-hot-spots-problem-emerge"><a class="markdownIt-Anchor" href="#when-will-hot-spots-problem-emerge"></a> When will hot spots problem emerge?</h4><ol><li><p>A more common case is that an executable was written to GFS as a single-chunk file and then started on hundreds of machines at the same time.</p></li><li><p>We can fix this problem by storing such executables with a higher replication factor.</p></li></ol><h3 id="consistency"><a class="markdownIt-Anchor" href="#consistency"></a> Consistency</h3><h4 id="how-do-we-define-a-file-region-being-consistent-or-defined"><a class="markdownIt-Anchor" href="#how-do-we-define-a-file-region-being-consistent-or-defined"></a> How do we define a file region being consistent or defined?</h4><ol><li><p>A file region is consistent if all clients will always see the same data, regardless of which replicas they read from.</p></li><li><p>A region is defined after a file data mutation if it is consistent and clients will see what the mutation writes in its entirety.</p></li><li><p>Concurrent successful mutations leave the region undefined but consistent: all clients see the same data, but it may not reflect what any one mutation has written. Typically, it consists of mingled fragments from multiple mutations.</p></li></ol><h4 id="how-many-consistency-rules-should-be-considered"><a class="markdownIt-Anchor" href="#how-many-consistency-rules-should-be-considered"></a> How many consistency rules should be considered?</h4><ol><li>File namespace mutations (e.g. file creation) are atomic.</li><li>After a sequence of successful mutations, the mutated file region is guaranteed to be defined and contain the data written by the last mutation.</li></ol><h4 id="how-do-gfs-guarantees-the-second-rule"><a class="markdownIt-Anchor" href="#how-do-gfs-guarantees-the-second-rule"></a> How do GFS guarantees the second rule?</h4><ol><li>Applying mutations to a chunk in the same order on all its replicas.</li><li>Using chunk version numbers to detect any replica that has become stale because it has missed mutations while its chunkserver was down.</li><li>Stale replicas will never be involved in a mutation or given to clients asking the master for chunk locations. They are garbage collected at the earliest opportunity.</li></ol><h4 id="what-is-the-side-effect-of-clients-caching-chunk-locations"><a class="markdownIt-Anchor" href="#what-is-the-side-effect-of-clients-caching-chunk-locations"></a> What is the side-effect of clients caching chunk locations?</h4><ol><li>They may read from a stale replica before that information is refreshed.</li><li>This window is limited by the cache entry’s timeout and dthe next open of the file.</li><li>As most of files are append-only, a stale replica usually returns a premature end of chunk rather than outdated data.</li></ol><h2 id="data-mutation"><a class="markdownIt-Anchor" href="#data-mutation"></a> Data mutation</h2><h3 id="control-data-flow"><a class="markdownIt-Anchor" href="#control-data-flow"></a> Control &amp; data flow</h3><h4 id="how-do-we-minimize-management-overhead-at-the-master-of-data-mutation"><a class="markdownIt-Anchor" href="#how-do-we-minimize-management-overhead-at-the-master-of-data-mutation"></a> How do we minimize management overhead at the master of data mutation?</h4><ol><li>We use leases to maintain a consistent mutation order across replicas.</li><li>The master grants a chunk lease to one of the replicas, which we call the primary. The primary picks a serial order for all mutations to the chunk. All replicas follow this order when applying mutations.</li><li>The client caches who is the lease of a certain chunk for future mutations. It needs to contact the master again only when the primary becomes unreachable or replies that it no longer holds a lease.</li></ol><h4 id="what-does-leases-change"><a class="markdownIt-Anchor" href="#what-does-leases-change"></a> What does leases change?</h4><ol><li>A lease has an initial timeout of 60 seconds. However, as long as the chunk is being mutated, the primary can request and typically receive extensions from the master indefinitely.</li><li>These extension requests and grants are piggybacked on the HeartBeat messages regularly exchanged between the master and all chunkservers.</li><li>The master may sometimes try to revoke a lease before it expires (e.g., when the master wants to disable mutations on a file that is being renamed).</li><li>Even if the master loses communication with a primary, it can safely grant a new lease to another replica after the old lease expires.</li></ol><h4 id="how-does-the-control-flow"><a class="markdownIt-Anchor" href="#how-does-the-control-flow"></a> How does the control flow?</h4><ol><li><p>the client asks the master which chunkserver holds the current lease for the chunk and the locations of the other replicas. If no one has a lease, the master grants one to a replica it chooses</p></li><li><p>the master replies with the identity of the primary and the locations of the other (secondary) replicas.</p></li><li><p>The client pushes the data to all the replicas in any order, instead of only sending to the lease.</p></li><li><p>once all the replicas have acknowledged receiving the data, the client sends a write request to the primary.</p></li><li><p>the primary forwards the write request to all secondary replicas.</p></li><li><p>the secondaries all reply to the primary indicating that they have completed the operation.</p></li><li><p>the primary replies to the client. Any errors encountered at any of the replicas are reported to the client.</p><img src="/imgs/Distributed/GFS/02.png" style="zoom:25%;" /></li></ol><h4 id="how-does-primary-and-secondary-servers-write-data"><a class="markdownIt-Anchor" href="#how-does-primary-and-secondary-servers-write-data"></a> How does primary and secondary servers write data?</h4><ol><li><p>Each chunkserver will store the data from client in an internal LRU buffer cache until the data is used or aged out.</p></li><li><p>The write request from client to primary identifies the data pushed earlier to all of the replicas.</p></li><li><p>The primary assigns consecutive serial numbers to all the mutations it receives, possibly from multiple clients, which provides the necessary serialization.</p></li><li><p>The primary applies the mutation to its own local state in serial number order.</p></li></ol><h4 id="what-would-the-system-do-if-write-fails"><a class="markdownIt-Anchor" href="#what-would-the-system-do-if-write-fails"></a> What would the system do if write fails?</h4><ol><li><p>If it had failed at the primary, it would not have been assigned a serial number and forwarded.</p></li><li><p>In other cases, the write may have succeeded at the primary and an arbitrary subset of the secondary replicas. The client request is considered to have failed, and the modified region is left in an inconsistent state.</p></li><li><p>The client code handles such errors by retrying the failed mutation. It will make a few attempts at steps 3 through 7 before falling back to a retry from the beginning of the write.</p></li></ol><h4 id="what-if-a-write-is-large-or-straddles-a-chunk-boundary"><a class="markdownIt-Anchor" href="#what-if-a-write-is-large-or-straddles-a-chunk-boundary"></a> What if a write is large or straddles a chunk boundary?</h4><ol><li>GFS client code breaks it down into multiple write operations.</li><li>They all follow the control flow described above but may be interleaved with and overwritten by concurrent operations from other clients.</li><li>The shared file region may end up containing fragments from different clients, although the replicas will be identical because the individual operations are completed successfully in the same order on all replicas.</li></ol><h4 id="how-to-prevent-primary-become-bottleneck-of-pushing-data"><a class="markdownIt-Anchor" href="#how-to-prevent-primary-become-bottleneck-of-pushing-data"></a> How to prevent primary become bottleneck of pushing data?</h4><ol><li>While control flows from the client to the primary and then to all secondaries, data is pushed linearly along a carefully picked chain of chunkservers in a pipelined fashion.</li><li>By decoupling the data flow from the control flow, we can improve performance by scheduling the expensive data flow based on the network topology regardless of which chunkserver is the primary.</li><li>Our goals are to fully utilize each machine’s network bandwidth, avoid network bottlenecks and high-latency links, and minimize the latency to push through all the data.</li><li>Each machine forwards the data to the “closest” machine in the network topology that has not received it.</li><li>Our network topology is simple enough that “distances” can be accurately estimated from IP addresses.</li></ol><h4 id="how-to-minimize-latency-of-pushing-data"><a class="markdownIt-Anchor" href="#how-to-minimize-latency-of-pushing-data"></a> How to minimize latency of pushing data?</h4><ol><li>We minimize latency by pipelining the data transfer over TCP connections. Once a chunkserver receives some data, it starts forwarding immediately.</li><li>Pipelining is especially helpful to us because we use a switched network with full-duplex links. Sending the data immediately does not reduce the receive rate.</li></ol><h3 id="write-and-record-append"><a class="markdownIt-Anchor" href="#write-and-record-append"></a> Write and record append</h3><h4 id="what-is-the-difference-between-write-and-record-append"><a class="markdownIt-Anchor" href="#what-is-the-difference-between-write-and-record-append"></a> What is the difference between write and record append?</h4><ol><li><p>A write causes data to be written at an application-specified file offset.</p></li><li><p>A record append causes data (the “record”) to be appended atomically at least once even in the presence of concurrent mutations, but at an offset of GFS’s choosing.</p><ul><li><p>The offset is returned to the client and marks the beginning of a defined region that contains the record.</p></li><li><p>GFS may insert padding or record duplicates in between. They occupy regions considered to be inconsistent and are typically dwarfed by the amount of user data.</p></li></ul></li><li><p>A “regular” append is merely a write at an offset that the client believes to be the current end of file.</p></li></ol><h4 id="how-does-typical-writing-happen"><a class="markdownIt-Anchor" href="#how-does-typical-writing-happen"></a> How does typical writing happen?</h4><ol><li>A writer generates a file from beginning to end. It atomically renames the file to a permanent name after writing all the data, or periodically checkpoints how much has been successfully written.</li><li>Checkpoints may also include application-level checksums. Readers verify and process only the file region up to the last checkpoint, which is known to be in the defined state.</li><li>Checkpointing allows writers to restart incrementally and keeps readers from processing successfully written file data that is still incomplete.</li></ol><h4 id="how-does-readers-deal-with-occasional-padding-and-duplicates"><a class="markdownIt-Anchor" href="#how-does-readers-deal-with-occasional-padding-and-duplicates"></a> How does readers deal with occasional padding and duplicates?</h4><ol><li>Each record prepared by the writer contains extra information like checksums so that its validity can be verified.</li><li>A reader can identify and discard extra padding and record fragments using the checksums.</li><li>If it cannot tolerate the occasional duplicates, it can filter them out using unique identifiers in the records, which are often needed anyway to name corresponding application entities such as web documents.</li></ol><h3 id="atomic-record-appends"><a class="markdownIt-Anchor" href="#atomic-record-appends"></a> Atomic record appends</h3><h4 id="what-if-appending-causes-the-current-chunk-to-exceed-the-maximum-size"><a class="markdownIt-Anchor" href="#what-if-appending-causes-the-current-chunk-to-exceed-the-maximum-size"></a> What if appending causes the current chunk to exceed the maximum size?</h4><ol><li>The primary checks to see if appending the record to the current chunk would cause the chunk to exceed the maximum size.</li><li>If so, it pads the chunk to the maximum size, tells secondaries to do the same, and replies to the client indicating that the operation should be retried on the next chunk.</li><li>If the record fits within the maximum size, which is the common case, the primary appends the data to its replica, tells the secondaries to write the data at the exact offset where it has, and finally replies success to the client.</li></ol><h4 id="what-if-appending-fails-at-some-chunkservers"><a class="markdownIt-Anchor" href="#what-if-appending-fails-at-some-chunkservers"></a> What if appending fails at some chunkservers?</h4><ol><li>Replicas of the same chunk may contain different data possibly including duplicates of the same record in whole or in part.</li><li>GFS does not guarantee that all replicas are bytewise identical. It only guarantees that the data is written at least once as an atomic unit.</li><li>If there is any secondary chunkserver that can successfully append the record, the primary is succeed. Next time, the primary can choose an offset after the failed record.</li><li>Hence, after this, all replicas are at least as long as the end of record and therefore any future record will be assigned a higher offset or a different chunk even if a different replica later becomes the primary.</li></ol><h3 id="snapshot"><a class="markdownIt-Anchor" href="#snapshot"></a> Snapshot</h3><h4 id="what-does-snapshot-do"><a class="markdownIt-Anchor" href="#what-does-snapshot-do"></a> What does snapshot do?</h4><ol><li>The snapshot operation makes a copy of a file or a directory tree (the “source”) almost instantaneously, while minimizing any interruptions of ongoing mutations.</li><li>Users use it to quickly create branch copies of huge data sets (and often copies of those copies, recursively), or to checkpoint the current state before experimenting with changes that can later be committed or rolled back easily.</li></ol><h4 id="how-does-snapshot-be-implemented"><a class="markdownIt-Anchor" href="#how-does-snapshot-be-implemented"></a> How does snapshot be implemented?</h4><ol><li><p>It use standard copy-on-write techniques.</p></li><li><p>Master revokes leases on the chunks in the files it is about to snapshot.</p><ul><li><p>This ensures that any subsequent writes to these chunks will require an interaction with the master to find the lease holder.</p></li><li><p>And this will give the master an opportunity to create a new copy of the chunk first.</p></li></ul></li><li><p>Master logs the operation to disk.</p></li><li><p>It then applies this log record to its in-memory state by duplicating the metadata for the source file or directory tree. The newly created snapshot files point to the same chunks as the source files.</p></li></ol><h4 id="how-does-clients-write-a-chunk-after-snapshot"><a class="markdownIt-Anchor" href="#how-does-clients-write-a-chunk-after-snapshot"></a> How does clients write a chunk after snapshot?</h4><ol><li>The first time a client wants to write to a chunk C after the snapshot operation, it sends a request to the master to find the current lease holder.</li><li>The master notices that the reference count for chunk C is greater than one. It defers replying to the client request and instead picks a new chunk handle C’.</li><li>It then asks each chunkserver that has a current replica of C to create a new chunk called C’.</li><li>By creating the new chunk on the same chunkservers as the original, we ensure that the data can be copied locally, not over the network.</li><li>The master grants one of the replicas a lease on the new chunk C’ and replies to the client, which can write the chunk normally.</li></ol><h2 id="master"><a class="markdownIt-Anchor" href="#master"></a> Master</h2><h3 id="basic-operations"><a class="markdownIt-Anchor" href="#basic-operations"></a> Basic operations</h3><h4 id="how-does-client-communicate-with-master-specifically"><a class="markdownIt-Anchor" href="#how-does-client-communicate-with-master-specifically"></a> How does client communicate with master specifically?</h4><ol><li>The client translates the file name and byte offset specified by the application into a chunk index within the file.</li><li>It sends the master a requeust containing the file name and chunk index.</li><li>The master replies with the corresponding chunk handle and locations of the replicas.</li><li>The client caches this information using the file name and chunk index as the key.</li></ol><h4 id="what-metadata-does-master-need-to-store"><a class="markdownIt-Anchor" href="#what-metadata-does-master-need-to-store"></a> What metadata does master need to store?</h4><ol><li><p>Stored persistently: the file and chunk namespace, the mapping from files to chunks</p><ul><li><p>The master will scan periodically through its entire state in the background</p></li><li><p>Periodic scanning is to implement chunk garbage collection, re-replication in the presence of chunkserver failures, and chunk migration to balance load and disk space usage across chunkservers.</p></li><li><p>The number of chunks and hence the capacity of the whole system is limited by how much memory the master has. But not a serious limitation for less than <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>64</mn></mrow><annotation encoding="application/x-tex">64</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">6</span><span class="mord">4</span></span></span></span> bytes of metadata for each chunk.</p></li></ul></li><li><p>No need to store persistently: the locations of each chunk’s replicas.</p><ul><li><p>The master asks each chunkserver about its chunks at master startup and whenever a chunkserver joins the cluster.</p></li><li><p>The master can keep itself up-to-date thereafter because it controls all chunk placement and monitors chunkserver status.</p></li></ul></li><li><p>Operation record</p><ul><li><p>The namespace and mapping are kept persistent by logging mutations to operation log</p></li><li><p>It is stored on the master’s local disk and replicated on remote machines</p></li></ul></li></ol><h4 id="how-to-persist"><a class="markdownIt-Anchor" href="#how-to-persist"></a> How to persist?</h4><ol><li>Operation log<ul><li>The operation log contains a historical record of critical metadata changes. Not only is it the only persistent record of critical metadata, it also serves as a logical time line that defines the order of concurrent operations.</li><li>The system respond to a client operation only after flushing the corresponding log record to disk both locally and remotely.</li><li>The master batches several log records together before flushing thereby reducing the impact of flushing and replication on overall system thoughput.</li></ul></li><li>Checkpoint<ul><li>To minimize startup time, we must keep the log small. The master checkpoints its state whenever the log grows beyond a certain size. It can recover by loading the latest checkpoint and replaying only the records after that.</li><li>The checkpoint is in a compact B-tree like form.</li><li>The master switches to a new log file and creates the new checkpoint in a separate thread.</li><li>Older checkpoints and log files can be freely deleted, though we keep a few around to guard against catastrophes. A failure during checkpointing does not affect correctness because the recovery code detects and skips incomplete checkpoints.</li></ul></li></ol><h4 id="how-does-gfs-manage-namespace"><a class="markdownIt-Anchor" href="#how-does-gfs-manage-namespace"></a> How does GFS manage namespace?</h4><ol><li>GFS does not have a per-directory data structure that lists all the files in that directory. Nor does it support aliases for the same file or directory.</li><li>GFS logically represents its namespace as a lookup table mapping full pathnames to metadata. With prefix compression, this table can be efficiently represented in memory.</li><li>Each node in the namespace tree (either an absolute file name or an absolute directory name) has an associated read-write lock.</li></ol><h4 id="how-does-gfs-design-locking-scheme"><a class="markdownIt-Anchor" href="#how-does-gfs-design-locking-scheme"></a> How does GFS design locking scheme?</h4><ol><li>If a master operation involves a certain file or directory, it will acquire read-locks on all the parent directories, and either a read-lock or a write-lock on the leaf file or directory that it will operate directly.</li><li>File creation does not require a write lock on the parent directory because there is no “directory”, or inode-like, data structure to be protected from modification.</li><li>This locking scheme allows concurrent mutations in the same directory.</li></ol><h3 id="replica-management"><a class="markdownIt-Anchor" href="#replica-management"></a> Replica management</h3><h4 id="how-to-place-replicas"><a class="markdownIt-Anchor" href="#how-to-place-replicas"></a> How to place replicas?</h4><ol><li>There are two purposes: maximize data reliability and availability, and maximize network bandwidth utilization.</li><li>It is not enough to spread replicas across machines, which only guards against disk or machine failures and fully utilizes each machine’s network bandwidth.</li><li>We must also spread chunk replicas across racks. This ensures that some replicas of a chunk will survive and remain available even if an entire rack is damaged or offline. It also means that traffic, especially reads, for a chunk can exploit the aggregate bandwidth of multiple racks.</li><li>On the other hand, write traffic has to flow through multiple racks, a tradeoff we make willingly.</li><li>An even safer way is to spread across data centers in different cities. It can guards against a city-level catastrophe.</li></ol><h4 id="what-factors-are-considered-when-create-a-new-chunk"><a class="markdownIt-Anchor" href="#what-factors-are-considered-when-create-a-new-chunk"></a> What factors are considered when create a new chunk?</h4><ol><li>We want to place new replicas on chunkservers with below-average disk space utilization. Over time this will equalize disk utilization across chunkservers.</li><li>We want to limit the number of “recent” creations on each chunkserver. Although creation itself is cheap, it reliably predicts imminent heavy write traffic because chunks are created when demanded by writes.</li><li>We want to spread replicas of a chunk across racks.</li></ol><h4 id="what-if-the-number-of-available-replicas-of-a-chunk-falls-below-a-user-specified-goal"><a class="markdownIt-Anchor" href="#what-if-the-number-of-available-replicas-of-a-chunk-falls-below-a-user-specified-goal"></a> What if the number of available replicas of a chunk falls below a user-specified goal?</h4><ol><li><p>The master would re-replicate the chunk.</p></li><li><p>If there are many chunks below their goal, the master picks the highest priority chunk considering some factors and “clones” it by instructing some chunkserver to copy the chunk data directly from an existing valid replica.</p><ul><li><p>How far it is from its replication goal.</p></li><li><p>Prefer to first re-replicate chunks for live files as opposed to chunks that belong to recently deleted files.</p></li><li><p>To minimize the impact of failures on running applications, we boost the priority of any chunk that is blocking client progress.</p></li></ul></li></ol><h4 id="what-if-cloning-traffic-from-overwhelming-client-traffic"><a class="markdownIt-Anchor" href="#what-if-cloning-traffic-from-overwhelming-client-traffic"></a> What if cloning traffic from overwhelming client traffic?</h4><ol><li>The master limits the numbers of active clone operations both for the cluster and for each chunkserver.</li><li>Each chunkserver limits the amount of bandwidth it spends on each clone operation by throttling its read requests to the source chunkserver.</li></ol><h4 id="how-to-keep-the-placement-of-replicas-in-balance"><a class="markdownIt-Anchor" href="#how-to-keep-the-placement-of-replicas-in-balance"></a> How to keep the placement of replicas in balance?</h4><ol><li>It examines the current replica distribution and moves replicas for better disk space and load balancing.</li><li>The master gradually fills up a new chunkserver rather than instantly swamps it with new chunks and the heavy write traffic that comes with them.</li><li>The master must also choose which existing replica to remove. It prefers to remove those on chunkservers with below-average free space.</li></ol><h3 id="deletion"><a class="markdownIt-Anchor" href="#deletion"></a> Deletion</h3><h4 id="how-to-delete-a-file"><a class="markdownIt-Anchor" href="#how-to-delete-a-file"></a> How to delete a file?</h4><ol><li><p>GFS does not immediately reclaim the available physical storage, it is just renamed to a hidden name that includes the deletion timestamp. It does so only lazily during regular garbage collection at both the file and chunk levels.</p></li><li><p>During the master’s regular scan of the file system namespace, it removes any such hidden files if they have existed for more than three days (the interval is configurable).</p><ul><li><p>Until then, the file can still be read under the new, special name and can be undeleted by renaming it back to normal.</p></li><li><p>When the hidden file is removed from the namespace, its in-memory metadata is erased. This effectively severs its links to all its chunks.</p></li></ul></li><li><p>In a similar regular scan of the chunk namespace, the master identifies orphaned chunks (i.e., those not reachable from any file) and erases the metadata for those chunks.</p><ul><li><p>In a HeartBeat message exchanged with the master, each chunkserver reports a subset of the chunks it has, and the master replies with the identity of all chunks that are no longer present in the master’s metadata.</p></li><li><p>The chunkserver is free to delete its replicas of such chunks.</p></li></ul></li></ol><h4 id="what-are-the-advantages-and-disadvantages-of-lazy-deletion-over-eager-deletion"><a class="markdownIt-Anchor" href="#what-are-the-advantages-and-disadvantages-of-lazy-deletion-over-eager-deletion"></a> What are the advantages and disadvantages of lazy deletion over eager deletion?</h4><ol><li><p>It is simple and reliable in a large-scale distributed system where component failures are common.</p></li><li><p>It merges storage reclamation into the regular background activities of the master.</p></li><li><p>The delay in reclaiming storage provides a safety net against accidental, irreversible deletion.</p></li><li><p>The delay sometimes hinders user effort to fine tune usage when storage is tight.</p></li><li><p>Applications that repeatedly create and delete temporary files may not be able to reuse the storage right away.</p></li></ol><h4 id="how-to-address-the-issues-of-reusing"><a class="markdownIt-Anchor" href="#how-to-address-the-issues-of-reusing"></a> How to address the issues of reusing?</h4><ol><li><p>Expediting storage reclamation if a deleted file is explicitly deleted again.</p></li><li><p>Allow users to apply different replication and reclamation policies to different parts of the namespace.</p></li></ol><h4 id="how-to-handle-the-possible-stale-replicas"><a class="markdownIt-Anchor" href="#how-to-handle-the-possible-stale-replicas"></a> How to handle the possible stale replicas?</h4><ol><li><p>For each chunk, the master maintains a chunk version number to distinguish between up-to-date and stale replicas.</p></li><li><p>Whenever the master grants a new lease on a chunk, it increases the chunk version number and informs the up-to-date replicas. This occurs before any client is notified and therefore before it can start writing to the chunk.</p></li><li><p>If one replica is currently unavailable, its chunk version number will not be advanced. The master will detect that this chunkserver has a stale replica when the chunkserver restarts and reports its set of chunks and their associated version numbers.</p></li><li><p>The master removes stale replicas in its regular garbage collection. Before that, it effectively considers a stale replica not to exist at all when it replies to client requests for chunk information.</p></li><li><p>The master includes the chunk version number when it informs clients which chunkserver holds a lease on a chunk or when it instructs a chunkserver to read the chunk from another chunkserver in a cloning operation.</p></li></ol><h2 id="fault-tolerance"><a class="markdownIt-Anchor" href="#fault-tolerance"></a> Fault tolerance</h2><h3 id="how-to-handle-master-failure"><a class="markdownIt-Anchor" href="#how-to-handle-master-failure"></a> How to handle master failure?</h3><ol><li><p>The master state is replicated for reliability.</p><ul><li><p>When it fails, it can restart almost instantly.</p></li><li><p>When its machine or disk fails, monitoring infrastructure outside GFS starts a new master process elsewhere with the replicated operation log.</p></li><li><p>Clients use only the canonical name of the master, which is a DNS alias that can be changed if the master is relocated to another machine.</p></li></ul></li><li><p>“Shadow” masters provide read-only access to the file system even when the primary master is down.</p><ul><li><p>They enhance read availability for files that are not being actively mutated or applications that do not mind getting slightly stale results.</p></li><li><p>Since file content is read from chunkservers, applications do not observe stale file content. What could be stale within short windows is file metadata.</p></li><li><p>To keep itself informed, a shadow master reads a replica of the growing operation log and applies the same sequence of changes to its data structures exactly as the primary does.</p></li><li><p>It depends on the primary master only for replica location updates resulting from the primary’s decisions to create and delete replicas.</p></li></ul></li></ol><h3 id="why-cannot-recover-data-using-other-chunk-replicas-why-each-chunkserver-must-independently-verify-the-integrity"><a class="markdownIt-Anchor" href="#why-cannot-recover-data-using-other-chunk-replicas-why-each-chunkserver-must-independently-verify-the-integrity"></a> Why cannot recover data using other chunk replicas? Why each chunkserver must independently verify the integrity?</h3><ol><li><p>It would be impractical to detect corruption by comparing replicas across chunkservers.</p></li><li><p>Divergent replicas may be legal: the semantics of GFS mutations, in particular atomic record append, does not guarantee identical replicas.</p></li></ol><h3 id="how-to-ensure-data-integrity"><a class="markdownIt-Anchor" href="#how-to-ensure-data-integrity"></a> How to ensure data integrity?</h3><ol><li><p>Each chunkserver uses checksumming to detect corruption of stored data. A chunk is broken up into 64 KB blocks. Each has a corresponding 32 bit checksum.</p></li><li><p>Checksums are kept in memory and stored persistently with logging, separate from user data.</p></li><li><p>During idle periods, chunkservers can scan and verify the contents of inactive chunks.</p></li></ol><h3 id="how-to-read-data-with-checksum"><a class="markdownIt-Anchor" href="#how-to-read-data-with-checksum"></a> How to read data with checksum?</h3><ol><li><p>the chunkserver verifies the checksum of data blocks that overlap the read range before returning any data to the requester, whether a client or another chunkserver.</p></li><li><p>If a block does not match the recorded checksum, the chunkserver returns an error to the requestor and reports the mismatch to the master.</p></li><li><p>In response, the requestor will read from other replicas, while the master will clone the chunk from another replica.</p></li><li><p>After a valid new replica is in place, the master instructs the chunkserver that reported the mismatch to delete its replica.</p></li></ol><h3 id="how-to-write-data-with-checksum"><a class="markdownIt-Anchor" href="#how-to-write-data-with-checksum"></a> How to write data with checksum?</h3><ol><li><p>For writes that append to the end of a chunk, we just incrementally update the checksum for the last partial checksum block, and compute new checksums for any brand new checksum blocks filled by the append.</p><ul><li>Even if the last partial checksum block is already corrupted and we fail to detect it now, the new checksum value will not match the stored data, and the corruption will be detected as usual when the block is next read.</li></ul></li><li><p>If a write overwrites an existing range of the chunk, we must read and verify the first and last blocks of the range being overwritten, then perform the write, and finally compute and record the new checksums.</p><ul><li>If we do not verify the first and last blocks before overwriting them partially, the new checksums may hide corruption that exists in the regions not being overwritten.</li></ul></li></ol><h3 id="what-is-included-in-the-diagnostic-logs"><a class="markdownIt-Anchor" href="#what-is-included-in-the-diagnostic-logs"></a> What is included in the diagnostic logs?</h3><ol><li><p>GFS servers generate diagnostic logs that record many significant events (such as chunkservers going up and down) and all RPC requests and replies.</p></li><li><p>The RPC logs include the exact requests and responses sent on the wire, except for the file data being read or written.</p></li></ol><h2 id="other-parts-unmentioned"><a class="markdownIt-Anchor" href="#other-parts-unmentioned"></a> Other parts (unmentioned)</h2><h3 id="to-sum-up-what-is-the-metadata-of-master-and-where-are-they"><a class="markdownIt-Anchor" href="#to-sum-up-what-is-the-metadata-of-master-and-where-are-they"></a> To sum up, what is the metadata of master, and where are they?</h3><ol><li><p>File name: this is an array of chunk handles. It is stored on disk.</p></li><li><p>Handle: it contains a list of chunkservers, version number, primary, and lease expiration.</p><ul><li><p>Only the version number is stored on disk, due to the rest can be restored by asking chunkservers when master is recovered.</p></li><li><p>Given that there might have stale chunks, we cannot ask chunkservers for the version number of a chunk.</p></li></ul></li><li><p>Lops and checkpoints are stored on disk.</p></li></ol><h3 id="what-is-the-cause-of-split-brain-how-to-solve-it"><a class="markdownIt-Anchor" href="#what-is-the-cause-of-split-brain-how-to-solve-it"></a> What is the cause of split brain? How to solve it?</h3><ol><li>Split brain is caused by network partition, the master cannot talk to primary while the primary can talk to clients. Hence the master mistakingly designates two primary for the same chunk.</li><li>The master knowswhen the lease will expire, so when the master cannot talk to the primary, it will wait until the lease expired before assign another primary.</li></ol><h3 id="why-gfs-doesnt-overwrite-those-failed-records-immediately-but-leaving-padding-and-duplicates"><a class="markdownIt-Anchor" href="#why-gfs-doesnt-overwrite-those-failed-records-immediately-but-leaving-padding-and-duplicates"></a> Why GFS doesn’t overwrite those failed records immediately, but leaving padding and duplicates?</h3><p>Because When it starts to write the next record, it may not know the fate of prior record.</p><h3 id="gfs-is-a-weak-consistency-system-how-can-we-upgrade-it-to-a-strong-consistency-system"><a class="markdownIt-Anchor" href="#gfs-is-a-weak-consistency-system-how-can-we-upgrade-it-to-a-strong-consistency-system"></a> GFS is a weak consistency system, how can we upgrade it to a strong consistency system?</h3><ol><li>Primary detects duplicate requests to ensure the failed write doesn’t show up twice</li><li>When primary asks a secondary to do something, the secondary actually does it and doesn’t just return error (except the secondary has a permanent damage, in which case, it should be removed)</li><li>The secondary doesn’t expose data to readers until the primary is sure that all the secondaries really will be execute the append.</li><li>When primary crashes, there will have been some last set of operations that primary had launched to the secondaries, but primary crashed before ensure all operations are done. The new primary need to explicitly resync with all secondaries.</li></ol><h1 id="experiments-and-results"><a class="markdownIt-Anchor" href="#experiments-and-results"></a> Experiments and results</h1><h2 id="micro-benchmarks"><a class="markdownIt-Anchor" href="#micro-benchmarks"></a> Micro-benchmarks</h2><p>The author first tested several micro-benchmarks, i.e. reads, writes, and record appends. These tests are that <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>N</mi></mrow><annotation encoding="application/x-tex">N</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">N</span></span></span></span> clients do those operation simultaneously. For reading, they read from the file system; for writing, they write to distinct files; for appending, they append to a single file. And test the aggregate throughputs of the system, comparing them with the network limit. The results are as following:</p><p><img src="/imgs/Distributed/GFS/03.png" alt="" /></p><h3 id="read"><a class="markdownIt-Anchor" href="#read"></a> Read</h3><p>The reading efficiency drops because as the number of readers increases, so does the probability that multiple readers simultaneously read from the same chunkserver.</p><h3 id="write"><a class="markdownIt-Anchor" href="#write"></a> Write</h3><p>The limit plateaus of write rate at 67 MB/s because we need to write each byte to 3 of the 16 chunkservers, each with a 12.5 MB/s input connection.</p><p>The main culprit for a low write rate with only one client is the network stack. It does not interact very well with the pipelining scheme we use for pushing data to chunk replicas. Delays in propagating data from one replica to another reduce the overall write rate.</p><p>As the number of clients grows, it becomes more likely that multiple clients write concurrently to the same chunkserver as the number of clients increases. Moreover, collision is more likely for 16 writers than for 16 readers because each write involves three different replicas.</p><p>Writes are slower than we would like. In practice this has not been a major problem because even though it increases the latencies as seen by individual clients, it does not significantly affect the aggregate write bandwidth delivered by the system to a large number of clients.</p><h3 id="record-append"><a class="markdownIt-Anchor" href="#record-append"></a> Record append</h3><p>The performance of record appends is limited by the network bandwidth of the chunkservers that store the last chunk of the file, independent of the number of clients.</p><p>The append rate drops mostly due to congestion and variances in network transfer rates seen by different clients.</p><p>The chunkserver network congestion in our experiment is not a significant issue in practice because a client can make progress on writing one file while the chunkservers for another file are busy.</p><h2 id="real-world-clusters"><a class="markdownIt-Anchor" href="#real-world-clusters"></a> Real world clusters</h2><p>The author also measured the performance of real world clusters. First, the author measured their storage usage and size of metadata. Then, the read rate, write rate and the rate of operations sent to the master were measured. The results show that master can easily keep up with this rate, and therefore is not a bottleneck for these workloads.</p><p><img src="/imgs/Distributed/GFS/04.png" style="zoom: 33%;" /><img src="/imgs/Distributed/GFS/05.png" style="zoom: 31%;" /></p><p>After a chunkserver fails, some chunks will become underreplicated and must be cloned to restore their replication levels. To test the recovery time, the author killed a single chunkserver containing 15000 chunks of 600 GB data.</p><p>To limit the impact on running applications and provide leeway for scheduling decisions, our default parameters limit this cluster to 91 concurrent clonings (40% of the number of chunkservers) where each clone operation is allowed to consume at most 6.25 MB/s (50 Mbps). All chunks were restored in 23.2 minutes, at an effective replication rate of 440 MB/s.</p><p>Finally, the author also measured the workload of chunkserver and master, and breakdown the workload of chunkserver by size and same of master by type. The table 4 shows the distribution of operations by size, and the table 5 shows the total amount of data transferred in operations of various size.</p><p><img src="/imgs/Distributed/GFS/06.png" style="zoom:25%;" /><img src="/imgs/Distributed/GFS/07.png" style="zoom:25%;" /><img src="/imgs/Distributed/GFS/08.png" style="zoom: 31%;" /></p>]]></content>
      
      
      <categories>
          
          <category> Paper Notebook </category>
          
          <category> Distributed System </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Distributed System </tag>
            
            <tag> Distributed Storage </tag>
            
            <tag> File System </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>MapReduce</title>
      <link href="/2023/09/26/Paper/Distributed/MapReduce/"/>
      <url>/2023/09/26/Paper/Distributed/MapReduce/</url>
      
        <content type="html"><![CDATA[<p>Paper: <a href="http://nil.csail.mit.edu/6.824/2020/papers/mapreduce.pdf">MapReduce: Simplified Data Processing on Large Clusters</a></p><p><ul class="markdownIt-TOC"><li><a href="#abstract">Abstract</a></li><li><a href="#purpose">Purpose</a></li><li><a href="#model">Model</a><ul><li><a href="#paper-ideas">Paper ideas</a><ul><li><a href="#what-does-users-need-to-do">What does users need to do?</a></li><li><a href="#what-does-run-time-system-need-to-do">What does run-time system need to do?</a></li><li><a href="#how-does-the-system-run">How does the system run?</a></li><li><a href="#what-does-master-need-to-do">What does master need to do?</a></li><li><a href="#how-to-handle-worker-failure">How to handle worker failure?</a></li><li><a href="#how-to-handle-master-failure">How to handle master failure?</a></li><li><a href="#how-to-partition-reduce-tasks">How to partition reduce tasks?</a></li><li><a href="#how-do-we-ensure-that-nobody-observes-partially-written-files-in-the-presence-of-crashes">How do we ensure that nobody observes partially written files in the presence of crashes?</a></li><li><a href="#how-to-handle-straggler-problem">How to handle straggler problem?</a></li></ul></li><li><a href="#reproduce">Reproduce</a><ul><li><a href="#how-do-we-assign-map-tasks">How do we assign map tasks?</a></li><li><a href="#how-do-we-assign-reduce-tasks">How do we assign reduce tasks?</a></li><li><a href="#when-can-workers-stop-requesting-for-more-map-tasksreduce-tasks">When can workers stop requesting for more map tasks/reduce tasks?</a></li></ul></li></ul></li><li><a href="#experiments-and-results">Experiments and results</a></li></ul></p><h1 id="abstract"><a class="markdownIt-Anchor" href="#abstract"></a> Abstract</h1><ol><li><strong>Main idea</strong>: Asking user to write simple Map function and Reduce function. The distributed executing framework supporting parallel scheduling is provided as a standard library that will run those functions automatically.</li><li><strong>Key findings</strong>: Map and Reduce are easier to write and depends on the specific application. Despite their different implementations, their distribution and parallelism are similar and can be handled by a common framework.</li><li><strong>The system</strong>: A master will assign and monitor each tasks and nodes while several workers will perform Map phase and Reduce phase sequentially.</li><li><strong>Evaluation</strong>: The system is evaluated on grep and sort tasks with benchmarks of disk I/O speed and duration of each phase.</li></ol><h1 id="purpose"><a class="markdownIt-Anchor" href="#purpose"></a> Purpose</h1><ol><li>Issues: Hard to parallel computation, distribute data, and handle server failures</li><li>Contribution: Proposed an interface where users only need to write relatively simple Map function and Reduce function, and the system will parallel and distribute automatically.</li></ol><h1 id="model"><a class="markdownIt-Anchor" href="#model"></a> Model</h1><h2 id="paper-ideas"><a class="markdownIt-Anchor" href="#paper-ideas"></a> Paper ideas</h2><h3 id="what-does-users-need-to-do"><a class="markdownIt-Anchor" href="#what-does-users-need-to-do"></a> What does users need to do?</h3><ol><li>Users need to provide a Map function and a Reduce function.</li><li>Map function will read the original data as key-value pairs, take one pair as input each time, and output intermediate key-value pairs, i.e. <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>m</mi><mi>a</mi><mi>p</mi><mo stretchy="false">(</mo><mi>k</mi><mn>1</mn><mo separator="true">,</mo><mi>v</mi><mn>1</mn><mo stretchy="false">)</mo><mo>→</mo><mi>l</mi><mi>i</mi><mi>s</mi><mi>t</mi><mo stretchy="false">(</mo><mi>k</mi><mn>2</mn><mo separator="true">,</mo><mi>v</mi><mn>2</mn><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">map(k1,v1)\rightarrow list(k2,v2)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">m</span><span class="mord mathnormal">a</span><span class="mord mathnormal">p</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.03148em;">k</span><span class="mord">1</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">v</span><span class="mord">1</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">→</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.01968em;">l</span><span class="mord mathnormal">i</span><span class="mord mathnormal">s</span><span class="mord mathnormal">t</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.03148em;">k</span><span class="mord">2</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">v</span><span class="mord">2</span><span class="mclose">)</span></span></span></span></li><li>Reduce function will take the intermediate-key and a list of all intermediate-values for that key as input, and merge these values to form a smaller set of values, i.e. <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>r</mi><mi>e</mi><mi>d</mi><mi>u</mi><mi>c</mi><mi>e</mi><mo stretchy="false">(</mo><mi>k</mi><mn>2</mn><mo separator="true">,</mo><mi>l</mi><mi>i</mi><mi>s</mi><mi>t</mi><mo stretchy="false">(</mo><mi>v</mi><mn>2</mn><mo stretchy="false">)</mo><mo stretchy="false">)</mo><mo>→</mo><mi>l</mi><mi>i</mi><mi>s</mi><mi>t</mi><mo stretchy="false">(</mo><mi>v</mi><mn>2</mn><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">reduce(k2,list(v2))\rightarrow list(v2)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mord mathnormal">e</span><span class="mord mathnormal">d</span><span class="mord mathnormal">u</span><span class="mord mathnormal">c</span><span class="mord mathnormal">e</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.03148em;">k</span><span class="mord">2</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal" style="margin-right:0.01968em;">l</span><span class="mord mathnormal">i</span><span class="mord mathnormal">s</span><span class="mord mathnormal">t</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.03588em;">v</span><span class="mord">2</span><span class="mclose">)</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">→</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.01968em;">l</span><span class="mord mathnormal">i</span><span class="mord mathnormal">s</span><span class="mord mathnormal">t</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.03588em;">v</span><span class="mord">2</span><span class="mclose">)</span></span></span></span></li><li>Users need to implement the Mapper and Reducer as interface provided by the system, and pass to the MapReduce specification. After passing the input and output files, invoke the <code>MapReduce</code> function to execute.</li></ol><h3 id="what-does-run-time-system-need-to-do"><a class="markdownIt-Anchor" href="#what-does-run-time-system-need-to-do"></a> What does run-time system need to do?</h3><ol><li>Partition data</li><li>Schedule across a set of machines</li><li>Handle machine failures</li><li>Manage inter-machine communication.</li></ol><h3 id="how-does-the-system-run"><a class="markdownIt-Anchor" href="#how-does-the-system-run"></a> How does the system run?</h3><ol><li>When the <code>MapReduce</code> function is invoked, one <strong>master</strong> process and several <strong>worker</strong> processes will be forked.</li><li>Master will assign work to workers, either a Map work, or a Reduce work.</li><li>Master tries to make most of the <code>(3) read</code> run locally. In the <code>(5) remote read</code>, network communication is inevitable.<br /><img src="/imgs/Distributed/MapReduce/01.png" style="zoom: 50%;" /></li></ol><h3 id="what-does-master-need-to-do"><a class="markdownIt-Anchor" href="#what-does-master-need-to-do"></a> What does master need to do?</h3><ol><li>Master pings every worker periodically, and marks those no response in a certain amount of time as failed.</li><li>Track the state of each map task and reduce task (idle, in-progress or completed), and the identity of the worker machine (for non-idle tasks).</li><li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>M</mi></mrow><annotation encoding="application/x-tex">M</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">M</span></span></span></span> is the number of map tasks, while <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>R</mi></mrow><annotation encoding="application/x-tex">R</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.00773em;">R</span></span></span></span> is the number of reduce tasks. The master must make <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>O</mi><mo stretchy="false">(</mo><mi>M</mi><mo>+</mo><mi>R</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">O(M+R)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">O</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.10903em;">M</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="mclose">)</span></span></span></span> scheduling decisions, and keeps <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>O</mi><mo stretchy="false">(</mo><mi>M</mi><mo>∗</mo><mi>R</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">O(M*R)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">O</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.10903em;">M</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="mclose">)</span></span></span></span> state in memory (all map task/reduce task pair).</li></ol><h3 id="how-to-handle-worker-failure"><a class="markdownIt-Anchor" href="#how-to-handle-worker-failure"></a> How to handle worker failure?</h3><ol><li>What kinds of worker failure need re-execution?<ul><li>Any tasks in progress</li><li>Completed map tasks also need to be re-executed, since their output is stored on the local disks and is inaccessible.</li><li>Completed reduce tasks don’t need to be re-executed, since their output is stored on the global file system.</li></ul></li><li>Master will mark the state of those tasks that need re-execution to idle, and can assign them to other workers in the future.</li></ol><h3 id="how-to-handle-master-failure"><a class="markdownIt-Anchor" href="#how-to-handle-master-failure"></a> How to handle master failure?</h3><ol><li>One way is to make the master write periodic checkpoints of the master data structure.</li><li>Given that there is only a single master, its failure is unlikely. Therefore another way is to abort the MapReduce computation if the master fails, and clients can try again later. (This is the way the author takes)</li></ol><h3 id="how-to-partition-reduce-tasks"><a class="markdownIt-Anchor" href="#how-to-partition-reduce-tasks"></a> How to partition reduce tasks?</h3><p>The number of reduce tasks/output files (<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>R</mi></mrow><annotation encoding="application/x-tex">R</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.00773em;">R</span></span></span></span>) is specified by the users. The default partitioning uses hashing, namely partition according to <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>h</mi><mi>a</mi><mi>s</mi><mi>h</mi><mo stretchy="false">(</mo><mi>k</mi><mi>e</mi><mi>y</mi><mo stretchy="false">)</mo><mtext> </mtext><mi>m</mi><mi>o</mi><mi>d</mi><mtext> </mtext><mi>R</mi></mrow><annotation encoding="application/x-tex">hash(key)\ mod\ R</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">h</span><span class="mord mathnormal">a</span><span class="mord mathnormal">s</span><span class="mord mathnormal">h</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.03148em;">k</span><span class="mord mathnormal">e</span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="mclose">)</span><span class="mspace"> </span><span class="mord mathnormal">m</span><span class="mord mathnormal">o</span><span class="mord mathnormal">d</span><span class="mspace"> </span><span class="mord mathnormal" style="margin-right:0.00773em;">R</span></span></span></span>.</p><h3 id="how-do-we-ensure-that-nobody-observes-partially-written-files-in-the-presence-of-crashes"><a class="markdownIt-Anchor" href="#how-do-we-ensure-that-nobody-observes-partially-written-files-in-the-presence-of-crashes"></a> How do we ensure that nobody observes partially written files in the presence of crashes?</h3><p>Each worker first write their results to a temporary file. Then rename it once all writtens are completed.</p><h3 id="how-to-handle-straggler-problem"><a class="markdownIt-Anchor" href="#how-to-handle-straggler-problem"></a> How to handle straggler problem?</h3><ol><li>Straggler: a machine that takes an unusually long time to complete on of the last few map or reduce tasks. This may be caused by a bad disk, its scheduling system scheduling it a different other tasks.</li><li>So when a MapReduce operation is close to completion, the master schedules backup executions of the remaining in-progress tasks.</li></ol><h2 id="reproduce"><a class="markdownIt-Anchor" href="#reproduce"></a> Reproduce</h2><p>This reproduce part is based on the Lab 1 of MIT 6.824.</p><h3 id="how-do-we-assign-map-tasks"><a class="markdownIt-Anchor" href="#how-do-we-assign-map-tasks"></a> How do we assign map tasks?</h3><p>Each worker will request for more map tasks when it becomes idle, and the master will assign files directly to them.</p><h3 id="how-do-we-assign-reduce-tasks"><a class="markdownIt-Anchor" href="#how-do-we-assign-reduce-tasks"></a> How do we assign reduce tasks?</h3><ol><li>When worker is notified that there is no more map tasks, they will begin to request for reduce tasks. This time, the master won’t assign files directly, instead, master will only assign a number in the range from <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>0</mn></mrow><annotation encoding="application/x-tex">0</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">0</span></span></span></span> to <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>R</mi><mo>−</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">R-1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.76666em;vertical-align:-0.08333em;"></span><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">1</span></span></span></span>. Then each worker will try to read intermediate files from each workers according to its number automatically.</li><li>This requires those map workers store their output in a previously agreed file name for reduce workers to request.</li></ol><h3 id="when-can-workers-stop-requesting-for-more-map-tasksreduce-tasks"><a class="markdownIt-Anchor" href="#when-can-workers-stop-requesting-for-more-map-tasksreduce-tasks"></a> When can workers stop requesting for more map tasks/reduce tasks?</h3><ol><li>Only after all map tasks is completed, workers can stop requesting for more map tasks and begin to request for reduce tasks, since reduce tasks may depend on those unfinished map tasks. So the lifecycle of workers can be partitioned into two phase, the map phase and the reduce phase.</li><li>Also, only after all reduce tasks is completed, workers can stop requesting for more reduce tasks and quit the program. This is because those executing, yet uncompleted, tasks may fail, and when that happens, we need other workers to re-execute those tasks.</li><li>Similarly, reduce workers cannot delete those intermediate files right after they read them. Because if they fail, their successor need to read those files.</li></ol><h1 id="experiments-and-results"><a class="markdownIt-Anchor" href="#experiments-and-results"></a> Experiments and results</h1><ol><li><strong>What to notice when configurate cluster?</strong><ul><li>Need to reserve some memory for other tasks running on the cluster. The author reserved <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1</mn><mo>−</mo><mn>1.5</mn></mrow><annotation encoding="application/x-tex">1-1.5</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.72777em;vertical-align:-0.08333em;"></span><span class="mord">1</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">1</span><span class="mord">.</span><span class="mord">5</span></span></span></span> GB out of <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>4</mn></mrow><annotation encoding="application/x-tex">4</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">4</span></span></span></span> GB.</li><li>Best test when the CPUs, disks, and network were mostly idle.</li></ul></li><li>The author tested two representative situations, grep and sort.</li><li>In the grep test, the execution time includes a minute of startup overhead over <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>150</mn></mrow><annotation encoding="application/x-tex">150</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">1</span><span class="mord">5</span><span class="mord">0</span></span></span></span> seconds of total time. The overhead is due to the propagation of the program to all worker machines, and delays interacting with GFS to open the set of input files and to get the information needed for the locality optimization.<br /><img src="/imgs/Distributed/MapReduce/02.png" style="zoom: 33%;" /></li><li>In the sort test,<ul><li>It only consists of less than <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>50</mn></mrow><annotation encoding="application/x-tex">50</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">5</span><span class="mord">0</span></span></span></span> lines of user code</li><li>The entire computation time including startup overhead is similar to the best reported result at that time.</li><li>The author tested three kind of rates, the rate of reading by map workers (<em>input rate</em>), the rate of communicating intermediate files between map workers and reduce workers (<em>shuffle rate</em>), and the rate of writing output files by reduce workers (<em>output rate</em>). These are the I/O parts which affect the perfornmence significantly.<ul><li>The input rate is less than grep, because sort map tasks spend more time writing intermediate output to their local disks.</li><li>The input rate is higher than the shuffle rate and the output rate because of locality optimization.</li><li>The shuffle rate is higher than the output rate because the output phase writes replicas due to the mechanism for reliability  of the underlying file system.</li></ul></li><li>The author also tested when <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>200</mn></mrow><annotation encoding="application/x-tex">200</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">2</span><span class="mord">0</span><span class="mord">0</span></span></span></span> out of <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1746</mn></mrow><annotation encoding="application/x-tex">1746</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">1</span><span class="mord">7</span><span class="mord">4</span><span class="mord">6</span></span></span></span> workers are killed several minutes. The underlying cluster scheduler immediately restarted new worker processes on these mechines (only the processes were killed, the machines were still functioning properly). The entire computation time increases of <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>5</mn><mi mathvariant="normal">%</mi></mrow><annotation encoding="application/x-tex">5\%</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.80556em;vertical-align:-0.05556em;"></span><span class="mord">5</span><span class="mord">%</span></span></span></span> over the normal execution time.<br /><img src="/imgs/Distributed/MapReduce/03.png" style="zoom:50%;" /></li></ul></li></ol>]]></content>
      
      
      <categories>
          
          <category> Paper Notebook </category>
          
          <category> Distributed System </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Distributed System </tag>
            
            <tag> Distributed Computation </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>17 Distributed OLAP Databases</title>
      <link href="/2023/09/03/Courses/15445/17-Distributed-OLAP-Databases/"/>
      <url>/2023/09/03/Courses/15445/17-Distributed-OLAP-Databases/</url>
      
        <content type="html"><![CDATA[<p><ul class="markdownIt-TOC"><li><a href="#how-should-we-divide-tables">How should we divide tables?</a></li><li><a href="#execution-models">Execution models</a><ul><li><a href="#how-to-execute-when-required-data-are-in-different-nodes">How to execute when required data are in different nodes?</a></li><li><a href="#how-to-handle-query-fault">How to handle query fault?</a></li><li><a href="#when-pushing-query-to-data-what-are-the-queries">When pushing query to data, what are the queries?</a></li></ul></li><li><a href="#distributed-join-algorithms">Distributed Join Algorithms</a><ul><li><a href="#how-to-perform-distributed-joins">How to perform distributed joins?</a></li><li><a href="#what-is-semi-join">What is semi-join?</a></li></ul></li><li><a href="#cloud-systems">Cloud systems</a><ul><li><a href="#what-is-the-difference-for-dbmss-running-in-cloud-systems">What is the difference for DBMSs running in cloud systems?</a></li><li><a href="#how-to-store-data-of-different-schema">How to store data of different schema?</a></li><li><a href="#how-to-share-data-between-systems">How to share data between systems?</a></li></ul></li></ul></p><h1 id="how-should-we-divide-tables"><a class="markdownIt-Anchor" href="#how-should-we-divide-tables"></a> How should we divide tables?</h1><ol><li>The first schema is star schema.<ul><li>Star schemas contain two types of tables: fact tables and dimension tables.</li><li>The fact table contains multiple “events” that occur in the application. It will contain the minimal unique information per event.</li><li>The rest of the attributes will be foreign key references to outer dimension tables.</li><li>In a star schema, there can only be one dimension-level out from the fact table.</li></ul></li><li>The second schema is snowflake schema.<ul><li>It allows for more than one dimension out from the fact table.</li></ul></li><li>Snowflake schemas take up less storage space. Denormalized data models may incur integrity and consistency violations.</li><li>Snowflake schemas require more joins to get the data needed for a query. Queries on star schemas will usually be faster.</li></ol><h1 id="execution-models"><a class="markdownIt-Anchor" href="#execution-models"></a> Execution models</h1><h2 id="how-to-execute-when-required-data-are-in-different-nodes"><a class="markdownIt-Anchor" href="#how-to-execute-when-required-data-are-in-different-nodes"></a> How to execute when required data are in different nodes?</h2><ol><li>The first approach is to push query to data.<ul><li>Send the query (or a portion of it) to the node that contains the data.</li><li>The result is then sent back to where the query is being executed, which uses local data and the data sent to it, to complete the query.</li><li>Perform as much filtering and processing as possible where data resides before transmitting over network.</li><li>This is more common in a shared nothing system.</li></ul></li><li>The second approach is to pull data to query.<ul><li>Bring the data to the node that is executing a query that needs it for processing.</li><li>This is normally what a shared disk system would do.</li><li>The problem with this is that the size of the data relative to the size of the query could be very different.</li></ul></li></ol><h2 id="how-to-handle-query-fault"><a class="markdownIt-Anchor" href="#how-to-handle-query-fault"></a> How to handle query fault?</h2><ol><li>The data that a node receives from remote sources are cached in the buffer pool.<ul><li>When buffer pool run out of memory, the DBMS can write some pages out to disk in some ephemeral pages.</li><li>This allows the DBMS to support intermediate results that are large than the amount of memory available.</li><li>Ephemeral pages are not persisted after a restart.</li></ul></li><li>Most shared-nothing distributed OLAP DBMSs are designed to assume that nodes do not fail during query execution.<ul><li>If one node fails during query execution, then the whole query fails.</li></ul></li><li>The DBMS could take a snapshot of the intermediate results for a query during execution to allow it to recover if nodes fail.<ul><li>Most of the DMBSs do not want to pay the penalty of writing intermediate results to disk for quick queries.</li><li>This is adopted if the query takes a long time.</li></ul></li><li>In shared-disk distributed OLAP DMBSs, they can write results to the shared disk to prevent performing the same calculation again. However, the frequency of writing to disk is also a trade-off.</li></ol><h2 id="when-pushing-query-to-data-what-are-the-queries"><a class="markdownIt-Anchor" href="#when-pushing-query-to-data-what-are-the-queries"></a> When pushing query to data, what are the queries?</h2><ol><li>The DBMSs only need to push fragments of the query instead of the whole query.</li><li>The first approach is pushing physical operators.<ul><li>Generate a single query plan and then break it up into partition-specific  fragments.</li><li>Most systems implement this approach.</li></ul></li><li>The second approach is pushing another SQL query.<ul><li>The DBMS will rewrite original query into partition-specific queries.</li><li>This approach allows for local optimization at each node.</li></ul></li></ol><h1 id="distributed-join-algorithms"><a class="markdownIt-Anchor" href="#distributed-join-algorithms"></a> Distributed Join Algorithms</h1><h2 id="how-to-perform-distributed-joins"><a class="markdownIt-Anchor" href="#how-to-perform-distributed-joins"></a> How to perform distributed joins?</h2><ol><li>One approach is to put entire tables on a single node and then perform the join.<ul><li>You lose the parallelism of a distributed DBMS.</li><li>It has expensive data transferring over the network.</li></ul></li><li>To join tables, the DBMS needs to get the proper tuples on the same node. Once the data is at the node, the DBMS then executes the single-node join algorithms.</li><li>The best scenario is that one table is replicated at every node.<ul><li>Each node joins its local data in parallel and then sends their results to a coordinating node.</li></ul></li><li>The second scenario is that tables are partitioned on the join attribute.<ul><li>Each node only needs to acquire tuples of the second table that will match the tuples of the left table that are already in it.</li><li>Each node performs the join on local data and then sends to a coordinator node for coalescing.</li></ul></li><li>The third scenario is that both tables are partitioned on different keys while one of the tables is small.<ul><li>The DBMS will broadcast that table to all nodes.</li></ul></li><li>The worst scenario is that both tables are not partitioned on the join key.<ul><li>The DBMS copies the tables by shuffling them across nodes.</li></ul></li></ol><h2 id="what-is-semi-join"><a class="markdownIt-Anchor" href="#what-is-semi-join"></a> What is semi-join?</h2><ol><li>If the result only contains columns sfrom the left table, the DBMSs use semi-join to minimize the amount of data sent during joins.</li><li>This is like a projection pushdown. The DBMS transmits only the necessary columns of the left table to other nodes.</li><li>For DBMSs that do not support <code>SEMI JOIN</code>, we can fake it with <code>EXISTS</code>.<ul><li>Wrap the predicates of <code>WHERE</code>  clause with <code>EXISTS (SELECT 1 from S WHERE predicates)</code>.</li></ul></li></ol><h1 id="cloud-systems"><a class="markdownIt-Anchor" href="#cloud-systems"></a> Cloud systems</h1><h2 id="what-is-the-difference-for-dbmss-running-in-cloud-systems"><a class="markdownIt-Anchor" href="#what-is-the-difference-for-dbmss-running-in-cloud-systems"></a> What is the difference for DBMSs running in cloud systems?</h2><ol><li>The first approach is managed DBMS.<ul><li>No significant modification to the DBMS to be aware that it is running in a cloud environment.</li></ul></li><li>The second approach is cloud-native DBMS.<ul><li>The system is designed explicitly to run in a cloud environment.</li><li>Usually based on a shared-disk architecture.</li></ul></li><li>A “serverless” DBMS evicts tenants when they become idle, rather than always maintaining compute resources for each customer.</li></ol><h2 id="how-to-store-data-of-different-schema"><a class="markdownIt-Anchor" href="#how-to-store-data-of-different-schema"></a> How to store data of different schema?</h2><ol><li>A Data Lake is a centralized repository for storing large amounts of structured, semi-structured, and un- structured data without having to define a schema or ingest the data into proprietary internal formats.</li><li>Data lakes are usually faster at ingesting data, as they do not require transformation right away. Yet, when they are fetching data, they need to look up the catalog before transforming data into the desired schema.</li><li>They do require the user to write their own transformation piplines.</li></ol><h2 id="how-to-share-data-between-systems"><a class="markdownIt-Anchor" href="#how-to-share-data-between-systems"></a> How to share data between systems?</h2><ol><li>Most DBMSs use a proprietary on-disk binary file format for their databases.</li><li>The only way to share data between systems is to convert data into a common text-based format.</li><li>There are new open-source binary file formats that make it easier to access data across systems.</li></ol>]]></content>
      
      
      <categories>
          
          <category> Open Courses </category>
          
          <category> CMU 15-445/645 Database System </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Database System </tag>
            
            <tag> Distributed System </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>16 Distributed OLTP Databases</title>
      <link href="/2023/09/02/Courses/15445/16-Distributed-OLTP-Databases/"/>
      <url>/2023/09/02/Courses/15445/16-Distributed-OLTP-Databases/</url>
      
        <content type="html"><![CDATA[<p><ul class="markdownIt-TOC"><li><a href="#what-is-the-difference-between-oltp-and-olap">What is the difference between OLTP and OLAP?</a></li><li><a href="#2-phase-commit-2pc">2-Phase Commit (2PC)</a><ul><li><a href="#what-is-the-procedure-of-2pc">What is the procedure of 2PC?</a></li><li><a href="#what-would-happen-if-some-nodes-crash-during-2pc">What would happen if some nodes crash during 2PC?</a></li><li><a href="#how-to-recover-from-crash-during-2pc">How to recover from crash during 2PC?</a></li><li><a href="#how-can-we-optimize-2pc-to-reduce-communication">How can we optimize 2PC to reduce communication?</a></li><li><a href="#what-is-the-difference-betwen-2pc-and-paxos">What is the difference betwen 2PC and Paxos?</a></li></ul></li><li><a href="#replication">Replication</a><ul><li><a href="#how-can-we-execute-readwrite-with-replication">How can we execute read/write with replication?</a></li><li><a href="#when-should-notify-application-of-result">When should notify application of result?</a></li><li><a href="#when-should-propagate-updates-between-nodes">When should propagate updates between nodes?</a></li><li><a href="#what-should-be-sent-to-the-followers">What should be sent to the followers?</a></li></ul></li></ul></p><h1 id="what-is-the-difference-between-oltp-and-olap"><a class="markdownIt-Anchor" href="#what-is-the-difference-between-oltp-and-olap"></a> What is the difference between OLTP and OLAP?</h1><ol><li>OLTP is the front-end databases that communicate and interact with the outside world, e.g. applications. And OLAP is the back-end databases that used to analyze the data in those front-end databases.</li><li>OLTP often executes repetitive short-lived read/write txns, while OLAP executes long-running, read-only queries involving complex joins.</li><li>Before going into OLAP system, data in OLTP databases need an intermediate step called ETL, or Extract, Transform, and Load, which combines the OLTP databases into a universal schema for the data warehouse.</li></ol><h1 id="2-phase-commit-2pc"><a class="markdownIt-Anchor" href="#2-phase-commit-2pc"></a> 2-Phase Commit (2PC)</h1><h2 id="what-is-the-procedure-of-2pc"><a class="markdownIt-Anchor" href="#what-is-the-procedure-of-2pc"></a> What is the procedure of 2PC?</h2><ol><li>When application sends a commit request to the coordinator, the coordinator tells other nodes to go into the first phase, prepare phase.</li><li>When participants are ready, they will reply to the coordinator with acknowledgement.</li><li>If the coordinator receives acknoledgement from all participants, they can begin the second phase, commit phase.<ul><li>And the coordinator will response to application with success after receiving all acknowledgement of commit phase from all participants.</li></ul></li><li>If the coordinator receives abort messages from any of the participants, the coordinator responses to application with abort message and begins the abort phase.<ul><li>As usual, participants need to reply acknowledgement to coordinator in abort phase.</li></ul></li></ol><h2 id="what-would-happen-if-some-nodes-crash-during-2pc"><a class="markdownIt-Anchor" href="#what-would-happen-if-some-nodes-crash-during-2pc"></a> What would happen if some nodes crash during 2PC?</h2><ol><li>If the coordinator crashes, participants must decide what to do after a timeout, either abort or elect a new coordinator.<ul><li>The system is not available during this timeout.</li></ul></li><li>If one of the participants crashes, coordinator assumes that it responded with an abort if it hasn’t sent an acknowledgement yet.<ul><li>Nodes use a timeout to determine that participant is dead.</li></ul></li></ol><h2 id="how-to-recover-from-crash-during-2pc"><a class="markdownIt-Anchor" href="#how-to-recover-from-crash-during-2pc"></a> How to recover from crash during 2PC?</h2><ol><li>Each node records the inbound/outbound messages and outcome of each phase in a non-volatile storage log.</li><li>On recovery, examine the log for 2PC messages<ul><li>If local txn in prepared state, contact coordinator.</li><li>If local txn not in prepared, abort it.</li><li>If local txn was committing and node is the coordinator, send <code>COMMIT</code> message to nodes.</li></ul></li></ol><h2 id="how-can-we-optimize-2pc-to-reduce-communication"><a class="markdownIt-Anchor" href="#how-can-we-optimize-2pc-to-reduce-communication"></a> How can we optimize 2PC to reduce communication?</h2><ol><li>The first method is early prepare voting.<ul><li>If you send a query to a remote node that you know will be the last one you execute there, then that node will also return their vote for the prepare phase with the query result.</li><li>This is rare due to rarely write database application with the idea of last query.</li><li>However, this can be used in RPC sorts of things where we can sure that this process will terminate after executed certain query.</li></ul></li><li>The second method is early ACK after prepare.<ul><li>If all nodes vote to commit a txn, the coordinator can send the client an acknowledgement that their txn was successful before the commit phase finishes, i.e. send acknowledgement to client after receiving all acknowledgement from participants.</li><li>This could cause a small windown of client receiving success, yet cannot see modifications from servers due to commit phase is not finished yet.</li></ul></li></ol><h2 id="what-is-the-difference-betwen-2pc-and-paxos"><a class="markdownIt-Anchor" href="#what-is-the-difference-betwen-2pc-and-paxos"></a> What is the difference betwen 2PC and Paxos?</h2><ol><li>2-phase commit is a degenerate case of Paxos.<ul><li>Paxos uses <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>2</mn><mi>F</mi><mo>+</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">2F + 1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.76666em;vertical-align:-0.08333em;"></span><span class="mord">2</span><span class="mord mathnormal" style="margin-right:0.13889em;">F</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">1</span></span></span></span> coordinators and makes progress as long as at least <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>F</mi><mo>+</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">F + 1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.76666em;vertical-align:-0.08333em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">F</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">1</span></span></span></span> of them are working properly.</li><li>2-phase commit sets <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>F</mi><mo>=</mo><mn>0</mn></mrow><annotation encoding="application/x-tex">F = 0</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">F</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">0</span></span></span></span>.</li></ul></li><li>2-phase commit blocks if coordinator fails after the prepare message is sent, until coordinator recovers.<br />Paxos remains non-blocking if a majority participants are alive, provided there is a sufficiently long period without further failures.</li><li>2-phase commit requires all nodes to agree on the commit while Paxos only requires majority agreement.</li><li>In 2-phase commit, each node may have different data, executing different commands. However, in Paxos, all nodes are only replications.</li></ol><h1 id="replication"><a class="markdownIt-Anchor" href="#replication"></a> Replication</h1><h2 id="how-can-we-execute-readwrite-with-replication"><a class="markdownIt-Anchor" href="#how-can-we-execute-readwrite-with-replication"></a> How can we execute read/write with replication?</h2><ol><li>The first approach is primary-replica.<ul><li>All updates go to a designated primary for each object. The primary propagates updates to its replicas without an atomic commit protocol.</li><li>Read-only txns may be allowed to access replicas.</li><li>If the primary goes down, then hold an election to select a new primary.</li></ul></li><li>The second approach is multi-primary.<ul><li>Txns can update data objects at any replica.</li><li>Replicas must synchronize with each other using an atomic commit protocol.</li></ul></li></ol><h2 id="when-should-notify-application-of-result"><a class="markdownIt-Anchor" href="#when-should-notify-application-of-result"></a> When should notify application of result?</h2><ol><li>When a txn commits on a replicated database, the DBMS decides whether it must wait for that txn’s changes to propagate to other nodes before it can send the acknowledgement to application.</li><li>The first propagation level is synchronous, which leads to strong consistency.<ul><li>The primary sends updates to replicas and then waits for them to acknowledge that they fully applied (i.e., logged) the changes before sending acknowledgement to application.</li></ul></li><li>The second propagation level is asynchronous, which leads to eventual consistency.<ul><li>The primary immediately returns the acknowledgement to the client without waiting for replicas to apply the changes.</li></ul></li></ol><h2 id="when-should-propagate-updates-between-nodes"><a class="markdownIt-Anchor" href="#when-should-propagate-updates-between-nodes"></a> When should propagate updates between nodes?</h2><ol><li>The first approach is continuous.<ul><li>The DBMS sends log messages immediately as it generates them.</li><li>It also needs to send a commit/abort message.</li></ul></li><li>The second approach is on commit.<ul><li>The DBMS only sends the log messages for a txn to the replicas once the txn is commits.</li><li>Do not waste time sending log records for aborted txns.</li><li>It assumes that a txn’s log records fits entirely in memory.</li></ul></li></ol><h2 id="what-should-be-sent-to-the-followers"><a class="markdownIt-Anchor" href="#what-should-be-sent-to-the-followers"></a> What should be sent to the followers?</h2><ol><li>The first choice is active-active.<ul><li>A txn executes at each replica independently.</li><li>Need to check at the end whether the txn ends up with the same result at each replica.</li></ul></li><li>The second choice is active-passive.<ul><li>Each txn executes at a single location and propagates the changes to the replica.</li><li>Can either do physical or logical replication.</li></ul></li></ol>]]></content>
      
      
      <categories>
          
          <category> Open Courses </category>
          
          <category> CMU 15-445/645 Database System </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Database System </tag>
            
            <tag> Distributed System </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>15 Introduction to Distributed Databases</title>
      <link href="/2023/08/31/Courses/15445/15-Introduction-to-Distributed-Databases/"/>
      <url>/2023/08/31/Courses/15445/15-Introduction-to-Distributed-Databases/</url>
      
        <content type="html"><![CDATA[<p><ul class="markdownIt-TOC"><li><a href="#system-architecture">System architecture</a><ul><li><a href="#what-will-system-architecture-affect">What will system architecture affect?</a></li><li><a href="#what-is-shared-memory-architecture">What is shared memory architecture?</a></li><li><a href="#what-is-shared-disk-architecture">What is shared disk architecture?</a></li><li><a href="#what-is-shared-nothing-architecture">What is shared nothing architecture?</a></li></ul></li><li><a href="#design-issues">Design issues</a><ul><li><a href="#what-are-the-design-issues-of-distributed-database">What are the design issues of distributed database?</a></li><li><a href="#what-do-nodes-look-like">What do nodes look like?</a></li><li><a href="#how-to-coordinate-execution">How to coordinate execution?</a></li></ul></li><li><a href="#partitioning-schemes">Partitioning Schemes</a><ul><li><a href="#what-do-we-desire-when-partitioning-database">What do we desire when partitioning database?</a></li><li><a href="#how-can-we-partition-database">How can we partition database?</a></li><li><a href="#how-can-we-optimize-horizontal-partitioning">How can we optimize horizontal partitioning?</a></li></ul></li></ul></p><h1 id="system-architecture"><a class="markdownIt-Anchor" href="#system-architecture"></a> System architecture</h1><h2 id="what-will-system-architecture-affect"><a class="markdownIt-Anchor" href="#what-will-system-architecture-affect"></a> What will system architecture affect?</h2><ol><li>A distributed DBMS’s system architecture specifies what shared resources are directly accessible to CPUs.</li><li>This affects how CPUs coordinate with each other and where they retrieve/store objects in the database.</li><li>There are four architectures: shared everything, shared memory, shared disk and shared nothing.</li><li>In shared everything architecture, CPU, memories and disks are all in local. This is more of a parallel architecture than a distributed architecture.</li></ol><h2 id="what-is-shared-memory-architecture"><a class="markdownIt-Anchor" href="#what-is-shared-memory-architecture"></a> What is shared memory architecture?</h2><ol><li>CPUs have access to common memory address space via a fast interconnect.</li><li>Each processor has a global view of all the in-memory data structures.<ul><li>Each process’s scope of memory is the same memory address space, which can be modified by multiple processes.</li></ul></li><li>Each DBMS instance on a processor must “know” about the other instances.</li><li>In practice, most DBMSs do not use this architecture, as it is provided at the OS / kernel level.</li></ol><img src="/imgs/15445/Distributed/shared_mem.png" width="30%"><h2 id="what-is-shared-disk-architecture"><a class="markdownIt-Anchor" href="#what-is-shared-disk-architecture"></a> What is shared disk architecture?</h2><ol><li>All CPUs can access a single logical disk directly via an interconnect, but each have their own private memories.</li><li>It can scale execution layer independently from the storage layer.<ul><li>The advantage of shared disk over shared nothing is that it can easily scale up with compute layer and storage layer independent.</li><li>What we want to persist after crash is in the storage layer.</li><li>Theoretically, we can kill or add front-end nodes without losing database or add storage disks / change storage layer with modfying compute nodes.</li></ul></li><li>It must send messages between CPUs to learn about their current state.</li><li>This architecture is commonly used in OLAP systems. Many DBSMs begin to think that shared disk architecture is better than shared nothing.</li></ol><img src="/imgs/15445/Distributed/shared_disk.png" width="30%"><h2 id="what-is-shared-nothing-architecture"><a class="markdownIt-Anchor" href="#what-is-shared-nothing-architecture"></a> What is shared nothing architecture?</h2><ol><li>Each DBMS instance has its own CPU, memory, and local disk.</li><li>Nodes only communicate with each other via network.<ul><li>When executing a query that requires data from different nodes, the DBMS can either send data up to the node connected with application, or that node can ask another node to execute the query and return the result.</li></ul></li><li>All data in the database are sharded into different nodes.<ul><li>When adding a new node into the architecture, that node is initially empty. The DBMS must re-shard data so that they are distributed evenly.</li><li>It is more difficult to increase capacity because the DBMS has to physically move data to new nodes.</li><li>It might have small window for queries to receive false positive due to that part of data was in that node and now moving to another node.</li></ul></li><li>It is also difficult to ensure consistency across all nodes in the DBMS, since the nodes must coordinate with each other on the state of transactions.</li><li>However, it can potentially achieve better performance and are more efficient then other types of distributed DBMS architectures.</li></ol><img src="/imgs/15445/Distributed/shared_nothing.png" width="30%"><h1 id="design-issues"><a class="markdownIt-Anchor" href="#design-issues"></a> Design issues</h1><h2 id="what-are-the-design-issues-of-distributed-database"><a class="markdownIt-Anchor" href="#what-are-the-design-issues-of-distributed-database"></a> What are the design issues of distributed database?</h2><ol><li>How does the application find data?</li><li>Where does the application send queries?</li><li>How to execute queries on distributed data? Push query to data? Or pull data to query?</li><li>How does the DBMS ensure correctness?</li><li>How do we divide the database across resources?</li></ol><h2 id="what-do-nodes-look-like"><a class="markdownIt-Anchor" href="#what-do-nodes-look-like"></a> What do nodes look like?</h2><ol><li>The first approach is homogenous nodes.<ul><li>Every node in the cluster can perform the same set of tasks albeit on potentially different partitions of data.</li><li>Makes provisioning and failover “easier” since any node can replace other nodes.</li></ul></li><li>The second approach is heterogenous nodes.<ul><li>Nodes are assigned specific tasks.</li><li>It can allow a single physical node to host multiple “virtual” node types for dedicated tasks.</li><li>A design of heterogenous nodes have two kinds of nodes router and config server.<ul><li>Router can directly access shards of database yet it does not know where are that data they want.</li><li>Config server knows the data contained in each shards. However, it does not responsible for retrieving them.</li></ul></li></ul></li></ol><h2 id="how-to-coordinate-execution"><a class="markdownIt-Anchor" href="#how-to-coordinate-execution"></a> How to coordinate execution?</h2><ol><li>If our DBMS supports multi-operation and distributed transactions, we need a way to coordinate their execution in the system.</li><li>The first approach is centerlized coordinator. There is a centralized coordinator that receives commands from application.<ul><li>The first design requires applications to handle transactions.<ul><li>The client communicates with the coordinator to acquire locks on the partitions that the client wants to access.</li><li>Once it receives an acknowledgement from the coordinator, the client sends its queries to those partitions.</li><li>Once all queries for a given transaction are done, the client sends a commit request to the coordinator.</li><li>The coordinator then communicates with the partitions involved in the transaction to determine whether the transaction is allowed to commit.</li></ul></li><li>Another design uses a middleware to accept query requests and routes queries to correct partitions.</li></ul></li><li>The second approach is decentralized.<ul><li>The client directly sends queries to one of the partitions which will be the leader node of that transaction.</li><li>The leader node will coordinate the following communicating with other partitions and committing.</li></ul></li></ol><h1 id="partitioning-schemes"><a class="markdownIt-Anchor" href="#partitioning-schemes"></a> Partitioning Schemes</h1><h2 id="what-do-we-desire-when-partitioning-database"><a class="markdownIt-Anchor" href="#what-do-we-desire-when-partitioning-database"></a> What do we desire when partitioning database?</h2><ol><li>Applications should not be required to know where data is physically located in a distributed DBMS.<ul><li>Any query that run on a single-node DBMS should produce the same result on a distributed DBMS.</li><li>The DBMS executes query fragments on each partition and then combines the results to produce a single answer.</li></ul></li><li>In practice, developers need to be aware of the communication costs of queries to avoid excessively “expensive” data movement.</li><li>The DBMS can partition a database physically for shared nothing or logically for shared disk.<ul><li>In Logical partitioning, each node is responsible for certain designated data. They cannot access data out of their duty. Though data are actually stored in independent storage nodes which computation nodes all can access.</li><li>In physical partitioning, data out of their duty cannot be accessed directly since they are stored in the local disk of other nodes.</li></ul></li></ol><h2 id="how-can-we-partition-database"><a class="markdownIt-Anchor" href="#how-can-we-partition-database"></a> How can we partition database?</h2><ol><li>The first method is the naive table partitioning.<ul><li>Assign an entire table to a single node.</li><li>It assumes that each node has enough storage space for an entire table.</li><li>This is ideal if queries never join data across tables stored on different nodes and access patterns are uniform.</li></ul></li><li>The second method is vertical partitioning.<ul><li>Split a table’s attributes into separate partitions.</li><li>It must store tuple information to reconstruct the original record.</li></ul></li><li>The third method is horizontal partitioning.<ul><li>Split a table’s tuples into disjoint subsets based on some partitioning key and scheme.</li><li>Choose column(s) that divides the database equally in terms of size, load, or usage.</li><li>It can partition based on hashing, ranges, or predicates.</li></ul></li></ol><h2 id="how-can-we-optimize-horizontal-partitioning"><a class="markdownIt-Anchor" href="#how-can-we-optimize-horizontal-partitioning"></a> How can we optimize horizontal partitioning?</h2><ol><li>The main problem is that when adding a new storage nodes, the DBMS needs to reshuffle data.</li><li>We can use the consistent hashing.<ul><li>The hashing value is betwen <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>0</mn></mrow><annotation encoding="application/x-tex">0</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">0</span></span></span></span> and <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1</mn></mrow><annotation encoding="application/x-tex">1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">1</span></span></span></span> forming a circle.</li><li>Each nodes are assigned a value betwen <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>0</mn></mrow><annotation encoding="application/x-tex">0</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">0</span></span></span></span> and <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1</mn></mrow><annotation encoding="application/x-tex">1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">1</span></span></span></span>. Data are stored in the node with the closest value to its hashing values going in clock-wise order.</li><li>When adding a node, only one node needs to transmit data to the new node, instead of transmit data between all pairs of nodes.</li></ul></li><li>With consistent hashing, we can support replication easily.<ul><li>Just store data in the first batch of nodes with closest value in clock-wise order.</li></ul></li></ol>]]></content>
      
      
      <categories>
          
          <category> Open Courses </category>
          
          <category> CMU 15-445/645 Database System </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Database System </tag>
            
            <tag> Distributed System </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>14 Database Recovery</title>
      <link href="/2023/08/30/Courses/15445/14-Database-Recovery/"/>
      <url>/2023/08/30/Courses/15445/14-Database-Recovery/</url>
      
        <content type="html"><![CDATA[<p><ul class="markdownIt-TOC"><li><a href="#what-are-the-main-ideas-of-aries">What are the main ideas of ARIES?</a></li><li><a href="#record-logs">Record logs</a><ul><li><a href="#what-are-the-lsns">What are the LSNs?</a></li><li><a href="#how-to-handle-transaction-commit">How to handle transaction commit?</a></li><li><a href="#how-to-handle-transaction-abort">How to handle transaction abort?</a></li></ul></li><li><a href="#fuzzy-checkpoints">Fuzzy checkpoints</a><ul><li><a href="#how-can-we-improve-the-naive-checkpoints">How can we improve the naive checkpoints?</a></li><li><a href="#how-can-we-checkpoint-without-stalling-transactions">How can we checkpoint without stalling transactions?</a></li></ul></li><li><a href="#recovery">Recovery</a><ul><li><a href="#how-does-aries-recover-from-crash">How does ARIES recover from crash?</a></li><li><a href="#what-does-analysis-phase-do">What does analysis phase do?</a></li><li><a href="#what-does-redo-phase-do">What does redo phase do?</a></li><li><a href="#what-does-undo-phase-do">What does undo phase do?</a></li></ul></li></ul></p><h1 id="what-are-the-main-ideas-of-aries"><a class="markdownIt-Anchor" href="#what-are-the-main-ideas-of-aries"></a> What are the main ideas of ARIES?</h1><ol><li>ARIES: Algorithms for Recovery and Isolation Exploiting Semantics</li><li>Write-Ahead Logging:<ul><li>Any change is recorded in log on stable storage before the database change is written to disk.</li><li>Must use steal and no-force buffer pool policies.<ul><li>Logs are forced to be flushed into disk while modified pages are not.</li><li>Force is also correct, but it damages runtime performance, which makes no one uses it.</li></ul></li></ul></li><li>Repeating History During Redo: On DBMS restart, retrace actions and restore database to exact state before crash.</li><li>Logging Changes During Undo: Record undo actions to log to ensure action is not repeated in the event of repeated failures.</li></ol><h1 id="record-logs"><a class="markdownIt-Anchor" href="#record-logs"></a> Record logs</h1><h2 id="what-are-the-lsns"><a class="markdownIt-Anchor" href="#what-are-the-lsns"></a> What are the LSNs?</h2><ol><li>Every log record now includes a globally unique, monotonically increasing log sequence number (LSN).<ul><li>LSNs represent the physical order that transactions make changes to the database.</li></ul></li><li>Various components in the system keep track of LSNs that pertain to them<ul><li>In memory, the system uses <code>flushedLSN</code> to track the last LSN in log on disk.</li><li>In each page in disk, <code>pageLSN</code> is used to track the newest update to that page while <code>recLSN</code> is tracking the oldest update to that page since it was last flushed.</li><li>Each transaction maintains <code>lastLSN</code> representing the latest record of that transaction.</li><li>In disk, there is also a <code>MasterRecord</code> meaning the LSN of latest checkpoint.</li></ul></li><li>Before the DBMS can write page x to disk, it must flush the log at least to the point where <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi><mi>a</mi><mi>g</mi><mi>e</mi><mi>L</mi><mi>S</mi><msub><mi>N</mi><mi>x</mi></msub><mo>≤</mo><mi>f</mi><mi>l</mi><mi>u</mi><mi>s</mi><mi>h</mi><mi>e</mi><mi>d</mi><mi>L</mi><mi>S</mi><mi>N</mi></mrow><annotation encoding="application/x-tex">pageLSN_x ≤ flushedLSN</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8777699999999999em;vertical-align:-0.19444em;"></span><span class="mord mathnormal">p</span><span class="mord mathnormal">a</span><span class="mord mathnormal" style="margin-right:0.03588em;">g</span><span class="mord mathnormal">e</span><span class="mord mathnormal">L</span><span class="mord mathnormal" style="margin-right:0.05764em;">S</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.10903em;">N</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:-0.10903em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">x</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">≤</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="mord mathnormal" style="margin-right:0.01968em;">l</span><span class="mord mathnormal">u</span><span class="mord mathnormal">s</span><span class="mord mathnormal">h</span><span class="mord mathnormal">e</span><span class="mord mathnormal">d</span><span class="mord mathnormal">L</span><span class="mord mathnormal" style="margin-right:0.05764em;">S</span><span class="mord mathnormal" style="margin-right:0.10903em;">N</span></span></span></span>.</li><li>Update the <code>pageLSN</code> every time a transaction modifies a record in the page.</li><li>Update the <code>flushedLSN</code> in memory every time the DBMS writes out the WAL buffer to disk.</li></ol><h2 id="how-to-handle-transaction-commit"><a class="markdownIt-Anchor" href="#how-to-handle-transaction-commit"></a> How to handle transaction commit?</h2><ol><li>When a transaction commits, the DBMS writes a <code>COMMIT</code> record to log and guarantees that all log records up to transaction’s <code>COMMIT</code> record are flushed to disk.<ul><li>Log flushes are sequential, synchronous writes to disk.</li></ul></li><li>When the commit succeeds, write a special <code>TXN-END</code> record to log.<ul><li>Indicates that no new log record for a transaction will appear in the log ever again.</li><li>This does not need to be flushed immediately.</li></ul></li></ol><h2 id="how-to-handle-transaction-abort"><a class="markdownIt-Anchor" href="#how-to-handle-transaction-abort"></a> How to handle transaction abort?</h2><ol><li>Another <code>prevLSN</code> is added to log records pointing to the previous LSN for that transaction to make it easy to walk through its records.</li><li>First write an <code>ABORT</code> record to log for the transaction.<ul><li>Following that, we need to records steps taken to undo the transaction.<ul><li>A <code>CLR</code> describes the actions taken to undo the actions of a previous update record.</li><li>It has all the fields of an update log record plus the <code>undoNext</code> pointer pointing to the next-to-be-undone LSN.</li><li><code>CLR</code>s are added to log records but the DBMS does not wait for them to be flushed before notifying the application that the transaction aborted.</li></ul></li><li>Lastly, write a <code>TXN-END</code> record.</li></ul></li><li>To add <code>CLR</code> records, we need to analyze the transaction’s updates in reverse order.<ul><li>For each update record, write a <code>CLR</code> entry to the log, and restore old value.</li><li><code>CLR</code>s never need to be undone.</li></ul></li></ol><h1 id="fuzzy-checkpoints"><a class="markdownIt-Anchor" href="#fuzzy-checkpoints"></a> Fuzzy checkpoints</h1><h2 id="how-can-we-improve-the-naive-checkpoints"><a class="markdownIt-Anchor" href="#how-can-we-improve-the-naive-checkpoints"></a> How can we improve the naive checkpoints?</h2><ol><li>The naive checkpoint needs to halt the start of any new transactions and wait until all active transactions finish executing.</li><li>We can only pause modifying transactions while the DBMS takes the checkpoint.<ul><li>It can be done through preventing queries from acquiring write latch on table/index pages.</li><li>Don’t have to wait until all transactions finish before taking the checkpoint.</li></ul></li><li>We must record internal state as of the beginning of the checkpoint.<ul><li>Active Transaction Table (ATT): What transactions are running at the time we took checkpoint.</li><li>Dirty Page Table (DPT): What pages are dirty.</li></ul></li><li>ATT is maintained at runtime and recovery. There is a entry per currently active transaction<ul><li>Each entry contains<ul><li><code>transactionId</code>: Unique transaction identifier</li><li><code>status</code>: The current “mode” of the transaction</li><li><code>lastLSN</code>: Most recent LSN created by transaction.</li></ul></li><li>Remove entry after the <code>TXN-END</code> record.</li><li>Txn Status Codes<ul><li><code>R</code>: Running</li><li><code>C</code>: Committing</li><li><code>U</code>: Candidate for undo</li></ul></li><li><code>U</code> is the default mode in recovery.<ul><li>When replaying the log, we cannot see what’s come up ahead, assuming not gonna see a transaction commit record.</li><li>Flip to commit when see a transaction commit record</li></ul></li></ul></li><li>DPT contains one entry per dirty page in the buffer pool including <code>recLSN</code>.<ul><li><code>recLSN</code> is the LSN of the log record that first caused the page to be dirty.</li></ul></li><li>Each checkpoint record includes ATT and DPT in it.</li></ol><h2 id="how-can-we-checkpoint-without-stalling-transactions"><a class="markdownIt-Anchor" href="#how-can-we-checkpoint-without-stalling-transactions"></a> How can we checkpoint without stalling transactions?</h2><ol><li>In fuzzy checkpoint, there are two kind of records to track checkpoint boundaries.<ul><li><code>CHECKPOINT-BEGIN</code> indicates start of checkpoint. Recovery begins from here.</li><li><code>CHECKPOINT-END</code> contains ATT and DPT at the moment of <code>CHECKPOINT-BEGIN</code>.</li></ul></li><li>The <code>LSN</code> of the <code>CHECKPOINT-BEGIN</code> record is written to the <code>MasterRecord</code> when it completes.</li><li>Any transaction that begins after the checkpoint starts is excluded from the ATT in the <code>CHECKPOINT-END</code> record.</li></ol><h1 id="recovery"><a class="markdownIt-Anchor" href="#recovery"></a> Recovery</h1><h2 id="how-does-aries-recover-from-crash"><a class="markdownIt-Anchor" href="#how-does-aries-recover-from-crash"></a> How does ARIES recover from crash?</h2><ol><li>The first phase is analysis.<ul><li>Examine the WAL in forward direction starting at MasterRecord to identify dirty pages in the buffer pool and active transactions at the time of the crash.</li><li>This is to figure out which transactions committed or failed since checkpoint.</li></ul></li><li>The second phase is redo phase.<ul><li>Repeat all actions starting from an appropriate point in the log in forward direction.</li><li>This phase is to repeat all actions, even transactions that will abort.</li></ul></li><li>The last phase is undo.<ul><li>Reverse the actions of transactions that did not commit before the crash in reverse order.</li><li>This phase is to reverse effects of failed transactions.</li></ul></li><li>If crashes happen during recovery, just run recovery again.</li></ol><img src="/imgs/15445/Recovery/aries.png" width="20%"><h2 id="what-does-analysis-phase-do"><a class="markdownIt-Anchor" href="#what-does-analysis-phase-do"></a> What does analysis phase do?</h2><ol><li>Scan log forward from the <code>CHECKPOINT-END</code> of the last successful checkpoint.</li><li>If the DBMS finds a <code>TXN-END</code> record, remove its corresponding transaction from ATT.</li><li>For all other records,<ul><li>If transaction not in ATT, add it with status <code>UNDO</code>. On commit, change transaction status to <code>COMMIT</code>.</li><li>For update log records, if page <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>P</mi></mrow><annotation encoding="application/x-tex">P</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span></span></span></span> not in DPT, add <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>P</mi></mrow><annotation encoding="application/x-tex">P</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span></span></span></span> to DPT, set its <code>recLSN=LSN</code>.</li></ul></li><li>At end of the Analysis Phase,<ul><li>ATT identifies which transactions were active at time of crash.</li><li>DPT identifies which dirty pages might not have made it to disk.</li></ul></li></ol><h2 id="what-does-redo-phase-do"><a class="markdownIt-Anchor" href="#what-does-redo-phase-do"></a> What does redo phase do?</h2><ol><li>The goal is to repeat history to reconstruct the database state at the moment of the crash.</li><li>Scan forward from the log record containing smallest <code>recLSN</code> in DPT.</li><li>For each update log record or <code>CLR</code> with a given LSN, redo the action unless affected page is not in DPT, or affected page is in DPT but that record’s LSN is less than the page’s <code>recLSN</code>.<ul><li>If the affected page is not in DPT, that means that that modification is already flushed in disk.</li><li>If that record’s LSN is less than the page’s <code>recLSN</code>, that means that that page is dirty but due to some updates after the record. The modification of that record is also flushed into the disk.</li></ul></li><li>To redo an action,<ul><li>Reapply logged update.</li><li>Set <code>pageLSN</code> to log record’s LSN.</li><li>No additional logging, no forced flushes.</li><li>To improve performance, we can assume that it is not going to crash again and flush all changes to disk asynchronously in the background.</li></ul></li><li>At the end of Redo Phase, write <code>TXN-END</code> log records for all transactions with status <code>C</code> and remove them from the ATT.</li></ol><h2 id="what-does-undo-phase-do"><a class="markdownIt-Anchor" href="#what-does-undo-phase-do"></a> What does undo phase do?</h2><ol><li>Undo all transactions that were active at the time of crash and therefore will never commit.</li><li>These are all the transactions with <code>U</code> status in the ATT after the Analysis Phase.</li><li>Process them in reverse LSN order using the <code>lastLSN</code> to speed up traversal.</li><li>Write a <code>CLR</code> for every modification.</li><li>To improve performance,<ul><li>Lazily rollback changes before new transactions access pages.</li><li>Rewrite the application to avoid long-running transactions, which will never be used.</li></ul></li></ol>]]></content>
      
      
      <categories>
          
          <category> Open Courses </category>
          
          <category> CMU 15-445/645 Database System </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Database System </tag>
            
            <tag> Durability </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>13 Database Logging</title>
      <link href="/2023/08/29/Courses/15445/13-Database-Logging/"/>
      <url>/2023/08/29/Courses/15445/13-Database-Logging/</url>
      
        <content type="html"><![CDATA[<p><ul class="markdownIt-TOC"><li><a href="#crash">Crash</a><ul><li><a href="#how-to-recover-from-crash">How to recover from crash?</a></li><li><a href="#what-are-the-possible-classification-of-failures">What are the possible classification of failures?</a></li></ul></li><li><a href="#naive-solution">Naive solution</a><ul><li><a href="#what-buffer-pool-policies-can-we-choose">What buffer pool policies can we choose?</a></li><li><a href="#what-are-the-pros-and-cons-of-no-steal-and-force-policy">What are the pros and cons of no-steal and force policy?</a></li><li><a href="#how-does-shadow-paging-work">How does shadow paging work?</a></li><li><a href="#what-are-the-disadvantages-of-shadow-paging">What are the disadvantages of shadow paging?</a></li><li><a href="#how-does-journal-file-work">How does journal file work?</a></li></ul></li><li><a href="#write-ahead-log">Write-ahead log</a><ul><li><a href="#what-is-the-main-idea-of-wal">What is the main idea of WAL?</a></li><li><a href="#how-to-write-under-wal-protocol">How to write under WAL protocol?</a></li><li><a href="#how-to-reduce-flushing-the-log-buffer">How to reduce flushing the log buffer?</a></li><li><a href="#how-to-store-changes">How to store changes?</a></li><li><a href="#what-is-log-structured-system">What is log-structured system?</a></li><li><a href="#how-to-prevent-wal-from-growing-forever">How to prevent WAL from growing forever?</a></li><li><a href="#what-is-the-problem-of-this-naive-checkpoint-protocol">What is the problem of this naive checkpoint protocol?</a></li></ul></li></ul></p><h1 id="crash"><a class="markdownIt-Anchor" href="#crash"></a> Crash</h1><h2 id="how-to-recover-from-crash"><a class="markdownIt-Anchor" href="#how-to-recover-from-crash"></a> How to recover from crash?</h2><ol><li>Recovery algorithms are techniques to ensure database consistency, transaction atomicity, and durability despite failures.</li><li>The DBMS needs to ensure the following:<ul><li>The changes for any transaction are durable once the DBMS has told somebody that it committed.</li><li>No partial changes are durable if the transaction aborted.</li></ul></li><li>Recovery algorithms have two parts:<ul><li>The first is runtime part: Actions during normal transaction processing to ensure that the DBMS can recover from a failure.</li><li>The second is startup part: Actions after a failure to recover the database to a state that ensures atomicity, consistency, and durability.</li></ul></li></ol><h2 id="what-are-the-possible-classification-of-failures"><a class="markdownIt-Anchor" href="#what-are-the-possible-classification-of-failures"></a> What are the possible classification of failures?</h2><ol><li>Transaction failures:<ul><li>Logical errors: Transaction cannot complete due to some internal error condition (e.g., integrity constraint violation).</li><li>Internal state errors: DBMS must terminate an active transaction due to an error condition (e.g., deadlock).</li></ul></li><li>System failures:<ul><li>Software failure: Problem with the OS or DBMS implementation (e.g., uncaught divide-by-zero exception).</li><li>Hardware failure: The computer hosting the DBMS crashes (e.g., power plug gets pulled).</li><li>Fail-stop assumption: Non-volatile storage contents are assumed to not be corrupted by system crash.</li></ul></li><li>Storage media failure:<ul><li>Non-repairable hardware failure: A head crash or similar disk failure destroys all or part of non-volatile storage.</li><li>Destruction is assumed to be detectable (e.g., disk controller use checksums to detect failures).</li><li>No DBMS can recover from this! Database must be restored from archived version.</li><li>Stable storage is a non-existent form of non-volatile storage that survives all possible failures scenarios.</li></ul></li></ol><h1 id="naive-solution"><a class="markdownIt-Anchor" href="#naive-solution"></a> Naive solution</h1><h2 id="what-buffer-pool-policies-can-we-choose"><a class="markdownIt-Anchor" href="#what-buffer-pool-policies-can-we-choose"></a> What buffer pool policies can we choose?</h2><ol><li>Steal policy:<ul><li>Whether the DBMS allows an uncommitted transaction to overwrite the most recent committed value of an object in non-volatile storage.</li><li>Steal: Is allowed</li><li>No-steal: Is not allowed</li></ul></li><li>Force policy:<ul><li>Whether the DBMS requires that all updates made by a transaction are reflected on non-volatile storage before the transaction can commit.</li><li>Force: Is required</li><li>No-force: Is not required</li></ul></li><li>Undo: The process of removing the effects of an incomplete or aborted transaction.</li><li>Redo: The process of re-applying the effects of a committed transaction for durability.</li><li>Stead and no-force policy has the best runtime performance since it does not need to wait for conflicted uncommitted transactions and not necessarily to flush when commit.</li><li>No-steal and force policy has the best recovery performance since it does not need undo and redo anything.</li></ol><h2 id="what-are-the-pros-and-cons-of-no-steal-and-force-policy"><a class="markdownIt-Anchor" href="#what-are-the-pros-and-cons-of-no-steal-and-force-policy"></a> What are the pros and cons of no-steal and force policy?</h2><ol><li>This approach is the easiest to implement:<ul><li>Never have to undo changes of an aborted transaction because the changes were not written to disk.</li><li>Never have to redo changes of a committed transaction because all the changes are guaranteed to be written to disk at commit time (assuming atomic hardware writes).</li></ul></li><li>An uncommitted transaction and another committing transaction may have written the same page. Then the buffer pool manager needs to copy that page with only modifications from the committing transaction and writes that copied page to non-volatile storage.</li><li>The disadvantages are as following:<ul><li>Copying data is expensive.</li><li>The buffer pool manager needs to be aware of the context.</li><li>Cannot support write sets that exceed the amount of physical memory available.</li></ul></li></ol><h2 id="how-does-shadow-paging-work"><a class="markdownIt-Anchor" href="#how-does-shadow-paging-work"></a> How does shadow paging work?</h2><ol><li>Instead of copying the entire database, the DBMS copies pages on write to create two versions<ul><li>Master: Contains only changes from committed transactions. Read-only transactions access the current master.</li><li>Shadow: Temporary database with changes made from uncommitted transactions.</li></ul></li><li>Active modifying transaction copies the page table as the shadow page table.<ul><li>When it tries to modify a page, it will copy that page, and modify the shadow page table to point to the new copied page.</li><li>To install updates when a transaction commits, overwrite the root so it points to the shadow, thereby swapping the master and shadow. Then DMBS needs to do some garbage collection.</li></ul></li><li>The buffer pool policy is no-steal and force.</li><li>To support rollbacks and recovery, the DBMS needs to Remove the shadow pages. Leave the master and the DB root pointer alone on undo phase, and no need to redo at all.</li></ol><h2 id="what-are-the-disadvantages-of-shadow-paging"><a class="markdownIt-Anchor" href="#what-are-the-disadvantages-of-shadow-paging"></a> What are the disadvantages of shadow paging?</h2><ol><li>Copying the entire page table is expensive:<ul><li>We can use a page table structured like a B+tree (LMDB). There is no need to copy entire tree, only need to copy paths in the tree that lead to updated leaf nodes.</li></ul></li><li>Commit overhead is high:<ul><li>Need to flush every updated page, page table, and root.</li><li>Data gets fragmented, which is bad for sequential scans.</li><li>Require the DBMS to perform writes to random non-contiguous pages on disk.</li><li>Need garbage collection.</li></ul></li><li>Only supports one writer transaction at a time or transactions in a batch. If two concurrent writer write on the same page, they all copies from master version causing only one write is reflected on the committed database.</li></ol><h2 id="how-does-journal-file-work"><a class="markdownIt-Anchor" href="#how-does-journal-file-work"></a> How does journal file work?</h2><ol><li>When a transaction modifies a page, the DBMS copies the original page to a separate journal file before overwriting master version.</li><li>After restarting, if a journal file exists, then the DBMS restores it to undo changes from uncommitted transactions.</li></ol><h1 id="write-ahead-log"><a class="markdownIt-Anchor" href="#write-ahead-log"></a> Write-ahead log</h1><h2 id="what-is-the-main-idea-of-wal"><a class="markdownIt-Anchor" href="#what-is-the-main-idea-of-wal"></a> What is the main idea of WAL?</h2><ol><li>Maintain a log file separate from data files that contains the changes that transactions make to database.<ul><li>Assume that the log is on stable storage.</li><li>Log contains enough information to perform the necessary undo and redo actions to restore the database.</li></ul></li><li>DBMS must write to disk the log file records that correspond to changes made to a database object before it can flush that object to disk.<ul><li>The buffer pool policy is steal and no-force.</li></ul></li></ol><h2 id="how-to-write-under-wal-protocol"><a class="markdownIt-Anchor" href="#how-to-write-under-wal-protocol"></a> How to write under WAL protocol?</h2><ol><li>The DBMS stages all a transaction’s log records in volatile storage backed by buffer pool.<ul><li>All log records pertaining to an updated page are written to non-volatile storage before the page itself is over-written in non-volatile storage.</li><li>A transaction is not considered committed until all its log records have been written to stable storage.</li></ul></li><li>A <code>&lt;BEGIN&gt;</code> record is written to the log for each transaction to mark its starting point.<ul><li>Most DBMS only writes <code>&lt;BEGIN&gt;</code> on first write command of a transaction instead of on the beginning.</li></ul></li><li>When a transaction finishes, the DBMS will write a <code>&lt;COMMIT&gt;</code> record on the log, and make sure that all log records are flushed before it returns an acknowledgement to application.</li><li>Each log entry contains information about the change to a single object<ul><li>Transaction ID, object ID, before value (for undo) and after value (for redo).</li></ul></li></ol><h2 id="how-to-reduce-flushing-the-log-buffer"><a class="markdownIt-Anchor" href="#how-to-reduce-flushing-the-log-buffer"></a> How to reduce flushing the log buffer?</h2><ol><li>Flushing the log buffer to disk every time a transaction commits will become a bottleneck.</li><li>The DBMS can use the group commit optimization to batch multiple log flushes together to amortize overhead.<ul><li>When the buffer is full, flush it to disk. Or if there is a timeout.</li><li>Log records from different transaction are mixed. This is fine since we can sort them out by recorded transaction ID.</li></ul></li></ol><h2 id="how-to-store-changes"><a class="markdownIt-Anchor" href="#how-to-store-changes"></a> How to store changes?</h2><ol><li>The first logging scheme is physical logging.<ul><li>Record the byte-level changes made to a specific page.</li></ul></li><li>The second is logical logging.<ul><li>Record the high-level operations executed by transactions, e.g. queries.</li><li>Logical logging requires less data written in each log record than physical logging.</li><li>Difficult to implement recovery with logical logging if you have concurrent transactions running at lower isolation levels.<ul><li>The crash may happen in the middle of a query.</li><li>It is hard to determine which parts of the database may have been modified by a query before crash.</li></ul></li><li>Also takes longer to recover because you must re-execute every transaction all over again.</li></ul></li><li>The last is physiological logging.<ul><li>Hybrid approach with byte-level changes for a single tuple identified by page ID and slot number.</li></ul></li></ol><h2 id="what-is-log-structured-system"><a class="markdownIt-Anchor" href="#what-is-log-structured-system"></a> What is log-structured system?</h2><ol><li>Log-structured DBMSs do not have dirty pages.<ul><li>Any page retrieved from disk is immutable.</li><li>All modifications are reflected through logs.</li></ul></li><li>The DBMS buffers log records in in-memory pages (MemTable).<ul><li>If this buffer is full, it must be flushed to disk. But it may contain changes from uncommitted transactions.</li></ul></li><li>These DBMSs still maintain a separate WAL to recreate the MemTable on crash.</li></ol><h2 id="how-to-prevent-wal-from-growing-forever"><a class="markdownIt-Anchor" href="#how-to-prevent-wal-from-growing-forever"></a> How to prevent WAL from growing forever?</h2><ol><li>If the WAL will grow forever, after a crash, the DBMS must replay the entire log, which will take a long time.</li><li>The DBMS periodically takes a checkpoint where it flushes all buffers out to disk.</li><li>In blocking / consistent checkpoint protocol,<ul><li>Procedure<ul><li>Pause all queries</li><li>Flush all WAL records in memory to disk</li><li>Flush all modified pages in the buffer pool to disk</li><li>Write a <code>&lt;CHECKPOINT&gt;</code> entry to WAL and flush to disk</li><li>Resume queries</li></ul></li><li>On recovery, we can use the <code>&lt;CHECKPOINT&gt;</code> record as the starting point for analyzing the WAL.<ul><li>Any transaction that committed before the checkpoint is ignored.</li><li>Redo transactions that is committed after checkpoint and undo transactions that is not committed before the crash.</li></ul></li></ul></li></ol><h2 id="what-is-the-problem-of-this-naive-checkpoint-protocol"><a class="markdownIt-Anchor" href="#what-is-the-problem-of-this-naive-checkpoint-protocol"></a> What is the problem of this naive checkpoint protocol?</h2><ol><li>The DBMS must stall transactions when it takes a checkpoint to ensure a consistent snapshot.<ul><li>Checkpointing too often causes the runtime performance to degrade due to system spends too much time flushing buffers.</li><li>But waiting a long time is just as bad since the checkpoint will be large and slow, which makes recovery time much longer.</li></ul></li><li>Scanning the log to find uncommitted transactions can take a long time.</li></ol>]]></content>
      
      
      <categories>
          
          <category> Open Courses </category>
          
          <category> CMU 15-445/645 Database System </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Database System </tag>
            
            <tag> Durability </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>12 Multi-Version Concurrency Control</title>
      <link href="/2023/08/22/Courses/15445/12-Multi-Version-Concurrency-Control/"/>
      <url>/2023/08/22/Courses/15445/12-Multi-Version-Concurrency-Control/</url>
      
        <content type="html"><![CDATA[<p><ul class="markdownIt-TOC"><li><a href="#multi-version-logic">Multi-version logic</a><ul><li><a href="#what-does-multi-version-mean">What does multi-version mean?</a></li><li><a href="#how-to-maintain-multi-version-logically">How to maintain multi-version logically?</a></li><li><a href="#what-isolation-can-mvcc-support">What isolation can MVCC support?</a></li></ul></li><li><a href="#design-decisions">Design decisions</a><ul><li><a href="#what-concurrency-control-protocol-can-be-used">What concurrency control protocol can be used?</a></li><li><a href="#how-are-versions-stored">How are versions stored?</a></li><li><a href="#how-to-perform-garbage-collection">How to perform garbage collection?</a></li><li><a href="#how-to-manage-indexes">How to manage indexes?</a></li><li><a href="#how-to-delete-a-tuple">How to delete a tuple?</a></li></ul></li></ul></p><h1 id="multi-version-logic"><a class="markdownIt-Anchor" href="#multi-version-logic"></a> Multi-version logic</h1><h2 id="what-does-multi-version-mean"><a class="markdownIt-Anchor" href="#what-does-multi-version-mean"></a> What does multi-version mean?</h2><ol><li><p>The DBMS maintains multiple physical versions of a single logical object in the database.</p><ul><li><p>When a txn writes to an object, the DBMS creates a new version of that object.</p></li><li><p>When a txn reads an object, it reads the newest version that existed when the txn started.</p></li></ul></li><li><p>Writers do not block readers and readers do not block writers.</p></li><li><p>Read-only txns can read a consistent snapshot without acquiring locks using timestamps to determine visibility.</p></li><li><p>Multi-version can easily support time-travel queries on a snapshot version on database.</p></li></ol><h2 id="how-to-maintain-multi-version-logically"><a class="markdownIt-Anchor" href="#how-to-maintain-multi-version-logically"></a> How to maintain multi-version logically?</h2><ol><li>Each version describes the current version number, the value for this version and the range of lifetime, i.e. the begin and end timestamps.</li><li>End timestamp is marked infinity for the newest version.</li><li>When a transaction writes an object:<ul><li>First it creates a new entry with a new version number and setting its begin timestamp as its timestamp and end timestamp being infinity.</li><li>Then it marks the end timestamp of last version as its timestamp.</li><li>Physically this transaction should modifiy the last version to point to this new version. Hence it need to wait for the transaction creating last version to commit to begin its own commit phase.</li></ul></li></ol><h2 id="what-isolation-can-mvcc-support"><a class="markdownIt-Anchor" href="#what-isolation-can-mvcc-support"></a> What isolation can MVCC support?</h2><ol><li><code>SNAPSHOT ISOLATION</code> is another isolation supported by Oracle.<ul><li>It guarantees that all reads made in a transaction see a consistent snapshot of the database that existed at the time the transaction started.</li><li>A transaction will commit only if its writes do not conflict with any concurrent updates made since that snapshot.</li></ul></li><li>It is susceptible to write skew anomaly.<ul><li>Two concurrent transactions modify different objects resulting in race conditions.</li><li>If a transaction wants to modify all values to <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1</mn></mrow><annotation encoding="application/x-tex">1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">1</span></span></span></span> while another transaction wants to modifiy all values to <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>0</mn></mrow><annotation encoding="application/x-tex">0</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">0</span></span></span></span>. The first transaction changes all <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>0</mn></mrow><annotation encoding="application/x-tex">0</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">0</span></span></span></span>s and the second transaction changes all <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1</mn></mrow><annotation encoding="application/x-tex">1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">1</span></span></span></span>s. When their result merges to the database, it would be the <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1</mn></mrow><annotation encoding="application/x-tex">1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">1</span></span></span></span>s and <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>0</mn></mrow><annotation encoding="application/x-tex">0</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">0</span></span></span></span>s are flipped instead of all being <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1</mn></mrow><annotation encoding="application/x-tex">1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">1</span></span></span></span>s or <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>0</mn></mrow><annotation encoding="application/x-tex">0</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">0</span></span></span></span>s.</li></ul></li></ol><h1 id="design-decisions"><a class="markdownIt-Anchor" href="#design-decisions"></a> Design decisions</h1><h2 id="what-concurrency-control-protocol-can-be-used"><a class="markdownIt-Anchor" href="#what-concurrency-control-protocol-can-be-used"></a> What concurrency control protocol can be used?</h2><ol><li>All aforementioned protocols can be used in MVCC.</li><li>Timestamp ordering assigns transactions timestamps to determine what they can see.</li><li>Optimistic concurrency control uses private workspace for new versions.</li><li>Two-phase locking requires transactions to acquire appropriate lock on physical version before they can read/write a logical tuple.</li></ol><h2 id="how-are-versions-stored"><a class="markdownIt-Anchor" href="#how-are-versions-stored"></a> How are versions stored?</h2><ol><li>The DBMS uses the tuples’ pointer field to create a version chain per logical tuple.<ul><li>This allows the DBMS to find the version that is visible to a particular txn at runtime.</li><li>Indexes always point to the “head” of the chain.</li></ul></li><li>The first approach is append-only storage: New versions are appended to the same table space.<ul><li>The versions of different logical tuples are inter-mixed.</li><li>On every update, append a new version of the tuple into an empty space in the table.</li><li>If the chain is from oldest-to-newest, the DBMS must traverse chain on look-ups. However, the update do not need to update index.</li><li>Or, the chain can be from oldest-to-newest. The pros and cons are contrary with last scenario.</li></ul></li><li>The second approach is time-travel storage: Old versions are copied to separate table space.<ul><li>On every update, copy the current version to the time- travel table. Update pointers. Then Overwrite master version in the main table and update pointers.</li></ul></li><li>The third approach is delta storage: The original values of the modified attributes are copied into a separate delta record space.<ul><li>On every update, copy only the values that were modified to the delta storage and overwrite the master version.</li><li>Txns can recreate old versions by applying the delta in reverse order.</li></ul></li></ol><h2 id="how-to-perform-garbage-collection"><a class="markdownIt-Anchor" href="#how-to-perform-garbage-collection"></a> How to perform garbage collection?</h2><ol><li>The DBMS needs to remove reclaimable physical versions from the database over time.<ul><li>Reclaimable means that no active txn in the DBMS can see that version (SI), or the version was created by an aborted txn.</li><li>To support time-travel queries, the DBMS can only reclaim versions created by an aborted txn.</li></ul></li><li>To look for expired versions, the implementation has two choices.</li><li>The first approach is tuple-level: Find old versions by examining tuples directly.<ul><li>In background vacuuming manner, separate thread(s) periodically scan the table and look for reclaimable versions. This design works with any storage.</li><li>In cooperative cleaning manner, worker threads identify reclaimable versions as they traverse version chain. It only works with oldest-to-newest.</li></ul></li><li>The second approach is transaction-level: Txns keep track of their old versions on updates so the DBMS does not have to scan tuples to determine visibility.<ul><li>Each txn keeps track of its read/write set. On commit/abort, the txn provides this information to a centralized vacuum worker.</li><li>The DBMS periodically determines when all versions created by a finished txn are no longer visible.</li></ul></li></ol><h2 id="how-to-manage-indexes"><a class="markdownIt-Anchor" href="#how-to-manage-indexes"></a> How to manage indexes?</h2><ol><li>Primary key indexes point to version chain head.<ul><li>How often the DBMS must update the primary key index depends on whether the system creates new versions when a tuple is updated.</li><li>If a txn updates a tuple’s primary key attribute(s), then this is treated as a <code>DELETE</code> followed by an <code>INSERT</code>.</li></ul></li><li>Secondary indexes may use the physical address to the version chain head the same way as primary key index.</li><li>The secondary indexes may also use logical pointers.<ul><li>It uses a fixed identifier per tuple that does not change, e.g. primary key or tuple ID.</li><li>This would require an extra indirection layer.</li></ul></li></ol><h2 id="how-to-delete-a-tuple"><a class="markdownIt-Anchor" href="#how-to-delete-a-tuple"></a> How to delete a tuple?</h2><ol><li>The DBMS physically deletes a tuple from the database only when all versions of a logically deleted tuple are not visible.</li><li>If a tuple is deleted, then there cannot be a new version of that tuple after the newest version.</li><li>There are two ways to denote that tuple has been logically delete at some point in time.<ul><li>The first deleted flag way is to maintain a flag to indicate that the logical tuple has been deleted after the newest physical version. The flag can either be in tuple header or a separate column.</li><li>The second tombstone tuple way is to create an empty physical version to indicate that a logical tuple is deleted.<ul><li>It uses a separate pool for tombstone tuples with only a special bit pattern in version chain pointer to reduce the storage overhead.</li></ul></li></ul></li></ol>]]></content>
      
      
      <categories>
          
          <category> Open Courses </category>
          
          <category> CMU 15-445/645 Database System </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Database System </tag>
            
            <tag> Concurrency Control </tag>
            
            <tag> Transaction </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>11 Timestamp Ordering Concurrency Control</title>
      <link href="/2023/08/20/Courses/15445/11-Timestamp-Ordering-Concurrency-Control/"/>
      <url>/2023/08/20/Courses/15445/11-Timestamp-Ordering-Concurrency-Control/</url>
      
        <content type="html"><![CDATA[<p><ul class="markdownIt-TOC"><li><a href="#to-protocols">T/O Protocols</a><ul><li><a href="#what-is-the-difference-between-2pl-and-to">What is the difference between 2PL and T/O?</a></li><li><a href="#basic-to-protocol">Basic T/O protocol</a><ul><li><a href="#what-is-the-main-idea-of-basic-to-protocol">What is the main idea of basic T/O protocol?</a></li><li><a href="#how-does-basic-to-check-each-operation">How does basic T/O check each operation?</a></li><li><a href="#can-we-optimize-the-write-rule-to-decrease-possibility-of-abort">Can we optimize the write rule to decrease possibility of abort?</a></li><li><a href="#what-is-the-issues-of-basic-to">What is the issues of basic T/O?</a></li></ul></li><li><a href="#optimistic-concurrency-control">Optimistic concurrency control</a><ul><li><a href="#what-is-the-main-idea-of-occ">What is the main idea of OCC?</a></li><li><a href="#what-will-happen-in-validation-phase">What will happen in validation phase?</a></li><li><a href="#what-are-the-issues-of-occ">What are the issues of OCC?</a></li></ul></li></ul></li><li><a href="#the-phantom-problem">The phantom problem</a><ul><li><a href="#what-is-the-phantom-problem">What is the phantom problem?</a></li><li><a href="#how-can-we-solve-the-phantom-problem">How can we solve the phantom problem?</a></li><li><a href="#what-are-isolation-levels">What are isolation levels?</a></li></ul></li></ul></p><h1 id="to-protocols"><a class="markdownIt-Anchor" href="#to-protocols"></a> T/O Protocols</h1><h2 id="what-is-the-difference-between-2pl-and-to"><a class="markdownIt-Anchor" href="#what-is-the-difference-between-2pl-and-to"></a> What is the difference between 2PL and T/O?</h2><ol><li>2PL determine serializability order of conflicting operations at runtime while transactions execute while T/O determine serializability order of transactions before they execute.<ul><li>If <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>T</mi><mi>S</mi><mo stretchy="false">(</mo><msub><mi>T</mi><mi>i</mi></msub><mo stretchy="false">)</mo><mo>&lt;</mo><mi>T</mi><mi>S</mi><mo stretchy="false">(</mo><msub><mi>T</mi><mi>j</mi></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">TS(T_i) &lt; TS(T_j)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="mord mathnormal" style="margin-right:0.05764em;">S</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">&lt;</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.036108em;vertical-align:-0.286108em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="mord mathnormal" style="margin-right:0.05764em;">S</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.311664em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span>, then the DBMS must ensure that the execution schedule is equivalent to a serial schedule where <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>T</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">T_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> appears before <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>T</mi><mi>j</mi></msub></mrow><annotation encoding="application/x-tex">T_j</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.969438em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.311664em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span></span></span></span>.</li><li>Different schemes assign timestamps at different times during the transaction.</li><li>Timestamps can be implemented by different strategies: system/wall clock, logical counter, or hybrid.</li></ul></li><li>2PL is in a manner of pessimistic way. It assumes that conflicts between transactions are very common.<ul><li>Hence it uses locks to prevent conflicts.</li></ul></li><li>Timestamp  ordering (T/O) is a more optimistic way. It assumes that conflicts between transactions are rare.<ul><li>Hence it allows each transaction to execute all operations they want and validates their legitimate after each transaction committing and before applying anything to main database.</li></ul></li></ol><h2 id="basic-to-protocol"><a class="markdownIt-Anchor" href="#basic-to-protocol"></a> Basic T/O protocol</h2><h3 id="what-is-the-main-idea-of-basic-to-protocol"><a class="markdownIt-Anchor" href="#what-is-the-main-idea-of-basic-to-protocol"></a> What is the main idea of basic T/O protocol?</h3><ol><li>Txns read and write objects without locks.</li><li>The timestamp of each transaction is assigned at the <code>BEGIN</code> command.</li><li>Every object <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>X</mi></mrow><annotation encoding="application/x-tex">X</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.07847em;">X</span></span></span></span> is tagged with timestamp of the last transaction that successfully did read/write<ul><li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>W</mi><mo>−</mo><mi>T</mi><mi>S</mi><mo stretchy="false">(</mo><mi>X</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">W-TS(X)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.76666em;vertical-align:-0.08333em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="mord mathnormal" style="margin-right:0.05764em;">S</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class="mclose">)</span></span></span></span>: Write timestamp on <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>X</mi></mrow><annotation encoding="application/x-tex">X</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.07847em;">X</span></span></span></span></li><li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>R</mi><mo>−</mo><mi>T</mi><mi>S</mi><mo stretchy="false">(</mo><mi>X</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">R-TS(X)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.76666em;vertical-align:-0.08333em;"></span><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="mord mathnormal" style="margin-right:0.05764em;">S</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class="mclose">)</span></span></span></span>: Read timestamp on <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>X</mi></mrow><annotation encoding="application/x-tex">X</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.07847em;">X</span></span></span></span></li></ul></li><li>Check timestamps for every operation. If transaction tries to access an object “from the future”, it aborts and restarts.</li></ol><h3 id="how-does-basic-to-check-each-operation"><a class="markdownIt-Anchor" href="#how-does-basic-to-check-each-operation"></a> How does basic T/O check each operation?</h3><ol><li>When <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>T</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">T_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> wants to read <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>X</mi></mrow><annotation encoding="application/x-tex">X</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.07847em;">X</span></span></span></span>:<ul><li>If <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>T</mi><mi>S</mi><mo stretchy="false">(</mo><msub><mi>T</mi><mi>i</mi></msub><mo stretchy="false">)</mo><mo>&lt;</mo><mi>W</mi><mo>−</mo><mi>T</mi><mi>S</mi><mo stretchy="false">(</mo><mi>X</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">TS(T_i)&lt;W-TS(X)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="mord mathnormal" style="margin-right:0.05764em;">S</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">&lt;</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.76666em;vertical-align:-0.08333em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="mord mathnormal" style="margin-right:0.05764em;">S</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class="mclose">)</span></span></span></span>, abort <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>T</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">T_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> and restart it with a new TS to prevent it from starvation.<ul><li>This condition means that this <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>T</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">T_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> is trying to read something from the future.</li></ul></li><li>Else, allow <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>T</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">T_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> to read <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>X</mi></mrow><annotation encoding="application/x-tex">X</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.07847em;">X</span></span></span></span>, and update <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>R</mi><mo>−</mo><mi>T</mi><mi>S</mi><mo stretchy="false">(</mo><mi>X</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">R-TS(X)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.76666em;vertical-align:-0.08333em;"></span><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="mord mathnormal" style="margin-right:0.05764em;">S</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class="mclose">)</span></span></span></span> to <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>m</mi><mi>a</mi><mi>x</mi><mo stretchy="false">(</mo><mi>R</mi><mo>−</mo><mi>T</mi><mi>S</mi><mo stretchy="false">(</mo><mi>X</mi><mo stretchy="false">)</mo><mo separator="true">,</mo><mi>T</mi><mi>S</mi><mo stretchy="false">(</mo><msub><mi>T</mi><mi>i</mi></msub><mo stretchy="false">)</mo><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">max(R-TS(X), TS(T_i))</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">m</span><span class="mord mathnormal">a</span><span class="mord mathnormal">x</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="mord mathnormal" style="margin-right:0.05764em;">S</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class="mclose">)</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="mord mathnormal" style="margin-right:0.05764em;">S</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mclose">)</span></span></span></span>.</li><li>A local copy of <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>X</mi></mrow><annotation encoding="application/x-tex">X</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.07847em;">X</span></span></span></span> is made to ensure repeatable reads for <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>T</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">T_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>.</li></ul></li><li>When <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>T</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">T_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> wants to write <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>X</mi></mrow><annotation encoding="application/x-tex">X</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.07847em;">X</span></span></span></span>:<ul><li>If <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>T</mi><mi>S</mi><mo stretchy="false">(</mo><msub><mi>T</mi><mi>i</mi></msub><mo stretchy="false">)</mo><mo>&lt;</mo><mi>R</mi><mo>−</mo><mi>T</mi><mi>S</mi><mo stretchy="false">(</mo><mi>X</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">TS(T_i)&lt;R-TS(X)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="mord mathnormal" style="margin-right:0.05764em;">S</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">&lt;</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.76666em;vertical-align:-0.08333em;"></span><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="mord mathnormal" style="margin-right:0.05764em;">S</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class="mclose">)</span></span></span></span> or <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>T</mi><mi>S</mi><mo stretchy="false">(</mo><msub><mi>T</mi><mi>i</mi></msub><mo stretchy="false">)</mo><mo>&lt;</mo><mi>W</mi><mo>−</mo><mi>T</mi><mi>S</mi><mo stretchy="false">(</mo><mi>X</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">TS(T_i)&lt;W-TS(X)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="mord mathnormal" style="margin-right:0.05764em;">S</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">&lt;</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.76666em;vertical-align:-0.08333em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="mord mathnormal" style="margin-right:0.05764em;">S</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class="mclose">)</span></span></span></span>, abort and restart <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>T</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">T_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>.<ul><li>The first condition means that another transaction from the future cannot see the write from <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>T</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">T_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> in the past.</li><li>The second condition means that another transaction from the future already wrote this object and <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>T</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">T_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> cannot overwrite it in the past.</li></ul></li><li>Else, allow <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>T</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">T_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> to write <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>X</mi></mrow><annotation encoding="application/x-tex">X</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.07847em;">X</span></span></span></span> and update <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>W</mi><mo>−</mo><mi>T</mi><mi>S</mi><mo stretchy="false">(</mo><mi>X</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">W-TS(X)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.76666em;vertical-align:-0.08333em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="mord mathnormal" style="margin-right:0.05764em;">S</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class="mclose">)</span></span></span></span>.</li><li>Also, a local copy is made.</li></ul></li></ol><h3 id="can-we-optimize-the-write-rule-to-decrease-possibility-of-abort"><a class="markdownIt-Anchor" href="#can-we-optimize-the-write-rule-to-decrease-possibility-of-abort"></a> Can we optimize the write rule to decrease possibility of abort?</h3><ol><li>Thomas write rule: If <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>T</mi><mi>S</mi><mo stretchy="false">(</mo><msub><mi>T</mi><mi>i</mi></msub><mo stretchy="false">)</mo><mo>&lt;</mo><mi>W</mi><mo>−</mo><mi>T</mi><mi>S</mi><mo stretchy="false">(</mo><mi>X</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">TS(T_i) &lt; W-TS(X)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="mord mathnormal" style="margin-right:0.05764em;">S</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">&lt;</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.76666em;vertical-align:-0.08333em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="mord mathnormal" style="margin-right:0.05764em;">S</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class="mclose">)</span></span></span></span>, ignore the write to allow the transaction to continue executing without aborting.<ul><li>The thought is that we can see this violation as an immediate write from a future transaction right after the successful write from <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>T</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">T_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>.</li><li>The effects are similar, i.e. no one sees what does <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>T</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">T_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> write.</li></ul></li><li>If <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>T</mi><mi>S</mi><mo stretchy="false">(</mo><msub><mi>T</mi><mi>i</mi></msub><mo stretchy="false">)</mo><mo>&lt;</mo><mi>R</mi><mo>−</mo><mi>T</mi><mi>S</mi><mo stretchy="false">(</mo><mi>X</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">TS(T_i)&lt;R-TS(X)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="mord mathnormal" style="margin-right:0.05764em;">S</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">&lt;</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.76666em;vertical-align:-0.08333em;"></span><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="mord mathnormal" style="margin-right:0.05764em;">S</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class="mclose">)</span></span></span></span>, we still need to abort <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>T</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">T_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>.</li></ol><h3 id="what-is-the-issues-of-basic-to"><a class="markdownIt-Anchor" href="#what-is-the-issues-of-basic-to"></a> What is the issues of basic T/O?</h3><ol><li>High overhead from copying data to transaction’s workspace and from updating timestamps. Every read requires the transaction to write to the database.</li><li>Long running transactions can get starved. The likelihood that a transaction will read something from a newer transaction increases.</li><li>If you assume that conflicts between transactions are rare and that most transactions are short-lived, then forcing transactions to acquire locks or update timestamps adds unnecessary overhead.</li></ol><h2 id="optimistic-concurrency-control"><a class="markdownIt-Anchor" href="#optimistic-concurrency-control"></a> Optimistic concurrency control</h2><h3 id="what-is-the-main-idea-of-occ"><a class="markdownIt-Anchor" href="#what-is-the-main-idea-of-occ"></a> What is the main idea of OCC?</h3><ol><li>OCC assumes that the number of conflicts is low. Especially when:<ul><li>All transactions are read-only (ideal).</li><li>Txns access disjoint subsets of data.</li><li>The database is large and the workload is not skewed.</li></ul></li><li>The DBMS creates a private workspace for each transaction.<ul><li>Any object read is copied into workspace. Modifications are applied to workspace.</li><li>When a transaction commits, the DBMS compares workspace write set to see whether it conflicts with other transactions.</li><li>If there are no conflicts, the write set is installed into the “global” database.</li></ul></li><li>OCC has three phases:<ul><li>Read Phase: Track the read/write sets of transactions and store their writes in a private workspace, i.e. execution of transaction content.</li><li>Validation Phase: When a transaction commits, check whether it conflicts with other transactions.</li><li>Write Phase: If validation succeeds, apply private changes to database. Otherwise abort and restart the transaction.<ul><li>Serial Commits: Use a global latch to limit a single transaction to be in the Validation/Write phases at a time.</li><li>Parallel Commits: Use fine-grained write latches to support parallel Validation/Write phases. Txns acquire latches in primary key order to avoid deadlocks.</li></ul></li></ul></li></ol><h3 id="what-will-happen-in-validation-phase"><a class="markdownIt-Anchor" href="#what-will-happen-in-validation-phase"></a> What will happen in validation phase?</h3><ol><li>When transaction <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>T</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">T_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> invokes <code>COMMIT</code>, the DBMS checks if it conflicts with other transactions.<ul><li>The DBMS needs to guarantee only serializable schedules are permitted.</li><li>Checks other transactions for RW and WW conflicts and ensure that conflicts are in one direction (e.g., older→younger).</li></ul></li><li>There are two approaches to valid:<ul><li>In backward validation, check whether the committing transaction intersects its read/write sets with those of any transactions that have already committed.<br /><img src="/imgs/15445/TO/backward.png" width="50%"></li><li>In forward validation, check whether the committing transaction intersects its read/write sets with any active transactions that have not yet committed.<br /><img src="/imgs/15445/TO/forward.png" width="50%"></li></ul></li><li>Each transaction’s timestamp is assigned at the beginning of the validation phase. Check the timestamp ordering of the committing transaction with all other concerned transactions. When <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>T</mi><mi>S</mi><mo stretchy="false">(</mo><msub><mi>T</mi><mi>i</mi></msub><mo stretchy="false">)</mo><mo>&lt;</mo><mi>T</mi><mi>S</mi><mo stretchy="false">(</mo><msub><mi>T</mi><mi>j</mi></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">TS(T_i)&lt;TS(T_j)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="mord mathnormal" style="margin-right:0.05764em;">S</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">&lt;</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.036108em;vertical-align:-0.286108em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="mord mathnormal" style="margin-right:0.05764em;">S</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.311664em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span>, there are only three cases:<ul><li>If <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>T</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">T_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> completes all three phases before <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>T</mi><mi>j</mi></msub></mrow><annotation encoding="application/x-tex">T_j</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.969438em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.311664em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span></span></span></span> begins its execution. This just means that there is serial ordering.</li><li>If <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>T</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">T_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> completes before <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>T</mi><mi>j</mi></msub></mrow><annotation encoding="application/x-tex">T_j</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.969438em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.311664em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span></span></span></span> starts its Write phase, then we require that <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>T</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">T_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> does not write to any object read by <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>T</mi><mi>j</mi></msub></mrow><annotation encoding="application/x-tex">T_j</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.969438em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.311664em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span></span></span></span>, i.e. <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>W</mi><mi>r</mi><mi>i</mi><mi>t</mi><mi>e</mi><mi>S</mi><mi>e</mi><mi>t</mi><mo stretchy="false">(</mo><msub><mi>T</mi><mi>i</mi></msub><mo stretchy="false">)</mo><mo>∩</mo><mi>R</mi><mi>e</mi><mi>a</mi><mi>d</mi><mi>S</mi><mi>e</mi><mi>t</mi><mo stretchy="false">(</mo><msub><mi>T</mi><mi>j</mi></msub><mo stretchy="false">)</mo><mo>=</mo><mi mathvariant="normal">∅</mi></mrow><annotation encoding="application/x-tex">WriteSet(T_i)\cap ReadSet(T_j)=\empty</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mord mathnormal">i</span><span class="mord mathnormal">t</span><span class="mord mathnormal">e</span><span class="mord mathnormal" style="margin-right:0.05764em;">S</span><span class="mord mathnormal">e</span><span class="mord mathnormal">t</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">∩</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1.036108em;vertical-align:-0.286108em;"></span><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="mord mathnormal">e</span><span class="mord mathnormal">a</span><span class="mord mathnormal">d</span><span class="mord mathnormal" style="margin-right:0.05764em;">S</span><span class="mord mathnormal">e</span><span class="mord mathnormal">t</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.311664em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.80556em;vertical-align:-0.05556em;"></span><span class="mord">∅</span></span></span></span>.<ul><li>At this condition, we can conclude that <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>T</mi><mi>j</mi></msub></mrow><annotation encoding="application/x-tex">T_j</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.969438em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.311664em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span></span></span></span> cannot see anythin written by <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>T</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">T_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>. Therefore, if <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>T</mi><mi>j</mi></msub></mrow><annotation encoding="application/x-tex">T_j</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.969438em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.311664em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span></span></span></span> read anything written by <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>T</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">T_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>, it is a violation.</li></ul></li><li>If <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>T</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">T_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> completes its Read phase before <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>T</mi><mi>j</mi></msub></mrow><annotation encoding="application/x-tex">T_j</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.969438em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.311664em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span></span></span></span>​ completes its Read phase, then we require that <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>T</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">T_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> does not write to any object that is either read or written by <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>T</mi><mi>j</mi></msub></mrow><annotation encoding="application/x-tex">T_j</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.969438em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.311664em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span></span></span></span>.<ul><li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>W</mi><mi>r</mi><mi>i</mi><mi>t</mi><mi>e</mi><mi>S</mi><mi>e</mi><mi>t</mi><mo stretchy="false">(</mo><msub><mi>T</mi><mi>i</mi></msub><mo stretchy="false">)</mo><mo>∩</mo><mi>R</mi><mi>e</mi><mi>a</mi><mi>d</mi><mi>S</mi><mi>e</mi><mi>t</mi><mo stretchy="false">(</mo><msub><mi>T</mi><mi>j</mi></msub><mo stretchy="false">)</mo><mo>=</mo><mi mathvariant="normal">∅</mi></mrow><annotation encoding="application/x-tex">WriteSet(T_i) \cap ReadSet(T_j) = \empty</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mord mathnormal">i</span><span class="mord mathnormal">t</span><span class="mord mathnormal">e</span><span class="mord mathnormal" style="margin-right:0.05764em;">S</span><span class="mord mathnormal">e</span><span class="mord mathnormal">t</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">∩</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1.036108em;vertical-align:-0.286108em;"></span><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="mord mathnormal">e</span><span class="mord mathnormal">a</span><span class="mord mathnormal">d</span><span class="mord mathnormal" style="margin-right:0.05764em;">S</span><span class="mord mathnormal">e</span><span class="mord mathnormal">t</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.311664em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.80556em;vertical-align:-0.05556em;"></span><span class="mord">∅</span></span></span></span> and <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>W</mi><mi>r</mi><mi>i</mi><mi>t</mi><mi>e</mi><mi>S</mi><mi>e</mi><mi>t</mi><mo stretchy="false">(</mo><msub><mi>T</mi><mi>i</mi></msub><mo stretchy="false">)</mo><mo>∩</mo><mi>W</mi><mi>r</mi><mi>i</mi><mi>t</mi><mi>e</mi><mi>S</mi><mi>e</mi><mi>t</mi><mo stretchy="false">(</mo><msub><mi>T</mi><mi>j</mi></msub><mo stretchy="false">)</mo><mo>=</mo><mi mathvariant="normal">∅</mi></mrow><annotation encoding="application/x-tex">WriteSet(T_i) \cap WriteSet(T_j) = \empty</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mord mathnormal">i</span><span class="mord mathnormal">t</span><span class="mord mathnormal">e</span><span class="mord mathnormal" style="margin-right:0.05764em;">S</span><span class="mord mathnormal">e</span><span class="mord mathnormal">t</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">∩</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1.036108em;vertical-align:-0.286108em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mord mathnormal">i</span><span class="mord mathnormal">t</span><span class="mord mathnormal">e</span><span class="mord mathnormal" style="margin-right:0.05764em;">S</span><span class="mord mathnormal">e</span><span class="mord mathnormal">t</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.311664em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.80556em;vertical-align:-0.05556em;"></span><span class="mord">∅</span></span></span></span>.</li><li>Anything wrote by <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>T</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">T_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> should be seen by <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>T</mi><mi>j</mi></msub></mrow><annotation encoding="application/x-tex">T_j</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.969438em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.311664em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span></span></span></span> and should not conflict with what <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>T</mi><mi>j</mi></msub></mrow><annotation encoding="application/x-tex">T_j</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.969438em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.311664em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span></span></span></span> intends to write.</li><li>OCC wants more than just serializable order. Similar with Thomas write rule, if we allow the write sets have something in common it still would be serializable, yet in conflict.</li></ul></li></ul></li></ol><h3 id="what-are-the-issues-of-occ"><a class="markdownIt-Anchor" href="#what-are-the-issues-of-occ"></a> What are the issues of OCC?</h3><ol><li>High overhead for copying data locally.</li><li>Validation/Write phase bottlenecks.</li><li>Aborts are more wasteful than in 2PL because they only occur after a transaction has already executed.</li></ol><h1 id="the-phantom-problem"><a class="markdownIt-Anchor" href="#the-phantom-problem"></a> The phantom problem</h1><h2 id="what-is-the-phantom-problem"><a class="markdownIt-Anchor" href="#what-is-the-phantom-problem"></a> What is the phantom problem?</h2><ol><li>In the above transaction management protocols, we assume that the total number  of tuples in a table is fixed, i.e. transactions will not execute insertion or deletion.</li><li>Insertion or deletions result in different results for the same range scan queries, e.g. count, maximum.<ul><li>The reason is that transactions can only lock on existing records and not one under way.</li></ul></li></ol><h2 id="how-can-we-solve-the-phantom-problem"><a class="markdownIt-Anchor" href="#how-can-we-solve-the-phantom-problem"></a> How can we solve the phantom problem?</h2><ol><li>The first approach is to re-execute scans.<ul><li>The DBMS tracks the <code>WHERE</code> clause for all queries that the transaction executes. Retain the scan set for every range query in a transaction.</li><li>Upon commit, re-execute just the scan portion of each query and check whether it generates the same result.</li><li>This could double the execute time for all queries, which may be unacceptable.</li></ul></li><li>The second approach is by predicate locking.<ul><li>Shared lock on the predicate in a <code>WHERE</code> clause of a <code>SELECT</code> query.</li><li>Exclusive lock on the predicate in a <code>WHERE</code> clause of any <code>UPDATE</code>, <code>INSERT</code>, or <code>DELETE</code> query.</li><li>Prevent any query changing the result of locked predicate from executing.</li></ul></li><li>The third approach is by index locking.<ul><li>Key-value locks only cover a single existing key-value in an index, while gap locks cover those virtual keys for non-existent values.</li><li>Key-range locks takes multiple key-value locks and gap locks to lock on a range.</li><li>Hierarchical locking allows for a transaction to hold wider key-range locks with different locking modes to reduce the number of visits to lock manager.</li></ul></li><li>If there is no suitable index, then the transaction must obtain:<ul><li>A lock on every page in the table to prevent a record’s attributes from being changed to fit the predicates.</li><li>The lock for the table itself to prevent records fit the predicates from being added or deleted.</li></ul></li></ol><h2 id="what-are-isolation-levels"><a class="markdownIt-Anchor" href="#what-are-isolation-levels"></a> What are isolation levels?</h2><ol><li>We may want to use a weaker level of consistency to improve scalability.</li><li>Provides for greater concurrency at the cost of exposing transactions to uncommitted changes: dirty reads, unrepeatable reads and phantom reads.</li><li>The four isolation levels are as shown below:<br /><img src="/imgs/15445/TO/isolation.png" width="50%"></li><li>Each isolation level requires different locks to implement:<ul><li><code>SERIALIZABLE</code>: Obtain all locks first; plus index locks, plus strict 2PL.</li><li><code>REPEATABLE READS</code>: Same as above, but no index locks.</li><li><code>READ COMMITTED</code>: Same as above, but S locks are released immediately.</li><li><code>READ UNCOMMITTED</code>: Same as above but allows dirty reads (no S locks).</li></ul></li></ol>]]></content>
      
      
      <categories>
          
          <category> Open Courses </category>
          
          <category> CMU 15-445/645 Database System </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Database System </tag>
            
            <tag> Concurrency Control </tag>
            
            <tag> Transaction </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>10 Two-Phase Locking</title>
      <link href="/2023/08/04/Courses/15445/10-Two-Phase-Locking/"/>
      <url>/2023/08/04/Courses/15445/10-Two-Phase-Locking/</url>
      
        <content type="html"><![CDATA[<p><ul class="markdownIt-TOC"><li><a href="#two-phase-locking">Two-phase Locking</a><ul><li><a href="#how-can-we-guarantee-serializable-without-knowing-the-entire-schedule-ahead-of-time">How can we guarantee serializable without knowing the entire schedule ahead of time?</a></li><li><a href="#what-is-the-problem-of-releasing-locks-and-acquiring-it-later-again">What is the problem of releasing locks and acquiring it later again?</a></li><li><a href="#what-is-the-problem-of-two-phase-locking">What is the problem of two-phase locking?</a></li></ul></li><li><a href="#deadlock">Deadlock</a><ul><li><a href="#how-to-detect-and-resolve-deadlocks">How to detect and resolve deadlocks?</a></li><li><a href="#how-to-prevent-deadlocks">How to prevent deadlocks?</a></li></ul></li><li><a href="#lock-granularity">Lock granularity</a><ul><li><a href="#what-are-the-database-objects">What are the database objects?</a></li><li><a href="#how-to-support-multiple-granularities">How to support multiple granularities?</a></li><li><a href="#how-to-use-locks">How to use locks?</a></li></ul></li></ul></p><h1 id="two-phase-locking"><a class="markdownIt-Anchor" href="#two-phase-locking"></a> Two-phase Locking</h1><h2 id="how-can-we-guarantee-serializable-without-knowing-the-entire-schedule-ahead-of-time"><a class="markdownIt-Anchor" href="#how-can-we-guarantee-serializable-without-knowing-the-entire-schedule-ahead-of-time"></a> How can we guarantee serializable without knowing the entire schedule ahead of time?</h2><ol><li>We can use locks to protect database objects.<ul><li>When a transaction wants to access some objects, it needs to acquire locks of that objects from a centralized lock manager.</li><li>Locks are issued by applications and handled in lock manager while latches are issued and acquired locally. Hence acquiring locks are more expensive than acquiring latches even if locks are free.</li></ul></li><li>There are <code>S-LOCK</code> and <code>X-LOCK</code>.<ul><li><code>S-LOCKs</code> are shared locks for reads while <code>X-LOCKs</code> are exclusive locks for writes.</li><li>Their compatibility matrix is as followed:<br /><img src="/imgs/15445/2pl/sx_comp_matrix.png" width="50%"></li></ul></li><li>Lock manager keeps track of what transaction hold what locks and what transactions are waiting to acquire any locks.<ul><li>When transactions request or upgrade locks, lock manager grants or blocks requests. When transactions release or downgrade locks, lock manager updates its internal lock-table.</li><li>Lock manager is responsible for detecting deadlock and choosing some transactions to kill.</li></ul></li></ol><h2 id="what-is-the-problem-of-releasing-locks-and-acquiring-it-later-again"><a class="markdownIt-Anchor" href="#what-is-the-problem-of-releasing-locks-and-acquiring-it-later-again"></a> What is the problem of releasing locks and acquiring it later again?</h2><ol><li>This may cause in-consistent reads for a transaction when another transaction modified the object during lock is available.</li><li>This problem can be solved by two-phase locking.<ul><li>The first phase is growing:<ul><li>Each transaction requests or upgrades the locks that it needs from the DBMS’s lock manager. The lock manager grants/denies lock requests.</li></ul></li><li>The second phase is shrinking:<ul><li>The transaction is allowed to only release or downgrade locks that it previously acquired. It cannot acquire new locks.</li></ul></li></ul></li><li>Two-phase locking on its own is sufficient to guarantee conflict serializability because it generates schedules whose precedence graph is acyclic.</li></ol><h2 id="what-is-the-problem-of-two-phase-locking"><a class="markdownIt-Anchor" href="#what-is-the-problem-of-two-phase-locking"></a> What is the problem of two-phase locking?</h2><ol><li>It is subject to cascading aborts caused by dirty reads.<ul><li>When a transaction modified an object, and released the lock before it is aborted, the modified object is exposed to other transactions.</li><li>When the modifier is aborted, all other transactions that have used the modified object needs to abort.</li></ul></li><li>This can be solved by strong strict two-phase locking (rigorous two-phase locking).<ul><li>The transaction is only allowed to release locks after it has ended, i.e., committed or aborted.</li></ul></li><li>A schedule is strict if a value written by a transaction is not read or overwritten by other transactions until that transaction finishes.<ul><li>Its advantages are that it does not incurcascading aborts, and aborted transactions can be undone by just restoring original values of modified tuples.</li><li>However, it allows only conflict serializable schedules, but it is often stronger than needed for some apps. Most DBMSs prefer correctness before performance.</li></ul></li></ol><h1 id="deadlock"><a class="markdownIt-Anchor" href="#deadlock"></a> Deadlock</h1><h2 id="how-to-detect-and-resolve-deadlocks"><a class="markdownIt-Anchor" href="#how-to-detect-and-resolve-deadlocks"></a> How to detect and resolve deadlocks?</h2><ol><li>The two-phase locking may lead to deadlocks.</li><li>The DBMS creates a waits-for graph to keep track of what locks each transaction is waiting to acquire<ul><li>Nodes are transactions. Edge from <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>T</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">T_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> to <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>T</mi><mi>j</mi></msub></mrow><annotation encoding="application/x-tex">T_j</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.969438em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.311664em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span></span></span></span> if <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>T</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">T_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> is waiting for <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>T</mi><mi>j</mi></msub></mrow><annotation encoding="application/x-tex">T_j</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.969438em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.311664em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span></span></span></span> to release a lock.</li><li>The system periodically checks for cycles in waits- for graph and then decides how to break it.</li></ul></li><li>When the DBMS detects a deadlock, it will select a “victim” transaction to rollback to break the cycle.<ul><li>The victim transaction will either restart or abort (more common) depending on how it was invoked.</li><li>There is a trade-off between the frequency of checking for deadlocks and how long transactions wait before deadlocks are broken.</li></ul></li><li>Selecting the proper victim depends on a lot of different variables<ul><li>By age (lowest timestamp)</li><li>By progress (least/most queries executed)</li><li>By the number of items already locked</li><li>By the number of transactions that we have to rollback with it</li><li>We also should consider the # of times a transaction has been restarted in the past to prevent starvation.</li></ul></li><li>After selecting a victim transaction to abort, the DBMS can also decide on how far to rollback the transaction’s changes.<ul><li>The first approach is to rollback entire transaction and tell the application it was aborted.</li><li>The second approach is rolling back a portion of a transaction to break deadlock and then attempts to re-execute the undone queries.</li></ul></li></ol><h2 id="how-to-prevent-deadlocks"><a class="markdownIt-Anchor" href="#how-to-prevent-deadlocks"></a> How to prevent deadlocks?</h2><ol><li>When a transaction tries to acquire a lock that is held by another transaction, the DBMS kills one of them to prevent a deadlock.</li><li>Assign priorities based on timestamps, e.g older timestamp means higher priority.</li><li>The first kind of rule is Wait-Die (“Old Waits for Young”)<ul><li>If requesting transaction has higher priority than holding transaction, then requesting transaction waits for holding transaction. Otherwise requesting transaction aborts.</li></ul></li><li>The second kind of rule is Wound-Wait (“Young Waits for Old”)<ul><li>If requesting transaction has higher priority than holding transaction, then holding transaction aborts and releases lock. Otherwise requesting transaction waits.</li></ul></li><li>In this case, only one “type” of direction allowed when waiting for a lock.</li><li>When a transaction restarts, its new priority is still its original timestamp to prevent it from getting starved for resources like an old man at a corrupt senior center.</li></ol><h1 id="lock-granularity"><a class="markdownIt-Anchor" href="#lock-granularity"></a> Lock granularity</h1><h2 id="what-are-the-database-objects"><a class="markdownIt-Anchor" href="#what-are-the-database-objects"></a> What are the database objects?</h2><ol><li>It can be attributes, tuples, pages, tables depending on the lock granularity.</li><li>The trade-off is between parallelism versus overhead of requesting and lock manager processing.</li><li>In a hierachical lock scheme, the objects from top-layer to lower-layer are database, table, page, tuple, attribute.</li></ol><h2 id="how-to-support-multiple-granularities"><a class="markdownIt-Anchor" href="#how-to-support-multiple-granularities"></a> How to support multiple granularities?</h2><ol><li>With only <code>S-LOCK</code> and <code>X-LOCK</code>, we have to check the locks of all children when we try to lock a higher-level node.</li><li>An intention lock allows a higher-level node to be locked in shared or exclusive mode without having to check all descendent nodes.</li><li>If a node is locked in an intention mode, then some transaction is doing explicit locking at a lower level in the tree.<ul><li>Intention-Shared (<code>IS</code>) indicates explicit locking at lower level with shared locks.</li><li>Intention-Exclusive (<code>IX</code>) indicates explicit locking at lower level with exclusive locks.</li><li>Shared+Intention-Exclusive (<code>SIX</code>) indicates that the subtree rooted by that node is locked explicitly in shared mode and explicit locking is being done at a lower level with exclusive-mode locks.</li><li>Their compatibility matrix is as followed:<br /><img src="/imgs/15445/2pl/intention.png" width="50%"></li></ul></li><li>Each transaction obtains appropriate lock at highest level of the database hierarchy.<ul><li>To get <code>S</code> or <code>IS</code> lock on a node, the transaction must hold at least <code>IS</code> on parent node.</li><li>To get <code>X</code>, <code>IX</code>, or <code>SIX</code> on a node, must hold at least <code>IX</code> on parent node.</li></ul></li><li>Multiple lock granularities is shown in the <code>S</code>, <code>X</code>, <code>SIX</code> locks on higher-level objects.<ul><li>Intention-Shared (<code>IS</code>): Intent to get <code>S</code> lock(s) at finer granularity.</li><li>Intention-Exclusive (<code>IX</code>): Intent to get <code>X</code> lock(s) at finer granularity.</li><li>Shared+Intention-Exclusive (<code>SIX</code>): Like <code>S</code> and <code>IX</code> at the same time.</li></ul></li></ol><h2 id="how-to-use-locks"><a class="markdownIt-Anchor" href="#how-to-use-locks"></a> How to use locks?</h2><ol><li>Applications typically don’t acquire a transaction’s locks manually (i.e., explicit SQL commands).<ul><li>Sometimes you need to provide the DBMS with hints to help it to improve concurrency.</li><li>Explicit locks are also useful when doing major changes to the database.</li></ul></li><li>Lock escalation: The DBMS can automatically switch to coarser- grained locks when a transaction acquires too many low-level locks. This reduces the number of requests that the lock manager must process.</li></ol>]]></content>
      
      
      <categories>
          
          <category> Open Courses </category>
          
          <category> CMU 15-445/645 Database System </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Database System </tag>
            
            <tag> Concurrency Control </tag>
            
            <tag> Transaction </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Project #3: Query Execution</title>
      <link href="/2023/08/02/OpenSource/BusTub/Project-3-Query-Execution/"/>
      <url>/2023/08/02/OpenSource/BusTub/Project-3-Query-Execution/</url>
      
        <content type="html"><![CDATA[<p><ul class="markdownIt-TOC"><li><a href="#executors">Executors</a><ul><li><a href="#overall">Overall</a></li><li><a href="#scan">Scan</a></li><li><a href="#modification">Modification</a></li><li><a href="#aggregation">Aggregation</a></li><li><a href="#nestedloopjoin">NestedLoopJoin</a></li><li><a href="#hashjoin">HashJoin</a></li><li><a href="#sort-top-n">Sort &amp; Top-N</a></li></ul></li><li><a href="#optimizer">Optimizer</a><ul><li><a href="#nested-loop-join">Nested loop join</a></li><li><a href="#order-by">Order by</a></li><li><a href="#projection">Projection</a></li><li><a href="#filter">Filter</a></li></ul></li></ul></p><h1 id="executors"><a class="markdownIt-Anchor" href="#executors"></a> Executors</h1><h2 id="overall"><a class="markdownIt-Anchor" href="#overall"></a> Overall</h2><ol><li>The planner for each operation stores the necessary information to calculate the correct output.</li><li>The executor class for each operation stores the corresponding plan and other information for it to determine what tuple will be returned.<ul><li>All executors need to override the <code>Init()</code> and <code>Next(Tuple *tuple, RID *rid)</code>.</li><li><code>Init()</code> is used to initialize the information to determine what tuple will be returned. It is separated from the constructor because its parent executor may need to fetch the tuples of the current executor several times.</li></ul></li><li>The <code>ExecutorContext</code> in each executor stores the metadata of the database system, including catalog, buffer pool manager.<ul><li>Catalog maintains the tables and indexes in the current database.</li><li>We can register a new table or index through catalog or acquire metadata of a table (<code>TableInfo</code>) or index (<code>IndexInfo</code>) from catalog.</li></ul></li><li>The <code>TableInfo</code> stores the name, OID, schema of the table, and a pointer of <code>TableHeap</code>.<ul><li>We can manipulate a table through its <code>TableHeap</code>.</li><li>The <code>TableHeap</code> provides methods to insert or get tuples and update or get tuple metadata.<ul><li>To delete a tuple, we just need to mark the <code>is_deleted_</code> flag in its metadata as <code>true</code>.</li><li>To update a tuple, we need to delete it first and insert the new updated tuple into the table again.</li><li>To iterate through the table, <code>TableHeap</code> also provided <code>MakeIterator()</code>.</li></ul></li></ul></li><li>The <code>IndexInfo</code> stores the name and OID of the index, the schema for the index key, the name of the table and a pointer of <code>Index</code>.<ul><li>We can manipulate an index through its <code>Index</code>.</li><li>The <code>Index</code> provides methods to insert or delete an entry from the index, and get metadata of the index.<ul><li>The metadata includes the names of the index and table, mapping relation between key schema and tuple schema, and the schema of the indexed key.</li><li>The <code>Index</code> is the abstract class of all kinds of index implementations. To use a specific known index implementation, we can <code>dynamic_cast</code> it.</li></ul></li></ul></li><li>This system support <code>ArithmeticExpression</code>, <code>ColumnValueExpression</code>, <code>ComparisonExpression</code>, <code>ConstantValueExpression</code>, <code>LogicExpression</code>, <code>StringExpression</code>.<ul><li>The <code>AbstractExpression</code> provides an <code>Evaluate</code> method to calculate desired <code>Value</code> according to provided one <code>Tuple</code> and <code>Schema</code>.<ul><li>The <code>ArithmeticExpression</code> only supports <code>PLUS</code> and <code>MINUS</code> operation of two <code>Value</code>s.</li><li>The <code>ColumnValueExpression</code> returns the <code>Value</code> of the designated column.</li><li>The <code>ComparisonExpression</code> supports the comparison result of two <code>Values</code>s of <code>equal, not equal, less, less or equal, greater, greater or equal</code>.</li><li>The <code>ConstantValueExpression</code> returns a single constant <code>Value</code>.</li><li>The <code>LogicExpression</code> supports the <code>AND/OR</code> of two <code>Value</code>s.</li><li>The <code>StringExpression</code> converts a string  to lower-case or upper-case.</li></ul></li><li>The <code>AbstractExpression</code> also provides an <code>EvaluateJoin</code> method to calculate the join condition of two <code>Tuple</code>s. They support the same functions as <code>Evaluation</code> except that they consider two tuples.</li><li><code>ArithmeticExpression</code>, <code>ComparisonExpression</code>, <code>LogicExpression</code> and <code>LogicExpression</code> may have child-expressions. During evaluation, they will perform child expressions first recursively.</li></ul></li></ol><h2 id="scan"><a class="markdownIt-Anchor" href="#scan"></a> Scan</h2><ol><li>In sequential scan, we only need to know which table to scan.<ul><li>The object ID and name of the table is stored in the planner.</li><li>In the <code>Init()</code>, the metadata of the table (<code>TableInfo</code>) is fetched from catalog and the corresponding iterator of the table is created.</li><li>In the <code>Next(Tuple *tuple, RID *rid)</code>, as long as the iterator is not at the end, we need to find the first tuple with <code>is_deleted_</code> being <code>false</code> and matching with <code>filter_predicate_</code>.</li></ul></li><li>In the index scan, we need to know which index to scan and which table to fetch the tuple.<ul><li>The OID of the index is stored in the planner while the name of the table is stored in the <code>IndexInfo</code>.</li><li>To fetch the iterator of the index, we need to cast the <code>Index</code> into the specific implementation.</li><li>Each iterator points to a paire of the key and the RecordID. We can fetch the tuple with the <code>GetTuple</code> of the <code>TableHeap</code>.</li><li>As long as the iterator is not at the end, we need to find the first tuple with <code>is_deleted_</code> being <code>false</code>.</li></ul></li></ol><h2 id="modification"><a class="markdownIt-Anchor" href="#modification"></a> Modification</h2><ol><li>In the modification executors, we will modify the table and all the associated indexes.<ul><li>The table OIDs are stored in corresponding planner, while we can fetch all indexes of that table with the name of the table in <code>TableInfo</code>.</li><li>The indexed keys can be acquired with the <code>KeyFromTuple</code> method of the <code>Tuple</code>. The stored values are RecordIDs.</li></ul></li><li>All the modification executors only return one row representing the number of modified tuples. Hence in one <code>Next</code> call, the executor should handle all the modification.<ul><li>When no modification is performed, we should also return one row of <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>0</mn></mrow><annotation encoding="application/x-tex">0</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">0</span></span></span></span>.</li><li>To distinguish between no modification and modification already finished in last call, we should have a flag representing whether or not we have already modified the table.</li></ul></li><li>In the insert executor and delete executor, the tuples to insert or delete are acquired from child executor.</li><li>In the update planner, there is a target expression for each output column.<ul><li>After acquired the original tuple from the child executor, we can evaluate each output column with target expressions.</li><li>The expressions can be any kind of expressions here.</li><li>When updating indexes, it needs to first delete the old indexes first before insert updated indexes.</li></ul></li></ol><h2 id="aggregation"><a class="markdownIt-Anchor" href="#aggregation"></a> Aggregation</h2><ol><li>The aggregations are implemented with a hash table.<ul><li>The hash table hashes the aggregate keys to the aggregate result.</li><li>When insert a tuple into the hash table, it updates the aggregate result in it according to the aggregate function and the aggregate values from the tuple.</li><li>To use <code>std::hash</code>, the key is <code>AggregateKey</code> containing a vector of <code>Value</code> describing the group-by keys while the value is <code>AggregateValue</code> containing another vector of <code>Value</code> describing aggregate values.<ul><li>The <code>AggregateKey</code> needs to override <code>==</code> operator and provide <code>()</code> operator in <code>struct std::hash&lt;bustub::AggregateKey&gt;</code> to calculate the hash value of <code>AggregateKey</code>.</li></ul></li></ul></li><li>Aggregations are pipeline breakers. Hence the build phase could be performed in the <code>Init()</code> where all tuples from child executor are read and inserted into the hash table to calculate the outputs.<ul><li>If no tuple is inserted, the aggregation executor still need to return the default values for each aggregate function.</li><li>The aggregation planner has two vectors of <code>AbstractExpressionRef</code> to fetch the aggregate keys and aggregate values from tuples received from child executor for aggregate computation. They are all <code>ColumnExpression</code>.</li></ul></li><li>In the <code>Next(Tuple *tuple, RID *rid)</code>, we just need to iterate over the hash table and output a tuple combining the aggregate keys and aggregate results.</li></ol><h2 id="nestedloopjoin"><a class="markdownIt-Anchor" href="#nestedloopjoin"></a> NestedLoopJoin</h2><ol><li><p>The executor needs to iterate over left child executor and right child executor.</p><ul><li>When the right child executor has emitted all tuples, the join executor will try to fetch a new tuple from the left child executor and re-initialize the right child executor for the following comparison.</li><li>Since we do not always fetch from left child executor when the <code>Next</code> is called, we need to record the current left tuple when it is fetched.</li><li>To distinguish between the status of no more left tuples and have not fetched any left tuples yet, we can fetch the first left tuple in <code>Init()</code>.</li><li>To mark the status of no more left tuples, i.e. no more tuples to emit, we need a flag to record the status of left tuples, which is the returned value of the <code>Next</code> of left child executor.</li></ul></li><li><p>For left join, if an outer tuple does not match with any inner tuple, we still need to emit the concatenation of that outer tuple with all-null inner tuple.</p></li><li><p>The predicate expression of the executor can be either a <code>LogicExpression</code> or <code>ComparisonExpression</code>.</p></li></ol><h2 id="hashjoin"><a class="markdownIt-Anchor" href="#hashjoin"></a> HashJoin</h2><ol><li>Similar with aggregations, we need a hash table for the outer table. We define <code>JoinKey</code> and <code>JoinBucket</code> to hash.<ul><li>We store all tuples with the same values in the attributes of join condition.</li><li>To support left join, we also need to record whether one tuple is used.<ul><li>When a tuple is matched with some inner tuple, all tuples in the same bucket must also matched. Hence we only need to record the usage of each <code>JoinBucket</code>.</li><li>For left join, when there is no more right tuples, the executor still need to iterate through the hash table to see if any bucket is unused.</li></ul></li><li>Similar with aggregation, <code>HashJoin</code> need to build the hash table based on the outer table in <code>Init()</code>.</li></ul></li><li>Different with <code>NestedLoopJoin</code>, the plan of <code>HashJoin</code> only need to know how to fetch columns from each tuples to determine whether those tuples are matched.<ul><li>The expressions of the <code>HashJoin</code> planner are only <code>ColumnValueExpression</code>.</li></ul></li></ol><h2 id="sort-top-n"><a class="markdownIt-Anchor" href="#sort-top-n"></a> Sort &amp; Top-N</h2><ol><li>The compare function needs specific expressions to fetch designated columns from each tuple.<ul><li>Hence we cannot only implement a non-static member function or a function with expressions being one of the parameters.</li><li>We need to implement a structure with override <code>()</code> operator. The expressions are passed to the object in initialization.</li><li>For <code>priority_queue</code>, two nodes will be swapped when the comparison function returns true.</li></ul></li><li>In the <code>Init()</code>, we need to fetch all tuples from child executor and sort them.<ul><li>For Top-N executor, the heap size should not be larger than <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>N</mi></mrow><annotation encoding="application/x-tex">N</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">N</span></span></span></span>. The heap after the <code>Init()</code> is the counter-order of the output order, hence we still need a stack to support output in <code>Next</code>.</li></ul></li></ol><h1 id="optimizer"><a class="markdownIt-Anchor" href="#optimizer"></a> Optimizer</h1><ol><li>When trying to optimize a plan, the root plan is passed to the optimizer and the optimizer will perform a DFS of the plan tree.</li><li>Each optimizer tries to recognize the pattern they need to handle and produce a new plan when it is matched.</li></ol><h2 id="nested-loop-join"><a class="markdownIt-Anchor" href="#nested-loop-join"></a> Nested loop join</h2><ol><li>To optimize nested loop join with hash join, the optimizer need to find a nested loop join and separate all the conditions from <code>LogicExpression</code> into <code>ComparisonExpression</code>.<ul><li>If all the <code>ComparisonExpression</code> are <code>ComparisonType::Equal</code>, we can create a new plan of <code>HashJoin</code> with <code>left_key_expressions</code> and <code>right_key_expressions</code> extracted from those <code>ComparisonExpression</code>.</li></ul></li><li>Push down predicates of nested loop join to reduce the output of children of join to reduce the complexity of join.<ul><li>Only predicates that only involve one side of input of join operator can be pushed down.</li><li>Some predicates need to be pushed into the left child, some are pushed to the right child, while some are remained in the join.</li><li>To push down predicate, we can create a new <code>FilterPlanNode</code> as a child of join and father of original child.</li></ul></li><li>Nested loop join can be replaced by hash join when the predicates are all equal conditions.</li><li>If the parent planner of a nested loop join is an aggregation planner and that aggregation planner involves only data from one side, we can push down that aggregation as one of the children of join.<ul><li>The insight is that aggregation usually output less rows than its input since aggregation groups rows before sending one row for each group.</li><li>The columns in the mathmatical expressions need to be modified according to the side of aggregation.</li></ul></li></ol><h2 id="order-by"><a class="markdownIt-Anchor" href="#order-by"></a> Order by</h2><ol><li>To optimize limit followed by sort into top-N, we just need to check whether the child of a limit plan is a sort.</li><li>When sorting the table, instead of exeuting sort algorithms, we may use the existing index to traverse the table.<ul><li>It can only be used when the desired order is ascending or default and the child of sorting planner is SeqScan planner.</li></ul></li></ol><h2 id="projection"><a class="markdownIt-Anchor" href="#projection"></a> Projection</h2><ol><li><code>SELECT *</code>, aggregations, or renaming the columns in the planner may cauing multiple identical project planner.<ul><li>The child of projection planner is not required to be a projection.</li><li>We can remove the projection planner as long as it has the same schema as its child except column name.</li><li>Then the output schema of the child is replaced by the output schema of projection.</li></ul></li><li>The child of projection planner may be emitting unnecessary columns.<ul><li>Besides naive projection, a projection planner could also perform arithmathical expressions.</li><li>If the child is another projection, we can merge them and express the new projection under the column schema of the input schema of the child.</li><li>If the child  is an aggregation planner, it only need to calculate those necessary aggregations.</li></ul></li></ol><h2 id="filter"><a class="markdownIt-Anchor" href="#filter"></a> Filter</h2><ol><li>Always true filters can be eliminated to avoid re-evaluation for every row.</li><li>The filter planner with a child of sequential scan can be merged to reduce the data transmission between executors.</li><li>When the predicate of sequential scan is all equal conditions and there exists a corresponding index, the sequential scan can be replaced by index scan to avoid scanning the entire table.<ul><li>It needs to modify the <code>IndexScanPlanner</code> and the <code>IndexScanExecutor</code> to support scanning only the row designated by the equal conditions.</li></ul></li></ol>]]></content>
      
      
      <categories>
          
          <category> Open Source Code </category>
          
          <category> BusTub </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Database System </tag>
            
            <tag> Executor </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>09 Concurrency Control</title>
      <link href="/2023/07/16/Courses/15445/09-Concurrency-Control/"/>
      <url>/2023/07/16/Courses/15445/09-Concurrency-Control/</url>
      
        <content type="html"><![CDATA[<p><ul class="markdownIt-TOC"><li><a href="#concurency-control-recovery">Concurency control &amp; recovery</a><ul><li><a href="#what-do-we-want-from-concurrency-control-recovery">What do we want from concurrency control &amp; recovery?</a></li><li><a href="#how-does-applications-issue-changes-to-a-dbms">How does applications issue changes to a DBMS?</a></li><li><a href="#what-does-the-dbms-want-to-prevent-when-supporting-concurrency">What does the DBMS want to prevent when supporting concurrency?</a></li></ul></li><li><a href="#correctness">Correctness</a><ul><li><a href="#what-is-the-correctness-criteria">What is the correctness criteria?</a></li><li><a href="#how-to-ensure-atomicity">How to ensure atomicity?</a></li><li><a href="#what-is-consistency">What is consistency?</a></li><li><a href="#isolation">Isolation</a><ul><li><a href="#what-do-we-want-from-isolation">What do we want from isolation?</a></li><li><a href="#how-to-decide-whether-a-schedule-matches-isolation">How to decide whether a schedule matches isolation?</a></li><li><a href="#what-conflicts-do-we-want-to-prevent">What conflicts do we want to prevent?</a></li><li><a href="#how-do-we-determine-whether-a-schedule-is-conflict-serializable">How do we determine whether a schedule is conflict serializable?</a></li><li><a href="#how-do-we-determine-whether-a-schedule-is-view-serializable">How do we determine whether a schedule is view serializable?</a></li></ul></li></ul></li></ul></p><h1 id="concurency-control-recovery"><a class="markdownIt-Anchor" href="#concurency-control-recovery"></a> Concurency control &amp; recovery</h1><h2 id="what-do-we-want-from-concurrency-control-recovery"><a class="markdownIt-Anchor" href="#what-do-we-want-from-concurrency-control-recovery"></a> What do we want from concurrency control &amp; recovery?</h2><ol><li>The concurrency control is responsible for lost update problem.<ul><li>How can we avoid race conditions when updating records at the same time?</li><li>This involves the buffer pool manager layer, access methods layer and operator execution layer.</li></ul></li><li>Recovery is responsible for durability problems.<ul><li>How can we ensure the correct state in case of a power failure?</li><li>This involves the disk manager layer and buffer pool manager layer.</li></ul></li></ol><h2 id="how-does-applications-issue-changes-to-a-dbms"><a class="markdownIt-Anchor" href="#how-does-applications-issue-changes-to-a-dbms"></a> How does applications issue changes to a DBMS?</h2><ol><li>A transaction is the execution of a sequence of one or more operations (e.g., SQL queries) on a database to perform some higher-level function.<ul><li>Transaction is the basic unit of change in a DBMS. Partial transactions are not allowed.</li><li>A new transaction starts with the <code>BEGIN</code> command.</li><li>The transaction stops with either <code>COMMIT</code> or <code>ABORT</code>:<ul><li>If commit, the DBMS either saves all the transaction’s changes <strong>or aborts</strong> it.</li><li>If abort, all changes are undone so that it’s like as if the transaction never executed at all.</li><li>Abort can be either self-inflicted or caused by the DBMS.</li></ul></li></ul></li><li>In a strawman system, each transaction is executed one-by-one as  they arrive at the DBMS.<ul><li>Before a transaction starts, copy the entire database to a new file and make all changes to that file.<ul><li>If the txn completes successfully, overwrite the original file with the new one.</li><li>If the txn fails, just remove the dirty copy.</li></ul></li><li>The problem of this system is that there is no concurrency and copying the entire database can be expensive if the it is large.</li></ul></li><li>Besides correctness and fairness, we also want the DBMS to allow concurrent execution of independent transactions to provide better utilization / throughput and increase response times to users.</li></ol><h2 id="what-does-the-dbms-want-to-prevent-when-supporting-concurrency"><a class="markdownIt-Anchor" href="#what-does-the-dbms-want-to-prevent-when-supporting-concurrency"></a> What does the DBMS want to prevent when supporting concurrency?</h2><ol><li>Arbitrary interleaving of operations can lead to temporary inconsistency and permanent inconsistency.<ul><li>Temporary inconsistency is unavoidable and it is fine as long as no other transactions can see it.</li><li>Permanent inconsistency is unacceptable.</li></ul></li><li>The DBMS is only concerned about what data is read/written from/to the database. Changes to the “outside world”, e.g. sending an email, are beyond the scope of the DBMS.</li></ol><h1 id="correctness"><a class="markdownIt-Anchor" href="#correctness"></a> Correctness</h1><h2 id="what-is-the-correctness-criteria"><a class="markdownIt-Anchor" href="#what-is-the-correctness-criteria"></a> What is the correctness criteria?</h2><ol><li><strong>Atomicity</strong>: All actions in transaction happen, or none happen, i.e. “all or nothing”.</li><li><strong>Consistency</strong>: If each transaction is consistent and the DB starts consistent, then it ends up consistent.</li><li><strong>Isolation</strong>: Execution of one transaction is isolated from that of other transactions.</li><li><strong>Durability</strong>: If a txn commits, its effects persist.</li></ol><h2 id="how-to-ensure-atomicity"><a class="markdownIt-Anchor" href="#how-to-ensure-atomicity"></a> How to ensure atomicity?</h2><ol><li>The first approach is logging (Write Ahead Log / WAL).<ul><li>DBMS logs all actions so that it can undo the actions of aborted transactions.</li><li>Maintain undo records both in memory and on disk.</li><li>When the DBMS come back from a crash, it need to undo partial transactions according to the undo records.</li></ul></li><li>Another approach is shadow paging.<ul><li>DBMS makes copies of pages and txns make changes to those copies.</li><li>Only when the txn commits is the page made visible to others by modifying the pointer at directory.</li><li>It does not need extra operations when come back from crash.</li></ul></li></ol><h2 id="what-is-consistency"><a class="markdownIt-Anchor" href="#what-is-consistency"></a> What is consistency?</h2><ol><li>At a high level, consisitency means the “world” represented by the database is logically correct. All questions (i.e., queries) that the application asks about the data will return logically correct results.</li><li>There are two notions of consistency<ul><li>Database consistency means that the database accurately models the real world and follows integrity constraints.<ul><li>Transactions in the future see the effects of transactions committed in the past inside of the database.</li><li>The designer of DBMS should maintain this consistency.</li></ul></li><li>Transaction consistency means that if the database is consistent before the transaction starts, it will also be consistent after.<ul><li>The application programmer is responsible for this consistency. The DBMS does not know the semantics of correctness.</li></ul></li></ul></li></ol><h2 id="isolation"><a class="markdownIt-Anchor" href="#isolation"></a> Isolation</h2><h3 id="what-do-we-want-from-isolation"><a class="markdownIt-Anchor" href="#what-do-we-want-from-isolation"></a> What do we want from isolation?</h3><ol><li>Users submit txns, and each txn executes as if it was running by itself, i.e. it is executed in a strawman system where no other transaction is executing at the same time.</li><li>Isolation provides an easier programming model to reason about.</li><li>But the DBMS achieves concurrency by interleaving the actions (reads/writes of DB objects) of txns. Hence we need to schedule to interleave txns but still make it appear as if they ran one-at-a-time.</li><li>There is no guarantee that <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>T</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">T_1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> will execute before <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>T</mi><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">T_2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> or vice-versa, if both are submitted together. The net effect must be equivalent to these two transactions running serially in some order.</li></ol><h3 id="how-to-decide-whether-a-schedule-matches-isolation"><a class="markdownIt-Anchor" href="#how-to-decide-whether-a-schedule-matches-isolation"></a> How to decide whether a schedule matches isolation?</h3><ol><li>If the schedule is equivalent to some serial execution, we can consider it correct.</li><li>For any database state, if the effect of executing the first schedule is identical to the effect of executing the second schedule, we say these two schedules are equivalent.</li><li>A schedule is serializable schedule if it is equivalent to some serial execution of the transactions.<ul><li>If each transaction preserves consistency, every serializable schedule preserves consistency.</li></ul></li><li>There are two different levels of serializability: conflict serializability (most commonly used) and view serializability.</li></ol><h3 id="what-conflicts-do-we-want-to-prevent"><a class="markdownIt-Anchor" href="#what-conflicts-do-we-want-to-prevent"></a> What conflicts do we want to prevent?</h3><ol><li>Two operations conflict if: They are by different transactions, and they are on the same object while one of them is a write.</li><li>A read-write conflict will cause unrepeatable read.<ul><li>Transaction gets different values when reading the same object multiple times.</li><li>The conflict is between the write from one transaction and a repeated following read from another transaction, i.e. this is actually <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>r</mi><mi>e</mi><mi>a</mi><msub><mi>d</mi><mn>1</mn></msub><mo>−</mo><mi>w</mi><mi>r</mi><mi>i</mi><mi>t</mi><mi>e</mi><mo>−</mo><mi>r</mi><mi>e</mi><mi>a</mi><msub><mi>d</mi><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">read_1-write-read_2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.84444em;vertical-align:-0.15em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mord mathnormal">e</span><span class="mord mathnormal">a</span><span class="mord"><span class="mord mathnormal">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.74285em;vertical-align:-0.08333em;"></span><span class="mord mathnormal" style="margin-right:0.02691em;">w</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mord mathnormal">i</span><span class="mord mathnormal">t</span><span class="mord mathnormal">e</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.84444em;vertical-align:-0.15em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mord mathnormal">e</span><span class="mord mathnormal">a</span><span class="mord"><span class="mord mathnormal">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> conflict where the conflict is between <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>w</mi><mi>r</mi><mi>i</mi><mi>t</mi><mi>e</mi><mo>−</mo><mi>r</mi><mi>e</mi><mi>a</mi><msub><mi>d</mi><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">write-read_2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.74285em;vertical-align:-0.08333em;"></span><span class="mord mathnormal" style="margin-right:0.02691em;">w</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mord mathnormal">i</span><span class="mord mathnormal">t</span><span class="mord mathnormal">e</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.84444em;vertical-align:-0.15em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mord mathnormal">e</span><span class="mord mathnormal">a</span><span class="mord"><span class="mord mathnormal">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>.</li><li>If there is only one read, it is not a read-write conflict. The first read will never be a read-write conflict.</li></ul></li></ol><ul><li>A write-read conflict will cause dirty read.<ul><li>One transaction reads data written by another transaction that has not committed yet.</li><li>The problem will happen when the read transaction is commited before the write transaction aborts.</li><li>If the write transaction successfully commits, there is no problem. But we cannot know that when we commit the read transaction first.</li></ul></li><li>A write-write conflict will cause lost update.<ul><li>One transaction overwrites uncommitted data from another uncommitted transaction.</li><li>This may cause the result becoming combination of two partial transactions.</li><li>There is no problem when every data written by <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>T</mi><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">T_2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> is the last write to that data, i.e. every data written by <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>T</mi><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">T_2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> is not overwritten by <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>T</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">T_1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>. The problem happens when <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>T</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">T_1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> overwrites some data of <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>T</mi><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">T_2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> while <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>T</mi><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">T_2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> overwrites some data of <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>T</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">T_1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>.</li></ul></li></ul><h3 id="how-do-we-determine-whether-a-schedule-is-conflict-serializable"><a class="markdownIt-Anchor" href="#how-do-we-determine-whether-a-schedule-is-conflict-serializable"></a> How do we determine whether a schedule is conflict serializable?</h3><ol><li>When there are only two schedules:<ul><li>Two schedules are conflict equivalent if and only if they involve the same actions of the same transactions and every pair of conflicting actions is ordered the same way.</li><li>Schedule S is conflict serializable if S is conflict equivalent to some serial schedule.</li><li>We can transform S into a serial schedule by swapping consecutive non-conflicting operations of different transactions.</li></ul></li><li>For more schedules, we can use the dependency graphs.<ul><li>Create one node per txn in the graph.</li><li>Create an edge from <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>T</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">T_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> to <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>T</mi><mi>j</mi></msub></mrow><annotation encoding="application/x-tex">T_j</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.969438em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.311664em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span></span></span></span> if an operation <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>O</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">O_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02778em;">O</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> of <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>T</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">T_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> conflicts with an<br />operation <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>O</mi><mi>j</mi></msub></mrow><annotation encoding="application/x-tex">O_j</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.969438em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02778em;">O</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.311664em;"><span style="top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span></span></span></span> of <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>T</mi><mi>j</mi></msub></mrow><annotation encoding="application/x-tex">T_j</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.969438em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.311664em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span></span></span></span> and <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>O</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">O_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02778em;">O</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> appears earlier in the schedule than <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>O</mi><mi>j</mi></msub></mrow><annotation encoding="application/x-tex">O_j</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.969438em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02778em;">O</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.311664em;"><span style="top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span></span></span></span>.</li><li>A schedule is conflict serializable if and only if its dependency graph is acyclic.</li></ul></li></ol><h3 id="how-do-we-determine-whether-a-schedule-is-view-serializable"><a class="markdownIt-Anchor" href="#how-do-we-determine-whether-a-schedule-is-view-serializable"></a> How do we determine whether a schedule is view serializable?</h3><ol><li>Schedules <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>S</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">S_1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05764em;">S</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.05764em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> and <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>S</mi><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">S_2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05764em;">S</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.05764em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> are view equivalent if:<ul><li>If <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>T</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">T_1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> reads initial value of A in <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>S</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">S_1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05764em;">S</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.05764em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>, then <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>T</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">T_1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> also reads initial value of A in <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>S</mi><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">S_2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05764em;">S</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.05764em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>.</li><li>If <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>T</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">T_1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> reads value of A written by <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>T</mi><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">T_2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> in <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>S</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">S_1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05764em;">S</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.05764em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>, then <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>T</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">T_1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> also reads value of A written by <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>T</mi><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">T_2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> in <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>S</mi><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">S_2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05764em;">S</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.05764em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>.</li><li>If <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>T</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">T_1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> writes final value of A in <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>S</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">S_1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05764em;">S</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.05764em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>, then <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>T</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">T_1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> also writes final value of A in <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>S</mi><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">S_2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05764em;">S</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.05764em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>.</li></ul></li><li>In a word, each transaction is different schedules read the same values written by the same transaction and at the final end of all transactions, all data are written by the same transaction in the same value.</li><li>View Serializability allows for (slightly) more schedules than Conflict Serializability does. Neither definition allows all serializable schedules.</li></ol>]]></content>
      
      
      <categories>
          
          <category> Open Courses </category>
          
          <category> CMU 15-445/645 Database System </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Database System </tag>
            
            <tag> Concurrency Control </tag>
            
            <tag> Transaction </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>08 Query Planning &amp; Optimization</title>
      <link href="/2023/07/15/Courses/15445/08-Query-Planning-Optimization/"/>
      <url>/2023/07/15/Courses/15445/08-Query-Planning-Optimization/</url>
      
        <content type="html"><![CDATA[<p><ul class="markdownIt-TOC"><li><a href="#query-planning">Query planning</a><ul><li><a href="#what-are-the-logical-plans-and-physical-plans">What are the logical plans and physical plans?</a></li><li><a href="#what-is-the-process-flow-of-query-execution">What is the process flow of query execution?</a></li><li><a href="#how-does-optimizer-work">How does optimizer work?</a></li></ul></li><li><a href="#heuristics-optimization">Heuristics optimization</a><ul><li><a href="#how-should-we-optimize-logical-plans">How should we optimize logical plans?</a></li><li><a href="#how-should-we-optimize-for-nested-sub-queries">How should we optimize for nested sub-queries?</a></li><li><a href="#how-can-we-rewrite-expression">How can we rewrite expression?</a></li></ul></li><li><a href="#cost-based-search">Cost-based search</a><ul><li><a href="#cost-estimation">Cost estimation</a><ul><li><a href="#what-cost-do-we-care">What cost do we care?</a></li><li><a href="#how-do-dbms-estimate-the-costs">How do DBMS estimate the costs?</a></li><li><a href="#what-statistics-does-the-dbms-maintain">What statistics does the DBMS maintain?</a></li></ul></li><li><a href="#query-optimization">Query optimization</a><ul><li><a href="#how-do-we-perform-cost-based-optimization">How do we perform cost-based optimization?</a></li><li><a href="#how-does-bottom-up-optimization-work">How does bottom-up optimization work?</a></li><li><a href="#how-does-top-down-optimization-work">How does top-down optimization work?</a></li></ul></li></ul></li></ul></p><h1 id="query-planning"><a class="markdownIt-Anchor" href="#query-planning"></a> Query planning</h1><h2 id="what-are-the-logical-plans-and-physical-plans"><a class="markdownIt-Anchor" href="#what-are-the-logical-plans-and-physical-plans"></a> What are the logical plans and physical plans?</h2><ol><li>The optimizer generates a mapping of a logical algebra expression to the optimal equivalent physical algebra expression.</li><li>Physical operators define a specific execution strategy using an access path, i.e. a specific algorithm.<ul><li>They depend on the physical format of the data that they process, i.e., sorting, compression.</li></ul></li></ol><h2 id="what-is-the-process-flow-of-query-execution"><a class="markdownIt-Anchor" href="#what-is-the-process-flow-of-query-execution"></a> What is the process flow of query execution?</h2><ol><li>The application connected to the database system and sends a SQL query, which may be rewritten to a different format in SQL rewriter.</li><li>The SQL string is parsed into tokens that make up the syntax tree.</li><li>The binder converts named objects in the syntax tree to internal identifiers by consulting the system catalog.</li><li>The binder emits a logical plan which may be fed to a tree rewriter for additional schema info.</li><li>The logical plan is given to the optimizer which selects the most efficient procedure to execute the plan.</li></ol><img src="/imgs/15445/Optimizer/architecture.png" width="50%"><h2 id="how-does-optimizer-work"><a class="markdownIt-Anchor" href="#how-does-optimizer-work"></a> How does optimizer work?</h2><ol><li>One way is heuristics / rules.<ul><li>Rewrite the query to remove stupid / inefficient things.</li><li>These techniques may need to examine catalog, but they do not need to examine data.</li></ul></li><li>Another way is the cost-based search.<ul><li>We need to use a model to estimate the cost of executing a plan.</li><li>Enumerate multiple equivalent plans for a query and pick the one with the lowest cost.</li></ul></li></ol><h1 id="heuristics-optimization"><a class="markdownIt-Anchor" href="#heuristics-optimization"></a> Heuristics optimization</h1><h2 id="how-should-we-optimize-logical-plans"><a class="markdownIt-Anchor" href="#how-should-we-optimize-logical-plans"></a> How should we optimize logical plans?</h2><ol><li>Split conjunctive predicates.<ul><li>Decompose predicates into their simplest forms to make it easier for the optimizer to move them around.</li></ul></li><li>Predicate pushdown<ul><li>Move the predicate to the lowest applicable point in the plan.</li></ul></li><li>Replace cartesian products with joins<ul><li>Replace all Cartesian Products with inner joins using the join predicates.</li></ul></li><li>Projection pushdown<ul><li>This is to eliminate redundant attributes before pipeline breakers to reduce materialization cost and the data passed aroung.</li></ul></li></ol><h2 id="how-should-we-optimize-for-nested-sub-queries"><a class="markdownIt-Anchor" href="#how-should-we-optimize-for-nested-sub-queries"></a> How should we optimize for nested sub-queries?</h2><ol><li>Rewrite to de-correlate and/or flatten them<ul><li>E.g. an <code>EXISTS</code> sub-query in <code>WHERE</code> clause may be rewrited as an inner-join.</li></ul></li><li>Decompose nested query and store result to temporary table.<ul><li>For those sub-queries uncorrelated with outer query, the optimizer breaks up queries into blocks and then concentrates on one block at a time.</li><li>Sub-queries are written to a temporary table that are discarded after the query finishes.</li></ul></li></ol><h2 id="how-can-we-rewrite-expression"><a class="markdownIt-Anchor" href="#how-can-we-rewrite-expression"></a> How can we rewrite expression?</h2><ol><li>This is implemented using if/then/else clauses or a pattern-matching rule engine.<ul><li>Search for expressions that match a pattern. When a match is found, rewrite the expression. Halt if there are no more rules that match.</li></ul></li><li>One approach is replacing impossible or unnecessary predicates by false.</li><li>Another approach is merging predicates, e.g. numeric ranging predicates.</li></ol><h1 id="cost-based-search"><a class="markdownIt-Anchor" href="#cost-based-search"></a> Cost-based search</h1><h2 id="cost-estimation"><a class="markdownIt-Anchor" href="#cost-estimation"></a> Cost estimation</h2><h3 id="what-cost-do-we-care"><a class="markdownIt-Anchor" href="#what-cost-do-we-care"></a> What cost do we care?</h3><ol><li>Physical Costs<ul><li>Predict CPU cycles, I/O, cache misses, RAM consumption, network messages.</li><li>This cost depends heavily on hardware.</li></ul></li><li>Logical Costs<ul><li>Estimate output size per operator.</li><li>This cost is independent of the operator algorithm since algorithms are physical.</li><li>It need estimations for operator result sizes.</li></ul></li><li>Algorithmic Costs<ul><li>Mainly the complexity of the operator algorithm implementation.</li></ul></li><li>We may use a combination of multiple costs that are weighted by magic constant factors.<ul><li>Some assumptions is that processing a tuple in memory is <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>400</mn><mo>×</mo></mrow><annotation encoding="application/x-tex">400\times</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.72777em;vertical-align:-0.08333em;"></span><span class="mord">4</span><span class="mord">0</span><span class="mord">0</span><span class="mord">×</span></span></span></span> faster than reading a tuple from disk, and sequential I/O is <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>4</mn><mo>×</mo></mrow><annotation encoding="application/x-tex">4\times</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.72777em;vertical-align:-0.08333em;"></span><span class="mord">4</span><span class="mord">×</span></span></span></span> faster than random I/O.</li><li>Most commonly used cost is the combination of the physical costs and logical costs.</li></ul></li></ol><h3 id="how-do-dbms-estimate-the-costs"><a class="markdownIt-Anchor" href="#how-do-dbms-estimate-the-costs"></a> How do DBMS estimate the costs?</h3><ol><li>The DBMS stores internal statistics about tables, attributes, and indexes in its internal catalog.<ul><li>Different systems update them at different times.</li></ul></li><li>Then DBMS derives the <strong>selection cardinality</strong> (<strong>selectivity</strong>) of a predicate which is the fraction of tuples that qualify.</li><li>We can make some assumptions to estimate selectivity<ul><li>Uniform data: The distribution of values (except for the heavy hitters) is the same. May maintain a heavy hitter list that stores most common values and assume that the occurrence of the rest data is the same.</li><li>Independent predicates: The predicates on attributes are independent, i.e. the conjuction of predicates can result in multiplication or addition of probabilities.</li><li>Inclusion principle: The domain of join keys overlap such that each key in the inner relation will also exist in the outer table.</li><li>These assumptions may not be true.</li></ul></li></ol><h3 id="what-statistics-does-the-dbms-maintain"><a class="markdownIt-Anchor" href="#what-statistics-does-the-dbms-maintain"></a> What statistics does the DBMS maintain?</h3><ol><li>Histograms:<ul><li>The naive and most accurate way is to maintain an occurrence count per value in a column.</li><li>Equi-width histograms maintain counts for a group of values. All buckets have the same width, i.e. the same number of values.</li><li>Equi-depth histograms vary the width of buckets so that the total number of occurrences for each bucket is roughly the same.</li><li>Equi-width or equi-depth histograms use the total count of a bucket dividing by the number of values in that bucket as the count of each values.</li></ul></li><li>Sketches:<ul><li>Probabilistic data structure that gives an approximate count for a given value.</li><li>Cost-model can replace histograms with sketches to improve its selectivity estimate accuracy.</li></ul></li><li>Sampling:<ul><li>DBMS maintains a small subset of each table that it then uses to evaluate expressions to compute selectivity.</li><li>The selectivity is estimated by running the same query on the sample table.</li><li>Sample table is updated when the underlying tables changes significantly.</li></ul></li></ol><h2 id="query-optimization"><a class="markdownIt-Anchor" href="#query-optimization"></a> Query optimization</h2><h3 id="how-do-we-perform-cost-based-optimization"><a class="markdownIt-Anchor" href="#how-do-we-perform-cost-based-optimization"></a> How do we perform cost-based optimization?</h3><ol><li>After performing rule-based rewriting, the DBMS will enumerate different plans for the query and estimate their costs.<ul><li>It chooses the best plan it has seen for the query after exhausting all plans or some timeout.</li><li>The time spent on search should be significantly smaller than the time of executing query. DBMS can set a time threshold to end search.</li></ul></li><li>DBMS mainly enumerates the access methods (sequential scan, binary search / clustered indexes, index scan) and evaluation ordering.</li><li>Query planning for OLTP queries is easy because they are <strong>sargable</strong> (Search Argument Able).<ul><li>It is usually just picking the best index.</li><li>Joins are almost always on foreign key relationships with a small cardinality.</li></ul></li><li>For multi-relation query planning, there are two choices.<ul><li>Bottom-up optimization: Start with nothing and then build up the plan to get to the outcome that you want.</li><li>Top-down optimization: Start with the outcome that you want, and then work down the tree to find the optimal plan that gets you to that goal.</li></ul></li></ol><h3 id="how-does-bottom-up-optimization-work"><a class="markdownIt-Anchor" href="#how-does-bottom-up-optimization-work"></a> How does bottom-up optimization work?</h3><ol><li>Break query up into blocks and generate the logical operators for each block. For each logical operator, generate a set of physical operators that implement it.</li><li>The whole diagram can be layered by relations or temporary relations, i.e. results of logical operators.</li><li>We can visualize the whole optimization diagram as a tree with different layers.<ul><li>The top layer is the output of the query and the bottom layer is all the relations.</li><li>The middle layers are the enumerations of different ordering. Each layer only performs one more operator than its last layer.</li><li>Hence each pair of layers is connected with an undetermined physical operator.</li></ul></li><li>From bottom layer up, we enumarate the possible physical algorithm of each logical operator.<ul><li>Then estimate the cost of all possible physical algorithms.</li><li>Leave only the more efficient physical algorithm for each logical operator after comare with only the possible physical algorithms of the same logical operator.</li></ul></li><li>When reaches the top layer, we can determine the most efficient path of all possible paths.</li><li>Then iteratively construct a “left-deep” join tree that minimizes the estimated amount of work to execute the plan.<ul><li>Generate a left-deep tree is to take advantages of pipeline.</li></ul></li></ol><h3 id="how-does-top-down-optimization-work"><a class="markdownIt-Anchor" href="#how-does-top-down-optimization-work"></a> How does top-down optimization work?</h3><ol><li>Start with a logical plan of what we want the query to be.</li><li>Perform a branch-and-bound search to traverse the plan tree by converting logical operators into physical operators.<ul><li>When traversing from logical operator to logical operators, it is enumarating different ordering.</li><li>When traversing from logical operator to physical operators, it is enumarating different physical algorithm.</li><li>The layers are similar with bottom-up optimization.</li><li>When we meet a logical operator, we need to estimate the cost of its all possible physical algorithms.<ul><li>So for each physical algorithm, we need to go deeper until the bottom to calculate the estimation.</li><li>For the sub-logical-operators in the physical algorithm, we will enumarate its optimal execution in the lower levels.</li></ul></li><li>During the search, we can cut-off a branch if its cost is already more expensive then another branch we have already seen.</li></ul></li></ol>]]></content>
      
      
      <categories>
          
          <category> Open Courses </category>
          
          <category> CMU 15-445/645 Database System </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Database System </tag>
            
            <tag> Executor </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>07 Query Execution</title>
      <link href="/2023/07/12/Courses/15445/07-Query-Execution/"/>
      <url>/2023/07/12/Courses/15445/07-Query-Execution/</url>
      
        <content type="html"><![CDATA[<p><ul class="markdownIt-TOC"><li><a href="#sequential-execution">Sequential Execution</a><ul><li><a href="#processing-model">Processing model</a><ul><li><a href="#what-does-processing-model-do">What does processing model do?</a></li><li><a href="#how-does-iterator-model-execute">How does iterator model execute?</a></li><li><a href="#how-does-materialization-model-execute">How does materialization model execute?</a></li><li><a href="#how-does-vectorization-model-execute">How does vectorization model execute?</a></li></ul></li><li><a href="#access-methods">Access methods</a><ul><li><a href="#how-can-we-optimize-sequential-scan-with-data-skipping">How can we optimize sequential scan with data skipping?</a></li><li><a href="#what-is-multi-index-scan">What is multi-index scan?</a></li></ul></li><li><a href="#modification-queries">Modification queries</a><ul><li><a href="#how-should-we-execute-update-and-delete-queries">How should we execute update and delete queries?</a></li><li><a href="#how-should-we-execute-insert-queries">How should we execute insert queries?</a></li></ul></li><li><a href="#how-to-evaluate-expressions">How to evaluate expressions?</a></li></ul></li><li><a href="#parallel-execution">Parallel execution</a><ul><li><a href="#parallel-and-distributed">Parallel and distributed</a><ul><li><a href="#why-care-about-parallel-execution">Why care about parallel execution?</a></li><li><a href="#what-are-the-similarities-and-differences-between-parallel-and-distributed-dbms">What are the similarities and differences between parallel and distributed DBMS?</a></li></ul></li><li><a href="#process-model">Process model</a><ul><li><a href="#what-does-process-model-of-parallel-dbmss-need-to-do">What does process model of parallel DBMSs need to do?</a></li><li><a href="#what-is-process-per-worker-model">What is process per worker model?</a></li><li><a href="#what-is-thread-per-worker-model">What is thread per worker model?</a></li><li><a href="#what-is-considered-when-dbms-scheduling-threads">What is considered when DBMS scheduling threads?</a></li><li><a href="#what-is-embedded-dbms-model">What is embedded DBMS model?</a></li></ul></li><li><a href="#query-level-parallelism">Query-level parallelism</a><ul><li><a href="#what-are-the-query-level-parallelisms">What are the query-level parallelisms?</a></li><li><a href="#how-can-we-achieve-intra-query-parallelism">How can we achieve intra-query parallelism?</a></li></ul></li><li><a href="#io-paralleism">I/O paralleism</a><ul><li><a href="#what-is-the-problem-of-query-level-parallelism">What is the problem of query-level parallelism?</a></li><li><a href="#how-can-we-parallel-ios-with-multi-disk">How can we parallel I/Os with multi-disk?</a></li><li><a href="#how-can-we-partition-database">How can we partition database?</a></li></ul></li></ul></li></ul></p><h1 id="sequential-execution"><a class="markdownIt-Anchor" href="#sequential-execution"></a> Sequential Execution</h1><h2 id="processing-model"><a class="markdownIt-Anchor" href="#processing-model"></a> Processing model</h2><h3 id="what-does-processing-model-do"><a class="markdownIt-Anchor" href="#what-does-processing-model-do"></a> What does processing model do?</h3><ol><li>Processing model defines how the system executes a query plan, i.e. how to traverse the query plan tree.</li><li>There are two processing directions:<ul><li>Top-to-Bottom: Start with the root and “pull” data up from its children. Tuples are always passed with function calls.</li><li>Bottom-to-Top: Start with leaf nodes and push data to their parents. Allows for tighter control of caches/registers in pipelines.</li></ul></li><li>There are three commonly used model: iterator model (volcano/pipeline model), materialization model and vectorized/batch model.</li></ol><h3 id="how-does-iterator-model-execute"><a class="markdownIt-Anchor" href="#how-does-iterator-model-execute"></a> How does iterator model execute?</h3><ol><li><p>In iterator model, operators are executed top-to-down.</p></li><li><p>Each query plan operator implements a <code>Next()</code> function. On each invocation, the operator returns either a single tuple or a <code>null</code> marker if there are no more tuples.</p><ul><li><p>The operator implements a loop that calls <code>Next()</code> on its children to retrieve their tuples and then process them.</p></li><li><p><code>Next()</code> is first called on the root operator and the nodes on the tree will call the <code>Next()</code> on their children recursively.</p></li></ul></li><li><p>This model allows for uple pipelining. Although some operators must block until their children emit all their tuples.</p><ul><li>Joins must wait until all tuples in the leaf child are processed and built the hash table to further process tuples from right child. Hence, the tuples from leaft child need to block the pipeline while the tuples from right child can enable pipeline.</li><li>Subqueries and ordering (<code>Order By</code>) clauses also need to block pipeline. These are called pipeline breaker.</li></ul></li><li><p>Output control works easily with this approach. We only need to add constraints on the root operator.</p></li></ol><h3 id="how-does-materialization-model-execute"><a class="markdownIt-Anchor" href="#how-does-materialization-model-execute"></a> How does materialization model execute?</h3><ol><li><p>In materialization model, operators are called bottom-to-up.</p></li><li><p>Each query plan operator implements a <code>Output()</code> function.</p><ul><li><p>On each invocation, the operator processes its input all at once and then emits its output all at once.</p></li><li><p>The operator materializes its output as a single result.</p></li><li><p>The operators can send either a materialized row or a single column.</p></li></ul></li><li><p>The DBMS can push down hints (e.g., <code>LIMIT</code>) to avoid scanning too many tuples.</p></li><li><p>The output can be either whole tuples (NSM) or subsets of columns (DSM).</p></li><li><p>This model is better for OLTP workloads because queries only access a small number of tuples at a time which means lower execution and coordination overhead and fewer function calls.</p><ul><li>It is not good for OLAP queries with large intermediate results.</li></ul></li></ol><h3 id="how-does-vectorization-model-execute"><a class="markdownIt-Anchor" href="#how-does-vectorization-model-execute"></a> How does vectorization model execute?</h3><ol><li>The problem of iterator model is that it can only process one tuple at a time when we can take multiple tuples and vectorize them to process in parallel (SIMD).</li><li>Vectorization model is similar with iterator model except that each operator emits a batch of tuples instead of a single tuple.</li><li>This is ideal for OLAP queries because it greatly reduces the number of invocations per operator.<ul><li>It allows for operators to more easily use vectorized (SIMD) instructions to process batches of tuples.</li></ul></li></ol><h2 id="access-methods"><a class="markdownIt-Anchor" href="#access-methods"></a> Access methods</h2><h3 id="how-can-we-optimize-sequential-scan-with-data-skipping"><a class="markdownIt-Anchor" href="#how-can-we-optimize-sequential-scan-with-data-skipping"></a> How can we optimize sequential scan with data skipping?</h3><ol><li><p>The first approach is approximate queries.</p><ul><li><p>This method is lossy, which means that it may return incorrect results, but it is OK.</p></li><li><p>Execute queries on a sampled subset of the entire table to produce approximate results.</p></li></ul></li><li><p>The second approach is zone maps.</p><ul><li>This method is lossless.</li><li>Pre-computed aggregates for the attribute values in a page. DBMS checks the zone map first to decide whether it wants to access the page.</li><li>The trade-off is between page size and filter efficacy.</li></ul></li></ol><h3 id="what-is-multi-index-scan"><a class="markdownIt-Anchor" href="#what-is-multi-index-scan"></a> What is multi-index scan?</h3><ol><li>If there are multiple indexes that the DBMS can use for a query, one method for DBMS to execute is try to filter tuples with index that has least number of tuples matches and filter other indexes based on the filtered tuples of previous indexes.<ul><li>This is ideal in the case that some indexes has little tuples that matches. Filtering those indexes first can significantly reduce the number of tuples to process in following indexes.</li></ul></li><li>If all indexes has a lot of matching tuples, we can use another method:<ul><li>Compute sets of Record IDs using each matching index. Combine these sets based on the query’s predicates (union or intersect). Retrieve the records and apply any remaining predicates.</li><li>In this way, we can reduce a log of I/O and memory space by only fetching Record IDs in the first phase instead of fetching entire tuple.</li></ul></li></ol><h2 id="modification-queries"><a class="markdownIt-Anchor" href="#modification-queries"></a> Modification queries</h2><h3 id="how-should-we-execute-update-and-delete-queries"><a class="markdownIt-Anchor" href="#how-should-we-execute-update-and-delete-queries"></a> How should we execute update and delete queries?</h3><ol><li>Operators that modify the database (<code>INSERT</code>, <code>UPDATE</code>, <code>DELETE</code>) are responsible for modifying the target table and its indexes.<ul><li>The output of these operators can either be Record Ids or tuple data (i.e., <code>RETURNING</code>).</li></ul></li><li>For update or delete, child operators pass Record IDs for target tuples.<ul><li>The operator should remove the corresponding item from index.</li><li>Then the operator can modify tuple or remove tuple.</li><li>Update should re-insert modified tuple into index again.</li></ul></li><li>Updates have a possible Halloween problem:<ul><li>When we re-inserted the modified tuple, its new place may be ahead of cursor, i.e. we will pass the new tuple again in the future.<ul><li>E.g. when the index is sorted according to an attribute, and the modification increases that attribute.</li></ul></li><li>An update operation changes the physical location of a tuple, which causes a scan operator to visit the tuple multiple times. It can occur on clustered tables or index scans.</li><li>The solution is to keep track of previously seen tuples (e.g. through Record IDs).</li></ul></li></ol><h3 id="how-should-we-execute-insert-queries"><a class="markdownIt-Anchor" href="#how-should-we-execute-insert-queries"></a> How should we execute insert queries?</h3><ol><li>The first choice is to materialize tuples inside of the operator.<ul><li>The insert operator needs to implement its own method of how to materialize tuples.</li></ul></li><li>The second choice is that operator inserts any tuple passed in from child operators.<ul><li>The insert operator only need to accept tuples from its children instead of implementing itself.</li></ul></li></ol><h2 id="how-to-evaluate-expressions"><a class="markdownIt-Anchor" href="#how-to-evaluate-expressions"></a> How to evaluate expressions?</h2><ol><li>The DBMS represents a <code>WHERE</code> clause as an expression tree.</li><li>The nodes in the tree represent different expression types: Comparisons (<code>=, &lt;, &gt;, !=</code>), conjunction (<code>AND</code>), disjunction (<code>OR</code>), arithmetic operators (<code>+, -, *, /, %</code>), constant values, tuple attribute references.</li><li>When evaluate the expression, DFS through the expression tree from the root.<ul><li>The performance is poor due to that the DBMS traverses the tree and for each node that it visits it must figure out what the operator needs to do.</li></ul></li><li>A better approach is to just evaluate the expression directly.<ul><li>Compile a function of the express (e.g. JIT compilation). In evaluation, DBMS just execute the compiled function instead of traversing through the tree.</li></ul></li></ol><h1 id="parallel-execution"><a class="markdownIt-Anchor" href="#parallel-execution"></a> Parallel execution</h1><h2 id="parallel-and-distributed"><a class="markdownIt-Anchor" href="#parallel-and-distributed"></a> Parallel and distributed</h2><h3 id="why-care-about-parallel-execution"><a class="markdownIt-Anchor" href="#why-care-about-parallel-execution"></a> Why care about parallel execution?</h3><ol><li>It increased performance for potentially the same hardware resources, i.e. to gain higher throughput and lower latency.</li><li>It increased the responsiveness of the system.</li><li>It potentially lower total cost of ownership (TCO).<ul><li>Fewer machines means less parts / physical footprint / energy consumption.</li></ul></li></ol><h3 id="what-are-the-similarities-and-differences-between-parallel-and-distributed-dbms"><a class="markdownIt-Anchor" href="#what-are-the-similarities-and-differences-between-parallel-and-distributed-dbms"></a> What are the similarities and differences between parallel and distributed DBMS?</h3><ol><li>Similarities:<ul><li>Database is spread out across multiple resources to improve different aspects of the DBMS.</li><li>They both need to make database  to appear as a single logical database instance to the application, regardless of physical organization.</li><li>SQL query for a single-resource DBMS should generate same result on a parallel or distributed DBMS.</li></ul></li><li>Differences:<ul><li>For parallel DBMSs, resources are physically close to each other. Hence resources communicate over high-speed interconnect. And communication is assumed to be cheap and reliable.</li><li>For distributed DBMSs, resources can be far from each other. Resources communicate using slow(er) interconnect. Therefore, communication cost and problems cannot be ignored. And communication is considered unreliable.</li></ul></li></ol><h2 id="process-model"><a class="markdownIt-Anchor" href="#process-model"></a> Process model</h2><h3 id="what-does-process-model-of-parallel-dbmss-need-to-do"><a class="markdownIt-Anchor" href="#what-does-process-model-of-parallel-dbmss-need-to-do"></a> What does process model of parallel DBMSs need to do?</h3><ol><li>It defines how the system is architected to support concurrent requests from a multi-user application.</li><li>A worker is the DBMS component that is responsible for executing tasks on behalf of the client and returning the results.</li><li>There are three approaches: process per DBMS worker, thread per DBMS worker and embedded DBMS</li></ol><h3 id="what-is-process-per-worker-model"><a class="markdownIt-Anchor" href="#what-is-process-per-worker-model"></a> What is process per worker model?</h3><ol><li>Each worker is a separate OS process. Hence, this model relies on OS scheduler entirely.</li><li>When an application connect with DBMS, it connect with a dispatcher process. The dispatcher picks on the processes for the application. Then the application communicate with the process directly.</li><li>The processes can use shared-memory for global data structures.</li><li>The advantage of this model is that a process crash does not take down entire system.</li></ol><h3 id="what-is-thread-per-worker-model"><a class="markdownIt-Anchor" href="#what-is-thread-per-worker-model"></a> What is thread per worker model?</h3><ol><li>In this model, the whole DBMS is a single process with multiple worker threads.</li><li>DBMS (mostly) manages its own scheduling by controlling what each threads is doing.<ul><li>This also means less overhead per context switch and that DBMS does not have to manage shared memory.</li></ul></li><li>There may or may not have a dispatcher thread in the front.<ul><li>Applications may connect to dispatcher, and dispatcher immediately forward request to another thread while application does not know about it.</li><li>Or applications can use the same scheme as process per worker model.</li></ul></li><li>In this model, thread crash may kill the entire system.</li></ol><h3 id="what-is-considered-when-dbms-scheduling-threads"><a class="markdownIt-Anchor" href="#what-is-considered-when-dbms-scheduling-threads"></a> What is considered when DBMS scheduling threads?</h3><p>For each query plan, the DBMS decides where, when, and how to execute it.</p><ol><li>How many tasks should it use?</li><li>How many CPU cores should it use?</li><li>What CPU core should the tasks execute on?</li><li>Where should a task store its output?</li></ol><h3 id="what-is-embedded-dbms-model"><a class="markdownIt-Anchor" href="#what-is-embedded-dbms-model"></a> What is embedded DBMS model?</h3><ol><li>In aforementioned systems and most common systems, applications are in separate machines. They are connected through TCP or socket. Even if the applications crashed, DBMS still remains running.</li><li>In embedded DBMS, DBMS runs inside of the same address space as the application. Application is (mostly) responsible for threads and scheduling.</li><li>The application may support outside connections.</li></ol><h2 id="query-level-parallelism"><a class="markdownIt-Anchor" href="#query-level-parallelism"></a> Query-level parallelism</h2><h3 id="what-are-the-query-level-parallelisms"><a class="markdownIt-Anchor" href="#what-are-the-query-level-parallelisms"></a> What are the query-level parallelisms?</h3><ol><li>Inter-Query: Execute multiple disparate queries simultaneously.<ul><li>This parallelism increases throughput and reduces latency. It improves overall performance by allowing multiple queries to execute simultaneously.</li><li>If queries are read-only, then this requires almost no explicit coordination between queries. Buffer pool can handle most of the sharing if necessary.</li><li>If multiple queries are updating the database at the same time, then this is hard to do correctly.</li></ul></li><li>Intra-Query: Execute the operations of a single query in parallel.<ul><li>This parallelism decreases latency for long-running queries, especially for OLAP queries. It improves the performance of a single query by executing its operators in parallel.</li><li>Organize operators in terms of a producer/consumer paradigm.</li></ul></li></ol><h3 id="how-can-we-achieve-intra-query-parallelism"><a class="markdownIt-Anchor" href="#how-can-we-achieve-intra-query-parallelism"></a> How can we achieve intra-query parallelism?</h3><ol><li>The first approach is using intra-operator (horizontal) parallelism.<ul><li>Decompose operators into independent fragments that perform the same function on different subsets of data.</li><li>In the generated query plan, those decomposed operators are copied for each thread.</li><li>The DBMS inserts an exchange operator into the query plan to coalesce/split results from multiple children/parent operators. The exchange operators are similar with barriers stating that data cannot be sent up to parent until received all results.</li><li>There are three kinds of exchange operators:<ul><li>Gather: Combine the results from multiple workers into a single output stream.</li><li>Distribute: Split a single input stream into multiple output streams.</li><li>Repartition: Shuffle multiple input streams across multiple output streams.</li></ul></li></ul></li><li>The second approach is using inter-operator (vertical / pipeline) parallelism.<ul><li>Operations are overlapped in order to pipeline data from one stage to the next without materialization.</li><li>Each operator is a worker. Workers execute operators from different segments of a query plan at the same time.</li></ul></li><li>We can also combine these two approaches, which is call bushy parallelism.</li></ol><h2 id="io-paralleism"><a class="markdownIt-Anchor" href="#io-paralleism"></a> I/O paralleism</h2><h3 id="what-is-the-problem-of-query-level-parallelism"><a class="markdownIt-Anchor" href="#what-is-the-problem-of-query-level-parallelism"></a> What is the problem of query-level parallelism?</h3><ol><li>Using additional processes/threads to execute queries in parallel won’t help if the disk is always the main bottleneck.</li><li>It can sometimes make the DBMS’s performance worse if worker is accessing different segments of the disk at the same time.</li></ol><h3 id="how-can-we-parallel-ios-with-multi-disk"><a class="markdownIt-Anchor" href="#how-can-we-parallel-ios-with-multi-disk"></a> How can we parallel I/Os with multi-disk?</h3><ol><li><p>Split the DBMS across multiple storage devices to improve disk bandwidth latency.</p><ul><li>There are many options<ul><li>Multiple disks per database, one database per disk, one relation per disk, split relation across multiple disks.</li><li>The main trade-off is the number of disks and I/O parallelism.</li></ul></li></ul></li><li><p>Configure OS/hardware to store the DBMS’s files across multiple storage<br />devices, e.g. storage appliances, RAID configuration.</p><ul><li><p>This is transparent to the DBMS.</p></li><li><p>RAID 0 strips data into different disks. Each disk stores different data.</p></li><li><p>RAID 1 mirrors data in different disks. Each disk stores the same data.</p></li></ul></li></ol><h3 id="how-can-we-partition-database"><a class="markdownIt-Anchor" href="#how-can-we-partition-database"></a> How can we partition database?</h3><ol><li>Some DBMSs allow you to specify the disk location of each individual database.<ul><li>The buffer pool manager maps a page to a disk location.</li><li>This is also easy to do at the filesystem level if the DBMS stores each database in a separate directory.</li><li>The DBMS recovery log file might still be shared if transactions can update multiple databases.</li></ul></li><li>Logical splitting is to split single logical table into disjoint physical segments that are stored/managed separately.<ul><li>Partitioning should (ideally) be transparent to the application.</li><li>The application should only access logical tables and not have to worry about how things are physically stored.</li></ul></li></ol>]]></content>
      
      
      <categories>
          
          <category> Open Courses </category>
          
          <category> CMU 15-445/645 Database System </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Database System </tag>
            
            <tag> Executor </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Project #2: B+Tree</title>
      <link href="/2023/07/07/OpenSource/BusTub/Project-2-B-Tree/"/>
      <url>/2023/07/07/OpenSource/BusTub/Project-2-B-Tree/</url>
      
        <content type="html"><![CDATA[<p><ul class="markdownIt-TOC"><li><a href="#btree-page">B+Tree Page</a></li><li><a href="#btree-search">B+Tree search</a></li><li><a href="#btree-insert">B+Tree insert</a></li><li><a href="#btree-delete">B+Tree delete</a></li></ul></p><h1 id="btree-page"><a class="markdownIt-Anchor" href="#btree-page"></a> B+Tree Page</h1><ol><li><p>The <code>size_</code> in each page means the number of stored values not keys, i.e. in internal nodes, <code>size_</code> is <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1</mn></mrow><annotation encoding="application/x-tex">1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">1</span></span></span></span> larger than the number of keys.</p></li><li><p><code>KeyComparator</code> accept two keys to compare, which will return <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>0</mn></mrow><annotation encoding="application/x-tex">0</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">0</span></span></span></span> when they are equal, <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>−</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">-1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.72777em;vertical-align:-0.08333em;"></span><span class="mord">−</span><span class="mord">1</span></span></span></span> for the first key “smaller” than the second key, <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1</mn></mrow><annotation encoding="application/x-tex">1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">1</span></span></span></span> for the second key being larger.</p></li><li><p>We need to design the sematic of the binary search that will be used in search, insert and delete a key inside a node.</p><ul><li>In the leaf node:<ul><li>For search and delete, we want this function to tell us the index of the key is it exists.</li><li>For insert, we want this function to indicate the index we need to place the key.</li></ul></li><li>In the internal node:<ul><li>For search, we only want it to inform us the child that might have the given key.</li><li>For insert, we want it to return the page ID to find a proper leaf page to store the key in forward search and give the index we need to place the split key when backward split is required.</li><li>For delete, we want it the same as for insert in the forward search and to provide the index to help merge two children when the backward merge is required.</li></ul></li><li>In the following implemetation of binary search, it will return the index of the key if it exists, or it will return the largest index with smaller key.<ul><li>Notably that if the given key is smaller than all keys in the node, it will return <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>−</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">-1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.72777em;vertical-align:-0.08333em;"></span><span class="mord">−</span><span class="mord">1</span></span></span></span>.</li><li>In internal node, we would expect the smallest possible result is <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>0</mn></mrow><annotation encoding="application/x-tex">0</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">0</span></span></span></span> since the first key is <code>NULL</code> which should be smaller than any other keys.</li></ul></li></ul><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">auto</span> <span class="title">BinarySearch</span><span class="params">(KeyType key, KeyComparator comparator)</span> <span class="type">const</span> -&gt; <span class="type">int</span> </span>&#123;</span><br><span class="line">  <span class="type">int</span> lo = <span class="number">0</span>;</span><br><span class="line">  <span class="type">int</span> hi = <span class="built_in">GetSize</span>();</span><br><span class="line">  <span class="keyword">while</span> (lo &lt; hi) &#123;</span><br><span class="line">    <span class="type">int</span> mid = (lo + hi) / <span class="number">2</span>;</span><br><span class="line">    <span class="keyword">if</span> (<span class="number">0</span> &lt; mid &amp;&amp; <span class="built_in">comparator</span>(key, array_[mid].first) &lt; <span class="number">0</span>) &#123;</span><br><span class="line">      hi = mid;</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">      lo = mid + <span class="number">1</span>;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">return</span> lo - <span class="number">1</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p><code>FindNextPageID</code> will provide the proper child for the caller to access to find a certain key.</p><ul><li>For leaf node, this will only be used in B+Tree search. If the binary search result is <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>−</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">-1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.72777em;vertical-align:-0.08333em;"></span><span class="mord">−</span><span class="mord">1</span></span></span></span>, we can conclude that that key does not exist and should tell caller that.</li><li>For internal node, this will be used in B+Tree search or the forward search in insert and delete. If the binary search result is <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>−</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">-1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.72777em;vertical-align:-0.08333em;"></span><span class="mord">−</span><span class="mord">1</span></span></span></span>, then we should return the first value to indicate the key is smaller than all keys.</li></ul></li><li><p><code>InsertKey</code> should</p></li></ol><h1 id="btree-search"><a class="markdownIt-Anchor" href="#btree-search"></a> B+Tree search</h1><ol><li>The thought is simple: we just go down from the root until hit a leaf node. If the key is in the leaf node, return the value. Otherwise, the key does not exists.</li><li>For concurrency control, we can only release the latch of a page after acquired the latch of its child.<ul><li>This can be implemented with the move assignment operation of <code>PageGuard</code>. In the execution, the right expression will first acquire the latch of next page, then destroy the original page guard of the left variable.</li></ul></li></ol><h1 id="btree-insert"><a class="markdownIt-Anchor" href="#btree-insert"></a> B+Tree insert</h1><ol><li><p>For concurrency control, I implemented both the optimistic scheme and the pessimistic scheme.</p><ul><li><p>The program will first try with optimistic search with only write latch on leaf node.</p></li><li><p>If the leaf node may overflow, release all latches and start again trying to acquire write latch for all nodes.</p></li></ul></li><li><p>In the optimistic search, we can use the queue in <code>Context</code>.</p><ul><li>When we fetched a new page guard, we push it to the back of <code>ctx.read_set_</code> and pop the front element out of the queue. Every time we just need to access the last element of the queue to find the next page to read.</li><li>When we realised that we have reached the leaf node, we are holding a read latch for that page. Hence, we still need to release the read latch and re-acquire the write latch, i.e. we cannot release the latch of last internal page when we first acquire the leaf page.</li><li>The solution is to release the latch before read the “grand-child” of it.</li></ul></li><li><p>In the pessimistic search, we need to acquire write latch for all pages we want to access.</p><ul><li>We can check whether a node is safe after its write latch is acquired. If the node is safe, we can release all latches acquired before it, including the header page.</li></ul></li><li><p>In the insert function, there are three cases to handle:</p><ul><li>The first case is that this is an empty tree, i.e. the <code>root_page_id_</code> in header page is invalid. We just need to create a new page for the node and update header page.</li><li>The second case is that the leaf node won’t overflow where a simple insertion is enough.</li><li>The last case is that the leaf node might overflow.</li></ul></li><li><p>When the leaf node might overflow:</p><ul><li>After acquired the write latches, we need to check whether there is an overflow again in case that other thread already handled overflow causing unexpected split.</li><li><code>SolveLeafOverflow</code><ul><li>When a leaf reaches max size after insertion, it will immediately split. So this is used after the insertion.</li><li>It will create a new page to store the larger half the nodes and return the first key in the new page to insert to its parent node to indicate to this page.</li><li>Also, it need to take care of the sibling pointers between leaf nodes. The new page will point to what the original page points to. And the original page will point to the new page.</li></ul></li><li><code>SolveInternalOverflow</code><ul><li>Internal nodes won’t split immediately when it reaches max size. This means that internal nodes must split first before insertion, otherwise the address will overflow.</li><li>The process is similar with the leaf case, except that it will choose a proper page to insert the key after split. (Or it just does not need to split if it is a safe node).</li></ul></li></ul></li></ol><h1 id="btree-delete"><a class="markdownIt-Anchor" href="#btree-delete"></a> B+Tree delete</h1><ol><li>The concurrency control is similar with the insert operation, except that the condition of whether a node is safe is different.</li><li>Compare with insertion,<ul><li>if the tree is empty, there is nothing else to do;</li><li>if the leaf node won’t underflow, a simple deletion is enough;</li><li>if the leaf node might underflow, we need to handle it and possible following cascade underflow.</li></ul></li><li>When the leaf node might overflow:<ul><li>Similar with the insertion situation, we need to re-acquire write latches, and check whether the underflow is handled by another thread.</li><li>If the underflowed leaf is the root, i.e. the tree has only one node, we do not need to do anything further.</li><li><code>SolveLeafUnderflow</code><ul><li>There are three situations: left sibling can borrow a key, right sibling can borrow a key or neither siblings can borrow a key.</li><li>When we can borrow a key, the underflow is solved easily, no more cascading. We need to modify the key in parent node that separates the two involving node to the new first key of the right node.</li><li>When we need to merge with one of the siblings, we also need to handle the pointers between leaf nodes. If we move the data of the left node to the right node and delete the left node, it is hard for us to modify the pointer of the left of the left node. Instead, if we move delete the right node, we only need to modify the pointer of the left node to the original pointer of the right node.</li><li>If a leaf only has left sibling or right sibling to merge with, then we do not have a choice.</li></ul></li><li><code>SolveInternalUnderflow</code><ul><li>The process is similar with <code>SolveLeafUnderflow</code>, except how to borrow a key.</li><li>When a node is borrowing a key to its left sibling, it will borrow the first valid key and the fire value, i.e. <code>array_[1].first</code> and <code>array_[0].second</code>.</li><li>When a node is borrowing a key to its right sibling, it will borrow the last key-value pair. And the node accpeting those keys will use the key as its first valid key and the value as its first valid value.</li><li>We need to set the corresponding key in parent node to the borrowed key.</li></ul></li></ul></li></ol>]]></content>
      
      
      <categories>
          
          <category> Open Source Code </category>
          
          <category> BusTub </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Database System </tag>
            
            <tag> Data Structure </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>06 Operator Algorithms</title>
      <link href="/2023/06/28/Courses/15445/06-Operator-Algorithms/"/>
      <url>/2023/06/28/Courses/15445/06-Operator-Algorithms/</url>
      
        <content type="html"><![CDATA[<p><ul class="markdownIt-TOC"><li><a href="#execute-queries">Execute queries</a><ul><li><a href="#how-are-queries-planned">How are queries planned?</a></li><li><a href="#what-is-the-assumption-of-algorithms-in-database-system">What is the assumption of algorithms in database system?</a></li></ul></li><li><a href="#sort">Sort</a><ul><li><a href="#what-implementation-should-we-use-to-execute-a-query-containing-an-order-by-with-a-limit">What implementation should we use to execute a query containing an ORDER BY with a LIMIT?</a></li><li><a href="#what-if-the-data-is-too-large-to-fit-in-memory-for-any-clause-including-order-by-with-a-limit">What if the data is too large to fit in memory? (for any clause including ORDER BY with a LIMIT)</a></li><li><a href="#how-to-perform-an-external-merge-sort">How to perform an external merge sort?</a></li><li><a href="#how-can-we-hide-the-disk-io">How can we hide the disk I/O?</a></li><li><a href="#how-can-we-optimize-comparison">How can we optimize comparison?</a></li><li><a href="#how-can-use-use-btree-for-sorting-since-it-is-sorted">How can use use B+Tree for sorting since it is sorted?</a></li></ul></li><li><a href="#aggregations">Aggregations</a><ul><li><a href="#how-can-we-implement-aggregations">How can we implement aggregations?</a></li><li><a href="#how-to-do-hashing-when-spill-data-to-disk">How to do hashing when spill data to disk?</a></li></ul></li><li><a href="#join">Join</a><ul><li><a href="#why-do-we-need-to-join">Why do we need to join?</a></li><li><a href="#what-are-join-algorithms-doing">What are join algorithms doing?</a></li><li><a href="#what-are-the-outputs-of-join-algorithms">What are the outputs of join algorithms?</a></li><li><a href="#how-can-we-measure-the-cost-of-join">How can we measure the cost of join?</a></li><li><a href="#join-algorithms">Join algorithms</a><ul><li><a href="#nested-loop-join">Nested loop join</a><ul><li><a href="#what-is-the-most-naive-algorithm">What is the most naive algorithm?</a></li><li><a href="#how-can-we-better-use-the-data-already-read-from-disk">How can we better use the data already read from disk?</a></li><li><a href="#how-can-we-take-advantages-of-more-buffer-space">How can we take advantages of more buffer space?</a></li><li><a href="#can-we-avoid-sequential-scans-by-using-an-index">Can we avoid sequential scans by using an index?</a></li></ul></li><li><a href="#sort-merge-join">Sort-merge join</a><ul><li><a href="#what-is-the-process-of-sort-merge-join">What is the process of sort-merge join?</a></li><li><a href="#how-does-the-two-cursors-move">How does the two cursors move?</a></li><li><a href="#when-is-sort-merge-join-useful">When is sort-merge join useful?</a></li></ul></li><li><a href="#hash-join">Hash join</a><ul><li><a href="#how-does-hash-join-work">How does hash join work?</a></li><li><a href="#how-big-of-a-table-can-we-hash-using-this-approach">How big of a table can we hash using this approach?</a></li><li><a href="#can-we-optimized-the-search-for-tuples-that-does-not-have-any-match">Can we optimized the search for tuples that does not have any match?</a></li><li><a href="#what-if-we-do-not-have-enough-memoty-to-fit-the-entire-hash-table">What if we do not have enough memoty to fit the entire hash table?</a></li></ul></li></ul></li></ul></li></ul></p><h1 id="execute-queries"><a class="markdownIt-Anchor" href="#execute-queries"></a> Execute queries</h1><h2 id="how-are-queries-planned"><a class="markdownIt-Anchor" href="#how-are-queries-planned"></a> How are queries planned?</h2><ol><li>The operators are arranged in an abstract syntax tree. Data flows from the leaves of the tree up towards the root.</li><li>The leaf nodes are access methods, e.g scanning index and scanning table, feeding data up along its path to its parent node to do processing.</li><li>The output of the root node is the result of the query.</li><li>This tree only describes a logical plan, i.e. instead of telling what implementation to use, it is just the logical flow we want. SQL only declare logical plan while it is the database system’s job to figure out the optimal way to execute.</li></ol><h2 id="what-is-the-assumption-of-algorithms-in-database-system"><a class="markdownIt-Anchor" href="#what-is-the-assumption-of-algorithms-in-database-system"></a> What is the assumption of algorithms in database system?</h2><ol><li>Just like it cannot assume that a table fits entirely in memory, a disk-oriented DBMS cannot assume that query results fit in memory.</li><li>We will use the buffer pool to implement algorithms that need to spill to disk.</li><li>We are also going to prefer algorithms that maximize the amount of sequential I/O.</li></ol><h1 id="sort"><a class="markdownIt-Anchor" href="#sort"></a> Sort</h1><h2 id="what-implementation-should-we-use-to-execute-a-query-containing-an-order-by-with-a-limit"><a class="markdownIt-Anchor" href="#what-implementation-should-we-use-to-execute-a-query-containing-an-order-by-with-a-limit"></a> What implementation should we use to execute a query containing an ORDER BY with a LIMIT?</h2><ol><li>The DBMS only needs to scan the data once to find the top-N elements.</li><li>The ideal scenario for heapsort is when the top-N elements fit in memory, so that the DBMS only has to maintain an in-memory sorted priority queue while scanning the data.</li></ol><h2 id="what-if-the-data-is-too-large-to-fit-in-memory-for-any-clause-including-order-by-with-a-limit"><a class="markdownIt-Anchor" href="#what-if-the-data-is-too-large-to-fit-in-memory-for-any-clause-including-order-by-with-a-limit"></a> What if the data is too large to fit in memory? (for any clause including ORDER BY with a LIMIT)</h2><ol><li>We do not want to use quick sort in this scenario since data spilling to disk will cause too many random access.</li><li>We can use external merge sort that splits data into separate runs, sorts them individually, and then combines them into longer sorted runs.</li><li>A run is a list of key/value pairs.<ul><li>Keys are the attribute(s) to compare to compute the sort order.</li><li>Values have two choices: it can either be the actual tuple data (i.e. early materialization) or be the Record IDs (i.e. late materialization)<ul><li>The advantage of early materialization is that it can be faster to produce result while the disadvantage is that it need to copy more data during the procedule.</li><li>The advantage of late materialization is that it can only fetch wanted data while it needs to find the actual data else where (probably involving another disk I/O).</li></ul></li></ul></li></ol><h2 id="how-to-perform-an-external-merge-sort"><a class="markdownIt-Anchor" href="#how-to-perform-an-external-merge-sort"></a> How to perform an external merge sort?</h2><ol><li>Data is broken up into <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>N</mi></mrow><annotation encoding="application/x-tex">N</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">N</span></span></span></span> pages. The DBMS has a finite number of <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>B</mi></mrow><annotation encoding="application/x-tex">B</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.05017em;">B</span></span></span></span> buffer pool pages to hold input and output data.</li><li>In the first phase, sort chunks of data that fit in memory and then write back the sorted chunks to a file on disk.<ul><li>In the first pass, we can read all <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>B</mi></mrow><annotation encoding="application/x-tex">B</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.05017em;">B</span></span></span></span> pages of the table into memory and sort pages into runs and write them back to disk.</li><li>Do not sort in buffer since we do not wish other threads seeing some partially sorted data which may cause errors. Copy the data to somewhere else and copy back to buffer after sorted.</li></ul></li><li>In the second phase, combine sorted runs into larger chunks.<ul><li>In the following passes, each pass use <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>B</mi><mo>−</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">B-1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.76666em;vertical-align:-0.08333em;"></span><span class="mord mathnormal" style="margin-right:0.05017em;">B</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">1</span></span></span></span> pages for input and <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1</mn></mrow><annotation encoding="application/x-tex">1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">1</span></span></span></span> page for output.</li><li>Recursively merge pairs of runs into runs <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>B</mi><mo>−</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">B-1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.76666em;vertical-align:-0.08333em;"></span><span class="mord mathnormal" style="margin-right:0.05017em;">B</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">1</span></span></span></span>-times as long.</li></ul></li><li>In general, the first pass create <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">⌈</mo><mi>N</mi><mi mathvariant="normal">/</mi><mi>B</mi><mo stretchy="false">⌉</mo></mrow><annotation encoding="application/x-tex">\lceil N/B\rceil</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">⌈</span><span class="mord mathnormal" style="margin-right:0.10903em;">N</span><span class="mord">/</span><span class="mord mathnormal" style="margin-right:0.05017em;">B</span><span class="mclose">⌉</span></span></span></span> sorted runs of size <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>B</mi></mrow><annotation encoding="application/x-tex">B</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.05017em;">B</span></span></span></span> and the following passes are <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">(</mo><mi>B</mi><mo>−</mo><mn>1</mn><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">(B-1)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.05017em;">B</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord">1</span><span class="mclose">)</span></span></span></span>-way merge.<ul><li>The number of passes is <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1</mn><mo>+</mo><mo stretchy="false">⌈</mo><msub><mo><mi>log</mi><mo>⁡</mo></mo><mrow><mi>B</mi><mo>−</mo><mn>1</mn></mrow></msub><mo stretchy="false">⌈</mo><mi>N</mi><mi mathvariant="normal">/</mi><mi>B</mi><mo stretchy="false">⌉</mo><mo stretchy="false">⌉</mo></mrow><annotation encoding="application/x-tex">1+\lceil\log_{B-1}\lceil N/B\rceil\rceil</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.72777em;vertical-align:-0.08333em;"></span><span class="mord">1</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1.052471em;vertical-align:-0.302471em;"></span><span class="mopen">⌈</span><span class="mop"><span class="mop">lo<span style="margin-right:0.01389em;">g</span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.23419099999999998em;"><span style="top:-2.45586em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.05017em;">B</span><span class="mbin mtight">−</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.302471em;"><span></span></span></span></span></span></span><span class="mopen">⌈</span><span class="mord mathnormal" style="margin-right:0.10903em;">N</span><span class="mord">/</span><span class="mord mathnormal" style="margin-right:0.05017em;">B</span><span class="mclose">⌉</span><span class="mclose">⌉</span></span></span></span>.</li><li>The total I/O cost is <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>2</mn><mi>N</mi><mo>⋅</mo><mo stretchy="false">(</mo><mi>n</mi><mi>u</mi><mi>m</mi><mi>b</mi><mi>e</mi><mi>r</mi><mtext> </mtext><mi>o</mi><mi>f</mi><mtext> </mtext><mi>p</mi><mi>a</mi><mi>s</mi><mi>s</mi><mi>e</mi><mi>s</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">2N\cdot (number\ of\ passes)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord">2</span><span class="mord mathnormal" style="margin-right:0.10903em;">N</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord mathnormal">n</span><span class="mord mathnormal">u</span><span class="mord mathnormal">m</span><span class="mord mathnormal">b</span><span class="mord mathnormal">e</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mspace"> </span><span class="mord mathnormal">o</span><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="mspace"> </span><span class="mord mathnormal">p</span><span class="mord mathnormal">a</span><span class="mord mathnormal">s</span><span class="mord mathnormal">s</span><span class="mord mathnormal">e</span><span class="mord mathnormal">s</span><span class="mclose">)</span></span></span></span>.</li></ul></li><li>In a 2-way external merge sort, instead of sort the <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>B</mi></mrow><annotation encoding="application/x-tex">B</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.05017em;">B</span></span></span></span> pages into a run in the first pass, each page is sorted into a run.<ul><li>So the number of passes is <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1</mn><mo>+</mo><mo stretchy="false">⌈</mo><msub><mo><mi>log</mi><mo>⁡</mo></mo><mn>2</mn></msub><mi>N</mi><mo stretchy="false">⌉</mo></mrow><annotation encoding="application/x-tex">1+\lceil\log_2N\rceil</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.72777em;vertical-align:-0.08333em;"></span><span class="mord">1</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">⌈</span><span class="mop"><span class="mop">lo<span style="margin-right:0.01389em;">g</span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.20696799999999996em;"><span style="top:-2.4558600000000004em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.24414em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">N</span><span class="mclose">⌉</span></span></span></span>.</li></ul></li></ol><h2 id="how-can-we-hide-the-disk-io"><a class="markdownIt-Anchor" href="#how-can-we-hide-the-disk-io"></a> How can we hide the disk I/O?</h2><ol><li>A typical setup is using <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>3</mn></mrow><annotation encoding="application/x-tex">3</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">3</span></span></span></span> pages (<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>2</mn></mrow><annotation encoding="application/x-tex">2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">2</span></span></span></span> for input pages and <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1</mn></mrow><annotation encoding="application/x-tex">1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">1</span></span></span></span> for output page). Even if we have more buffer space available (<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>B</mi><mo>&gt;</mo><mn>3</mn></mrow><annotation encoding="application/x-tex">B&gt;3</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.72243em;vertical-align:-0.0391em;"></span><span class="mord mathnormal" style="margin-right:0.05017em;">B</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">&gt;</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">3</span></span></span></span>), it does not effectively utilize them if the worker must block on disk I/O.</li><li>We can prefetch the next run in the background and store it in a second buffer while the system is processing the current run.</li><li>This method reduces the wait time for I/O requests at each step by continuously utilizing the disk.</li></ol><h2 id="how-can-we-optimize-comparison"><a class="markdownIt-Anchor" href="#how-can-we-optimize-comparison"></a> How can we optimize comparison?</h2><ol><li>The first approach is code specialization.<ul><li>Instead of providing a comparison function as a pointer to sorting algorithm, create a hardcoded version of sort that is specific to a key type.</li></ul></li><li>For string keys, the second approach is suffix truncation.<ul><li>First compare a binary prefix of keys instead of slower string comparison.</li><li>Fallback to slower version if prefixes are equal.</li></ul></li></ol><h2 id="how-can-use-use-btree-for-sorting-since-it-is-sorted"><a class="markdownIt-Anchor" href="#how-can-use-use-btree-for-sorting-since-it-is-sorted"></a> How can use use B+Tree for sorting since it is sorted?</h2><ol><li>If the table that must be sorted already has a B+Tree index on the sort attribute(s), then we can use that to accelerate sorting.</li><li>Retrieve tuples in desired sort order by simply traversing the leaf pages of the tree.<ul><li>For clustered B+Tree, this is always better than external sorting because there is no computational cost, and all disk access is sequential.</li><li>For non-clustered B+Tree, this is almost always a bad idea. In general, one I/O per data record.</li></ul></li></ol><h1 id="aggregations"><a class="markdownIt-Anchor" href="#aggregations"></a> Aggregations</h1><h2 id="how-can-we-implement-aggregations"><a class="markdownIt-Anchor" href="#how-can-we-implement-aggregations"></a> How can we implement aggregations?</h2><ol><li>The DBMS needs a way to quickly find tuples with the same distinguishing attributes for grouping.</li><li>For aggregations specified with a <code>ORDER BY</code> clause, we can directly use the aforementioned sorting algorithms.</li><li>For queries do not need the data to be ordered, e.g. forming groups in <code>GROUP BY</code> or removing duplicates in <code>DISTINCT</code>, hashing is a better alternative. Hashing can be computationally cheaper than sorting.<ul><li>For each record, check whether there is already an entry in the hash table. For <code>DISTINCT</code>, just discard duplicate. For <code>GROUP BY</code>, perform aggregate computation.</li></ul></li></ol><h2 id="how-to-do-hashing-when-spill-data-to-disk"><a class="markdownIt-Anchor" href="#how-to-do-hashing-when-spill-data-to-disk"></a> How to do hashing when spill data to disk?</h2><ol><li>The first phase is partition. Divide tuples into buckets based on hash key. Write them out to disk when they get full.<ul><li>Use a hash function <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>h</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">h_1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.84444em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> to split tuples into partitions on disk.</li><li>A partition is one or more pages that contain the set of keys with the same hash value.</li><li>Assume that we have <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>B</mi></mrow><annotation encoding="application/x-tex">B</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.05017em;">B</span></span></span></span> buffers. We will use <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>B</mi><mo>−</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">B-1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.76666em;vertical-align:-0.08333em;"></span><span class="mord mathnormal" style="margin-right:0.05017em;">B</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">1</span></span></span></span> buffers for the partitions and <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1</mn></mrow><annotation encoding="application/x-tex">1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">1</span></span></span></span> buffer for the input data.</li></ul></li><li>The second phase is ReHash. Build in-memory hash table for each partition and compute the aggregation.<ul><li>For each partition on disk, read it into memory and build an in-memory hash table based on a second hash function <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>h</mi><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">h_2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.84444em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>.</li><li>Then go through each bucket of this hash table to bring together matching tuples.</li><li>Each time we can use <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>B</mi><mo>−</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">B-1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.76666em;vertical-align:-0.08333em;"></span><span class="mord mathnormal" style="margin-right:0.05017em;">B</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">1</span></span></span></span> pages as input pages and <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1</mn></mrow><annotation encoding="application/x-tex">1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">1</span></span></span></span> page as output page.<ul><li>In each round, we can read in <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>B</mi><mo>−</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">B-1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.76666em;vertical-align:-0.08333em;"></span><span class="mord mathnormal" style="margin-right:0.05017em;">B</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">1</span></span></span></span> partitions.</li><li>After each round is finished, we can clear the hash table since the next <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>B</mi><mo>−</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">B-1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.76666em;vertical-align:-0.08333em;"></span><span class="mord mathnormal" style="margin-right:0.05017em;">B</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">1</span></span></span></span> partitions definitely won’t have the same keys as last round.</li></ul></li></ul></li><li>During the ReHash phase, store pairs of the form <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">(</mo><mi>G</mi><mi>r</mi><mi>o</mi><mi>u</mi><mi>p</mi><mi>K</mi><mi>e</mi><mi>y</mi><mo>→</mo><mi>R</mi><mi>u</mi><mi>n</mi><mi>n</mi><mi>i</mi><mi>n</mi><mi>g</mi><mi>V</mi><mi>a</mi><mi>l</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">(GroupKey→RunningVal)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord mathnormal">G</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mord mathnormal">o</span><span class="mord mathnormal">u</span><span class="mord mathnormal">p</span><span class="mord mathnormal" style="margin-right:0.07153em;">K</span><span class="mord mathnormal">e</span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">→</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="mord mathnormal">u</span><span class="mord mathnormal">n</span><span class="mord mathnormal">n</span><span class="mord mathnormal">i</span><span class="mord mathnormal">n</span><span class="mord mathnormal" style="margin-right:0.03588em;">g</span><span class="mord mathnormal" style="margin-right:0.22222em;">V</span><span class="mord mathnormal">a</span><span class="mord mathnormal" style="margin-right:0.01968em;">l</span><span class="mclose">)</span></span></span></span>.<ul><li>When we want to insert a new tuple into the hash table, if we find a matching <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>G</mi><mi>r</mi><mi>o</mi><mi>u</mi><mi>p</mi><mi>K</mi><mi>e</mi><mi>y</mi></mrow><annotation encoding="application/x-tex">GroupKey</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8777699999999999em;vertical-align:-0.19444em;"></span><span class="mord mathnormal">G</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mord mathnormal">o</span><span class="mord mathnormal">u</span><span class="mord mathnormal">p</span><span class="mord mathnormal" style="margin-right:0.07153em;">K</span><span class="mord mathnormal">e</span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span></span></span></span>, just update the<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>R</mi><mi>u</mi><mi>n</mi><mi>n</mi><mi>i</mi><mi>n</mi><mi>g</mi><mi>V</mi><mi>a</mi><mi>l</mi></mrow><annotation encoding="application/x-tex">RunningVal</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="mord mathnormal">u</span><span class="mord mathnormal">n</span><span class="mord mathnormal">n</span><span class="mord mathnormal">i</span><span class="mord mathnormal">n</span><span class="mord mathnormal" style="margin-right:0.03588em;">g</span><span class="mord mathnormal" style="margin-right:0.22222em;">V</span><span class="mord mathnormal">a</span><span class="mord mathnormal" style="margin-right:0.01968em;">l</span></span></span></span> appropriately. Else insert a new <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">(</mo><mi>G</mi><mi>r</mi><mi>o</mi><mi>u</mi><mi>p</mi><mi>K</mi><mi>e</mi><mi>y</mi><mo>→</mo><mi>R</mi><mi>u</mi><mi>n</mi><mi>n</mi><mi>i</mi><mi>n</mi><mi>g</mi><mi>V</mi><mi>a</mi><mi>l</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">(GroupKey→RunningVal)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord mathnormal">G</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mord mathnormal">o</span><span class="mord mathnormal">u</span><span class="mord mathnormal">p</span><span class="mord mathnormal" style="margin-right:0.07153em;">K</span><span class="mord mathnormal">e</span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">→</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="mord mathnormal">u</span><span class="mord mathnormal">n</span><span class="mord mathnormal">n</span><span class="mord mathnormal">i</span><span class="mord mathnormal">n</span><span class="mord mathnormal" style="margin-right:0.03588em;">g</span><span class="mord mathnormal" style="margin-right:0.22222em;">V</span><span class="mord mathnormal">a</span><span class="mord mathnormal" style="margin-right:0.01968em;">l</span><span class="mclose">)</span></span></span></span>.</li><li>The running totals of different aggregation function is as followed:<ul><li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>A</mi><mi>V</mi><mi>G</mi><mo stretchy="false">(</mo><mi>c</mi><mi>o</mi><mi>l</mi><mo stretchy="false">)</mo><mo>→</mo><mo stretchy="false">(</mo><mi>C</mi><mi>O</mi><mi>U</mi><mi>N</mi><mi>T</mi><mo separator="true">,</mo><mi>S</mi><mi>U</mi><mi>M</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">AVG(col)\rightarrow (COUNT,SUM)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">A</span><span class="mord mathnormal" style="margin-right:0.22222em;">V</span><span class="mord mathnormal">G</span><span class="mopen">(</span><span class="mord mathnormal">c</span><span class="mord mathnormal">o</span><span class="mord mathnormal" style="margin-right:0.01968em;">l</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">→</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.07153em;">C</span><span class="mord mathnormal" style="margin-right:0.02778em;">O</span><span class="mord mathnormal" style="margin-right:0.10903em;">U</span><span class="mord mathnormal" style="margin-right:0.10903em;">N</span><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal" style="margin-right:0.05764em;">S</span><span class="mord mathnormal" style="margin-right:0.10903em;">U</span><span class="mord mathnormal" style="margin-right:0.10903em;">M</span><span class="mclose">)</span></span></span></span></li><li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>S</mi><mi>U</mi><mi>M</mi><mo stretchy="false">(</mo><mi>c</mi><mi>o</mi><mi>l</mi><mo stretchy="false">)</mo><mo>→</mo><mo stretchy="false">(</mo><mi>S</mi><mi>U</mi><mi>M</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">SUM(col)\rightarrow(SUM)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.05764em;">S</span><span class="mord mathnormal" style="margin-right:0.10903em;">U</span><span class="mord mathnormal" style="margin-right:0.10903em;">M</span><span class="mopen">(</span><span class="mord mathnormal">c</span><span class="mord mathnormal">o</span><span class="mord mathnormal" style="margin-right:0.01968em;">l</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">→</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.05764em;">S</span><span class="mord mathnormal" style="margin-right:0.10903em;">U</span><span class="mord mathnormal" style="margin-right:0.10903em;">M</span><span class="mclose">)</span></span></span></span></li><li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>C</mi><mi>O</mi><mi>U</mi><mi>N</mi><mi>T</mi><mo stretchy="false">(</mo><mi>c</mi><mi>o</mi><mi>l</mi><mo stretchy="false">)</mo><mo>→</mo><mo stretchy="false">(</mo><mi>C</mi><mi>O</mi><mi>U</mi><mi>N</mi><mi>T</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">COUNT(col)\rightarrow(COUNT)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.07153em;">C</span><span class="mord mathnormal" style="margin-right:0.02778em;">O</span><span class="mord mathnormal" style="margin-right:0.10903em;">U</span><span class="mord mathnormal" style="margin-right:0.10903em;">N</span><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="mopen">(</span><span class="mord mathnormal">c</span><span class="mord mathnormal">o</span><span class="mord mathnormal" style="margin-right:0.01968em;">l</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">→</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.07153em;">C</span><span class="mord mathnormal" style="margin-right:0.02778em;">O</span><span class="mord mathnormal" style="margin-right:0.10903em;">U</span><span class="mord mathnormal" style="margin-right:0.10903em;">N</span><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="mclose">)</span></span></span></span></li><li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>M</mi><mi>I</mi><mi>N</mi><mo stretchy="false">(</mo><mi>c</mi><mi>o</mi><mi>l</mi><mo stretchy="false">)</mo><mo>→</mo><mo stretchy="false">(</mo><mi>M</mi><mi>I</mi><mi>N</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">MIN(col)\rightarrow(MIN)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">M</span><span class="mord mathnormal" style="margin-right:0.07847em;">I</span><span class="mord mathnormal" style="margin-right:0.10903em;">N</span><span class="mopen">(</span><span class="mord mathnormal">c</span><span class="mord mathnormal">o</span><span class="mord mathnormal" style="margin-right:0.01968em;">l</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">→</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.10903em;">M</span><span class="mord mathnormal" style="margin-right:0.07847em;">I</span><span class="mord mathnormal" style="margin-right:0.10903em;">N</span><span class="mclose">)</span></span></span></span></li><li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>M</mi><mi>A</mi><mi>X</mi><mo stretchy="false">(</mo><mi>c</mi><mi>o</mi><mi>l</mi><mo stretchy="false">)</mo><mo>→</mo><mo stretchy="false">(</mo><mi>M</mi><mi>A</mi><mi>X</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">MAX(col)\rightarrow(MAX)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">M</span><span class="mord mathnormal">A</span><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class="mopen">(</span><span class="mord mathnormal">c</span><span class="mord mathnormal">o</span><span class="mord mathnormal" style="margin-right:0.01968em;">l</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">→</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.10903em;">M</span><span class="mord mathnormal">A</span><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class="mclose">)</span></span></span></span></li></ul></li></ul></li></ol><h1 id="join"><a class="markdownIt-Anchor" href="#join"></a> Join</h1><h2 id="why-do-we-need-to-join"><a class="markdownIt-Anchor" href="#why-do-we-need-to-join"></a> Why do we need to join?</h2><ol><li>Tables are normalized in a relational database to avoid unnecessary repetition of information.</li><li>Join operator is used to reconstruct the original tuples without any information loss.</li><li>Join is an important operator in both OLAP and OLTP systems. Especially for OLAP system, join could take up to <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>15</mn><mo>∼</mo><mn>50</mn><mi mathvariant="normal">%</mi></mrow><annotation encoding="application/x-tex">15\sim 50\%</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">1</span><span class="mord">5</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">∼</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.80556em;vertical-align:-0.05556em;"></span><span class="mord">5</span><span class="mord">0</span><span class="mord">%</span></span></span></span> of time.</li></ol><h2 id="what-are-join-algorithms-doing"><a class="markdownIt-Anchor" href="#what-are-join-algorithms-doing"></a> What are join algorithms doing?</h2><ol><li>Most important kind is binary joins using inner equijoin algorithms.<ul><li>Binary means that the operator takes two tables as input.</li><li>Inner means that it matches certain tuple of left table with another tuple in the right table.</li><li>Equijoin means that the condition of matching two tuples is the equivalence of some attributes.</li></ul></li><li>There are also other joins.<ul><li>Multi-way joins take more than two tables as input, which exists primarily in research literature.</li><li>Beside equijoin, there could also be anti-join, non-equijoin, etc.</li></ul></li><li>Compare with cross-product, join is more efficient and can be carefully optimized.</li></ol><h2 id="what-are-the-outputs-of-join-algorithms"><a class="markdownIt-Anchor" href="#what-are-the-outputs-of-join-algorithms"></a> What are the outputs of join algorithms?</h2><ol><li>In <code>R JOIN S</code>, for tuple <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>r</mi><mo>∈</mo><mi>R</mi></mrow><annotation encoding="application/x-tex">r \in R</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5782em;vertical-align:-0.0391em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.00773em;">R</span></span></span></span> and tuple <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>s</mi><mo>∈</mo><mi>S</mi></mrow><annotation encoding="application/x-tex">s \in S</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5782em;vertical-align:-0.0391em;"></span><span class="mord mathnormal">s</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.05764em;">S</span></span></span></span> that match on join attributes, concatenate <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>r</mi></mrow><annotation encoding="application/x-tex">r</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span></span></span></span> and <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>s</mi></mrow><annotation encoding="application/x-tex">s</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathnormal">s</span></span></span></span> together into a new tuple.</li><li>The output contents can vary depends on processing model, storage model or data requirements in query.</li><li>Basically, there are two choises similar with sort.<ul><li>Early materialization<ul><li>Copy the values for the attributes in outer and inner tuples into a new output tuple.</li><li>Subsequent operators in the query plan never need to go back to the base tables to get more data.</li></ul></li><li>Late materialization<ul><li>Only copy the joins keys along with the Record IDs of the matching tuples.</li><li>This is ideal for column stores because the DBMS does not copy data that is not needed for the query.</li></ul></li></ul></li></ol><h2 id="how-can-we-measure-the-cost-of-join"><a class="markdownIt-Anchor" href="#how-can-we-measure-the-cost-of-join"></a> How can we measure the cost of join?</h2><ol><li>We can measure the cost of join by the number of I/Os to compute join.</li><li>Output costs are ignored since that depends on the data.</li><li>In the following analysis, we assume there are <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>m</mi></mrow><annotation encoding="application/x-tex">m</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathnormal">m</span></span></span></span> tuples stored in <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>M</mi></mrow><annotation encoding="application/x-tex">M</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">M</span></span></span></span> pages in table <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>R</mi></mrow><annotation encoding="application/x-tex">R</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.00773em;">R</span></span></span></span>, <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi></mrow><annotation encoding="application/x-tex">n</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathnormal">n</span></span></span></span> tuples stored in <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>N</mi></mrow><annotation encoding="application/x-tex">N</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">N</span></span></span></span> pages in table <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>S</mi></mrow><annotation encoding="application/x-tex">S</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.05764em;">S</span></span></span></span>.</li></ol><h2 id="join-algorithms"><a class="markdownIt-Anchor" href="#join-algorithms"></a> Join algorithms</h2><h3 id="nested-loop-join"><a class="markdownIt-Anchor" href="#nested-loop-join"></a> Nested loop join</h3><h4 id="what-is-the-most-naive-algorithm"><a class="markdownIt-Anchor" href="#what-is-the-most-naive-algorithm"></a> What is the most naive algorithm?</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> <span class="built_in">tuple</span> r <span class="keyword">in</span> R:</span><br><span class="line">  <span class="keyword">for</span> <span class="built_in">tuple</span> s <span class="keyword">in</span> S:</span><br><span class="line">    emit, <span class="keyword">if</span> r <span class="keyword">and</span> s <span class="keyword">match</span></span><br></pre></td></tr></table></figure><ol><li>For <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>R</mi><mo>⋈</mo><mi>S</mi></mrow><annotation encoding="application/x-tex">R\bowtie S</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68833em;vertical-align:-0.005em;"></span><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">⋈</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.05764em;">S</span></span></span></span>, he left table <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>R</mi></mrow><annotation encoding="application/x-tex">R</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.00773em;">R</span></span></span></span> in the outer loop is called outer table and <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>S</mi></mrow><annotation encoding="application/x-tex">S</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.05764em;">S</span></span></span></span> is called the inner table.</li><li>For every tuple in <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>R</mi></mrow><annotation encoding="application/x-tex">R</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.00773em;">R</span></span></span></span>, it scans <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>S</mi></mrow><annotation encoding="application/x-tex">S</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.05764em;">S</span></span></span></span> once. The cost is <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>M</mi><mo>+</mo><mo stretchy="false">(</mo><mi>m</mi><mo>⋅</mo><mi>N</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">M+(m\cdot N)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.76666em;vertical-align:-0.08333em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">M</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord mathnormal">m</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">N</span><span class="mclose">)</span></span></span></span>.</li><li>If we use the smaller table with less tuples as the outer table, we can have a better performance since the number of pages is significant smaller than the number of tuples.</li></ol><h4 id="how-can-we-better-use-the-data-already-read-from-disk"><a class="markdownIt-Anchor" href="#how-can-we-better-use-the-data-already-read-from-disk"></a> How can we better use the data already read from disk?</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> block B_R <span class="keyword">in</span> R:</span><br><span class="line">  <span class="keyword">for</span> block B_S <span class="keyword">in</span> S:</span><br><span class="line">    <span class="keyword">for</span> <span class="built_in">tuple</span> r <span class="keyword">in</span> B_R:</span><br><span class="line">      <span class="keyword">for</span> <span class="built_in">tuple</span> s <span class="keyword">in</span> B_S:</span><br><span class="line">        emit, <span class="keyword">if</span> r <span class="keyword">and</span> s <span class="keyword">match</span></span><br></pre></td></tr></table></figure><ol><li>For every read block <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>B</mi><mi>R</mi></msub></mrow><annotation encoding="application/x-tex">B_R</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05017em;">B</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.32833099999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.05017em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.00773em;">R</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> and <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>B</mi><mi>S</mi></msub></mrow><annotation encoding="application/x-tex">B_S</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05017em;">B</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.32833099999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.05017em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05764em;">S</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>, we try to compute as much as possible, i.e. pair all tuples in <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>B</mi><mi>R</mi></msub></mrow><annotation encoding="application/x-tex">B_R</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05017em;">B</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.32833099999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.05017em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.00773em;">R</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> with all tuples in <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>B</mi><mi>S</mi></msub></mrow><annotation encoding="application/x-tex">B_S</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05017em;">B</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.32833099999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.05017em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05764em;">S</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>.</li><li>For every block in R, it scans S once. The cost is <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>M</mi><mo>+</mo><mo stretchy="false">(</mo><mi>M</mi><mo>⋅</mo><mi>N</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">M+(M\cdot N)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.76666em;vertical-align:-0.08333em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">M</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.10903em;">M</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">N</span><span class="mclose">)</span></span></span></span>.</li><li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>M</mi><mo>⋅</mo><mi>N</mi></mrow><annotation encoding="application/x-tex">M\cdot N</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">M</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">N</span></span></span></span> won’t be affected by the order of tables. However, if we let the smaller table with less pages as the outer table, the first term can be smaller.</li></ol><h4 id="how-can-we-take-advantages-of-more-buffer-space"><a class="markdownIt-Anchor" href="#how-can-we-take-advantages-of-more-buffer-space"></a> How can we take advantages of more buffer space?</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> B-<span class="number">2</span> pages p_R <span class="keyword">in</span> R:</span><br><span class="line">  <span class="keyword">for</span> page p_S <span class="keyword">in</span> S:</span><br><span class="line">    <span class="keyword">for</span> <span class="built_in">tuple</span> r <span class="keyword">in</span> B_2 pages:</span><br><span class="line">      <span class="keyword">for</span> <span class="built_in">tuple</span> s <span class="keyword">in</span> p_S:</span><br><span class="line">        emit, <span class="keyword">if</span> r <span class="keyword">and</span> s <span class="keyword">match</span></span><br></pre></td></tr></table></figure><ol><li>Use <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>B</mi><mo>−</mo><mn>2</mn></mrow><annotation encoding="application/x-tex">B-2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.76666em;vertical-align:-0.08333em;"></span><span class="mord mathnormal" style="margin-right:0.05017em;">B</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">2</span></span></span></span> buffers for scanning the outer table. Use one buffer for the inner table, one buffer for storing<br />output.</li><li>The cost is <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>M</mi><mo>+</mo><mo stretchy="false">(</mo><mo stretchy="false">⌈</mo><mi>M</mi><mi mathvariant="normal">/</mi><mo stretchy="false">(</mo><mi>B</mi><mo>−</mo><mn>2</mn><mo stretchy="false">)</mo><mo stretchy="false">⌉</mo><mo>⋅</mo><mi>N</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">M+(\lceil M/(B-2)\rceil\cdot N)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.76666em;vertical-align:-0.08333em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">M</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mopen">⌈</span><span class="mord mathnormal" style="margin-right:0.10903em;">M</span><span class="mord">/</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.05017em;">B</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord">2</span><span class="mclose">)</span><span class="mclose">⌉</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">N</span><span class="mclose">)</span></span></span></span>.</li><li>If the outer relation completely fits in memory, the cost is <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>M</mi><mo>+</mo><mi>N</mi></mrow><annotation encoding="application/x-tex">M+N</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.76666em;vertical-align:-0.08333em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">M</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">N</span></span></span></span>.</li></ol><h4 id="can-we-avoid-sequential-scans-by-using-an-index"><a class="markdownIt-Anchor" href="#can-we-avoid-sequential-scans-by-using-an-index"></a> Can we avoid sequential scans by using an index?</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> <span class="built_in">tuple</span> r <span class="keyword">in</span> R:</span><br><span class="line">  <span class="keyword">for</span> <span class="built_in">tuple</span> s <span class="keyword">in</span> Index(r_i = s_j):</span><br><span class="line">    emit, <span class="keyword">if</span> r <span class="keyword">and</span> s <span class="keyword">match</span></span><br></pre></td></tr></table></figure><p>Assume the cost of each index probe is some constant <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>C</mi></mrow><annotation encoding="application/x-tex">C</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.07153em;">C</span></span></span></span> per tuple. The cost is <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>M</mi><mo>+</mo><mo stretchy="false">(</mo><mi>m</mi><mo>⋅</mo><mi>C</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">M+(m\cdot C)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.76666em;vertical-align:-0.08333em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">M</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord mathnormal">m</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.07153em;">C</span><span class="mclose">)</span></span></span></span></p><h3 id="sort-merge-join"><a class="markdownIt-Anchor" href="#sort-merge-join"></a> Sort-merge join</h3><h4 id="what-is-the-process-of-sort-merge-join"><a class="markdownIt-Anchor" href="#what-is-the-process-of-sort-merge-join"></a> What is the process of sort-merge join?</h4><ol><li>The first phase is to sort both tables on the join key(s).</li><li>In the second phase, we step through the two sorted tables with cursors and emit matching tuples.</li><li>The sort cost of outer table is <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>2</mn><mi>M</mi><mo>⋅</mo><mo stretchy="false">(</mo><mn>1</mn><mo>+</mo><mo stretchy="false">⌈</mo><msub><mo><mi>log</mi><mo>⁡</mo></mo><mrow><mi>B</mi><mo>−</mo><mn>1</mn></mrow></msub><mo stretchy="false">⌈</mo><mi>M</mi><mi mathvariant="normal">/</mi><mi>B</mi><mo stretchy="false">⌉</mo><mo stretchy="false">⌉</mo><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">2M\cdot(1+\lceil \log_{B-1}\lceil M/B\rceil\rceil)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord">2</span><span class="mord mathnormal" style="margin-right:0.10903em;">M</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord">1</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1.052471em;vertical-align:-0.302471em;"></span><span class="mopen">⌈</span><span class="mop"><span class="mop">lo<span style="margin-right:0.01389em;">g</span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.23419099999999998em;"><span style="top:-2.45586em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.05017em;">B</span><span class="mbin mtight">−</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.302471em;"><span></span></span></span></span></span></span><span class="mopen">⌈</span><span class="mord mathnormal" style="margin-right:0.10903em;">M</span><span class="mord">/</span><span class="mord mathnormal" style="margin-right:0.05017em;">B</span><span class="mclose">⌉</span><span class="mclose">⌉</span><span class="mclose">)</span></span></span></span> and the sort cost of inner table is <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>2</mn><mi>N</mi><mo>⋅</mo><mo stretchy="false">(</mo><mn>1</mn><mo>+</mo><mo stretchy="false">⌈</mo><msub><mo><mi>log</mi><mo>⁡</mo></mo><mrow><mi>B</mi><mo>−</mo><mn>1</mn></mrow></msub><mo stretchy="false">⌈</mo><mi>N</mi><mi mathvariant="normal">/</mi><mi>B</mi><mo stretchy="false">⌉</mo><mo stretchy="false">⌉</mo><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">2N\cdot (1+\lceil\log_{B-1}\lceil N/B \rceil \rceil)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord">2</span><span class="mord mathnormal" style="margin-right:0.10903em;">N</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord">1</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1.052471em;vertical-align:-0.302471em;"></span><span class="mopen">⌈</span><span class="mop"><span class="mop">lo<span style="margin-right:0.01389em;">g</span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.23419099999999998em;"><span style="top:-2.45586em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.05017em;">B</span><span class="mbin mtight">−</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.302471em;"><span></span></span></span></span></span></span><span class="mopen">⌈</span><span class="mord mathnormal" style="margin-right:0.10903em;">N</span><span class="mord">/</span><span class="mord mathnormal" style="margin-right:0.05017em;">B</span><span class="mclose">⌉</span><span class="mclose">⌉</span><span class="mclose">)</span></span></span></span>.</li><li>The merge cost is <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>M</mi><mo>+</mo><mi>N</mi></mrow><annotation encoding="application/x-tex">M+N</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.76666em;vertical-align:-0.08333em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">M</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">N</span></span></span></span>.<ul><li>The worst case for the merging phase is when the join attribute of all the tuples in both relations contains the same value.</li></ul></li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">sort R,S on join keys</span><br><span class="line">cursor_R points to R_sorted, cursor_S points to S_sorted</span><br><span class="line"><span class="keyword">while</span> cursor_R <span class="keyword">and</span> cursor_S:</span><br><span class="line">  <span class="keyword">if</span> cursor_R &gt; cursor_S:</span><br><span class="line">    increment cursor_S</span><br><span class="line">  <span class="keyword">if</span> cursor_R &lt; cursor_S:</span><br><span class="line">    increment cursor_R</span><br><span class="line">    possible backtrack cursor_S</span><br><span class="line">  <span class="keyword">elif</span> cursor_R <span class="keyword">and</span> surcor_s <span class="keyword">match</span>:</span><br><span class="line">    emit</span><br><span class="line">    increment cursor_s</span><br></pre></td></tr></table></figure><h4 id="how-does-the-two-cursors-move"><a class="markdownIt-Anchor" href="#how-does-the-two-cursors-move"></a> How does the two cursors move?</h4><ol><li>The cursor of outer table will only move forward. Specifically, it will only move forward when we can assure that we have already match the current tuple with all possible tuples, i.e. when we occurred a larger inner tuple.</li><li>The cursor of inner table may move both forward and backward.<ul><li>It moves forward when some later tuple in inned table may match with the current tuple in outer tuple, i.e. when inner tuple is smaller than outer tuple or when they matches (there are possible more matches in the following).</li><li>It moves backward when there might have some missing matches in the past, i.e. when the outer cursor moving forward, the key is the same as the last one, we need to backtrack to the earliest tuple that matches with the last outer tuple.</li></ul></li></ol><h4 id="when-is-sort-merge-join-useful"><a class="markdownIt-Anchor" href="#when-is-sort-merge-join-useful"></a> When is sort-merge join useful?</h4><ol><li>When one or both tables are already sorted on join key, we can save some sort cost.</li><li>When output must be sorted on join key, if the output of join is larger, we might use sort-merge join to produce sorted output directly.<ul><li>If the output has a small amout, hash join might still be the better way.</li></ul></li></ol><h3 id="hash-join"><a class="markdownIt-Anchor" href="#hash-join"></a> Hash join</h3><h4 id="how-does-hash-join-work"><a class="markdownIt-Anchor" href="#how-does-hash-join-work"></a> How does hash join work?</h4><ol><li><p>The thought behind hash join is that:</p><ul><li>If tuple <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>r</mi><mo>∈</mo><mi>R</mi></mrow><annotation encoding="application/x-tex">r \in R</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5782em;vertical-align:-0.0391em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.00773em;">R</span></span></span></span> and a tuple<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>s</mi><mo>∈</mo><mi>S</mi></mrow><annotation encoding="application/x-tex">s \in S</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5782em;vertical-align:-0.0391em;"></span><span class="mord mathnormal">s</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.05764em;">S</span></span></span></span> satisfy the join condition, then they have the same value for the join attributes.</li><li>If that value is hashed to some partition <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>i</mi></mrow><annotation encoding="application/x-tex">i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.65952em;vertical-align:0em;"></span><span class="mord mathnormal">i</span></span></span></span>, the <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>R</mi></mrow><annotation encoding="application/x-tex">R</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.00773em;">R</span></span></span></span> tuple must be in <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>r</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">r_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> and the <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>S</mi></mrow><annotation encoding="application/x-tex">S</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.05764em;">S</span></span></span></span> tuple in <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>s</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">s_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>.</li><li>Therefore, <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>R</mi></mrow><annotation encoding="application/x-tex">R</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.00773em;">R</span></span></span></span> tuples in <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>r</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">r_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> need only to be compared with <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>S</mi></mrow><annotation encoding="application/x-tex">S</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.05764em;">S</span></span></span></span> tuples in <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>s</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">s_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>.</li></ul></li><li><p>In the first phase (build), we scan the outer relation and populate a hash table using the hash function <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>h</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">h_1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.84444em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> on the join attributes.</p><p>In the second phase (probe), scan the inner relation and use <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>h</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">h_1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.84444em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> on each tuple to jump to a location in the hash table and find a matching tuple.</p></li><li><p>The keys stored in the hash table is the attribute(s) that the query is joining the tables on. We always need the original key to verify that we have a correct match in case of hash collisions.</p><p>The values stored varies per implementation, which depends on what the operators above the join in the query plan expect as its input.</p></li><li><p>Assume that we have enough buffers, we need to read and write both tables with cost of <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>2</mn><mo stretchy="false">(</mo><mi>M</mi><mo>+</mo><mi>N</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">2(M+N)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord">2</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.10903em;">M</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">N</span><span class="mclose">)</span></span></span></span> in partitioning phase, and read both tables with cost of <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>M</mi><mo>+</mo><mi>N</mi></mrow><annotation encoding="application/x-tex">M+N</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.76666em;vertical-align:-0.08333em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">M</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">N</span></span></span></span> in probing phase.</p><ul><li>We can see that there is no constraint on the size of inner table.</li></ul></li></ol><h4 id="how-big-of-a-table-can-we-hash-using-this-approach"><a class="markdownIt-Anchor" href="#how-big-of-a-table-can-we-hash-using-this-approach"></a> How big of a table can we hash using this approach?</h4><ol><li>In the first phase of building hash table, we can use at most <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>B</mi><mo>−</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">B-1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.76666em;vertical-align:-0.08333em;"></span><span class="mord mathnormal" style="margin-right:0.05017em;">B</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">1</span></span></span></span> spill partitions leaving one page as input buffer. When one partition is full, we should write it out to disk and clear it.</li><li>total number of both outer and inner table of each partition should be no more than <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>B</mi></mrow><annotation encoding="application/x-tex">B</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.05017em;">B</span></span></span></span> blocks big so that in the second phase, we can store all tuples in the same partition in memory.</li><li>The total page used is <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>B</mi><mo>⋅</mo><mo stretchy="false">(</mo><mi>B</mi><mo>−</mo><mn>1</mn><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">B\cdot (B-1)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.05017em;">B</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.05017em;">B</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord">1</span><span class="mclose">)</span></span></span></span>. A hash table of <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>N</mi></mrow><annotation encoding="application/x-tex">N</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">N</span></span></span></span> pages needs about <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msqrt><mi>N</mi></msqrt></mrow><annotation encoding="application/x-tex">\sqrt{N}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.04em;vertical-align:-0.11333499999999996em;"></span><span class="mord sqrt"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.9266650000000001em;"><span class="svg-align" style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord" style="padding-left:0.833em;"><span class="mord mathnormal" style="margin-right:0.10903em;">N</span></span></span><span style="top:-2.886665em;"><span class="pstrut" style="height:3em;"></span><span class="hide-tail" style="min-width:0.853em;height:1.08em;"><svg width='400em' height='1.08em' viewBox='0 0 400000 1080' preserveAspectRatio='xMinYMin slice'><path d='M95,702c-2.7,0,-7.17,-2.7,-13.5,-8c-5.8,-5.3,-9.5,-10,-9.5,-14c0,-2,0.3,-3.3,1,-4c1.3,-2.7,23.83,-20.7,67.5,-54c44.2,-33.3,65.8,-50.3,66.5,-51c1.3,-1.3,3,-2,5,-2c4.7,0,8.7,3.3,12,10s173,378,173,378c0.7,0,35.3,-71,104,-213c68.7,-142,137.5,-285,206.5,-429c69,-144,104.5,-217.7,106.5,-221l0 -0c5.3,-9.3,12,-14,20,-14H400000v40H845.2724s-225.272,467,-225.272,467s-235,486,-235,486c-2.7,4.7,-9,7,-19,7c-6,0,-10,-1,-12,-3s-194,-422,-194,-422s-65,47,-65,47zM834 80h400000v40h-400000z'/></svg></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.11333499999999996em;"><span></span></span></span></span></span></span></span></span> buffers if the hash distribution is even.</li><li>When including the fudge factor <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>f</mi><mo>&gt;</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">f&gt;1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">&gt;</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">1</span></span></span></span> when hash distribution is skewed, we need <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>B</mi><mo>⋅</mo><msqrt><mrow><mi>f</mi><mo>⋅</mo><mi>N</mi></mrow></msqrt></mrow><annotation encoding="application/x-tex">B\cdot\sqrt{f\cdot N}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.05017em;">B</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1.04em;vertical-align:-0.20500000000000007em;"></span><span class="mord sqrt"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.835em;"><span class="svg-align" style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord" style="padding-left:0.833em;"><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">N</span></span></span><span style="top:-2.795em;"><span class="pstrut" style="height:3em;"></span><span class="hide-tail" style="min-width:0.853em;height:1.08em;"><svg width='400em' height='1.08em' viewBox='0 0 400000 1080' preserveAspectRatio='xMinYMin slice'><path d='M95,702c-2.7,0,-7.17,-2.7,-13.5,-8c-5.8,-5.3,-9.5,-10,-9.5,-14c0,-2,0.3,-3.3,1,-4c1.3,-2.7,23.83,-20.7,67.5,-54c44.2,-33.3,65.8,-50.3,66.5,-51c1.3,-1.3,3,-2,5,-2c4.7,0,8.7,3.3,12,10s173,378,173,378c0.7,0,35.3,-71,104,-213c68.7,-142,137.5,-285,206.5,-429c69,-144,104.5,-217.7,106.5,-221l0 -0c5.3,-9.3,12,-14,20,-14H400000v40H845.2724s-225.272,467,-225.272,467s-235,486,-235,486c-2.7,4.7,-9,7,-19,7c-6,0,-10,-1,-12,-3s-194,-422,-194,-422s-65,47,-65,47zM834 80h400000v40h-400000z'/></svg></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.20500000000000007em;"><span></span></span></span></span></span></span></span></span>.</li></ol><h4 id="can-we-optimized-the-search-for-tuples-that-does-not-have-any-match"><a class="markdownIt-Anchor" href="#can-we-optimized-the-search-for-tuples-that-does-not-have-any-match"></a> Can we optimized the search for tuples that does not have any match?</h4><ol><li>We can create a Bloom filter during the build phase when the key is likely to not exist in the hash table. This method is called Bloom filter or sideways information passing.</li><li>The Bloom filter is a probabilistic data structure (bitmap) that answers set membership queries.<ul><li>False negatives will never occur while false positives can sometimes occur.</li><li>To insert a key into the filter, we use <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi></mrow><annotation encoding="application/x-tex">k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.03148em;">k</span></span></span></span> hash functions to set all <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi></mrow><annotation encoding="application/x-tex">k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.03148em;">k</span></span></span></span> bits to <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1</mn></mrow><annotation encoding="application/x-tex">1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">1</span></span></span></span>.</li><li>During lookup a key, the key may exist if all <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi></mrow><annotation encoding="application/x-tex">k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.03148em;">k</span></span></span></span> bits hashed by the same <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi></mrow><annotation encoding="application/x-tex">k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.03148em;">k</span></span></span></span> hash function are all <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1</mn></mrow><annotation encoding="application/x-tex">1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">1</span></span></span></span>. The key definitely does not exists if one of the <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi></mrow><annotation encoding="application/x-tex">k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.03148em;">k</span></span></span></span> bits is <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>0</mn></mrow><annotation encoding="application/x-tex">0</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">0</span></span></span></span>.</li></ul></li></ol><h4 id="what-if-we-do-not-have-enough-memoty-to-fit-the-entire-hash-table"><a class="markdownIt-Anchor" href="#what-if-we-do-not-have-enough-memoty-to-fit-the-entire-hash-table"></a> What if we do not have enough memoty to fit the entire hash table?</h4><ol><li>We can use the recursive hash join (GRACE hash join).</li><li>Similar with aforementioned algorithm, hash both tables into same number of buckets with the same hash function.</li><li>Perform regular hash join on each pair of matching buckets in the same level between two tables.</li><li>If the buckets do not fit in memory, then use recursive partitioning to split the tables into chunks that will fit.<ul><li>Build another hash table for <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>b</mi><mi>u</mi><mi>c</mi><mi>k</mi><mi>e</mi><msub><mi>t</mi><mrow><mi>R</mi><mo separator="true">,</mo><mi>i</mi></mrow></msub></mrow><annotation encoding="application/x-tex">bucket_{R,i}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.980548em;vertical-align:-0.286108em;"></span><span class="mord mathnormal">b</span><span class="mord mathnormal">u</span><span class="mord mathnormal">c</span><span class="mord mathnormal" style="margin-right:0.03148em;">k</span><span class="mord mathnormal">e</span><span class="mord"><span class="mord mathnormal">t</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.328331em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.00773em;">R</span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight">i</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span></span></span></span> using hash function <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>h</mi><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">h_2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.84444em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> (with <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>h</mi><mn>2</mn></msub><mo mathvariant="normal">≠</mo><msub><mi>h</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">h_2≠h_1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord"><span class="mord mathnormal">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel"><span class="mrel"><span class="mord vbox"><span class="thinbox"><span class="rlap"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="inner"><span class="mrel"></span></span><span class="fix"></span></span></span></span></span><span class="mrel">=</span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.84444em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>).</li><li>Then probe it for each tuple of the other table’s bucket at that level.</li></ul></li><li><strong>Hybrid hash join</strong>: If the keys are skewed, then the DBMS keeps the hot partition in-memory and immediately perform the comparison instead of spilling it to disk.</li></ol>]]></content>
      
      
      <categories>
          
          <category> Open Courses </category>
          
          <category> CMU 15-445/645 Database System </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Database System </tag>
            
            <tag> External Algorithms </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Project #1: Buffer Pool</title>
      <link href="/2023/06/27/OpenSource/BusTub/Project-1-Buffer-Pool/"/>
      <url>/2023/06/27/OpenSource/BusTub/Project-1-Buffer-Pool/</url>
      
        <content type="html"><![CDATA[<p><ul class="markdownIt-TOC"><li><a href="#task-1-lru-k-replacement-policy">Task #1 - LRU-K Replacement Policy</a></li><li><a href="#task-2-buffer-pool-manager">Task #2 - Buffer Pool Manager</a><ul><li><a href="#basic">Basic</a></li><li><a href="#leaderboard-optimization">Leaderboard optimization</a></li></ul></li><li><a href="#task-3-readwrite-page-guards">Task #3 - Read/Write Page Guards</a></li></ul></p><h1 id="task-1-lru-k-replacement-policy"><a class="markdownIt-Anchor" href="#task-1-lru-k-replacement-policy"></a> Task #1 - LRU-K Replacement Policy</h1><ol><li><p>Evict rule:</p><ul><li>When all evictable frames have more than <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>K</mi></mrow><annotation encoding="application/x-tex">K</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.07153em;">K</span></span></span></span> access records, evict the one whose backward k-distance is maximum.</li><li>When some frames only have less than <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>K</mi></mrow><annotation encoding="application/x-tex">K</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.07153em;">K</span></span></span></span> access records, evict the one with earliest first access record among those less than <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>K</mi></mrow><annotation encoding="application/x-tex">K</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.07153em;">K</span></span></span></span> frames.</li></ul></li><li><p>Comparison:</p><ul><li>When each frame is created or stored with a new page, push an access record of <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>0</mn></mrow><annotation encoding="application/x-tex">0</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">0</span></span></span></span> to its history to represent <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>+</mo><mi>inf</mi><mo>⁡</mo></mrow><annotation encoding="application/x-tex">+\inf</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.77777em;vertical-align:-0.08333em;"></span><span class="mord">+</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mop">in<span style="margin-right:0.07778em;">f</span></span></span></span></span>.</li><li>Each comparison use the first two records in the list. If the first record (the earliest backward most k-distance) is the same, it must be <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>0</mn></mrow><annotation encoding="application/x-tex">0</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">0</span></span></span></span> causing comparing second record where represent true first access of that frame.</li><li>Remember to update second comparison timestamp when the first time find <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>0</mn></mrow><annotation encoding="application/x-tex">0</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">0</span></span></span></span> in first timestamp.</li></ul><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">size_t</span> k_timestamp = frame.second.<span class="built_in">GetKTimestamp</span>();</span><br><span class="line"><span class="type">size_t</span> sec_timestamp = frame.second.<span class="built_in">GetSecondTimestamp</span>();</span><br><span class="line"><span class="keyword">if</span> (k_timestamp &lt; cmp_k_timestamp) &#123;</span><br><span class="line">victim = frame.first;</span><br><span class="line">cmp_k_timestamp = k_timestamp;</span><br><span class="line"><span class="keyword">if</span> (k_timestamp == <span class="number">0</span>) &#123;</span><br><span class="line">cmp_sec_timestamp = sec_timestamp;</span><br><span class="line">&#125;</span><br><span class="line">&#125; <span class="keyword">else</span> <span class="keyword">if</span> (k_timestamp == cmp_k_timestamp &amp;&amp; sec_timestamp &lt; cmp_sec_timestamp) &#123;</span><br><span class="line">victim = frame.first;</span><br><span class="line">cmp_sec_timestamp = sec_timestamp;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>After successfully choosing a victim, we need to clear its history (leaving the <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>0</mn></mrow><annotation encoding="application/x-tex">0</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">0</span></span></span></span> as sentinel), set it to non-evictable, and recude the current size of replacer.</p></li></ol><h1 id="task-2-buffer-pool-manager"><a class="markdownIt-Anchor" href="#task-2-buffer-pool-manager"></a> Task #2 - Buffer Pool Manager</h1><h2 id="basic"><a class="markdownIt-Anchor" href="#basic"></a> Basic</h2><ol><li><p>When the page that is asked to fetch is already in the buffer pool, we still need to do several things:</p><ul><li>Set it to non-evictable.</li><li>Record its access in replacer.</li><li>Increase its pin count.</li></ul></li><li><p>When the page is not in buffer pool, or creating a new page:</p><ul><li>First, we need to acquire a free frame.<ul><li>Erase it from page table when we are evicting one.</li><li>Write the content to disk when the old page is dirty.</li></ul></li><li>Then, similar to the other situation, we need to:<ul><li>Set it to non-evictable</li><li>Record its access in replacer</li><li>Put it in page table</li><li>Set its pin count to <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1</mn></mrow><annotation encoding="application/x-tex">1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">1</span></span></span></span></li><li>Set <code>is_dirty_</code> to <code>false</code></li><li>Set its page ID to frame.</li></ul></li><li>Even in <code>NewPage</code>, the <code>is_dirty_</code> is false due to it can directly “write” empty to file by increasing offset which is done when larger page ID is written. There is no need to actually write empty content.</li></ul></li><li><p>When setting <code>is_dirty_</code> in <code>Unpin</code>, if the page is already dirty, we should not set it to clean no matter what we are told to.</p></li></ol><h2 id="leaderboard-optimization"><a class="markdownIt-Anchor" href="#leaderboard-optimization"></a> Leaderboard optimization</h2><ol><li>Fine-grain lock<ul><li>A coarse-grain lock is easier to program while sacrificing performance.</li><li>In fine-grain lock, a <code>core_latch_</code> is used to protect the core data of buffer pool manager, i.e. <code>page_table_</code>, <code>free_list_</code>, <code>next_page_id_</code>). Each frame has its own latch to protect its data, i.e. <code>pin_count_</code>, <code>is_dirty_</code>, <code>page_id_</code>.</li><li>In each function thread, it will at most grab the <code>core_latch_</code> and one of frame latches.</li><li>To avoid deadlock, each procedule is designed that a thread will try to acquire a page latch only if it already has a core_latch, or it won’t want a core_latech later.</li><li>To obtain atomic when switching from <code>core_latch_</code> to a page latch, we need to acquire the page latch before release the <code>core_latch_</code>.<ul><li>If release <code>core_latch_</code> first, some other thread may change the frame we want to use (e.g. evict the frame, modify its metadata) before we can acquire the frame latch.</li></ul></li></ul></li><li>Delay write out:<ul><li>Disk I/Os consume a large amount of time. So we need to avoid holding a lock while communicate with disk.</li><li>When we need to write data into disk, instead of immediately call the <code>disk_manager_-&gt;WritePage</code>, we create a temporary buffer in memory, and copy data into the buffer. After all locks are released, we actually write those content in buffer into disk.</li><li>A similar thought is to delay read data until all locks are released. However, <code>ReadData</code> are call in <code>FetchPage</code> where  we can only release the frame latch after the whole frame is ready for others to visit. Still, we can <code>ReadData</code> after <code>core_latch_</code> is released since the <code>core_latch_</code> could be the bottleneck of the manager.</li><li>However, there is a problem:<ul><li>When a page is evicted, and only a short time later, that exact page is fetched again. Since all latches are release before write dirty data to disk, there is a chance that <code>FetchPage</code> read stale data from disk before the up-to-date data is written to disk.</li><li>Then my another thought is to maintain a list of page IDs in the writing buffer. If the page ID of <code>FetchPage</code> is in the list, it just copy data from the writing buffer and erase that page from writing buffer.</li><li>The problem here is that we need to guarantee the atomic between getting the writing content and writing them to disk. Otherwise, tricky concurrent operations may cause the written content to be wrong.</li><li>Hence we cannot unlock the latches until we are sure the content is written, which also makes fine-grained latches meaningless given that disk I/O is the key problem of performance.</li></ul></li></ul></li><li>Pre-fetch<ul><li>To better suit the scan case, when we accessing three consecutive page IDs in a row, the buffer pool manager is allowed to pre-fetch several following pages.</li><li>Different from fetching pages through <code>FetchPage</code>, pre-fetched frames need to set <code>pin_count_</code> to <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>0</mn></mrow><annotation encoding="application/x-tex">0</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">0</span></span></span></span> and evictable.</li><li>Pre-fetch should not stall <code>FetchPage</code> from returning, so it must be run in a separate thread.</li><li>The problem is that pre-fetch must be an independent background thread. It won’t know whether the buffer pool manager is destroyed, which will cause heap-use-after-free error.</li></ul></li></ol><h1 id="task-3-readwrite-page-guards"><a class="markdownIt-Anchor" href="#task-3-readwrite-page-guards"></a> Task #3 - Read/Write Page Guards</h1><ol><li>Any <code>PageGuard</code> will automatically unpin itself when it is deconstructed. But they don’t need to pin themselves since they are pinned before <code>PageGuard</code> is created when fetching or creating page.</li><li>If a <code>Read/WritePageGuard</code> is acquired through <code>FetchPageRead</code> or <code>FetchPageWrite</code>, the latch is acquired inside these functions. However, if a <code>PageGuard</code> is acquired through it construction function, the latch won’t be acquired automatically.</li><li>No matter how <code>Read/WritePageGuard</code> is acquired, the latch will always be released automatically when the <code>PageGuard</code> is deconstructed by deconstructor or move operation.</li><li>In the move assignment, we need to first drop the original page, copy from right reference and finally deconstruct right reference.</li></ol>]]></content>
      
      
      <categories>
          
          <category> Open Source Code </category>
          
          <category> BusTub </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Database System </tag>
            
            <tag> Storage </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>05 Index Concurrency</title>
      <link href="/2023/06/25/Courses/15445/05-Index-Concurrency/"/>
      <url>/2023/06/25/Courses/15445/05-Index-Concurrency/</url>
      
        <content type="html"><![CDATA[<p><ul class="markdownIt-TOC"><li><a href="#concurrency-control">Concurrency control</a><ul><li><a href="#what-is-the-correctness-criteria-of-concurrency-control">What is the correctness criteria of concurrency control?</a></li><li><a href="#what-is-more-specific-difference-between-locks-and-latches">What is more specific difference between locks and latches?</a></li><li><a href="#what-are-the-two-latch-modes">What are the two latch modes?</a></li><li><a href="#what-are-the-different-latch-implementations">What are the different latch implementations?</a></li></ul></li><li><a href="#latching-scheme">Latching scheme</a><ul><li><a href="#hash-table-latching">Hash table latching</a><ul><li><a href="#why-are-deadlocks-not-possible-in-hash-table">Why are deadlocks not possible in hash table?</a></li><li><a href="#how-can-we-design-hash-table-latching">How can we design hash table latching?</a></li></ul></li><li><a href="#btree-latching">B+Tree latching</a><ul><li><a href="#what-should-we-use-latching-to-prevent">What should we use latching to prevent?</a></li><li><a href="#how-should-we-achieve-physical-correctness">How should we achieve physical correctness?</a></li><li><a href="#what-is-the-problem-of-aforementioned-strategy">What is the problem of aforementioned strategy?</a></li><li><a href="#when-will-a-deadlock-occur">When will a deadlock occur?</a></li></ul></li></ul></li></ul></p><h1 id="concurrency-control"><a class="markdownIt-Anchor" href="#concurrency-control"></a> Concurrency control</h1><h2 id="what-is-the-correctness-criteria-of-concurrency-control"><a class="markdownIt-Anchor" href="#what-is-the-correctness-criteria-of-concurrency-control"></a> What is the correctness criteria of concurrency control?</h2><ol><li>Logical Correctness:<ul><li>Can a thread see the data that it is supposed to see? For example, correctly control data race.</li></ul></li><li>Physical Correctness:<ul><li>Is the internal representation of the object sound? For example, when fetched a ptr, it will points to a correct address, and it won’t be freed between fetching and accessing.</li></ul></li></ol><h2 id="what-is-more-specific-difference-between-locks-and-latches"><a class="markdownIt-Anchor" href="#what-is-more-specific-difference-between-locks-and-latches"></a> What is more specific difference between locks and latches?</h2><ol><li>What are they used to separate? What are they protecting? How long will they be held?<ul><li>Locks are used to separate user transactions accessing the same tuples in database contents. Locks are held in the entire transaction.</li><li>Latches are used to separate threads accessing the same in-memory data structures. Latchs are held in the critical section.</li></ul></li><li>How many modes do they have?<ul><li>Locks have four modes: shared, excusive, update, intention.</li><li>Latches only have two modes: read and write.</li></ul></li><li>How do they solve deadlock?<ul><li>Locks use detection and resolution by waits-for, timeout or abort.</li><li>Latches can only avoid deadlock by code discipline.</li></ul></li><li>Where are they kept?<ul><li>Locks are kept in Lock Manager while latches are kept in protected data structure.</li></ul></li></ol><h2 id="what-are-the-two-latch-modes"><a class="markdownIt-Anchor" href="#what-are-the-two-latch-modes"></a> What are the two latch modes?</h2><ol><li><p>Read mode means that Multiple threads can read the same object at the same time.</p><ul><li>A thread can acquire the read latch if another thread has it in read mode.</li></ul></li><li><p>Write mode onely allows one thread to access the object.</p><ul><li>A thread cannot acquire a write latch if another thread has it in any mode.</li></ul></li><li><p>In the compatibility matrix, only two read mode access is allowed.</p></li></ol><h2 id="what-are-the-different-latch-implementations"><a class="markdownIt-Anchor" href="#what-are-the-different-latch-implementations"></a> What are the different latch implementations?</h2><ol><li>The first is blocking OS Mutex.<ul><li>It is simple to use.</li><li>It takes about <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>25</mn><mtext> </mtext><mi>n</mi><mi>s</mi></mrow><annotation encoding="application/x-tex">25\ ns</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">2</span><span class="mord">5</span><span class="mspace"> </span><span class="mord mathnormal">n</span><span class="mord mathnormal">s</span></span></span></span> per lock/unlock invocation, which means that it is non-scalable.<ul><li><code>std::mutex</code> is slower than <code>pthread_mutex</code> and <code>futex</code> is faster than both of them.</li></ul></li><li><code>futex</code> stands for fast userspace mutex.<ul><li>It has a userspace spinlock and a heavy-weight OS latch.</li><li>Threads will first try to acquire the userspace lock. If success, then that is good.</li><li>But if failed, the thread will fall back to the OS latch. And OS takes control of the thread with when to schedule it and DBMS can do nothing with the thread. Also <code>syscall</code> is expensive.</li></ul></li></ul></li><li>The second approach is reader-writer latches.<ul><li>It allows for concurrent readers. Must manage read/write queues to avoid starvation.</li><li>It can be implemented on top of spinlock.</li><li>Still <code>std::shared_mutex</code> is slower than <code>pthread_rwlock</code>.</li></ul></li></ol><h1 id="latching-scheme"><a class="markdownIt-Anchor" href="#latching-scheme"></a> Latching scheme</h1><h2 id="hash-table-latching"><a class="markdownIt-Anchor" href="#hash-table-latching"></a> Hash table latching</h2><h3 id="why-are-deadlocks-not-possible-in-hash-table"><a class="markdownIt-Anchor" href="#why-are-deadlocks-not-possible-in-hash-table"></a> Why are deadlocks not possible in hash table?</h3><ol><li>All threads move in the same direction and only access a single page/slot at a time.<ul><li>Hence there are no loop waiting in this scenario.</li></ul></li><li>To resize the table, take a global write latch on the entire table.</li></ol><h3 id="how-can-we-design-hash-table-latching"><a class="markdownIt-Anchor" href="#how-can-we-design-hash-table-latching"></a> How can we design hash table latching?</h3><ol><li>The coarser-grain approach is to use page latches.<ul><li>Each page has its own reader-writer latch that protects its entire contents.</li></ul></li><li>The finer-grain approach is to use slot latches.<ul><li>Each slot has its own latch.</li><li>It can use a single-mode latch to reduce meta-data and computational overhead.</li></ul></li></ol><h2 id="btree-latching"><a class="markdownIt-Anchor" href="#btree-latching"></a> B+Tree latching</h2><h3 id="what-should-we-use-latching-to-prevent"><a class="markdownIt-Anchor" href="#what-should-we-use-latching-to-prevent"></a> What should we use latching to prevent?</h3><ol><li>Threads trying to modify the contents of a node at the same time. (This is logical correctness, i.e. data race)</li><li>One thread traversing the tree while another thread splits/merges nodes.<ul><li>This is physical correctness. Splitting/merging will causing free pointers, nodes or in-node entries.</li><li>This will also cause a problem with logical correctness, i.e. false negative.<ul><li>If a thread get the pointer of node which possess the key it want, then before it accesses the node, the key is borrowed by a sibling causing the thread thought the key does not exists.</li></ul></li></ul></li><li>When introducing sibling pointers, we may have a deadlock situation.</li></ol><h3 id="how-should-we-achieve-physical-correctness"><a class="markdownIt-Anchor" href="#how-should-we-achieve-physical-correctness"></a> How should we achieve physical correctness?</h3><ol><li>The most naive method is to hold all locks until the entire process is done. But its performance is a disaster.<ul><li>We must release some latches when we are sure it is safe.</li><li>According to our goal, a node is safe when we know that it won’t be changed (split, merge or redistribute) when updated.</li><li>We can know a child is safe when its child is not full on insertion or more than half-full on deletion, i.e. any later opereations can be isolated on or below its level.</li></ul></li><li>For find operation, there won’t have any updates. Hence we can always unlatch parent when acquired a R latch on child.</li><li>For insert or delete operation, we need to obtaining W latches as needed. Once child is latched, check if it is safe.<ul><li>If the child is safe, we can release all latches on ancestors. The latches should be released from top to bottom to have a better performance.</li></ul></li></ol><h3 id="what-is-the-problem-of-aforementioned-strategy"><a class="markdownIt-Anchor" href="#what-is-the-problem-of-aforementioned-strategy"></a> What is the problem of aforementioned strategy?</h3><ol><li>Every insert/delete operation will take a write latch on the root, which makes the root a bottleneck with higher concurrency.</li><li>We can make the assumption that most modifications to a B+Tree will not require a split or merge.</li><li>Hence, instead of assuming that there will be a split/merge as aforementioned, optimistically traverse the tree using read latches. If the guess is wrong in the end, just repeat traversal with pessimistic algorithm.</li><li>For insert/delete operations, set latches as if for search, get to leaf, and set W latch on leaf. If leaf is not safe, release all latches, and restart thread using previous insert/delete protocol with write latches.</li></ol><h3 id="when-will-a-deadlock-occur"><a class="markdownIt-Anchor" href="#when-will-a-deadlock-occur"></a> When will a deadlock occur?</h3><ol><li>With sibling pointers, we may move from one leaf node to another leaf node where deadlock could occur.</li><li>Latches cannot detect deadlock, so the only solution is to kill one thread.</li><li>The leaf node sibling latch acquisition protocol must support a “no-wait” mode. The DBMS’s data structures must cope with failed latch acquisitions.</li><li>Though some scenario is not a deadlock, the waiting thread cannot know what the other thread is doing, which means it can only kill itself to avoid deadlock.</li></ol>]]></content>
      
      
      <categories>
          
          <category> Open Courses </category>
          
          <category> CMU 15-445/645 Database System </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Database System </tag>
            
            <tag> Concurrency Control </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>04 Data Organization</title>
      <link href="/2023/06/24/Courses/15445/04-Data-Organization/"/>
      <url>/2023/06/24/Courses/15445/04-Data-Organization/</url>
      
        <content type="html"><![CDATA[<p><ul class="markdownIt-TOC"><li><a href="#what-does-the-database-access-methods-layer-need-to-do">What does the database access methods layer need to do?</a></li><li><a href="#hash-table">Hash table</a><ul><li><a href="#how-is-the-naive-static-hash-table">How is the naive static hash table?</a></li><li><a href="#what-are-hash-functions">What are hash functions?</a></li><li><a href="#static-hashing-schemes">Static hashing schemes</a><ul><li><a href="#how-is-linear-probe-hashing">How is linear probe hashing?</a></li><li><a href="#how-to-solve-the-non-unique-keys-problem">How to solve the non-unique keys problem?</a></li><li><a href="#how-is-the-robin-hood-hashing">How is the robin hood hashing?</a></li><li><a href="#how-is-the-cuckoo-hashing">How is the cuckoo hashing?</a></li></ul></li><li><a href="#dynamic-hashing-schemes">Dynamic hashing schemes</a><ul><li><a href="#how-is-chained-hashing">How is chained hashing?</a></li><li><a href="#how-is-extendible-hashing">How is extendible hashing?</a></li><li><a href="#how-is-linear-hashing">How is linear hashing?</a></li></ul></li></ul></li><li><a href="#tree">Tree</a><ul><li><a href="#table-indexes">Table indexes</a><ul><li><a href="#what-does-table-indexs-do">What does table indexs do?</a></li><li><a href="#what-is-clustered-indexes">What is clustered indexes?</a></li></ul></li><li><a href="#basic-b-tree">Basic B+ Tree</a><ul><li><a href="#what-is-a-b-tree">What is a B+ Tree?</a></li><li><a href="#how-is-keyvalue-pairs-stored-in-each-node">How is key/value pairs stored in each node?</a></li><li><a href="#what-is-stored-is-leaf-node">What is stored is leaf node?</a></li><li><a href="#what-is-the-pros-and-cons-of-b-tree-compare-with-btree">What is the pros and cons of B-Tree compare with B+Tree?</a></li><li><a href="#how-does-btree-insert-a-node">How does B+Tree insert a node?</a></li><li><a href="#how-does-btree-delete-a-node">How does B+Tree delete a node?</a></li></ul></li><li><a href="#btree-usage-and-design">B+Tree usage and design</a><ul><li><a href="#how-does-dbms-use-btree-in-selection-query">How does DBMS use B+Tree in selection query?</a></li><li><a href="#how-to-handle-duplicate-keys">How to handle duplicate keys?</a></li><li><a href="#how-to-solve-redundant-page-jump-when-sequential-access-leaf-nodes">How to solve redundant page jump when sequential access leaf nodes?</a></li><li><a href="#how-to-choose-node-size">How to choose node size?</a></li><li><a href="#how-to-choose-merge-threshold">How to choose merge threshold?</a></li><li><a href="#how-to-handle-variable-length-keys">How to handle variable length keys?</a></li><li><a href="#how-can-we-do-the-intra-node-search">How can we do the intra-node search?</a></li><li><a href="#how-can-we-optimize-space-usage">How can we optimize space usage?</a></li><li><a href="#how-can-we-optimize-consumed-time">How can we optimize consumed time?</a></li></ul></li></ul></li></ul></p><h1 id="what-does-the-database-access-methods-layer-need-to-do"><a class="markdownIt-Anchor" href="#what-does-the-database-access-methods-layer-need-to-do"></a> What does the database access methods layer need to do?</h1><ol><li><p>Data Organization</p><ul><li>How we layout data structure in memory/pages and what information to store to support efficient access.</li><li>This layer will in charge of the organization of all kinds of data inside database, e.g. internal meta-data, core data storage, temporary data structures, table indexes.</li></ul></li><li><p>Concurrency</p><ul><li>How to enable multiple threads to access the data structure at the same time without causing problems.</li></ul></li><li><p>There are two types of data structure: hash tables and trees.</p></li></ol><h1 id="hash-table"><a class="markdownIt-Anchor" href="#hash-table"></a> Hash table</h1><h2 id="how-is-the-naive-static-hash-table"><a class="markdownIt-Anchor" href="#how-is-the-naive-static-hash-table"></a> How is the naive static hash table?</h2><ol><li><p>A hash table implements an unordered associative array that maps keys to values.</p></li><li><p>For any input key, hash functions return an integer representation of that key.</p></li><li><p>The space complexity is <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>O</mi><mo stretchy="false">(</mo><mi>n</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">O(n)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">O</span><span class="mopen">(</span><span class="mord mathnormal">n</span><span class="mclose">)</span></span></span></span>, the average time complexity is <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>O</mi><mo stretchy="false">(</mo><mn>1</mn><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">O(1)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">O</span><span class="mopen">(</span><span class="mord">1</span><span class="mclose">)</span></span></span></span> and the worst time complexity is <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>O</mi><mo stretchy="false">(</mo><mi>n</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">O(n)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">O</span><span class="mopen">(</span><span class="mord mathnormal">n</span><span class="mclose">)</span></span></span></span>.</p><ul><li>Databases need to are about constants. For time complexity, smaller constants can save much time in billions of operations.</li><li>The space will be several times larger than the number of keys.</li></ul></li><li><p>The naive static hash table assumes:</p><ul><li>The number of elements is known ahead of time and fixed.</li><li>Each key is unique.</li><li>We have the perfect hash function where two different keys must have different hash values.</li></ul></li><li><p>These assumptions is not always satisfied.</p><ul><li><p>To suit when the first assumption failed, we need dynamic hashing scheme.</p></li><li><p>To suit when the last two assumptions failed, we need to design more delicate hash function to reduce collision rate and hashing scheme to handle collisions after hashing.</p><ul><li><p>The trade-off of hash function is between being fast and collision rate.</p></li><li><p>The trade-off of hashing scheme is between allocating a larger hash table and additional instructions to get/put keys.</p></li></ul></li></ul></li></ol><h2 id="what-are-hash-functions"><a class="markdownIt-Anchor" href="#what-are-hash-functions"></a> What are hash functions?</h2><ol><li><p>We do not want to use a cryptographic hash function for DBMS hash tables, e.g., SHA-2.</p><ul><li>Because this hashing is only using internally, we will never worry about leaking keys.</li><li>We want something that is fast and has a low collision rate.</li></ul></li><li><p>The commonly used hash functions are:</p><ul><li>CRC-64: Used in networking for error detection.</li><li>MurmurHash: Designed as a fast, general-purpose hash function.</li><li>Google CityHash: Designed to be faster for short keys (&lt;64 bytes).</li><li>Facebook XXHash: From the creator of zstd compression, which is the state-of-the-art.</li><li>Google Farmhash: Newer version of CityHash with better collision rates.</li></ul></li><li><p>Their speed comparison is as followed:</p><img src="/imgs/15445/Organization/hash_func.png" width="75%"></li></ol><h2 id="static-hashing-schemes"><a class="markdownIt-Anchor" href="#static-hashing-schemes"></a> Static hashing schemes</h2><h3 id="how-is-linear-probe-hashing"><a class="markdownIt-Anchor" href="#how-is-linear-probe-hashing"></a> How is linear probe hashing?</h3><ol><li>As all the following schemes, a key-value paire is stored in hashing table. The key is to determin whether this is actually the key we want to find.</li><li>It resolve collisions by linearly searching for the next free slot in the table.</li><li>To determine whether an element is present, hash to a location in the index and scan for it. If find an empty slot before the key, then the element does not exists.</li><li>To delete an entry, there are two approaches:<ul><li><strong>Movement</strong>: Rehash rest of the keys until find the first empty slot. Nobody actually does this.</li><li><strong>Tombstone</strong>: Set a marker to indicate that the entry in the slot is logically deleted. The slot can be reused for new keys. This may still need periodic garbage collection.</li></ul></li></ol><h3 id="how-to-solve-the-non-unique-keys-problem"><a class="markdownIt-Anchor" href="#how-to-solve-the-non-unique-keys-problem"></a> How to solve the non-unique keys problem?</h3><ol><li>The first choise is to store values in separate storage area for each key and the value of hash table points to the area.</li><li>The second choise is to store duplicate keys entries together in the hash table.<ul><li>Read would return the first key they found.</li><li>Deletes would remove all the keys or a specific key-value pair.</li></ul></li></ol><h3 id="how-is-the-robin-hood-hashing"><a class="markdownIt-Anchor" href="#how-is-the-robin-hood-hashing"></a> How is the robin hood hashing?</h3><ol><li>This is a variant of linear probe hashing that steals slots from “rich” keys and give them to “poor” keys.<ul><li>Each key tracks the number of positions they are from where its optimal position (original hash value) in the table.</li><li>The keys farther away from its optimal position is poorer while the keys closer is richer.</li><li>On insert, a key takes the slot of another key if the first key is “richer” than the second key. And the second key will keep searching linearly until it found another “richer” key.</li></ul></li><li>Stealing increases the number of writing operation compare with the linear probing scheme while may reduce the time of worst case.</li><li>This could have cascading/flooding problem where one insert causing multiple “stealing”. Also it does not consider the possibility of hot keys.</li></ol><h3 id="how-is-the-cuckoo-hashing"><a class="markdownIt-Anchor" href="#how-is-the-cuckoo-hashing"></a> How is the cuckoo hashing?</h3><ol><li>Use multiple hash tables with different hash function seeds to ensure they won’t hash to the same value.<ul><li>On insert, check every table and pick anyone that has a free slot.</li><li>If no table has a free slot, choose one victim, evict it and then re-hash it find a new location.</li></ul></li><li>Look-ups and deletions are always <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>O</mi><mo stretchy="false">(</mo><mn>1</mn><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">O(1)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">O</span><span class="mopen">(</span><span class="mord">1</span><span class="mclose">)</span></span></span></span> because only one location per hash table is checked.</li><li>There is a possibility of cascading. The worst case is an infinite cascading loop.<ul><li>We can use extra code to detect if replacing is going in a loop. If so, we need to double the hash table size with new hash functions and re-insert all keys.</li></ul></li></ol><h2 id="dynamic-hashing-schemes"><a class="markdownIt-Anchor" href="#dynamic-hashing-schemes"></a> Dynamic hashing schemes</h2><h3 id="how-is-chained-hashing"><a class="markdownIt-Anchor" href="#how-is-chained-hashing"></a> How is chained hashing?</h3><ol><li>It maintains a linked list of buckets for each slot in the hash table.</li><li>Resolve collisions by placing all elements with the same hash key into the same bucket.<ul><li>To determine whether an element is present, hash to its bucket and scan for it.</li></ul></li><li>The problem is that the linked list can grow forever causing the time spent on search increases as the system runs.</li></ol><h3 id="how-is-extendible-hashing"><a class="markdownIt-Anchor" href="#how-is-extendible-hashing"></a> How is extendible hashing?</h3><ol><li>Multiple slot locations can point to the same bucket chain.</li><li>For the number of bits needs to examine, there is a global one and a local one.</li><li>It reshuffle bucket entries on split and increase the number of bits to examine when a list is full.<ul><li>If there is only one slot pointing to this list, i.e. the global examining bits is the same as the local one,<ul><li>The DBMS increases the global number causing the size of hashing table doubled.</li><li>Those lists with smaller local number will set the pointers of corresponding new slots (with only the last global examining bit different) still to themselves.</li><li>DBMS also increases the local examining bits of the fulled list. The keys in it will re-hash to their two new lists.</li></ul></li><li>If there are more than one slots pointing to this list, i.e. the global examning bits is larger the the local one,<ul><li>The DBMS only increases the local examining bits of the fulled list and do the re-hashing.</li></ul></li></ul></li></ol><h3 id="how-is-linear-hashing"><a class="markdownIt-Anchor" href="#how-is-linear-hashing"></a> How is linear hashing?</h3><ol><li>It is similar to extensible hashing. But the hash table maintains a pointer that tracks the next bucket to split.</li><li>When any bucket overflows, split the bucket at the pointer location.<ul><li>When the split causing the number of slots in hash table doubled, it introduces a new hash function taking modulo with the new hash table size.</li></ul></li><li>It uses multiple hashes to find the right bucket for a given key.<ul><li>It always first use the old hash function with smaller modulus.</li><li>If this hash value is smaller than the split pointer, which means that this slot has already been splitted, DBMS need to use the new hash function to find the true hash value.</li><li>Otherwise, this slot is not splitted and the old hash value works fine.</li></ul></li><li>Splitting buckets based on the split pointer will eventually get to all overflowed buckets.<ul><li>When the pointer reaches the last slot, delete the first hash function and move back to beginning.</li></ul></li><li>Deleting may cause the size of hash table to shrink when it deleted the only entry in the second half of the hash table.<ul><li>DMBS shrinks the size of hash table and deletes the new hash function.</li></ul></li></ol><h1 id="tree"><a class="markdownIt-Anchor" href="#tree"></a> Tree</h1><h2 id="table-indexes"><a class="markdownIt-Anchor" href="#table-indexes"></a> Table indexes</h2><h3 id="what-does-table-indexs-do"><a class="markdownIt-Anchor" href="#what-does-table-indexs-do"></a> What does table indexs do?</h3><ol><li>A table index is a replica of a subset of a table’s attributes that are organized and/or sorted for efficient access using those attributes.</li><li>It is used in queries to find tuples with attributes matches certain values.</li><li>The DBMS ensures that the contents of the table and the index are logically synchronized.</li><li>It is the DBMS’s job to figure out the best index(es) to use to execute each query.</li><li>There is a trade-off regarding the number of indexes to create per database, i.e. the lookup speed and synchronization overhead.<ul><li>We need extra storage overhead to store the data structure and maintenance overhead to keep synchronization.</li></ul></li></ol><h3 id="what-is-clustered-indexes"><a class="markdownIt-Anchor" href="#what-is-clustered-indexes"></a> What is clustered indexes?</h3><ol><li>The table is stored in the sort order specified by the primary key.<ul><li>It can be either heap- or index-organized storage.</li></ul></li><li>Some DBMSs always use a clustered index. If a table does not contain a primary key, the DBMS will<br />automatically make a hidden primary key.</li><li>Other DBMSs cannot use them at all.</li></ol><h2 id="basic-b-tree"><a class="markdownIt-Anchor" href="#basic-b-tree"></a> Basic B+ Tree</h2><h3 id="what-is-a-b-tree"><a class="markdownIt-Anchor" href="#what-is-a-b-tree"></a> What is a B+ Tree?</h3><ol><li>A B+Tree is a self-balancing tree data structure that keeps data sorted and allows searches, sequential access, insertions, and deletions always in <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>O</mi><mo stretchy="false">(</mo><mi>log</mi><mo>⁡</mo><mi>n</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">O(\log n)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">O</span><span class="mopen">(</span><span class="mop">lo<span style="margin-right:0.01389em;">g</span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal">n</span><span class="mclose">)</span></span></span></span>.</li><li>A B+Tree is an M-way search tree.<ul><li>It is perfectly balanced, i.e. every leaf node is at the same depth in the tree.</li><li>Every node other than the root is at least half-full, i.e. <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>M</mi><mi mathvariant="normal">/</mi><mn>2</mn><mo>−</mo><mn>1</mn><mo>≤</mo><mi>n</mi><mi>u</mi><mi>m</mi><mi>b</mi><mi>e</mi><mi>r</mi><mtext> </mtext><mi>o</mi><mi>f</mi><mtext> </mtext><mi>k</mi><mi>e</mi><mi>y</mi><mi>s</mi><mo>≤</mo><mi>M</mi><mo>−</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">M/2-1 ≤ number\ of\ keys ≤ M-1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">M</span><span class="mord">/</span><span class="mord">2</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.78041em;vertical-align:-0.13597em;"></span><span class="mord">1</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">≤</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord mathnormal">n</span><span class="mord mathnormal">u</span><span class="mord mathnormal">m</span><span class="mord mathnormal">b</span><span class="mord mathnormal">e</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mspace"> </span><span class="mord mathnormal">o</span><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="mspace"> </span><span class="mord mathnormal" style="margin-right:0.03148em;">k</span><span class="mord mathnormal">e</span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="mord mathnormal">s</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">≤</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.76666em;vertical-align:-0.08333em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">M</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">1</span></span></span></span>.</li><li>Every inner node with <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi></mrow><annotation encoding="application/x-tex">k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.03148em;">k</span></span></span></span> keys has <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi><mo>+</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">k+1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.77777em;vertical-align:-0.08333em;"></span><span class="mord mathnormal" style="margin-right:0.03148em;">k</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">1</span></span></span></span> non-null children.</li></ul></li></ol><h3 id="how-is-keyvalue-pairs-stored-in-each-node"><a class="markdownIt-Anchor" href="#how-is-keyvalue-pairs-stored-in-each-node"></a> How is key/value pairs stored in each node?</h3><ol><li>Every B+Tree node is comprised of an array of key/value pairs.</li><li>The keys are derived from the attribute(s) that the index is based on.</li><li>The value stored in a inner node is a pointer to its corresponding children while the value stored in a leaf node is its specific value.</li><li>There are two storage methods for the key-value pair.<ul><li>One is to store them consecutively, i.e. each value is stored immediately after its key.</li><li>The other is to store them in the same place in two arrays, i.e. each value has the same index as its key.</li></ul></li><li>The arrays are (usually) kept in sorted key order.</li></ol><h3 id="what-is-stored-is-leaf-node"><a class="markdownIt-Anchor" href="#what-is-stored-is-leaf-node"></a> What is stored is leaf node?</h3><ol><li><p>Each leaf node also has pointers points to its siblings.</p></li><li><p>There are two approaches to store the values:</p><ul><li>The first approach is to store them with record IDs which is a pointer to the page ID and offset of the tuple to which the index entry corresponds.</li><li>The second approach is to store them with tuple data, specifically primary keys.</li></ul></li><li><p>The pros of the second approach is that we do not need to access another address to fetch the contents when primary keys are all we want.</p><p>But seondary indexs must store the Record ID as their values. Hence if we want secondary indexs in second approach, we need to lookup another tables to find the Record ID with the same primary keys.</p></li></ol><h3 id="what-is-the-pros-and-cons-of-b-tree-compare-with-btree"><a class="markdownIt-Anchor" href="#what-is-the-pros-and-cons-of-b-tree-compare-with-btree"></a> What is the pros and cons of B-Tree compare with B+Tree?</h3><ol><li>The main difference is that  B-Tree stored keys and values in all nodes in the tree while B+Tree only stores values in leaf nodes. Inner nodes only guide the search process.</li><li>B-Tree is more space-efficient, since each key only appears once in the tree.</li><li>However, when we want to sequential access keys, B-Tree needs to jump between pages causing much more I/O.</li></ol><h3 id="how-does-btree-insert-a-node"><a class="markdownIt-Anchor" href="#how-does-btree-insert-a-node"></a> How does B+Tree insert a node?</h3><ol><li>Find correct leaf node L. Insert data entry into L in sorted order.</li><li>If L has enough space, then it is done.</li><li>Otherwise, split L keys into L and a new node L2. Insert index entry pointing to L2 into parent of L.<ul><li>The parent of L may need rebalance after this insertion.</li></ul></li></ol><h3 id="how-does-btree-delete-a-node"><a class="markdownIt-Anchor" href="#how-does-btree-delete-a-node"></a> How does B+Tree delete a node?</h3><ol><li>Start at root, find leaf L where entry belongs. Remove the entry.</li><li>If L is at least half-full, then it is done.</li><li>If L has only M/2-1 entries,<ul><li>First try to re-distribute, borrowing from sibling.</li><li>If re-distribution fails, merge L and sibling and delete entry (pointing to L or sibling) from parent of L.<ul><li>The parent of L may need rebalance .</li></ul></li></ul></li></ol><h2 id="btree-usage-and-design"><a class="markdownIt-Anchor" href="#btree-usage-and-design"></a> B+Tree usage and design</h2><h3 id="how-does-dbms-use-btree-in-selection-query"><a class="markdownIt-Anchor" href="#how-does-dbms-use-btree-in-selection-query"></a> How does DBMS use B+Tree in selection query?</h3><ol><li><p>When creating an index, a certain order of attributes are specified to sort the tuple.</p><ul><li><p>When <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>A</mi><mn>1</mn></msub><mo separator="true">,</mo><mo>…</mo><mo separator="true">,</mo><msub><mi>A</mi><mi>n</mi></msub></mrow><annotation encoding="application/x-tex">A_1, \dots,A_n</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8777699999999999em;vertical-align:-0.19444em;"></span><span class="mord"><span class="mord mathnormal">A</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="minner">…</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathnormal">A</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">n</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> are specified, the B+Tree will store corresponding <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi></mrow><annotation encoding="application/x-tex">n</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathnormal">n</span></span></span></span> values in as keys in each node.</p></li><li><p>When <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>a</mi><mn>1</mn></msub><mo separator="true">,</mo><mo>…</mo><mo separator="true">,</mo><msub><mi>a</mi><mi>n</mi></msub></mrow><annotation encoding="application/x-tex">a_1, \dots,a_n</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord"><span class="mord mathnormal">a</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="minner">…</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathnormal">a</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">n</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> are stored in one node, all nodes in its left sub-tree have <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>A</mi><mn>1</mn></msub><mo>≤</mo><msub><mi>a</mi><mn>1</mn></msub><mo separator="true">,</mo><mo>…</mo><mo separator="true">,</mo><msub><mi>A</mi><mi>n</mi></msub><mo>≤</mo><msub><mi>a</mi><mi>n</mi></msub></mrow><annotation encoding="application/x-tex">A_1≤a_1,\dots,A_n≤a_n</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">A</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">≤</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.8777699999999999em;vertical-align:-0.19444em;"></span><span class="mord"><span class="mord mathnormal">a</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="minner">…</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathnormal">A</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">n</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">≤</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">a</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">n</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> while all nodes in its right sub-tree only guarenteed with <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>A</mi><mn>1</mn></msub><mo>&gt;</mo><msub><mi>a</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">A_1 &gt; a_1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">A</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">&gt;</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">a</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>, i.e. the B+Tree is maintained with <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>A</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">A_1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">A</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> as its primary sorting key.</p></li></ul></li><li><p>In a selection condition, we can easily select with certain condition on <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>A</mi><mn>1</mn></msub><mo separator="true">,</mo><mo>…</mo><mo separator="true">,</mo><msub><mi>A</mi><mi>k</mi></msub><mtext> </mtext><mo stretchy="false">(</mo><mi>k</mi><mo>≤</mo><mi>n</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">A_1,\dots,A_k\ (k≤n)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathnormal">A</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="minner">…</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathnormal">A</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace"> </span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.03148em;">k</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">≤</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">n</span><span class="mclose">)</span></span></span></span>. Some DBMS also support conditions specified only on <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>A</mi><mi>k</mi></msub><mo separator="true">,</mo><mo>…</mo><mo separator="true">,</mo><msub><mi>A</mi><mi>n</mi></msub></mrow><annotation encoding="application/x-tex">A_k, \dots,A_n</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8777699999999999em;vertical-align:-0.19444em;"></span><span class="mord"><span class="mord mathnormal">A</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="minner">…</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathnormal">A</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">n</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>, which requires DBMS sequentially access all leaf nodes.</p></li><li><p>Compared with hash table, B+Tree can better support selection without a knowing attributes to lookup for.</p></li></ol><h3 id="how-to-handle-duplicate-keys"><a class="markdownIt-Anchor" href="#how-to-handle-duplicate-keys"></a> How to handle duplicate keys?</h3><ol><li>The first approach is to add the tuple’s unique Record ID as part of the key to ensure that all keys are unique.<ul><li>The DBMS can still use partial keys to find tuples.</li></ul></li><li>The second approach is to allow leaf nodes to spill into overflow nodes that contain the duplicate keys.<ul><li>Only duplicate keys of existing keys can overflow.</li><li>When split or merge nodes, overflow nodes also need to split or merge.</li><li>This is more complex to maintain and modify.</li></ul></li></ol><h3 id="how-to-solve-redundant-page-jump-when-sequential-access-leaf-nodes"><a class="markdownIt-Anchor" href="#how-to-solve-redundant-page-jump-when-sequential-access-leaf-nodes"></a> How to solve redundant page jump when sequential access leaf nodes?</h3><ol><li>In a clustered B+Tree, nodes in the same page are in consecutive order.<ul><li>We can traverse to the left-most leaf page and then retrieve tuples from all leaf pages.</li><li>This will always be better than sorting data for each query.</li></ul></li><li>In a non-clustered B+Tree, the DBMS can first figure out all the tuples that it needs and then sort them based on their Page ID.</li></ol><h3 id="how-to-choose-node-size"><a class="markdownIt-Anchor" href="#how-to-choose-node-size"></a> How to choose node size?</h3><ol><li>The slower the storage device, the larger the optimal node size for a B+Tree.<ul><li>HDD takes <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1</mn><mtext> </mtext><mi>M</mi><mi>B</mi></mrow><annotation encoding="application/x-tex">1\ MB</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord">1</span><span class="mspace"> </span><span class="mord mathnormal" style="margin-right:0.10903em;">M</span><span class="mord mathnormal" style="margin-right:0.05017em;">B</span></span></span></span>, SSD usually takes <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>10</mn><mtext> </mtext><mi>K</mi><mi>B</mi></mrow><annotation encoding="application/x-tex">10\ KB</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord">1</span><span class="mord">0</span><span class="mspace"> </span><span class="mord mathnormal" style="margin-right:0.07153em;">K</span><span class="mord mathnormal" style="margin-right:0.05017em;">B</span></span></span></span>, in-memory nodes have <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>512</mn><mtext> </mtext><mi>B</mi></mrow><annotation encoding="application/x-tex">512\ B</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord">5</span><span class="mord">1</span><span class="mord">2</span><span class="mspace"> </span><span class="mord mathnormal" style="margin-right:0.05017em;">B</span></span></span></span>.</li></ul></li><li>Optimal sizes can vary depending on the workload. The trade off is between leaf node scans and root-to-leaf traversals.<ul><li>With larger size, we can have more sequential reads in leaf node scans, but we need to read more data in root-to-leaf traversals.</li></ul></li></ol><h3 id="how-to-choose-merge-threshold"><a class="markdownIt-Anchor" href="#how-to-choose-merge-threshold"></a> How to choose merge threshold?</h3><ol><li>Some DBMSs do not always merge nodes when they are half full.</li><li>Delaying a merge operation may reduce the amount of reorganization. They assume that the missing part will be filled soon.</li><li>It may also be better to just let smaller nodes exist and then periodically rebuild entire tree.</li></ol><h3 id="how-to-handle-variable-length-keys"><a class="markdownIt-Anchor" href="#how-to-handle-variable-length-keys"></a> How to handle variable length keys?</h3><ol><li>The first approach is to store the keys as pointers to the tuple’s attribute.</li><li>The second approach is to allow variable-length nodes. It requires careful memory management.</li><li>The third approach is always to pad the key to be max length of the key type.</li><li>The last approach is key map or indirection. It is similar to the in-node dictionary.</li></ol><h3 id="how-can-we-do-the-intra-node-search"><a class="markdownIt-Anchor" href="#how-can-we-do-the-intra-node-search"></a> How can we do the intra-node search?</h3><ol><li>The naive method is linear search. We can use SIMD to vectorize the process.</li><li>The second method is binary search given that keys in a node are already sorted.</li><li>The third method is interpolation search.<ul><li>This requires known distribution of keys.</li><li>It jumps to approximate location of desired key based on known distribution.</li></ul></li></ol><h3 id="how-can-we-optimize-space-usage"><a class="markdownIt-Anchor" href="#how-can-we-optimize-space-usage"></a> How can we optimize space usage?</h3><ol><li>Prefix compression<ul><li>Sorted keys in the same leaf node are likely to have the same prefix.</li><li>Extract common prefix and store only unique suffix for each key.</li></ul></li><li>Deduplication<ul><li>Non-unique indexes can end up storing multiple copies of the same key in leaf nodes.</li><li>Store the key once and then maintain a list of tuples with that key.</li></ul></li><li>Suffix truncation<ul><li>The keys in the inner nodes are only used to “direct traffic”. We don’t need the entire key.</li><li>Store a minimum prefix that is needed to correctly route probes into the index.</li></ul></li></ol><h3 id="how-can-we-optimize-consumed-time"><a class="markdownIt-Anchor" href="#how-can-we-optimize-consumed-time"></a> How can we optimize consumed time?</h3><ol><li>Pointer swizzling<ul><li>Nodes use page ids to reference other nodes in the index. The DBMS must get the memory location from the page table during traversal.</li><li>If a page is pinned in the buffer pool, then we can store raw pointers instead of page IDs. This avoids address lookups from the page table.</li></ul></li><li>Bulk insert<ul><li>The fastest way to build a new B+Tree for an existing table is to first sort the keys and then build the index from the bottom up.</li></ul></li></ol>]]></content>
      
      
      <categories>
          
          <category> Open Courses </category>
          
          <category> CMU 15-445/645 Database System </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Database System </tag>
            
            <tag> Data Structure </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>03 Buffer Pool Manage</title>
      <link href="/2023/06/24/Courses/15445/03-Buffer-Pool-Manage/"/>
      <url>/2023/06/24/Courses/15445/03-Buffer-Pool-Manage/</url>
      
        <content type="html"><![CDATA[<p><ul class="markdownIt-TOC"><li><a href="#buffer-pool-manage">Buffer pool manage</a><ul><li><a href="#what-does-databse-storage-need-to-control">What does databse storage need to control?</a></li><li><a href="#how-is-buffer-pool-organized">How is buffer pool organized?</a></li><li><a href="#clarification-what-is-the-locks-and-latches-referenced-in-database">Clarification: What is the locks and latches referenced in database?</a></li><li><a href="#how-can-we-optimize-performance-with-multiple-buffer-pools">How can we optimize performance with multiple buffer pools?</a></li><li><a href="#how-can-we-optimize-performance-with-pre-fetching">How can we optimize performance with pre-fetching?</a></li><li><a href="#how-can-we-optimize-performance-with-scan-sharing">How can we optimize performance with scan sharing?</a></li><li><a href="#how-can-we-optimize-performance-with-buffer-pool-bypass">How can we optimize performance with buffer pool bypass?</a></li><li><a href="#should-we-use-os-page-cache">Should we use OS page cache?</a></li></ul></li><li><a href="#buffer-replacement-policies">Buffer replacement policies</a><ul><li><a href="#what-is-lru-least-recently-used-policy-and-clock-policy">What is LRU (Least-Recently Used) policy and clock policy?</a></li><li><a href="#what-is-the-problem-of-lru-and-clock-how-to-alleviate">What is the problem of LRU and clock, how to alleviate?</a></li><li><a href="#how-do-we-deal-with-evicted-pages">How do we deal with evicted pages?</a></li></ul></li></ul></p><h1 id="buffer-pool-manage"><a class="markdownIt-Anchor" href="#buffer-pool-manage"></a> Buffer pool manage</h1><h2 id="what-does-databse-storage-need-to-control"><a class="markdownIt-Anchor" href="#what-does-databse-storage-need-to-control"></a> What does databse storage need to control?</h2><ol><li>Spatial Control: Where to write pages on disk.<ul><li>The goal is to keep pages that are used together often as physically close together as possible on disk.</li></ul></li><li>Temporal Control: When to read pages into memory, and when to write them to disk.<ul><li>The goal is to minimize the number of stalls from having to read data from disk.</li></ul></li></ol><h2 id="how-is-buffer-pool-organized"><a class="markdownIt-Anchor" href="#how-is-buffer-pool-organized"></a> How is buffer pool organized?</h2><ol><li>Memory region organized as an array of fixed-size pages. An array entry is called a <strong>frame</strong>.<ul><li>Pages are in disk while frames are in memory.</li></ul></li><li>When the DBMS requests a page, an exact copy is placed into one of these frames.</li><li>The buffer pool manager need to maintain a <strong>page table</strong> to keep track of pages that are currently in memory.<ul><li>The page table is the mapping from page ids to a copy of the page in buffer pool frames.<ul><li>This is an in-memory data structure that does not need to be stored on disk.</li></ul></li><li>The page directory is the mapping from page ids to page locations in the database files.<ul><li>All changes must be recorded on disk to allow the DBMS to find on restart.</li></ul></li></ul></li><li>Some additional meta-data per page also need to be maintained:<ul><li><strong>Dirty flag</strong>: Mark whether a page has been modified. Used to know whether can safely evict this page.</li><li><strong>Pin/reference counter</strong>: Some query use it to prevent buffer pool manager from evicting this page. They unpin this page after no-longer use it.</li><li><strong>Latches</strong>: Can be used to pre-occupy an entry in page table, and release the latch after copied that page and updated the entry.</li><li>These meta-data can either be stored in page or page table.</li></ul></li></ol><h2 id="clarification-what-is-the-locks-and-latches-referenced-in-database"><a class="markdownIt-Anchor" href="#clarification-what-is-the-locks-and-latches-referenced-in-database"></a> Clarification: What is the locks and latches referenced in database?</h2><ol><li>Locks:<ul><li>It protects the database’s logical contents from other transactions.</li><li>It is held for transaction duration. Need to be able to rollback changes.</li><li>Locks can be taken on a tuple or table, but not on a page.</li></ul></li><li>Latches:<ul><li>It protects the critical sections of the DBMS’s internal data structure from other threads.</li><li>It is held for operation duration. Do not need to be able to rollback changes.</li><li>This is similar to the mutex provided by OS.</li></ul></li></ol><h2 id="how-can-we-optimize-performance-with-multiple-buffer-pools"><a class="markdownIt-Anchor" href="#how-can-we-optimize-performance-with-multiple-buffer-pools"></a> How can we optimize performance with multiple buffer pools?</h2><ol><li>Advantages:<ul><li>Different pool can have different evict policy to improve locality.</li><li>Each time accessing meta-data of each buffer pool need to take a latch. Multiple buffer pool can reduce latch contention.</li></ul></li><li>The manager can use per-database buffer pool, per-page type buffer pool or per-index type buffer pool.</li><li>Manger decide which pool to store pages in two approaches:<ul><li>The first is to embed an object identifier in record ids and then maintain a mapping from objects to specific buffer pools.<ul><li>This can be used to specify certain pages must be stored in specific pool.</li></ul></li><li>The other is to hash the page id to select which buffer pool to access.</li></ul></li></ol><h2 id="how-can-we-optimize-performance-with-pre-fetching"><a class="markdownIt-Anchor" href="#how-can-we-optimize-performance-with-pre-fetching"></a> How can we optimize performance with pre-fetching?</h2><ol><li>Pre-fetching can be easily used in two situations: sequential scans and index scans.</li><li>In sequential scans, when manager fetched the first few consecutive pages, it can infer that the next consecutive pages will be used soon and pre-fetch them into memory.</li><li>In index scans, the query may not access consecutive pages, but DBMS sees the B+ tree structure, and thus knows the where are the following indices.</li></ol><h2 id="how-can-we-optimize-performance-with-scan-sharing"><a class="markdownIt-Anchor" href="#how-can-we-optimize-performance-with-scan-sharing"></a> How can we optimize performance with scan sharing?</h2><ol><li>It allows multiple queries to attach to a single cursor that scans a table.<ul><li>The queries do not have to be the same.</li><li>They can also share intermediate results.</li></ul></li><li>If a query wants to scan a table and another query is already doing this, then the DBMS will attach the second query’s cursor to the existing cursor.</li><li>After the ealier query finished, the later query will return to read the pages the earlier one already read before the later one begins.</li><li>If the later query has a <code>LIMIT</code> clause with out <code>WHERE</code> or <code>ORDER BY</code> clause, given that the relation is unordered, it may do not need to read extra data if those scan sharing data is enough to satisfy the <code>LIMIT</code> clause.</li></ol><h2 id="how-can-we-optimize-performance-with-buffer-pool-bypass"><a class="markdownIt-Anchor" href="#how-can-we-optimize-performance-with-buffer-pool-bypass"></a> How can we optimize performance with buffer pool bypass?</h2><ol><li>Sequential flooding: A query performs a sequential scan that reads every page.<ul><li>This pollutes the buffer pool with pages that are read once and then never again.</li></ul></li><li>Buffer pool bypass will not store fetched pages in the buffer pool. Insteach, the manager has a private pool where those pages will be stored temporarily and deleted once finished.</li><li>It works well if operator needs to read a large sequence of pages that are contiguous on disk. It can also be used for temporary data (sorting, joins).</li></ol><h2 id="should-we-use-os-page-cache"><a class="markdownIt-Anchor" href="#should-we-use-os-page-cache"></a> Should we use OS page cache?</h2><ol><li>Most disk operations go through the OS API. Unless the DBMS tells it not to, the OS maintains its own filesystem cache.</li><li>Most DBMSs use direct I/O (<code>O_DIRECT</code>) to bypass the OS’s cache.</li><li>The OS page cache can cause redundant copies of pages. OS and DBMS have different eviction policies causing DBMS Loss of control over file I/O.</li></ol><h1 id="buffer-replacement-policies"><a class="markdownIt-Anchor" href="#buffer-replacement-policies"></a> Buffer replacement policies</h1><h2 id="what-is-lru-least-recently-used-policy-and-clock-policy"><a class="markdownIt-Anchor" href="#what-is-lru-least-recently-used-policy-and-clock-policy"></a> What is LRU (Least-Recently Used) policy and clock policy?</h2><ol><li>Manager maintain a single timestamp of when each page was last accessed.</li><li>When the DBMS needs to evict a page, select the one with the oldest timestamp.<ul><li>It can keep the pages in sorted order to reduce the search time on eviction.</li></ul></li><li>An approximation of LRU that does not need a separate timestamp per page is clock policy.<ul><li>Each page has a reference bit. When a page is accessed, set to <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1</mn></mrow><annotation encoding="application/x-tex">1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">1</span></span></span></span>.</li><li>Organize the pages in a circular buffer with a “clock hand”: Upon sweeping, check if a page’s bit is set<br />to 1. If yes, set to zero. If no, then evict.</li></ul></li></ol><h2 id="what-is-the-problem-of-lru-and-clock-how-to-alleviate"><a class="markdownIt-Anchor" href="#what-is-the-problem-of-lru-and-clock-how-to-alleviate"></a> What is the problem of LRU and clock, how to alleviate?</h2><ol><li>LRU and CLOCK replacement policies are susceptible to sequential flooding. And in some workloads the most recently used page is the most unneeded page.</li><li><strong>LRU-K</strong> policy can alleviate the problem.<ul><li>Track the history of last K references to each page as timestamps and compute the average interval between subsequent accesses. And evict the one that will be accessed latest according to the prediction.</li><li>In the implementation, the manager only need to maintain a queue of size K. Pop out the oldest timestamp when a new timestamp arrives.</li></ul></li><li>Another policy is <strong>localization</strong>: The DBMS chooses which pages to evict on a per transaction/query basis, e.g. it allocate private frames to the query.</li><li><strong>Priority hints</strong>: The DBMS knows about the context of each page during query execution. It can provide hints to the buffer pool on whether a page is important or not.</li></ol><h2 id="how-do-we-deal-with-evicted-pages"><a class="markdownIt-Anchor" href="#how-do-we-deal-with-evicted-pages"></a> How do we deal with evicted pages?</h2><ol><li>Fast Path: If a page in the buffer pool is not dirty, then the DBMS can simply drop it.</li><li>Slow Path: If a page is dirty, then the DBMS must write back to disk to ensure that its changes are persisted.<ul><li>The DBMS can periodically walk through the page table and write dirty pages to disk.</li><li>When a dirty page is safely written, the DBMS can either evict the page or just unset the dirty flag.</li><li>Need to be careful that the system doesn’t write dirty pages before their log records are written.</li></ul></li><li>The Trade-off is between fast evictions versus dirty writing pages that will not be read again in the future.</li></ol>]]></content>
      
      
      <categories>
          
          <category> Open Courses </category>
          
          <category> CMU 15-445/645 Database System </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Database System </tag>
            
            <tag> Storage </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>02 Storage</title>
      <link href="/2023/06/24/Courses/15445/02-Storage/"/>
      <url>/2023/06/24/Courses/15445/02-Storage/</url>
      
        <content type="html"><![CDATA[<p><ul class="markdownIt-TOC"><li><a href="#disk-based-architecture">Disk-based architecture</a><ul><li><a href="#what-are-the-storage-devices">What are the storage devices?</a></li><li><a href="#what-is-disk-oriented-dmbs">What is disk-oriented DMBS?</a></li><li><a href="#why-not-use-the-os-memory-mapping-virtual-memory">Why not use the OS memory mapping (virtual memory)?</a></li></ul></li><li><a href="#page-oriented-architecture">Page-oriented architecture</a><ul><li><a href="#file-storage">File storage</a><ul><li><a href="#how-does-dbms-store-files">How does DBMS store files?</a></li><li><a href="#how-does-dbms-manage-pages-in-files-on-disk">How does DBMS manage pages in files on disk?</a></li></ul></li><li><a href="#page-layout">Page layout</a><ul><li><a href="#what-is-stored-in-each-page">What is stored in each page?</a></li><li><a href="#how-to-organize-tuple-oriented-data">How to organize tuple-oriented data?</a></li><li><a href="#how-do-we-find-the-tuple-we-need-in-a-page">How do we find the tuple we need in a page?</a></li></ul></li><li><a href="#tuple-layout">Tuple layout</a><ul><li><a href="#what-is-stored-in-a-tuple">What is stored in a tuple?</a></li><li><a href="#what-is-denormalized-data">What is denormalized data?</a></li></ul></li></ul></li><li><a href="#log-structured-storage">Log-structured storage</a><ul><li><a href="#what-is-stored-in-log-structured-storage">What is stored in log-structured storage?</a></li><li><a href="#how-to-read-in-a-log-structured-storage">How to read in a log-structured storage?</a></li><li><a href="#how-to-solve-that-the-log-will-become-larger-and-larger">How to solve that the log will become larger and larger?</a></li></ul></li><li><a href="#tuple-storage">Tuple storage</a><ul><li><a href="#how-to-store-data-in-a-tuple">How to store data in a tuple?</a></li><li><a href="#what-are-supported-data-types">What are supported data types?</a></li></ul></li><li><a href="#data-storage-models">Data storage models</a><ul><li><a href="#what-kind-of-database-workloads-are-there">What kind of database workloads are there?</a></li><li><a href="#how-does-dbms-store-tuples">How does DBMS store tuples?</a></li><li><a href="#database-compression">Database compression</a><ul><li><a href="#why-do-we-need-database-compression-and-what-is-the-trade-off">Why do we need database compression and what is the trade-off?</a></li><li><a href="#why-can-we-compress-data">Why can we compress data?</a></li><li><a href="#what-is-the-goals-of-compression">What is the goals of compression?</a></li><li><a href="#what-are-the-compression-granularities">What are the compression granularities?</a></li><li><a href="#what-is-the-naive-compression">What is the naive compression?</a></li><li><a href="#how-can-we-do-better-with-the-high-level-meaning-or-semantics-of-the-data">How can we do better with the high-level meaning or semantics of the data?</a></li></ul></li></ul></li></ul></p><h1 id="disk-based-architecture"><a class="markdownIt-Anchor" href="#disk-based-architecture"></a> Disk-based architecture</h1><h2 id="what-are-the-storage-devices"><a class="markdownIt-Anchor" href="#what-are-the-storage-devices"></a> What are the storage devices?</h2><ol><li>The first type is the volatile memory: CPU registers, CPU caches and DRAM<ul><li>They provide random access and they are byte-addressable.</li></ul></li><li>The second type is the non-volatile disks: SSD, HDD and network storage.<ul><li>They only provide sequential access.<ul><li>Random access on non-volatile storage is almost always much slower than sequential access.</li><li>DBMS will want to maximize sequential access.</li></ul></li><li>They are block-addressable.</li></ul></li><li>The access times of each storage is as followed:<br /><img src="/imgs/15445/Storage/access_times.png" width="50%"></li></ol><h2 id="what-is-disk-oriented-dmbs"><a class="markdownIt-Anchor" href="#what-is-disk-oriented-dmbs"></a> What is disk-oriented DMBS?</h2><ol><li>The DBMS assumes that the primary storage location of the database is on non-volatile disk.</li><li>DBMS manages a buffer pool in memory where directory and data pages are stored.</li><li>When execution engine asks DBMS for a certain page:<ul><li>If that page is not in memory already, DBMS will look up directory first (if also not in memory, load from disk) to find the disk position of that page.</li><li>Then DBMS will load that page from disk and return a pointer to the buffer pool to execution engine.</li></ul></li></ol><h2 id="why-not-use-the-os-memory-mapping-virtual-memory"><a class="markdownIt-Anchor" href="#why-not-use-the-os-memory-mapping-virtual-memory"></a> Why not use the OS memory mapping (virtual memory)?</h2><ol><li>Transaction safety: OS can flush dirty pages at any time causing dirty data corrupt database. OS doesn’t know anything about transaction, hence it doesn’t care whether it is safe to write a page to disk.</li><li>IO stalls: When a page miss happens, the thread will be stalled and DBMS can do nothing about it.<ul><li>Allowing multiple threads to access the <code>mmap</code> files to hide page fault stalls is good enough for read-only access. But it is complicated when there are multiple writers.</li></ul></li><li>Error handling: Any access can cause a <code>SIGBUS</code> that the DBMS must handle. However, DBMS may isolate the error and handle it only in the storage layer.</li><li>Performance issues: Like OS data structure contention or TLB shootdowns.</li><li>In conclusion, DBMS always knows better than OS. Thus DBMS almost always wants to control things itself and can do a better job than the OS.<ul><li>Like how to flush dirty pages to disk in the correct order, provide specialized prefetching, better buffer replacement policy and thread/process scheduling.</li></ul></li></ol><h1 id="page-oriented-architecture"><a class="markdownIt-Anchor" href="#page-oriented-architecture"></a> Page-oriented architecture</h1><h2 id="file-storage"><a class="markdownIt-Anchor" href="#file-storage"></a> File storage</h2><h3 id="how-does-dbms-store-files"><a class="markdownIt-Anchor" href="#how-does-dbms-store-files"></a> How does DBMS store files?</h3><ol><li>The DBMS stores a database as one or more files on disk typically in a proprietary format.</li><li>The storage manager is responsible for maintaining a database’s files.<ul><li>It organizes the files as a collection of pages.</li><li>It also tracks data read/written to pages and the available space.</li><li>Some do their own scheduling for reads and writes to improve spatial and temporal locality of pages.</li></ul></li><li>A database page is a fixed-size block of data.<ul><li>Most systems do not mix page types, i.e. data in a page belong to the same table.</li><li>Some systems require a page to be self-contained, i.e. all metadata we need to interpret the page has to be contained in the page in itself.</li><li>Hardware pages and OS pages are usually <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>4</mn><mtext> </mtext><mi>K</mi><mi>B</mi></mrow><annotation encoding="application/x-tex">4\ KB</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord">4</span><span class="mspace"> </span><span class="mord mathnormal" style="margin-right:0.07153em;">K</span><span class="mord mathnormal" style="margin-right:0.05017em;">B</span></span></span></span>. But database pages may be <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>512</mn><mtext> </mtext><mi>B</mi><mo>−</mo><mn>16</mn><mtext> </mtext><mi>K</mi><mi>B</mi></mrow><annotation encoding="application/x-tex">512\ B-16\ KB</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.76666em;vertical-align:-0.08333em;"></span><span class="mord">5</span><span class="mord">1</span><span class="mord">2</span><span class="mspace"> </span><span class="mord mathnormal" style="margin-right:0.05017em;">B</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord">1</span><span class="mord">6</span><span class="mspace"> </span><span class="mord mathnormal" style="margin-right:0.07153em;">K</span><span class="mord mathnormal" style="margin-right:0.05017em;">B</span></span></span></span> depending on DBMS and configuration.<ul><li>Larger page size can increase sequential IO, issue less system call and have a smaller page table.</li><li>Smaller page size only need to maintain less memory when only need small amout of data.</li></ul></li></ul></li></ol><h3 id="how-does-dbms-manage-pages-in-files-on-disk"><a class="markdownIt-Anchor" href="#how-does-dbms-manage-pages-in-files-on-disk"></a> How does DBMS manage pages in files on disk?</h3><ol><li>There are different ways to manage: Heap File Organization, Tree File Organization, Sequential / Sorted File Organization (ISAM), or Hashing File Organization.</li><li>A heap file is an unordered collection of pages with tuples that are stored in random order.</li><li>The DBMS maintains directory in special pages that tracks the location of data pages in the database files.<ul><li>Must make sure that the directory pages are in sync with the data pages.</li><li>The directory also records meta-data about available space: the number of free slots per page and list of free / empty pages.</li></ul></li></ol><h2 id="page-layout"><a class="markdownIt-Anchor" href="#page-layout"></a> Page layout</h2><h3 id="what-is-stored-in-each-page"><a class="markdownIt-Anchor" href="#what-is-stored-in-each-page"></a> What is stored in each page?</h3><ol><li>Every page contains a header of meta-data about the page’s contents.<ul><li>Page Size</li><li>Checksum to check whether data is corrupted</li><li>DBMS version of creator of this page, to provide compatibility even when DBMS update changed the page layout. With this, when DBMS is updated, it can correct re-layout the data.</li><li>Transaction Visibility</li><li>Compression Information</li></ul></li><li>The data in a page can be organize in tuple-oriented or log-structured.</li></ol><h3 id="how-to-organize-tuple-oriented-data"><a class="markdownIt-Anchor" href="#how-to-organize-tuple-oriented-data"></a> How to organize tuple-oriented data?</h3><ol><li>A naive strategy is to store the number of tuples in the header, and just append a new tuple to the end.<ul><li>What if we delete a tuple?<ul><li>How do we know there are available space?</li><li>What do we do to the following tuples? Do we move them forward, or just leave them there?</li></ul></li><li>More serious problem is what happens if we have a variable-length attribute?<ul><li>How can we know the begin and end of a tuple?</li></ul></li></ul></li><li>In the slotted pages scheme, we store a <strong>slot array</strong> at the header.<ul><li>The slot array maps “slots” to the tuples’ starting position offsets.</li><li>The header keeps track of the number of used slots and the offset of the starting location of the last slot used.</li><li>The space used to store tuples grows from tail to head, while the slot array grows from head to tail.</li><li>When a tuple is deleted, we need to invalidate its value in slot array where we can know available space.<ul><li>As for its following tuples, we can either leave them as be, or compact the space.</li><li>As modification goes in memory, and deleting is usually holding a lock, compact the space can be fast and there is no need to inform rest of the system.</li></ul></li><li><img src="/imgs/15445/Storage/slot-array.png" width="25%"></li></ul></li></ol><h3 id="how-do-we-find-the-tuple-we-need-in-a-page"><a class="markdownIt-Anchor" href="#how-do-we-find-the-tuple-we-need-in-a-page"></a> How do we find the tuple we need in a page?</h3><ol><li>Each tuple is assigned a unique record identifier.</li><li>Most commonly used is <code>page_id + offset/slot</code>.</li></ol><h2 id="tuple-layout"><a class="markdownIt-Anchor" href="#tuple-layout"></a> Tuple layout</h2><h3 id="what-is-stored-in-a-tuple"><a class="markdownIt-Anchor" href="#what-is-stored-in-a-tuple"></a> What is stored in a tuple?</h3><ol><li>A tuple is essentially a sequence of bytes. It’s the job of the DBMS to interpret those bytes into attribute types and values.</li><li>Each tuple is prefixed with a header that contains meta-data about it, e.g visibility info for concurrency control, Bit Map for NULL values.<ul><li>We do not need to store meta-data about the schema.</li></ul></li><li>Attributes are typically stored in the order that you specify them when you create the table.</li></ol><h3 id="what-is-denormalized-data"><a class="markdownIt-Anchor" href="#what-is-denormalized-data"></a> What is denormalized data?</h3><ol><li>DBMS can physically denormalize (pre-join) related tuples and store them together in the same page.<ul><li>For two tables, one table has an attribute referenced to another table, DBMS can store the tuples and thier referenced tuples in the same slot.</li><li><img src="/imgs/15445/Storage/denorm_declare.png" width="25%"></li><li><img src="/imgs/15445/Storage/denorm_diagram.png" width="25%"></li></ul></li><li>This can potentially reduces the amount of I/O for common workload patterns but also make updates more expensive.</li></ol><h1 id="log-structured-storage"><a class="markdownIt-Anchor" href="#log-structured-storage"></a> Log-structured storage</h1><h2 id="what-is-stored-in-log-structured-storage"><a class="markdownIt-Anchor" href="#what-is-stored-in-log-structured-storage"></a> What is stored in log-structured storage?</h2><ol><li>DBMS stores log records that contain changes to tuples (PUT, DELETE).<ul><li>Each log record must contain the tuple’s unique identifier. In this case, the identifier is not <code>page_id + offset/slot</code> metioned above since page doesn’t exists in this scheme.</li></ul></li><li>As the application makes changes to the database, the DBMS appends log records to the end of the file without checking previous log records.</li><li>When the page gets full, the DBMS writes it out disk and starts filling up the next page with records.<ul><li>All on-disk pages are immutable.</li><li>All disk writes are sequential.</li></ul></li></ol><h2 id="how-to-read-in-a-log-structured-storage"><a class="markdownIt-Anchor" href="#how-to-read-in-a-log-structured-storage"></a> How to read in a log-structured storage?</h2><ol><li>To read a tuple with a given id, the DBMS finds the newest log record corresponding to that id. It needs to scan log from newest to oldest.<ul><li>To optimize the linear scan, DBMS can maintain an index that maps a tuple id to the newest log record.</li></ul></li><li>If log record is in-memory, just read it. If log record is on a disk page, retrieve it.</li></ol><h2 id="how-to-solve-that-the-log-will-become-larger-and-larger"><a class="markdownIt-Anchor" href="#how-to-solve-that-the-log-will-become-larger-and-larger"></a> How to solve that the log will become larger and larger?</h2><ol><li>The DBMS can periodically compact pages to reduce wasted space.<ul><li>It can take two continuous pages and scan from newest to oldest leaving one newest log for each tuple.</li></ul></li><li>The DBMS can sort the page based on id order to improve efficiency of future look-ups.<ul><li>This sorted table is called <strong>Sorted String Tables</strong>, <strong>SSTables</strong>.</li><li>After a page is compacted, the DBMS does need to maintain temporal ordering of records within the page since each tuple id is guaranteed to appear at most once in the page.</li></ul></li><li>There are two strategy to choose which pages to compact:<ul><li>The Universal compaction chooses any two continuous pages.</li><li>The level compaction chooses two continuous pages in the same level, and compacts them into next level.</li></ul></li><li>The downsides of compaction is write-amplification caused by duplicate writing to the newest record of a tuple, and also compacting itself is expensive.</li></ol><h1 id="tuple-storage"><a class="markdownIt-Anchor" href="#tuple-storage"></a> Tuple storage</h1><h2 id="how-to-store-data-in-a-tuple"><a class="markdownIt-Anchor" href="#how-to-store-data-in-a-tuple"></a> How to store data in a tuple?</h2><ol><li>A tuple is essentially a sequence of bytes. It’s the job of the DBMS to interpret those bytes into attribute types and values.</li><li>The DBMS’s catalogs contain the schema information about tables that the system uses to figure out the tuple’s layout.<ul><li>A DBMS stores meta-data about databases in its internal catalogs.<ul><li>Tables, columns, indexes, views</li><li>Users, permissions</li><li>Internal statistics</li></ul></li></ul></li></ol><h2 id="what-are-supported-data-types"><a class="markdownIt-Anchor" href="#what-are-supported-data-types"></a> What are supported data types?</h2><ol><li>The basic types are supported: <code>INTEGER</code>/<code>BIGINT</code>/<code>SMALLINT</code>/<code>TINYINT</code>, <code>FLOAT</code>/<code>REAL</code>, <code>VARCHAR</code>/<code>VARBINARY</code>/<code>TEXT</code>/<code>BLOB</code>, <code>TIME</code>/<code>DATE</code>/<code>TIMESTAMP</code>.</li><li>Since IEEE 754 floating points may be inaccurate, fixed-point decimals are also supported as <code>NUMERIC</code>/<code>DECIMAL</code>. But their execution is way slower than floating points.</li><li>Most DBMSs don’t allow a tuple to exceed the size of a single page.<ul><li>To store values that are larger than a page, the DBMS uses separate <strong>overflow</strong> storage pages.</li><li>Some systems allow you to store a really large value in an external file. And treat the data as a BLOB type. Then the DBMS cannot manipulate the contents of an external file.<ul><li>No durability protections. No transaaction protections.</li><li>They are outside of DBMS, hence we cannot update it through DBMS either.</li></ul></li></ul></li></ol><h1 id="data-storage-models"><a class="markdownIt-Anchor" href="#data-storage-models"></a> Data storage models</h1><h2 id="what-kind-of-database-workloads-are-there"><a class="markdownIt-Anchor" href="#what-kind-of-database-workloads-are-there"></a> What kind of database workloads are there?</h2><ol><li>On-Line Transaction Processing (OLTP): In this situation, commands are fast operations that only read/update a small amount of data each time. The data accessed in a query is related to a single entity in the database.</li><li>On-Line Analytical Processing (OLAP): Here, commands are complex queries that read a lot of data to compute aggregates, i.e. it will execute complex writes and complex reads.</li><li>Hybrid Transaction + Analytical Processing: OLTP + OLAP together on the same database instance.</li></ol><h2 id="how-does-dbms-store-tuples"><a class="markdownIt-Anchor" href="#how-does-dbms-store-tuples"></a> How does DBMS store tuples?</h2><ol><li><strong>N-ary storage model</strong> (<strong>row storage</strong>): The DBMS stores all attributes for a single tuple contiguously in a page.<ul><li>This model is ideal for OLTP workloads where queries tend to operate only on an individual entity and insert-heavy workloads.</li><li>The advantage is fast inserts, updates, and deletes. It is also good for queries that need the entire tuple.</li><li>However, it is not good for scanning large portions of the table and/or a subset of the attributes.</li></ul></li><li><strong>Decomposition storage model</strong> (<strong>DSM</strong>, <strong>Column storage</strong>): The DBMS stores the values of a single attribute for all tuples contiguously in a page.<ul><li>This model is ideal for OLAP workloads where read-only queries perform large scans over a subset of the table’s attributes.</li><li>DBMS can identify tuple in two choices:<ul><li>The first is using fixed-length offsets when each value is the same length for an attribute. It does not require each attributes to have the same length. This is the most used scheme.</li><li>The second is using embedded tuple ids. Each value is stored with its tuple id in a column.</li></ul></li><li>The advantages of DSM is that it reduces the amount wasted I/O because the DBMS only reads the data that it needs, and provides better query processing and data compression.</li><li>The disadvantage is that it is slow for point queries, inserts, updates, and deletes because of tuple splitting/stitching.</li></ul></li></ol><h2 id="database-compression"><a class="markdownIt-Anchor" href="#database-compression"></a> Database compression</h2><h3 id="why-do-we-need-database-compression-and-what-is-the-trade-off"><a class="markdownIt-Anchor" href="#why-do-we-need-database-compression-and-what-is-the-trade-off"></a> Why do we need database compression and what is the trade-off?</h3><ol><li>I/O is the main bottleneck if the DBMS fetches data from disk during query execution.</li><li>The DBMS can compress pages to increase the utility of the data moved per I/O operation.</li><li>The key trade-off is between speed and compression ratio.<ul><li>To get a better compression ratio, it will take a higher CPU costs to both compress and decompress. But it can reduces DRAM requirements.</li><li>Some engines may work with compressed data, which can reduce CPU costs.</li></ul></li></ol><h3 id="why-can-we-compress-data"><a class="markdownIt-Anchor" href="#why-can-we-compress-data"></a> Why can we compress data?</h3><ol><li>Data sets tend to have highly skewed distributions for attribute values.</li><li>Data sets tend to have high correlation between attributes of the same tuple.</li></ol><h3 id="what-is-the-goals-of-compression"><a class="markdownIt-Anchor" href="#what-is-the-goals-of-compression"></a> What is the goals of compression?</h3><ol><li>It must produce fixed-length values. The only exception is var-length data stored in separate pool.</li><li>Late materialization: Postpone decompression for as long as possible during query execution.</li><li>It must be a lossless scheme.<ul><li>When a DBMS uses compression, it is always lossless because people don’t like losing data.</li><li>Any kind of lossy compression must be performed at the application level.</li></ul></li></ol><h3 id="what-are-the-compression-granularities"><a class="markdownIt-Anchor" href="#what-are-the-compression-granularities"></a> What are the compression granularities?</h3><ol><li>Block-level: Compression is performed on a block of tuples for the same table.</li><li>Tuple-level: Compression is performed on the contents of the entire tuple (NSM-only).</li><li>Attribute-level: Compression is performed on a single attribute within one tuple (overflow). It can target multiple attributes for the same tuple.</li><li>Column-level: Compression is performed on multiple values for one or more attributes stored for multiple tuples (DSM-only).</li></ol><h3 id="what-is-the-naive-compression"><a class="markdownIt-Anchor" href="#what-is-the-naive-compression"></a> What is the naive compression?</h3><ol><li>Naive means that data system does not understand the bits after compression.</li><li>We can compress data using a general-purpose algorithm. The scope of compression is only based on the data provided as input.</li><li>In disk, each page not only stores the compressed data, also stores the modification log of this page.</li><li>When DBMS read a page into the buffer pool<ul><li>It won’t decompress until queries actually need to return the whole tuple back.</li><li>Every update will only append an entry in the mod log. Hence no need to decompress data when only updating tuples. This only thing we need to know in updating is which page this tuple is.</li><li>When mod log is full, DBMS will decompress page and apply changes.</li></ul></li></ol><h3 id="how-can-we-do-better-with-the-high-level-meaning-or-semantics-of-the-data"><a class="markdownIt-Anchor" href="#how-can-we-do-better-with-the-high-level-meaning-or-semantics-of-the-data"></a> How can we do better with the high-level meaning or semantics of the data?</h3><ol><li>This is performed on column-level.</li><li>Run-length encoding:<ul><li>Compress runs of continuous same value in a single column into triplets: <code>(value, offset, length) </code>.<ul><li><code>Value</code> is the value of the attribute.</li><li><code>Offset</code> is the start position in the column segment of the continuous save value run.</li><li><code>Length</code> is the number of elements in the run.</li></ul></li><li>It requires the columns to be sorted intelligently to maximize compression opportunities.</li></ul></li><li>Bit-packing encoding:<ul><li>When values for an attribute are always less than the value’s declared largest size, store them as smaller data type.</li><li><strong>Mostly encoding</strong> uses a special marker to indicate when a value exceeds largest size and maintains a look-up table to store them.</li></ul></li><li>Bitmap encoding:<ul><li>Store a separate bitmap for <strong>each unique value</strong> for an attribute where an offset in the vector corresponds to a tuple.</li><li>When reading, DBMS need to look into the bits in the tuple to find which bit is <code>1</code> to know which value is stored in this attribute of this tuple.</li><li>We need to store the value for each bitmap. So the total space needed is the total length of possible values and the number of bits same as the number of tuples for each value.</li></ul></li><li>Delta encoding:<ul><li>Recording the difference between this tuple and its last tuple.</li><li>Store base value in-line or in a separate look-up table.</li><li>Combine with RLE to get even better compression ratios.</li></ul></li><li>Incremental encoding:<ul><li>Delta encoding is for numbers, while incremental encoding is for string.</li><li>It stores the length of common prefixes between this tuples and its last tuple and the extra suffixes of this tuple.</li><li>When there is no common prefix, the length is <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>0</mn></mrow><annotation encoding="application/x-tex">0</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">0</span></span></span></span>. It performs better when we sorted tuples according to the strings.</li></ul></li><li>Dictionary compression (most widely used):<ul><li>Build a data structure that maps variable-length values to a smaller integer identifier. And replace those values with their corresponding identifier in the dictionary data structure.</li><li>The dictionary is required to support fast encoding , decoding and range queries.</li><li>Hash function can not be used due to key confliction and unable to provide deoding.</li><li>When the dictionary encode values in certain order (e.g. alphabetic order), the execution engine can be optimized to do some queries only access dictionary, especially for those <code>DISTINCT</code> queries.</li></ul></li></ol>]]></content>
      
      
      <categories>
          
          <category> Open Courses </category>
          
          <category> CMU 15-445/645 Database System </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Database System </tag>
            
            <tag> Storage </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>01 Relational Model</title>
      <link href="/2023/06/24/Courses/15445/01-Relational-Model/"/>
      <url>/2023/06/24/Courses/15445/01-Relational-Model/</url>
      
        <content type="html"><![CDATA[<p><ul class="markdownIt-TOC"><li><a href="#database">Database</a><ul><li><a href="#why-shouldnt-we-just-store-database-in-a-flat-file-like-csv-that-we-manage-ourselve-in-our-application-code">Why shouldn’t we just store database in a flat file like CSV that we manage ourselve in our application code?</a></li><li><a href="#what-does-dbms-and-data-models-do">What does DBMS and data models do?</a></li><li><a href="#what-kinds-of-data-models-are-there">What kinds of data models are there?</a></li><li><a href="#how-does-document-data-model-store-data">How does document data model store data?</a></li></ul></li><li><a href="#relational-model">Relational model</a><ul><li><a href="#how-are-data-stored">How are data stored?</a></li><li><a href="#what-is-primary-keys-and-foreign-keys">What is primary keys and foreign keys?</a></li><li><a href="#what-is-supported-in-relational-algebra">What is supported in relational algebra?</a></li></ul></li><li><a href="#morden-sql">Morden SQL</a><ul><li><a href="#what-is-provided-in-a-relational-language">What is provided in a relational language?</a></li><li><a href="#aggregations-and-group-by">Aggregations and Group By</a><ul><li><a href="#what-are-aggregations">What are aggregations?</a></li><li><a href="#how-to-output-other-columns-with-aggregations">How to output other columns with aggregations?</a></li></ul></li><li><a href="#what-string-operations-are-supported">What string operations are supported?</a></li><li><a href="#output">Output</a><ul><li><a href="#where-can-we-redirect-outputs">Where can we redirect outputs?</a></li><li><a href="#how-can-we-control-the-outputs">How can we control the outputs?</a></li></ul></li><li><a href="#what-if-we-need-temporary-relation-in-a-query">What if we need temporary relation in a query?</a></li><li><a href="#how-does-window-functions-work">How does window functions work?</a></li></ul></li></ul></p><h1 id="database"><a class="markdownIt-Anchor" href="#database"></a> Database</h1><h2 id="why-shouldnt-we-just-store-database-in-a-flat-file-like-csv-that-we-manage-ourselve-in-our-application-code"><a class="markdownIt-Anchor" href="#why-shouldnt-we-just-store-database-in-a-flat-file-like-csv-that-we-manage-ourselve-in-our-application-code"></a> Why shouldn’t we just store database in a flat file like CSV that we manage ourselve in our application code?</h2><ol><li>The first concern is data integrity:<ul><li>How to ensure that the data is make sense to the design schema?</li><li>How to prevent invalid data and malicious attack?</li><li>And the management of deleting some entries causing deleting entries in other databases is pain.</li></ul></li><li>Another problem is implementation:<ul><li>How to find a record?</li><li>How to share database between applications?</li><li>How to handle concurrent writes?</li></ul></li><li>Also concerned about durability:<ul><li>What if machine crashed?</li><li>How to replicate database?</li></ul></li></ol><h2 id="what-does-dbms-and-data-models-do"><a class="markdownIt-Anchor" href="#what-does-dbms-and-data-models-do"></a> What does DBMS and data models do?</h2><ol><li>DBMS supports the definition, creation, querying, update, and administration of databases in accordance with some data model.<ul><li>The physical storage is left up to the DBMS implementation.</li><li>Programmers access data through high-level language, DBMS figures out best execution strategy.</li></ul></li><li>A data model is a collection of concepts for describing the data in a database.<ul><li>A schema is a description of a particular collection of data using a given data model.</li></ul></li></ol><h2 id="what-kinds-of-data-models-are-there"><a class="markdownIt-Anchor" href="#what-kinds-of-data-models-are-there"></a> What kinds of data models are there?</h2><ol><li>The most used is Relational model.</li><li>One class called NoSQL:<ul><li>Key/Value</li><li>Graph</li><li>Document / Object</li><li>Wide-Column / Column-family</li></ul></li><li>For machine learning, there are Array / Matrix / Vectors</li><li>The obsolete or legacy ones are:<ul><li>Hierarchical</li><li>Network</li><li>Multi-Value</li></ul></li></ol><h2 id="how-does-document-data-model-store-data"><a class="markdownIt-Anchor" href="#how-does-document-data-model-store-data"></a> How does document data model store data?</h2><ol><li>It embeds data hierarchy into a single object like JSON, or XML, etc.</li><li>The problem is similar with the aforementioned store database in a flat file like CSV.</li></ol><h1 id="relational-model"><a class="markdownIt-Anchor" href="#relational-model"></a> Relational model</h1><h2 id="how-are-data-stored"><a class="markdownIt-Anchor" href="#how-are-data-stored"></a> How are data stored?</h2><ol><li>Data are stored in simple data structures called relations.</li><li>A relation is an <strong>unordered set</strong> that contain the relationship of attributes that represent entities.<ul><li>A n-ary relation is  a table with n columns.</li></ul></li><li>A tuple is a set of attribute values (domain) in the relation.<ul><li>NULL is a member of every domain, if allowed.</li></ul></li></ol><h2 id="what-is-primary-keys-and-foreign-keys"><a class="markdownIt-Anchor" href="#what-is-primary-keys-and-foreign-keys"></a> What is primary keys and foreign keys?</h2><ol><li>A relation’s primary key uniquely identifies a single tuple.<ul><li>In the definition of a relation, primary keys are usually marked with underline.</li></ul></li><li>A foreign key specifies that an attribute from one relation has to map to a tuple in another relation.<ul><li>Normally, foreign keys must be primary keys in another relation.</li></ul></li></ol><h2 id="what-is-supported-in-relational-algebra"><a class="markdownIt-Anchor" href="#what-is-supported-in-relational-algebra"></a> What is supported in relational algebra?</h2><ol><li>Select: <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>σ</mi><mrow><mi>p</mi><mi>r</mi><mi>e</mi><mi>d</mi><mi>i</mi><mi>c</mi><mi>a</mi><mi>t</mi><mi>e</mi></mrow></msub><mo stretchy="false">(</mo><mi>R</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\sigma_{predicate}(R)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.036108em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">σ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361079999999999em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">p</span><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span><span class="mord mathnormal mtight">e</span><span class="mord mathnormal mtight">d</span><span class="mord mathnormal mtight">i</span><span class="mord mathnormal mtight">c</span><span class="mord mathnormal mtight">a</span><span class="mord mathnormal mtight">t</span><span class="mord mathnormal mtight">e</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="mclose">)</span></span></span></span><ul><li>Choose a subset of the tuples from a relation that satisfies the selection predicate.<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> R</span><br><span class="line"> <span class="keyword">WHERE</span> predicate;</span><br></pre></td></tr></table></figure></li></ul></li><li>Projection: <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="normal">Π</mi><mrow><msub><mi>A</mi><mn>1</mn></msub><mo separator="true">,</mo><msub><mi>A</mi><mn>2</mn></msub><mo separator="true">,</mo><mo>…</mo><mo separator="true">,</mo><msub><mi>A</mi><mi>n</mi></msub></mrow></msub><mo stretchy="false">(</mo><mi>R</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\Pi_{A_1,A_2,\dots,A_n}(R)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.036108em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord">Π</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.328331em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight">A</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31731428571428577em;"><span style="top:-2.357em;margin-left:0em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em;"><span></span></span></span></span></span></span><span class="mpunct mtight">,</span><span class="mord mtight"><span class="mord mathnormal mtight">A</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31731428571428577em;"><span style="top:-2.357em;margin-left:0em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em;"><span></span></span></span></span></span></span><span class="mpunct mtight">,</span><span class="minner mtight">…</span><span class="mpunct mtight">,</span><span class="mord mtight"><span class="mord mathnormal mtight">A</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.16454285714285719em;"><span style="top:-2.357em;margin-left:0em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight">n</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em;"><span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="mclose">)</span></span></span></span><ul><li>Generate a relation with tuples that contains only the specified attributes</li><li>It can be used to rearrange attributes’ ordering and manipulate the values.<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> A1, A2, ..., An <span class="keyword">FROM</span> R;</span><br></pre></td></tr></table></figure></li></ul></li><li>Union: <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>R</mi><mo>∪</mo><mi>S</mi></mrow><annotation encoding="application/x-tex">R\cup S</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">∪</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.05764em;">S</span></span></span></span><ul><li>Two relations must have same attributes.</li><li>The result may be duplicated if some tuples appeared in both relations.<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">(<span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> R) <span class="keyword">UNION</span> <span class="keyword">ALL</span> (<span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> S);</span><br></pre></td></tr></table></figure></li></ul></li><li>Intersection: <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>R</mi><mo>∩</mo><mi>S</mi></mrow><annotation encoding="application/x-tex">R\cap S</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">∩</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.05764em;">S</span></span></span></span><ul><li>Two relations must have same attributes.<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">(<span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> R) <span class="keyword">INTERSECT</span> (<span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> S);</span><br></pre></td></tr></table></figure></li></ul></li><li>Difference: <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>R</mi><mo>−</mo><mi>S</mi></mrow><annotation encoding="application/x-tex">R-S</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.76666em;vertical-align:-0.08333em;"></span><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.05764em;">S</span></span></span></span><ul><li>Two relations must have same attributes.<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">(<span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> R) <span class="keyword">EXCEPT</span> (<span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> S);</span><br></pre></td></tr></table></figure></li></ul></li><li>Product: <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>R</mi><mo>×</mo><mi>S</mi></mrow><annotation encoding="application/x-tex">R\times S</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.76666em;vertical-align:-0.08333em;"></span><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.05764em;">S</span></span></span></span><ul><li>Generate a relation that contains all possible combinations of tuple from the input relations, i.e. Cartesian product.<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> R <span class="keyword">CROSS</span> <span class="keyword">JOIN</span> S;</span><br><span class="line"># <span class="keyword">Or</span></span><br><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> R, S;</span><br></pre></td></tr></table></figure></li></ul></li><li>Join: <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>R</mi><mo>⋈</mo><mi>S</mi></mrow><annotation encoding="application/x-tex">R\bowtie S</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68833em;vertical-align:-0.005em;"></span><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">⋈</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.05764em;">S</span></span></span></span><ul><li>The difference between join and intersection is that join can match attributes’ name automatically, while intersetion requires that two relations have the same attribute order.</li><li>It does product first, then compare attributes.<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> R <span class="keyword">NATURAL</span> <span class="keyword">JOIN</span> S;</span><br><span class="line"># <span class="keyword">Or</span></span><br><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> R <span class="keyword">JOIN</span> S <span class="keyword">USING</span> (A1, A2, ..., An);</span><br></pre></td></tr></table></figure></li><li>In the broad sense, join can have predicate <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>R</mi><msub><mo>⋈</mo><mrow><mi>p</mi><mi>r</mi><mi>e</mi><mi>d</mi><mi>i</mi><mi>c</mi><mi>a</mi><mi>t</mi><mi>e</mi></mrow></msub><mi>S</mi></mrow><annotation encoding="application/x-tex">R\bowtie_{predicate}S</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.969438em;vertical-align:-0.286108em;"></span><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel"><span class="mrel">⋈</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361079999999999em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">p</span><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span><span class="mord mathnormal mtight">e</span><span class="mord mathnormal mtight">d</span><span class="mord mathnormal mtight">i</span><span class="mord mathnormal mtight">c</span><span class="mord mathnormal mtight">a</span><span class="mord mathnormal mtight">t</span><span class="mord mathnormal mtight">e</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.05764em;">S</span></span></span></span> which is the same as <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>σ</mi><mrow><mi>p</mi><mi>r</mi><mi>e</mi><mi>d</mi><mi>i</mi><mi>c</mi><mi>a</mi><mi>t</mi><mi>e</mi></mrow></msub><mo stretchy="false">(</mo><mi>R</mi><mo>×</mo><mi>S</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\sigma_{predicate}(R\times S)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.036108em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">σ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361079999999999em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">p</span><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span><span class="mord mathnormal mtight">e</span><span class="mord mathnormal mtight">d</span><span class="mord mathnormal mtight">i</span><span class="mord mathnormal mtight">c</span><span class="mord mathnormal mtight">a</span><span class="mord mathnormal mtight">t</span><span class="mord mathnormal mtight">e</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.05764em;">S</span><span class="mclose">)</span></span></span></span>.</li></ul></li><li>It is obvious that different order of steps can have the same result with different amout of computation.<ul><li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>R</mi><mo>⋈</mo><mo stretchy="false">(</mo><msub><mi>σ</mi><mrow><mi>p</mi><mi>r</mi><mi>e</mi><mi>d</mi><mi>i</mi><mi>c</mi><mi>a</mi><mi>t</mi><mi>e</mi></mrow></msub><mo stretchy="false">(</mo><mi>S</mi><mo stretchy="false">)</mo><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">R\bowtie(\sigma_{predicate}(S))</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68833em;vertical-align:-0.005em;"></span><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">⋈</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.036108em;vertical-align:-0.286108em;"></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">σ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361079999999999em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">p</span><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span><span class="mord mathnormal mtight">e</span><span class="mord mathnormal mtight">d</span><span class="mord mathnormal mtight">i</span><span class="mord mathnormal mtight">c</span><span class="mord mathnormal mtight">a</span><span class="mord mathnormal mtight">t</span><span class="mord mathnormal mtight">e</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.05764em;">S</span><span class="mclose">)</span><span class="mclose">)</span></span></span></span> is much efficient than <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>σ</mi><mrow><mi>p</mi><mi>r</mi><mi>e</mi><mi>d</mi><mi>i</mi><mi>c</mi><mi>a</mi><mi>t</mi><mi>e</mi></mrow></msub><mo stretchy="false">(</mo><mi>R</mi><mo>⋈</mo><mi>S</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\sigma_{predicate}(R\bowtie S)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.036108em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">σ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361079999999999em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">p</span><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span><span class="mord mathnormal mtight">e</span><span class="mord mathnormal mtight">d</span><span class="mord mathnormal mtight">i</span><span class="mord mathnormal mtight">c</span><span class="mord mathnormal mtight">a</span><span class="mord mathnormal mtight">t</span><span class="mord mathnormal mtight">e</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">⋈</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.05764em;">S</span><span class="mclose">)</span></span></span></span>.</li></ul></li></ol><h1 id="morden-sql"><a class="markdownIt-Anchor" href="#morden-sql"></a> Morden SQL</h1><h2 id="what-is-provided-in-a-relational-language"><a class="markdownIt-Anchor" href="#what-is-provided-in-a-relational-language"></a> What is provided in a relational language?</h2><ol><li>Data Manipulation Language (DML)</li><li>Data Definition Language (DDL)</li><li>Data Control Language (DCL)</li><li>Also view definition, integrity and referential constraints, transactions.</li></ol><h2 id="aggregations-and-group-by"><a class="markdownIt-Anchor" href="#aggregations-and-group-by"></a> Aggregations and Group By</h2><h3 id="what-are-aggregations"><a class="markdownIt-Anchor" href="#what-are-aggregations"></a> What are aggregations?</h3><ol><li>They are functions that return a single value from a bag of tuples.</li><li><code>AVG(col)</code>, <code>MIN(col)</code>, <code>MAX(col)</code>, <code>SUM(col)</code>, <code>COUNT(col)</code><ul><li>For <code>COUNT</code>, the passed argument actual does not mater since it only returns the number of rows.</li></ul></li><li>Aggregate functions can almost only be used in the <code>SELECT</code> output list.</li><li><code>COUNT</code>, <code>SUM</code>, <code>AVG</code> support <code>DISTINCT</code>.<ul><li>In this case, the columns passed to <code>COUNT</code> matters.</li></ul></li><li>Output of other columns outside of an aggregate is undefined.<ul><li>Aggregations actually create a new relation with different number of tuples.</li><li>If we directly ask for other colmns, the number of tuples won’t match with output of aggregations</li><li>And we don’t know the relation between output of aggregations and values from other columns (some language may allow this but with chaos order).</li></ul></li><li>We also cannot filter output tuples with the result of aggregation column names.<ul><li>Since <code>SELECT</code> happens a last, when <code>WHERE</code> or <code>HAVING </code> is calculated, the aggregation columns haven’t been calculated yet.</li></ul></li></ol><h3 id="how-to-output-other-columns-with-aggregations"><a class="markdownIt-Anchor" href="#how-to-output-other-columns-with-aggregations"></a> How to output other columns with aggregations?</h3><ol><li><code>GROUP BY</code> projects tuples into subsets and calculate aggregates against each subset.</li><li>Non-aggregated valuese in <code>SELECT</code> output clause must appear in <code>GROUP BY</code> clause.</li><li>With group-by, each aggregation output has the same values in those grouped columns. So <code>SELECT</code> knows their relation.</li><li><code>HAVING</code> like a <code>WHERE</code> clause for a <code>GROUP BY</code>.<ul><li>It can filter results based on aggregation computation. But it also shouldn’t use the columns names of aggregation in <code>SELECT</code>.</li><li>Instead, it should directly use aggregation function. Although the execution engine knows that these two are the same and don’t do the repeat calculation.</li></ul></li></ol><h2 id="what-string-operations-are-supported"><a class="markdownIt-Anchor" href="#what-string-operations-are-supported"></a> What string operations are supported?</h2><ol><li>Predicate of string matching can be done with <code>=</code><ul><li>Some DBMSs are case sensitive while others are not.</li><li>We can also use <code>LIKE</code> to match with string-match operators.<ul><li><code>%</code> matches any substring (including empty strings)</li><li><code>_</code> match any one character.</li></ul></li></ul></li><li>Other string functions are provided:<ul><li><code>UPPER</code> and <code>LOWER</code></li><li><code>SUBSTRING(str, start_index, end_index)</code></li></ul></li><li>Different language has different ways to concatenate strings: <code>str1 || str2</code>, <code>str1 + str2</code> or <code>CONCAT(str1, str2)</code>.</li></ol><h2 id="output"><a class="markdownIt-Anchor" href="#output"></a> Output</h2><h3 id="where-can-we-redirect-outputs"><a class="markdownIt-Anchor" href="#where-can-we-redirect-outputs"></a> Where can we redirect outputs?</h3><ol><li>We can store query restuls in another table.<ul><li>That table must not already be defined.</li><li>It will have the same number of columns with the same types as the input.</li></ul></li><li>We can also insert tuples from query into another table.<ul><li>The inner select must generate the same columns as the target table.</li><li>DMBSs have diferent options/syntax on what to do with integrity violations.</li></ul></li></ol><h3 id="how-can-we-control-the-outputs"><a class="markdownIt-Anchor" href="#how-can-we-control-the-outputs"></a> How can we control the outputs?</h3><ol><li>We can order the output tuples by the values in one or more of their columns with <code>ORDER BY &lt;column*&gt; [ASC|DESC]</code>.</li><li>We can also limit the number of tuples returned in output with <code>LIMIT &lt;count&gt; [OFFSET &lt;count2&gt;]</code>.<ul><li>Although this limits the number of output, its execution may still need to compute the whole relation, e.g. to output the top-10 largest numbers still need to sort all numbers.</li></ul></li></ol><h2 id="what-if-we-need-temporary-relation-in-a-query"><a class="markdownIt-Anchor" href="#what-if-we-need-temporary-relation-in-a-query"></a> What if we need temporary relation in a query?</h2><ol><li>The first solution is nested queries.<ul><li>Inner queries can appear almost anywhere in query.</li><li>In <code>WHERE</code> clause, we can perform predicate between the tuples from current relation and result of subqueries.<ul><li><code>ALL</code> must satisfy expression for all rows in the subquery.</li><li><code>ANY</code> must satisfy expression for at least one row in the subquery.</li><li><code>IN</code> is equivalent to <code>=ANY()</code>.</li><li><code>EXISTS</code> returns true if the relation is not empty.</li><li><code>NOT</code></li></ul></li></ul></li><li>Another choice is common table expression using <code>WITH cteName AS (query)</code>.<ul><li>It also supports bind/alias output columns to names <code>WITH cteName (col1, ..., coln) AS (query)</code></li><li>In the next one query, we can reference this temporary relation with <code>cteName</code>.</li><li>We can enable recursive calculation using <code>WITH RECURSIVE</code>.</li></ul></li></ol><h2 id="how-does-window-functions-work"><a class="markdownIt-Anchor" href="#how-does-window-functions-work"></a> How does window functions work?</h2><ol><li>Window functions perform a sliding calculation across a set of tuples that are related.</li><li>Like an aggregation, they only appear in <code>SELECT</code> clause. But tuples are not grouped into a single output tuples. Instead, the number of rows of the output is the same as input.</li><li>In <code>SELECT</code> clause, window functions syntax is <code>FUNC-NAME(...) OVER(...)</code>.<ul><li>The <code>FUNC-NAME</code> can be aggregation functions or special functions (<code>ROW_NUMBER</code> and <code>RANK</code>)<ul><li><code>ROW_NUMBER</code> assigns the nuber of current row in certain order.</li><li><code>RANK</code> assigns the order position of the current row.</li><li>When two rows tie, <code>RANK</code> will assign the same number to them and skip the next number while <code>ROW_NUMBER</code> will assign different number.</li></ul></li><li>The <code>OVER</code> paramater controls how to slice up data.<ul><li>It controls how to group together tuples when computing the window function with <code>PARTITION BY</code>.</li><li>It also controls the order of computing with <code>ORDER BY ... [ASC|DESC]</code>.</li></ul></li></ul></li></ol>]]></content>
      
      
      <categories>
          
          <category> Open Courses </category>
          
          <category> CMU 15-445/645 Database System </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Database System </tag>
            
            <tag> Relational Model </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>16. Heterogeneous Parallelism and Hardware Specialization</title>
      <link href="/2022/07/24/Courses/CS149/16-Heterogeneous-Parallelism-and-Hardware-Specialization/"/>
      <url>/2022/07/24/Courses/CS149/16-Heterogeneous-Parallelism-and-Hardware-Specialization/</url>
      
        <content type="html"><![CDATA[<ol><li>Amdahl’s law in terms of resource limits: <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>s</mi><mi>p</mi><mi>e</mi><mi>e</mi><mi>d</mi><mi>u</mi><mi>p</mi><mo stretchy="false">(</mo><mi>f</mi><mo separator="true">,</mo><mi>n</mi><mo separator="true">,</mo><mi>r</mi><mo stretchy="false">)</mo><mo>=</mo><mfrac><mn>1</mn><mrow><mfrac><mrow><mn>1</mn><mo>−</mo><mi>f</mi></mrow><mrow><mi>p</mi><mi>e</mi><mi>r</mi><mi>f</mi><mo stretchy="false">(</mo><mi>r</mi><mo stretchy="false">)</mo></mrow></mfrac><mo>+</mo><mfrac><mi>f</mi><mrow><mi>p</mi><mi>e</mi><mi>r</mi><mi>f</mi><mo stretchy="false">(</mo><mi>r</mi><mo stretchy="false">)</mo><mo>⋅</mo><mfrac><mi>n</mi><mi>r</mi></mfrac></mrow></mfrac></mrow></mfrac></mrow><annotation encoding="application/x-tex">speedup(f, n, r)=\frac{1}{\frac{1-f}{perf(r)}+\frac{f}{perf(r)\cdot\frac{n}{r}}}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">s</span><span class="mord mathnormal">p</span><span class="mord mathnormal">e</span><span class="mord mathnormal">e</span><span class="mord mathnormal">d</span><span class="mord mathnormal">u</span><span class="mord mathnormal">p</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal">n</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.877228em;vertical-align:-1.03212em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.845108em;"><span style="top:-2.51911em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mopen nulldelimiter sizing reset-size3 size6"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.9584142857142857em;"><span style="top:-2.640785714285714em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">p</span><span class="mord mathnormal mtight">e</span><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span><span class="mord mathnormal mtight" style="margin-right:0.10764em;">f</span><span class="mopen mtight">(</span><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span><span class="mclose mtight">)</span></span></span></span><span style="top:-3.2255000000000003em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line mtight" style="border-bottom-width:0.049em;"></span></span><span style="top:-3.4623857142857144em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight">1</span><span class="mbin mtight">−</span><span class="mord mathnormal mtight" style="margin-right:0.10764em;">f</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.5377857142857143em;"><span></span></span></span></span></span><span class="mclose nulldelimiter sizing reset-size3 size6"></span></span><span class="mbin mtight">+</span><span class="mord mtight"><span class="mopen nulldelimiter sizing reset-size3 size6"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.9584142857142857em;"><span style="top:-2.5925285714285713em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">p</span><span class="mord mathnormal mtight">e</span><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span><span class="mord mathnormal mtight" style="margin-right:0.10764em;">f</span><span class="mopen mtight">(</span><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span><span class="mclose mtight">)</span><span class="mbin mtight">⋅</span><span class="mord mtight"><span class="mopen nulldelimiter sizing reset-size1 size6"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8175600000000001em;"><span style="top:-2.468em;"><span class="pstrut" style="height:3em;"></span><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span></span></span><span style="top:-3.2255000000000003em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line mtight" style="border-bottom-width:0.049em;"></span></span><span style="top:-3.387em;"><span class="pstrut" style="height:3em;"></span><span class="mord mtight"><span class="mord mathnormal mtight">n</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.532em;"><span></span></span></span></span></span><span class="mclose nulldelimiter sizing reset-size1 size6"></span></span></span></span></span><span style="top:-3.2255000000000003em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line mtight" style="border-bottom-width:0.049em;"></span></span><span style="top:-3.4623857142857144em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.10764em;">f</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.7874714285714286em;"><span></span></span></span></span></span><span class="mclose nulldelimiter sizing reset-size3 size6"></span></span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.03212em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span>. Here, <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>f</mi><mo>=</mo></mrow><annotation encoding="application/x-tex">f =</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span></span></span></span> fraction of program that is parallelizable, <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi><mo>=</mo></mrow><annotation encoding="application/x-tex">n =</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathnormal">n</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span></span></span></span> total processing resources, <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>r</mi><mo>=</mo></mrow><annotation encoding="application/x-tex">r =</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span></span></span></span> resources dedicated to each processing core, each of the <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mi>n</mi><mi>r</mi></mfrac></mrow><annotation encoding="application/x-tex">\frac{n}{r}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.040392em;vertical-align:-0.345em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.695392em;"><span style="top:-2.6550000000000002em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">n</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.345em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span> cores has sequential performance <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi><mi>e</mi><mi>r</mi><mi>f</mi><mo stretchy="false">(</mo><mi>r</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">perf(r)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">p</span><span class="mord mathnormal">e</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mclose">)</span></span></span></span>.</li><li>If a processor has one <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi><mi>e</mi><mi>r</mi><mi>f</mi><mo stretchy="false">(</mo><mi>r</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">perf(r)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">p</span><span class="mord mathnormal">e</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mclose">)</span></span></span></span> core and <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi><mo>−</mo><mi>r</mi></mrow><annotation encoding="application/x-tex">n-r</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.66666em;vertical-align:-0.08333em;"></span><span class="mord mathnormal">n</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span></span></span></span> <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi><mi>e</mi><mi>r</mi><mi>f</mi><mo stretchy="false">(</mo><mn>1</mn><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">perf(1)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">p</span><span class="mord mathnormal">e</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="mopen">(</span><span class="mord">1</span><span class="mclose">)</span></span></span></span> cores, its <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>s</mi><mi>p</mi><mi>e</mi><mi>e</mi><mi>d</mi><mi>u</mi><mi>p</mi><mo stretchy="false">(</mo><mi>f</mi><mo separator="true">,</mo><mi>n</mi><mo separator="true">,</mo><mi>r</mi><mo stretchy="false">)</mo><mo>=</mo><mfrac><mn>1</mn><mrow><mfrac><mrow><mn>1</mn><mo>−</mo><mi>f</mi></mrow><mrow><mi>p</mi><mi>e</mi><mi>r</mi><mi>f</mi><mo stretchy="false">(</mo><mi>r</mi><mo stretchy="false">)</mo></mrow></mfrac><mo>+</mo><mfrac><mi>f</mi><mrow><mi>p</mi><mi>e</mi><mi>r</mi><mi>f</mi><mo stretchy="false">(</mo><mi>r</mi><mo stretchy="false">)</mo><mo>+</mo><mo stretchy="false">(</mo><mi>n</mi><mo>−</mo><mi>r</mi><mo stretchy="false">)</mo><mi>p</mi><mi>e</mi><mi>r</mi><mi>f</mi><mo stretchy="false">(</mo><mn>1</mn><mo stretchy="false">)</mo></mrow></mfrac></mrow></mfrac></mrow><annotation encoding="application/x-tex">speedup(f, n, r)=\frac{1}{\frac{1-f}{perf(r)}+\frac{f}{perf(r)+(n-r)perf(1)}}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">s</span><span class="mord mathnormal">p</span><span class="mord mathnormal">e</span><span class="mord mathnormal">e</span><span class="mord mathnormal">d</span><span class="mord mathnormal">u</span><span class="mord mathnormal">p</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal">n</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.702448em;vertical-align:-0.8573399999999999em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.845108em;"><span style="top:-2.5191100000000004em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mopen nulldelimiter sizing reset-size3 size6"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.9584142857142857em;"><span style="top:-2.640785714285714em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">p</span><span class="mord mathnormal mtight">e</span><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span><span class="mord mathnormal mtight" style="margin-right:0.10764em;">f</span><span class="mopen mtight">(</span><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span><span class="mclose mtight">)</span></span></span></span><span style="top:-3.2255000000000003em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line mtight" style="border-bottom-width:0.049em;"></span></span><span style="top:-3.4623857142857144em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight">1</span><span class="mbin mtight">−</span><span class="mord mathnormal mtight" style="margin-right:0.10764em;">f</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.5377857142857143em;"><span></span></span></span></span></span><span class="mclose nulldelimiter sizing reset-size3 size6"></span></span><span class="mbin mtight">+</span><span class="mord mtight"><span class="mopen nulldelimiter sizing reset-size3 size6"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.9584142857142857em;"><span style="top:-2.640785714285714em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">p</span><span class="mord mathnormal mtight">e</span><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span><span class="mord mathnormal mtight" style="margin-right:0.10764em;">f</span><span class="mopen mtight">(</span><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span><span class="mclose mtight">)</span><span class="mbin mtight">+</span><span class="mopen mtight">(</span><span class="mord mathnormal mtight">n</span><span class="mbin mtight">−</span><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span><span class="mclose mtight">)</span><span class="mord mathnormal mtight">p</span><span class="mord mathnormal mtight">e</span><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span><span class="mord mathnormal mtight" style="margin-right:0.10764em;">f</span><span class="mopen mtight">(</span><span class="mord mtight">1</span><span class="mclose mtight">)</span></span></span></span><span style="top:-3.2255000000000003em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line mtight" style="border-bottom-width:0.049em;"></span></span><span style="top:-3.4623857142857144em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.10764em;">f</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.5377857142857143em;"><span></span></span></span></span></span><span class="mclose nulldelimiter sizing reset-size3 size6"></span></span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.8573399999999999em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span>.</li><li>Most “real world” applications have complex workload characteristics. The most efficient processor is a heterogeneous mixture of resources, namely use the most efficient tool for the job.</li><li>Supercomputers are energy constrained due to shear scale and overall cost to operate (power for machine and for cooling)<br />Datacenters are energy constrained to reduce cost of cooling and reduce physical space requirements.<br />Mobile devices are energy constrained due to limited battery life and heat dissipation.</li><li>Challenge of heterogeneous for system designer: what is the right mixture of resources to meet performance, cost, and energy goals?<br />Too few throughput oriented resources would lower peak throughput for parallel workloads. Too few sequential processing resources make the overall system limited by sequential part of workload. How much chip area should be dedicated to a specific function. (these resources are taken away from general-purpose processing) Work balance must be anticipated at chip design time</li><li>Challenge to software developer: how to map programs onto a heterogeneous collection of resources?<br />Wish to design algorithms that decompose well into components that each map well to different processing components of the machine. The scheduling problem is more complex on a heterogeneous system. Available mixture of resources can dictate choice of algorithm. Software portability and maintenance nightmare.</li><li>Reducing energy consumption should use specialized processing and move less data.</li></ol>]]></content>
      
      
      <categories>
          
          <category> Open Courses </category>
          
          <category> CMU 15-418 / Stanford CS149 Parallel Computing </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Parallelism </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>15. Transactional Memory</title>
      <link href="/2022/07/21/Courses/CS149/15-Transactional-Memory/"/>
      <url>/2022/07/21/Courses/CS149/15-Transactional-Memory/</url>
      
        <content type="html"><![CDATA[<h1 id="transactional-memory"><a class="markdownIt-Anchor" href="#transactional-memory"></a> Transactional memory</h1><ol><li>The declarative programming is that programmer states what to do, not how to do it. System implements synchronization as necessary to ensure atomicity.</li><li>In transaction memory, atomic construct is declarative, which means that programmer states what to do, not how to do it. System implements synchronization as necessary to ensure atomicity.<br />System could implement <code>atomic&#123;&#125;</code> using a lock. But programmer has no explicit use or management of locks.<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Traditional method</span></span><br><span class="line"><span class="built_in">lock</span>(mutex);</span><br><span class="line"><span class="comment">//critical code</span></span><br><span class="line"><span class="built_in">unlock</span>(mutex);</span><br><span class="line"></span><br><span class="line"><span class="comment">// Transaction memory</span></span><br><span class="line">atomic &#123;</span><br><span class="line">  <span class="comment">// critical code</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li>Memory transaction is an atomic and isolated sequence of memory accesses inspired by database transactions.<br />Atomicity requires that upon transaction commit, all memory writes in transaction take effect at once, and on transaction abort, none of the writes appear to take effect as if transaction never happened.<br />Isolation means that no other processor can observe writes before transaction commits.<br />Serializability is that transactions appear to commit in a single serial order, but the exact order of commits is not guaranteed by semantics of transaction.</li><li>Load-linked, store conditional (LL/SC) is a light version of transactional memory. It has a pair of corresponding instructions (not a single atomic instruction)<br /><code>load_linked(x)</code>: load value from address<br /><code>store_conditional(x, value)</code>: store value to x, if x hasn’t been written to since<br />corresponding LL</li><li>Two read operations won’t cause true contention. In TM, we can allow the parallelism between two read operations. But serialization must be ensured when at least one write operation occurs.</li><li>Transactional memory system is also responsible for processing exceptions decreasing the complexity of programmers from using <code>try-catch</code> statement to manually catching exceptions.<br />When an exception inside the atomic block is occurred, transaction is aborted and memory updates are undone.</li><li>Transactional memory system needs composible locks.<br />Composing lock-based code can be tricky, which requires system-wide policies to get correct and system-wide policies can break software modularity.<br />The following code can end up in a deadlock. TM system should be able to compose the two synchronizations together to avoid the possible deadlock. Programmer can use an <code>atomic&#123;&#125;</code> to correctly represent the two <code>synchronizaed&#123;&#125;</code> structure.<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">void</span> <span class="title">function</span><span class="params">(A, B)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">  <span class="built_in">synchronized</span>(A)</span><br><span class="line">  &#123;</span><br><span class="line">    <span class="built_in">synchronized</span>(B)</span><br><span class="line">    &#123;</span><br><span class="line">      <span class="comment">// critical code</span></span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// thread 0</span></span><br><span class="line"><span class="built_in">function</span>(x, y);</span><br><span class="line"></span><br><span class="line"><span class="comment">//thread 1</span></span><br><span class="line"><span class="built_in">function</span>(y, x);</span><br></pre></td></tr></table></figure></li><li><code>Atomic&#123;&#125;</code> is not the same as <code>lock()/unlock()</code>. Atomic is a high-level declaration of atomicity, which does not specify implementation of atomicity. Lock is a low-level blocking primitive that does not provide atomicity or isolation on its own.<br />Locks can be used to implement anatomicblock. Also, locks can be used for purposes beyond atomicity, namely we cannot replace all uses of locks with atomic regions.<br />Atomic eliminates many data races, but programming with atomic blocks can still suffer from atomicity violations.</li><li>Atomicity violation due to programmer error: Logically atomic code sequence is erroneously separated into two atomic blocks.</li></ol><h1 id="implementing-transactional-memory"><a class="markdownIt-Anchor" href="#implementing-transactional-memory"></a> Implementing transactional memory</h1><h2 id="data-versioning"><a class="markdownIt-Anchor" href="#data-versioning"></a> Data versioning</h2><ol><li>Data versioning manages uncommitted (new) and previously committed (old) versions of data for concurrent transactions. This is used to allow transaction abort.</li><li>Eager versioning updates memory immediately, maintains “undo log” in case of abort.<br />When a write happens, the old value is pushed into the undo log and write the new value to memory.<br />When a transaction is aborted, we can search the undo log to recover the corresponding state.<br />When the transaction is committed, we can discard the undo log of those committed contents.</li><li>Lazy versioning is a deferred update, namely it logs memory updates in transaction write buffer, flushes buffer on commit.<br />When a write happens, the new value is pushed into the write buffer and we don’t write the new value to memory.<br />When a transaction is aborted, we simply discard the write buffer, and there is no need to modify the memory since we haven’t written anything to it yet.<br />When a transaction is committed, we write the data in write buffer to memory and discard the write buffer.</li><li>Eager versioning is faster in commit, since data is already in memory. But it is slower in aborts and has fault tolerance issues (crash in middle of transaction). It write to memory immediately, hoping transaction won’t abort, but deal with aborts when you have to.</li><li>Lazy versioning is faster in abort, which just clears log, has no fault tolerance issues. But it is slower in commits. It only write to memory when you have to.</li></ol><h2 id="conflict-detection-and-resolution"><a class="markdownIt-Anchor" href="#conflict-detection-and-resolution"></a> Conflict detection and resolution</h2><ol><li>This is to decide when to abort. It must detect and handle conflicts, read-write conflict and write-write conflict, between transactions. System must track a transaction’s read set and write set.</li><li>Pessimistic detection checks for conflicts during loads or stores. A hardware implementation will check for conflicts through coherence actions.<br />The philosophy is that “I suspect conflicts might happen, so let’s always check to see if one has occurred after each memory operation… if I’m going to have to roll back, might as well do it now to avoid wasted work.”</li><li>Contention manager decides to stall or abort transaction when a conflict is detected. When a conflict is detected before executing (early detection), it can be stalled. When a conflict is detected after executed, then it can only restart.<br />When the conflict is caused by two writes, it may raise a livelock, if both threads restart before the other one has finished.</li><li>Optimistic detection detects conflicts when a transaction attempts to commit. Hardware validates write set using coherence actions and gets exclusive access for cache lines in write set.<br />The intuition is that “Let’s hope for the best and sort out all the conflicts only when the transaction tries to commit”<br />On a conflict, it gives priority to committing transaction. Other transactions may abort later on. On conflicts between committing transactions, use contention manager to decide priority. Optimistic detection won’t cause livelock.</li><li>We can use optimistic and pessimistic schemes together. Several STM systems use optimistic for reads and pessimistic for writes.</li><li>Pessimistic conflict detection (“eager”) can detect conflicts early, and thus undo less work, turn some aborts to stalls. It has no forward progress guarantees, more aborts in some cases. Also, it requires fine-grained communication to check on each load/store.<br />Bad: detection on critical path</li><li>Optimistic conflict detection (“lazy” or “commit”) has forward progress guarantees. It requires bulk communication and conflict detection. It detects conflicts late, can still have fairness problems.</li><li>Conflict detection granularity<br />Object granularity is software-based techniques. It reduces overhead of time and space, and is close to programmer’s reasoning. But there might have false sharing on large objects.<br />Machine word granularity can minimize false sharing, but increases overhead of time and space.<br />Cache-line granularity is a compromise between object and word.</li></ol><h2 id="hardware-transactional-memory"><a class="markdownIt-Anchor" href="#hardware-transactional-memory"></a> Hardware transactional memory</h2><ol><li>Data versioning is implemented in caches. Cache the write buffer or the undo log. And add new cache line metadata to track transaction read set and write set.<br />Conflict detection is implemented through cache coherence protocol. Coherence lookups detect conflicts between transactions. It works with snooping and directory coherence.</li><li>Register checkpoint must also be taken at transaction begin to restore execution context state on abort.</li><li>Cache lines needs extra bits to track read set and write set.<br /><strong>R bit</strong> indicates data read by transaction and is set on loads, while <strong>W bit</strong> indicates data written by transaction and is set on stores. R/W bits gang-cleared on transaction commit or abort.<br />R/W bits can be at word or cache-line granularity.<br />For eager versioning, need a 2nd cache write for undo log.</li><li>Coherence requests check R/W bits to detect conflicts.<br />Observing shared request to W-word is a read-write conflict.<br />Observing exclusive (intent to write) request to R-word is a write-read conflict.<br />Observing exclusive (intent to write) request to W-word is a write-write conflict.</li><li>Fast two-phase commit<br />Validate: request RdX access to write set lines (if needed)<br />Commit: gang-reset R and W bits, turns write set data to valid (dirty) data.</li><li>Fast conflict detection and abort<br />Check: lookup exclusive requests in the read set and write set<br />Abort: invalidate write set, gang-reset R and W bits, restore to register checkpoint</li></ol>]]></content>
      
      
      <categories>
          
          <category> Open Courses </category>
          
          <category> CMU 15-418 / Stanford CS149 Parallel Computing </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Parallelism </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>14. Fine-grained Synchronization and Lock-free Programming</title>
      <link href="/2022/07/17/Courses/CS149/14-Fine-grained-Synchronization-and-Lock-free-Programming/"/>
      <url>/2022/07/17/Courses/CS149/14-Fine-grained-Synchronization-and-Lock-free-Programming/</url>
      
        <content type="html"><![CDATA[<h1 id="fine-grained-synchronization-and-fine-grained-lock"><a class="markdownIt-Anchor" href="#fine-grained-synchronization-and-fine-grained-lock"></a> Fine-grained synchronization and fine-grained lock</h1><ol><li>Data structures are often larger than a single memory location. One solution is to protect the structure with a single lock.<br />It is relatively simple to implement correct mutual exclusion for data structure operations. But the operations on the data structure are serialized, which may limit parallel application performance.</li><li>Another solution is “hand-over-hand” locking. We set a lock for each elements in the data structure. Each threads only keeps as less as lock they need, and every time a thread move forward, it unlock the locks they don’t need any more and lock the locks they need now.</li><li>The goal of fine-grained lock is to enable parallelism in data structure operations by Reducing contention for global data structure lock.<br />It is tricky to ensure correctness (how to determine when mutual exclusion is required, how to avoid deadlock or livelock).</li><li>It has an overhead of taking a lock each traversal step. There are extra instructions and traversal now involves memory writes. Also, it has extra storage cost, namely a lock per node.</li><li>C++11 has an <code>atomic&lt;T&gt;</code>. It provides atomic read, write, read-modify-write of entire objects. Atomicity may be implemented by mutex or efficiently by processor-supported atomic instructions if <code>T</code> is a basic type.<br />It also provides memory ordering semantics for operations before and after atomic operations.</li></ol><h1 id="lock-free-programming"><a class="markdownIt-Anchor" href="#lock-free-programming"></a> Lock-free programming</h1><ol><li><p>Single reader, single writer bounded queue: Only two threads (one producer, one consumer) accessing queue at the same time</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">struct</span> <span class="title class_">Queue</span> &#123;</span><br><span class="line">  <span class="type">int</span> data[N];</span><br><span class="line">  <span class="type">unsigned</span> head; <span class="comment">// head of queue</span></span><br><span class="line">  <span class="type">unsigned</span> tail; <span class="comment">// next free element</span></span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">init</span><span class="params">(Queue* q)</span> </span>&#123;</span><br><span class="line">  q-&gt;head = q-&gt;tail = <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// return false if queue is full</span></span><br><span class="line"><span class="function"><span class="type">bool</span> <span class="title">push</span><span class="params">(Queue* q, <span class="type">int</span> value)</span> </span>&#123;</span><br><span class="line">  <span class="comment">// queue is full if tail is element before head</span></span><br><span class="line">  <span class="keyword">if</span> (q-&gt;tail == <span class="built_in">MOD_N</span>(q-&gt;head - <span class="number">1</span>))</span><br><span class="line">    <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">  q.data[q-&gt;tail] = value;</span><br><span class="line">  q-&gt;tail = <span class="built_in">MOD_N</span>(q-&gt;tail + <span class="number">1</span>);</span><br><span class="line">  <span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// returns false if queue is empty</span></span><br><span class="line"><span class="function"><span class="type">bool</span> <span class="title">pop</span><span class="params">(Queue* q, <span class="type">int</span>* value)</span> </span>&#123;</span><br><span class="line">  <span class="comment">// if not empty</span></span><br><span class="line">  <span class="keyword">if</span> (q-&gt;head != q-&gt;tail) &#123;</span><br><span class="line">    *value = q-&gt;data[q-&gt;head];</span><br><span class="line">    q-&gt;head = <span class="built_in">MOD_N</span>(q-&gt;head + <span class="number">1</span>);</span><br><span class="line">    <span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>Single reader, single writer unbounded queue: Only push modifies <code>tail</code> and <code>reclaim</code>; only pop modifies <code>head</code>.</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">struct</span> <span class="title class_">Node</span> &#123;</span><br><span class="line">  Node* next;</span><br><span class="line">  <span class="type">int</span> value;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="keyword">struct</span> <span class="title class_">Queue</span> &#123;</span><br><span class="line">  Node* head;    <span class="comment">// the element before head of queue</span></span><br><span class="line">  Node* tail;    <span class="comment">// the last element added</span></span><br><span class="line">  Node* reclaim; <span class="comment">// the head of undeleted nodes</span></span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">init</span><span class="params">(Queue* q)</span> </span>&#123;</span><br><span class="line">  q-&gt;head = q-&gt;tail = q-&gt;reclaim = <span class="keyword">new</span> Node;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">push</span><span class="params">(Queue* q, <span class="type">int</span> value)</span> </span>&#123;</span><br><span class="line">  Node* n = <span class="keyword">new</span> Node;</span><br><span class="line">  n-&gt;next = <span class="literal">NULL</span>;</span><br><span class="line">  n-&gt;value = value;</span><br><span class="line">  q-&gt;tail-&gt;next = n;</span><br><span class="line">  q-&gt;tail = q-&gt;tail-&gt;next;</span><br><span class="line">  <span class="comment">// delete all nodes between reclaim and head</span></span><br><span class="line">  <span class="keyword">while</span> (q-&gt;reclaim != q-&gt;head) &#123;</span><br><span class="line">    Node* tmp = q-&gt;reclaim;</span><br><span class="line">    q-&gt;reclaim = q-&gt;reclaim-&gt;next;</span><br><span class="line">    <span class="keyword">delete</span> tmp;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// returns false if queue is empty</span></span><br><span class="line"><span class="function"><span class="type">bool</span> <span class="title">pop</span><span class="params">(Queue* q, <span class="type">int</span>* value)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">if</span> (q-&gt;head != q-&gt;tail) &#123;</span><br><span class="line">    *value = q-&gt;head-&gt;next-&gt;value;</span><br><span class="line">    q-&gt;head = q-&gt;head-&gt;next;</span><br><span class="line">    <span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>Lock-free stack: the main idea is that as long as no other thread has modified the stack, a thread’s modification can proceed. The <code>compare_and_swap</code> operation is atomic, but doesn’t need to hold any other lock on data structure.</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">struct</span> <span class="title class_">Node</span> &#123;</span><br><span class="line">  Node* next;</span><br><span class="line">  <span class="type">int</span> value;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="keyword">struct</span> <span class="title class_">Stack</span> &#123;</span><br><span class="line">  Node* top;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">init</span><span class="params">(Stack* s)</span> </span>&#123;</span><br><span class="line">  s-&gt;top = <span class="literal">NULL</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">push</span><span class="params">(Stack* s, Node* n)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">while</span> (<span class="number">1</span>) &#123;</span><br><span class="line">    Node* old_top = s-&gt;top;</span><br><span class="line">    n-&gt;next = old_top;</span><br><span class="line">    <span class="comment">// Check whether the current top is the old top, </span></span><br><span class="line">    <span class="comment">// if true, set the current top to n; or get a new top</span></span><br><span class="line">    <span class="keyword">if</span> (<span class="built_in">compare_and_swap</span>(&amp;s-&gt;top, old_top, n) == old_top)</span><br><span class="line">      <span class="keyword">return</span>;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function">Node* <span class="title">pop</span><span class="params">(Stack* s)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">while</span> (<span class="number">1</span>) &#123;</span><br><span class="line">    Node* old_top = s-&gt;top;</span><br><span class="line">    <span class="keyword">if</span> (old_top == <span class="literal">NULL</span>)</span><br><span class="line">      <span class="keyword">return</span> <span class="literal">NULL</span>;</span><br><span class="line">    Node* new_top = old_top-&gt;next;</span><br><span class="line">    <span class="comment">// if the top is still the old top, return old top and set to new top</span></span><br><span class="line">    <span class="comment">// or get a new top</span></span><br><span class="line">    <span class="keyword">if</span> (<span class="built_in">compare_and_swap</span>(&amp;s-&gt;top, old_top, new_top) == old_top)</span><br><span class="line">      <span class="keyword">return</span> old_top;  <span class="comment">// Assume that consumer then recycles old_top</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>The above push operation is fine, but the pop operation may have some error.<br />After thread0 stored the <code>old_top</code>, if thread1 pops the <code>old_top</code> out, modifies the stack, and pushes the <code>old_top</code> into stack again, then the <code>compare_and_swap</code> operation of thread0 will pass. Namely, thread0 cannot realize that the stack has already been modified.</p></li><li><p>One solution is adding a <code>pop_counter</code> to check whether other pop operations happened.</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">struct</span> <span class="title class_">Node</span> &#123;</span><br><span class="line">  Node* next;</span><br><span class="line">  <span class="type">int</span> value;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="keyword">struct</span> <span class="title class_">Stack</span> &#123;</span><br><span class="line">  Node* top;</span><br><span class="line">  <span class="type">int</span> pop_count;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">init</span><span class="params">(Stack* s)</span> </span>&#123;</span><br><span class="line">  s-&gt;top = <span class="literal">NULL</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">push</span><span class="params">(Stack* s, Node* n)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">while</span> (<span class="number">1</span>) &#123;</span><br><span class="line">    Node* old_top = s-&gt;top;</span><br><span class="line">    n-&gt;next = old_top;</span><br><span class="line">    <span class="keyword">if</span> (<span class="built_in">compare_and_swap</span>(&amp;s-&gt;top, old_top, n) == old_top)</span><br><span class="line">      <span class="keyword">return</span>;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function">Node* <span class="title">pop</span><span class="params">(Stack* s)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">while</span> (<span class="number">1</span>) &#123;</span><br><span class="line">    <span class="type">int</span> pop_count = s-&gt;pop_count;</span><br><span class="line">    Node* top = s-&gt;top;</span><br><span class="line">    <span class="keyword">if</span> (top == <span class="literal">NULL</span>)</span><br><span class="line">      <span class="keyword">return</span> <span class="literal">NULL</span>;</span><br><span class="line">    Node* new_top = top-&gt;next;</span><br><span class="line">    <span class="keyword">if</span> (<span class="built_in">double_compare_and_swap</span>(&amp;s-&gt;top, top, new_top,</span><br><span class="line">                                &amp;s-&gt;pop_count, pop_count, pop_count+<span class="number">1</span>))</span><br><span class="line">    &#123;</span><br><span class="line">      <span class="keyword">return</span> top;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure></li><li><p>Another solution of ABA problem is hazard pointers. The ABA problem is caused by the reuse of the <code>old_top</code>. We can use the hazard pointers to track all <code>old_top</code>s, and ode cannot be recycled or reused if matches any hazard pointer.</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">struct</span> <span class="title class_">Node</span> &#123;</span><br><span class="line">  Node* next;</span><br><span class="line">  <span class="type">int</span> value;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="keyword">struct</span> <span class="title class_">Stack</span> &#123;</span><br><span class="line">  Node* top;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line">Node *hazard[NUM_THREADS];</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">init</span><span class="params">(Stack* s)</span> </span>&#123;</span><br><span class="line">  s-&gt;top = <span class="literal">NULL</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">push</span><span class="params">(Stack* s, Node* n)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">while</span> (<span class="number">1</span>) &#123;</span><br><span class="line">    Node* old_top = s-&gt;top;</span><br><span class="line">    n-&gt;next = old_top;</span><br><span class="line">    <span class="keyword">if</span> (<span class="built_in">compare_and_swap</span>(&amp;s-&gt;top, old_top, n) == old_top)</span><br><span class="line">      <span class="keyword">return</span>;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function">Node* <span class="title">pop</span><span class="params">(Stack* s)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">while</span> (<span class="number">1</span>) &#123;</span><br><span class="line">    hazard[t] = s-&gt;top;</span><br><span class="line">    Node* top = hazard[t];</span><br><span class="line">    <span class="keyword">if</span> (top == <span class="literal">NULL</span>)</span><br><span class="line">      <span class="keyword">return</span> <span class="literal">NULL</span>;</span><br><span class="line">    Node* new_top = top-&gt;next;</span><br><span class="line">    <span class="keyword">if</span> (<span class="built_in">compare_and_swap</span>(&amp;s-&gt;top, top, new_top))</span><br><span class="line">      <span class="keyword">return</span> top;  <span class="comment">// Caller must clear hazard[t] when it’s done with top</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>Lock-free linked list insertion: assumes the only operation on the list is insert. Supporting lock-free deletion significantly complicates data-structure.</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">struct</span> <span class="title class_">Node</span> &#123;</span><br><span class="line">  <span class="type">int</span> value;</span><br><span class="line">  Node* next;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="keyword">struct</span> <span class="title class_">List</span> &#123;</span><br><span class="line">  Node* head;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="comment">// insert new node after specified node</span></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">insert_after</span><span class="params">(List* list, Node* after, <span class="type">int</span> value)</span> </span>&#123;</span><br><span class="line">  Node* n = <span class="keyword">new</span> Node;</span><br><span class="line">  n-&gt;value = value;</span><br><span class="line">  <span class="comment">// assume case of insert into empty list handled</span></span><br><span class="line">  <span class="comment">// here (keep code on slide simple for class discussion)</span></span><br><span class="line">  Node* prev = list-&gt;head;</span><br><span class="line">  <span class="keyword">while</span> (prev-&gt;next) &#123;</span><br><span class="line">    <span class="keyword">if</span> (prev == after) &#123;</span><br><span class="line">      <span class="keyword">while</span> (<span class="number">1</span>) &#123;</span><br><span class="line">        Node* old_next = prev-&gt;next;</span><br><span class="line">        n-&gt;next = old_next;</span><br><span class="line">        <span class="keyword">if</span> (<span class="built_in">compare_and_swap</span>(&amp;prev-&gt;next, old_next, n) == old_next)</span><br><span class="line">          <span class="keyword">return</span>;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    prev = prev-&gt;next;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>If only your program is using the machine, well written code with locks can be as fast (or faster) than lock-free code.<br />But there are situations where code with locks can suffer from tricky performance problems. Like multi-programmed situations where page faults, pre-emption, etc. can occur while thread is in a critical section</p></li></ol>]]></content>
      
      
      <categories>
          
          <category> Open Courses </category>
          
          <category> CMU 15-418 / Stanford CS149 Parallel Computing </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Parallelism </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>13. Implementing Synchronization</title>
      <link href="/2022/07/16/Courses/CS149/13-Implementing-Synchronization/"/>
      <url>/2022/07/16/Courses/CS149/13-Implementing-Synchronization/</url>
      
        <content type="html"><![CDATA[<h1 id="implementing-locks"><a class="markdownIt-Anchor" href="#implementing-locks"></a> Implementing locks</h1><ol><li>Three phases of a synchronization event：<br />Acquire method: How a thread attempts to gain access to protected resource?<br />Waiting algorithm: How a thread waits for access to be granted to shared resource?<br />Release method: How thread enables other threads to gain resource when its work in the synchronized region is complete?</li><li>Busy waiting (spinning): <code>while (condition X not true) ;</code></li><li>Blocking synchronization: <code>if (condition X not true) block until true;</code><br />If progress cannot be made because a resource cannot be acquired, it is desirable to free up execution resources for another thread and preempt the running thread.</li><li>Busy-waiting can be preferable to blocking if scheduling overhead is larger than expected wait time or processor’s resources are not needed for other tasks.<br />The later situation is often the case in a parallel program since we usually don’t oversubscribe a system when running a performance-critical parallel app</li><li>Desirable lock performance characteristics:<br /><strong>Low latency</strong>: If lock is free and no other processors are trying to acquire it, a processor should be able to acquire the lock quickly<br /><strong>Low interconnect traffic</strong>: If all processors are trying to acquire lock at once, they should acquire the lock in succession with as little traffic as possible<br /><strong>Scalability</strong>: Latency / traffic should scale reasonably with number of processors<br /><strong>Low storage cost</strong><br /><strong>Fairness</strong>: Avoid starvation or substantial unfairness. One ideal is that processors should acquire lock in the order they request access to it</li></ol><h2 id="test-and-set-lock"><a class="markdownIt-Anchor" href="#test-and-set-lock"></a> Test-and-set lock</h2><h3 id="simple-test-and-set-lock"><a class="markdownIt-Anchor" href="#simple-test-and-set-lock"></a> Simple test-and-set lock</h3><ol><li>The following spin lock has data race because LOAD-TEST-STORE is not atomic.<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">// Lock</span><br><span class="line">ld   R0, mem[addr]  // load word into R0</span><br><span class="line">cmp  R0, #0          // compare R0 to 0</span><br><span class="line">bnz  lock            // if nonzero jump to top</span><br><span class="line">st   mem[addr], #1  // set lock to 1</span><br><span class="line"></span><br><span class="line">// Unlock</span><br><span class="line">st   mem[addr], #0  // set lock to 0</span><br></pre></td></tr></table></figure></li><li>So we need an atomic test-and-set instruction<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">ts R0, mem[addr]  // load mem[addr] into R0</span><br><span class="line">                  // if mem[addr] is 0, set mem[addr] to 1</span><br><span class="line">                  </span><br><span class="line">// Lock</span><br><span class="line">ts   R0, mem[addr]  // load word into R0</span><br><span class="line">bnz  R0, lock        // if nonzero jump to top</span><br><span class="line"></span><br><span class="line">// Unlock</span><br><span class="line">st   mem[addr], #0  // store 0 to address</span><br></pre></td></tr></table></figure></li><li>Everytime a processor execute the <code>ts</code> instruction will send a BusRdX signal and invalidate the lock in all other processor’s cache. When there are many processors trying to execute on the same lock, the coherence traffic may be heavy.<br />This lock generates one invalidation per waiting processor per test.</li><li>Bus contention increases amount of time to transfer lock since lock holder must wait to acquire bus to release. Bus contention also slows down execution of critical section.</li><li>In x86, we can do the atomic compare and exchange by <code>lock cmpxchg src, dst</code> instruction. The <code>lock</code> prefix makes the operation atomic. The logic of the instruction is as followed:<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> (dst == %eax)  <span class="comment">// eax is the x86 accumulator register</span></span><br><span class="line">  ZF = <span class="number">1</span>          <span class="comment">// ZF is a flag registor</span></span><br><span class="line">dst = src <span class="keyword">else</span></span><br><span class="line">  ZF = <span class="number">0</span></span><br><span class="line">  %eax = dst</span><br></pre></td></tr></table></figure></li><li>Simple test-and-set lock has low latency (under low contention), high traffic, poor scaling, low storage cost (one int), no provisions for fairness.</li></ol><h3 id="test-and-set-lock-with-back-off"><a class="markdownIt-Anchor" href="#test-and-set-lock-with-back-off"></a> Test-and-set lock with back off</h3><ol><li><p>Upon failure to acquire lock, delay for awhile before retrying.</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">void</span> <span class="title">Lock</span><span class="params">(<span class="keyword">volatile</span> <span class="type">int</span>* lock)</span> </span>&#123;</span><br><span class="line">  <span class="type">int</span> amount = <span class="number">1</span>;</span><br><span class="line">  <span class="keyword">while</span> (<span class="number">1</span>) &#123;</span><br><span class="line">    <span class="keyword">if</span> (<span class="built_in">test_and_set</span>(lock) == <span class="number">0</span>)</span><br><span class="line">      <span class="keyword">return</span>;</span><br><span class="line">    <span class="built_in">delay</span>(amount);</span><br><span class="line">    amount *= <span class="number">2</span>;</span><br><span class="line">  &#125; </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>It has the same uncontended latency as test-and-set, but potentially higher latency under contention due to that the waiting processor may be still in delaying even when the lock is available.</p></li><li><p>It Generates less traffic than test-and-set since it is not continually attempting to acquire lock. It improves scalability due to less traffic.</p></li><li><p>Storage cost unchanged (still one int for lock)</p></li><li><p>Exponential back-off can cause severe unfairness. Newer requesters back off for shorter intervals</p></li></ol><h3 id="test-and-test-and-set-lock"><a class="markdownIt-Anchor" href="#test-and-test-and-set-lock"></a> Test-and-test-and-set lock</h3><ol><li><p>To prevent the coherence traffic problem, we can test first and do the test-and-set only if the earlier test has passed.</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">void</span> <span class="title">Lock</span><span class="params">(<span class="keyword">volatile</span> <span class="type">int</span>* lock)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">while</span> (<span class="number">1</span>) &#123;</span><br><span class="line">    <span class="keyword">while</span> (*lock != <span class="number">0</span>) ;</span><br><span class="line">    <span class="keyword">if</span> (<span class="built_in">test_and_set</span>(lock) == <span class="number">0</span>)</span><br><span class="line">      <span class="keyword">return</span>;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">Unlock</span><span class="params">(<span class="keyword">volatile</span> <span class="type">int</span>* lock)</span> </span>&#123;</span><br><span class="line">  *lock = <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>This lock has slightly higher latency than test-and-set in uncontended case, but generates much less interconnect traffic. Only One invalidation is generated per waiting processor per lock release.<br />Namely, only <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>O</mi><mo stretchy="false">(</mo><mi>P</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">O(P)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">O</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="mclose">)</span></span></span></span> invalidation and <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>O</mi><mo stretchy="false">(</mo><msup><mi>P</mi><mn>2</mn></msup><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">O(P^2)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.064108em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">O</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141079999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span> interconnect traffic.</p></li><li><p>It is more scalable due to less traffic, storage cost unchanged (still one int), and still no provisions for fairness.</p></li></ol><h2 id="ticket-lock"><a class="markdownIt-Anchor" href="#ticket-lock"></a> Ticket lock</h2><ol><li>The test-and-set style locks cannot provide for fairness because all waiting processors attempt to acquire lock using test-and-set upon release.</li><li>We can assign each thread a number when they try to acquire the lock. And everytime, we give the lock to the waiting thread with smallest number.<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">struct</span> <span class="title class_">lock</span> &#123;</span><br><span class="line">  <span class="keyword">volatile</span> <span class="type">int</span> next_ticket;</span><br><span class="line">  <span class="keyword">volatile</span> <span class="type">int</span> now_serving;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">Lock</span><span class="params">(lock* lock)</span> </span>&#123;</span><br><span class="line">  <span class="type">int</span> my_ticket = <span class="built_in">atomic_increment</span>(&amp;lock-&gt;next_ticket);  <span class="comment">// take a “ticket”</span></span><br><span class="line">  <span class="keyword">while</span> (my_ticket != lock-&gt;now_serving);                <span class="comment">//wait for number</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">unlock</span><span class="params">(lock* lock)</span> </span>&#123;</span><br><span class="line">  lock-&gt;now_serving++;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li>There is no atomic operation needed to acquire the lock. Only a read is needed when acquiring the lock, and write only happens when the lock is released. So only one invalidation is generated per lock release, namely <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>O</mi><mo stretchy="false">(</mo><mi>P</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">O(P)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">O</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="mclose">)</span></span></span></span> interconnect traffic.</li></ol><h2 id="array-based-lock"><a class="markdownIt-Anchor" href="#array-based-lock"></a> Array-based lock</h2><ol><li><p>Each processor spins on a different memory address. And utilizes atomic operation to assign address on attempt to acquire.<br />If there are two barriers, after some threads passed the first barrier, they might set the <code>flag</code> to 0 even if some other threads haven’t passed the first barrier yet causing those slower threads waiting.</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">struct</span> <span class="title class_">lock</span> &#123;</span><br><span class="line">  <span class="keyword">volatile</span> padded_int status[P];  <span class="comment">// padded to keep off same cache line</span></span><br><span class="line">  <span class="keyword">volatile</span> <span class="type">int</span> head;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="type">int</span> my_element;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">Lock</span><span class="params">(lock* lock)</span> </span>&#123;</span><br><span class="line">  my_element = <span class="built_in">atomic_circ_increment</span>(&amp;lock-&gt;head);  <span class="comment">// assume modular increment </span></span><br><span class="line">  <span class="keyword">while</span> (lock-&gt;status[my_element] == <span class="number">1</span>);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">unlock</span><span class="params">(lock* lock)</span> </span>&#123;</span><br><span class="line">  lock-&gt;status[my_element] = <span class="number">1</span>;</span><br><span class="line">  lock-&gt;status[<span class="built_in">circ_next</span>(my_element)] = <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>The lock only requires <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>O</mi><mo stretchy="false">(</mo><mn>1</mn><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">O(1)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">O</span><span class="mopen">(</span><span class="mord">1</span><span class="mclose">)</span></span></span></span> interconnect traffic per release, but requires space linear in <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>O</mi><mo stretchy="false">(</mo><mi>P</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">O(P)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">O</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="mclose">)</span></span></span></span>.</p></li><li><p>The atomic circular increment is a more complex operation. So the lock has a higher overhead.</p></li><li><p>Queue-based Lock (MCS lock): Create a queue of waiters. Each thread allocates a local space on which to wait.</p></li></ol><h1 id="implementing-barrier"><a class="markdownIt-Anchor" href="#implementing-barrier"></a> Implementing barrier</h1><ol><li>The following code uses <code>counter</code> to count how many threads have hit the barrier. The last thread hit the barrier wil release all of them.<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">struct</span> <span class="title class_">Barrier_t</span> &#123;</span><br><span class="line">   LOCK lock;</span><br><span class="line">  <span class="type">int</span> counter;  <span class="comment">// initialize to 0</span></span><br><span class="line">  <span class="type">int</span> flag;      <span class="comment">// the flag field should probably be padded to </span></span><br><span class="line">                <span class="comment">// sit on its own cache line. </span></span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="comment">// barrier for p processors</span></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">Barrier</span><span class="params">(Barrier_t* b, <span class="type">int</span> p)</span> </span>&#123;</span><br><span class="line">  <span class="built_in">lock</span>(b-&gt;lock);</span><br><span class="line">  <span class="keyword">if</span> (b-&gt;counter == <span class="number">0</span>) &#123;</span><br><span class="line">    b-&gt;flag = <span class="number">0</span>; <span class="comment">// first thread arriving at barrier clears flag </span></span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="type">int</span> num_arrived = ++(b-&gt;counter);</span><br><span class="line">  <span class="built_in">unlock</span>(b-&gt;lock);</span><br><span class="line"></span><br><span class="line">  <span class="keyword">if</span> (num_arrived == p) &#123; <span class="comment">// last arriver sets flag b-&gt;counter = 0;</span></span><br><span class="line">    b-&gt;flag = <span class="number">1</span>;</span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    <span class="keyword">while</span> (b-&gt;flag == <span class="number">0</span>); <span class="comment">// wait for flag</span></span><br><span class="line">  &#125; </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li>To solve the problem, we should wait for all processes to leave first barrier, before clearing flag for entry into the second<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Centralized barrier</span></span><br><span class="line"> </span><br><span class="line"><span class="keyword">struct</span> <span class="title class_">Barrier_t</span> &#123;</span><br><span class="line">  LOCK lock;</span><br><span class="line">  <span class="type">int</span> arrive_counter;  <span class="comment">// initialize to 0 (number of threads that have arrived)</span></span><br><span class="line">  <span class="type">int</span> leave_counter;  <span class="comment">// initialize to P (number of threads that have left barrier)</span></span><br><span class="line">  <span class="type">int</span> flag;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="comment">// barrier for p processors</span></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">Barrier</span><span class="params">(Barrier_t* b, <span class="type">int</span> p)</span> </span>&#123;</span><br><span class="line">  <span class="built_in">lock</span>(b-&gt;lock);</span><br><span class="line">  <span class="keyword">if</span> (b-&gt;arrive_counter == <span class="number">0</span>) &#123;   <span class="comment">// if first to arrive...</span></span><br><span class="line">    <span class="keyword">if</span> (b-&gt;leave_counter == P) &#123;  <span class="comment">// check to make sure no other threads “still in barrier”</span></span><br><span class="line">      b-&gt;flag = <span class="number">0</span>;               <span class="comment">// first arriving thread clears flag</span></span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">      <span class="built_in">unlock</span>(lock);</span><br><span class="line">      <span class="keyword">while</span> (b-&gt;leave_counter != P);  <span class="comment">// wait for all threads to leave before clearing</span></span><br><span class="line">      <span class="built_in">lock</span>(lock);</span><br><span class="line">      b-&gt;flag = <span class="number">0</span>;                <span class="comment">// first arriving thread clears flag</span></span><br><span class="line">    &#125; </span><br><span class="line">  &#125;</span><br><span class="line">  <span class="type">int</span> num_arrived = ++(b-&gt;arrive_counter);</span><br><span class="line">  <span class="built_in">unlock</span>(b-&gt;lock);</span><br><span class="line">  <span class="keyword">if</span> (num_arrived == p) &#123;  <span class="comment">// last arriver sets flag</span></span><br><span class="line">    b-&gt;arrive_counter = <span class="number">0</span>;</span><br><span class="line">    b-&gt;leave_counter = <span class="number">1</span>;</span><br><span class="line">    b-&gt;flag = <span class="number">1</span>;</span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    <span class="keyword">while</span> (b-&gt;flag == <span class="number">0</span>);  <span class="comment">// wait for flag</span></span><br><span class="line">    <span class="built_in">lock</span>(b-&gt;lock);</span><br><span class="line">    b-&gt;leave_counter++;</span><br><span class="line">    <span class="built_in">unlock</span>(b-&gt;lock);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li>We can save one variable by sense reversal. Processors wait for flag to be equal to local sense.<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">struct</span> <span class="title class_">Barrier_t</span> &#123;</span><br><span class="line">  LOCK lock;</span><br><span class="line">  <span class="type">int</span> counter; <span class="comment">// initialize to 0</span></span><br><span class="line">  <span class="type">int</span> flag; <span class="comment">// initialize to 0</span></span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="type">int</span> local_sense = <span class="number">0</span>;  <span class="comment">// private per processor</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// barrier for p processors</span></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">Barrier</span><span class="params">(Barrier_t* b, <span class="type">int</span> p)</span> </span>&#123;</span><br><span class="line">  local_sense = (local_sense == <span class="number">0</span>) ? <span class="number">1</span> : <span class="number">0</span>; <span class="built_in">lock</span>(b-&gt;lock);</span><br><span class="line">  <span class="type">int</span> num_arrived = ++(b-&gt;counter);</span><br><span class="line">  <span class="keyword">if</span> (b-&gt;counter == p) &#123; <span class="comment">// last arriver sets flag</span></span><br><span class="line">    <span class="built_in">unlock</span>(b-&gt;lock);</span><br><span class="line">    b-&gt;counter = <span class="number">0</span>;</span><br><span class="line">    b-&gt;flag = local_sense;</span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    <span class="built_in">unlock</span>(b-&gt;lock);</span><br><span class="line">    <span class="keyword">while</span> (b-&gt;flag != local_sense); <span class="comment">// wait for flag</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li>There are <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>O</mi><mo stretchy="false">(</mo><mi>P</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">O(P)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">O</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="mclose">)</span></span></span></span> traffic on interconnect per barrier.<br />All threads have <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>2</mn><mi>P</mi></mrow><annotation encoding="application/x-tex">2P</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord">2</span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span></span></span></span> write transactions to obtain barrier lock and update counter. <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>O</mi><mo stretchy="false">(</mo><mi>P</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">O(P)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">O</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="mclose">)</span></span></span></span> traffic assuming lock acquisition is implemented in <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>O</mi><mo stretchy="false">(</mo><mn>1</mn><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">O(1)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">O</span><span class="mopen">(</span><span class="mord">1</span><span class="mclose">)</span></span></span></span> manner<br />Last thread has <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>2</mn></mrow><annotation encoding="application/x-tex">2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">2</span></span></span></span> write transactions to write to the flag and reset the counter. <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>O</mi><mo stretchy="false">(</mo><mi>P</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">O(P)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">O</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="mclose">)</span></span></span></span> traffic since there are many sharers of the flag<br /><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>P</mi><mo>−</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">P-1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.76666em;vertical-align:-0.08333em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">1</span></span></span></span> transactions to read updated flag</li><li>In centralized barrier, all threads share single barrier lock and counter, which causes high contention.</li><li>Combining trees make better use of parallelism in interconnect topologies, which has <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>l</mi><mi>o</mi><mi>g</mi><mi>P</mi></mrow><annotation encoding="application/x-tex">logP</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord mathnormal" style="margin-right:0.01968em;">l</span><span class="mord mathnormal">o</span><span class="mord mathnormal" style="margin-right:0.03588em;">g</span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span></span></span></span> span (latency). This strategy makes less sense on a bus where all traffic still serialized on single shared bus.<br />Barrier acquire: when processor arrives at barrier, performs increment of parent counter. Process recurses to root.<br />Barrier release: beginning from root, notify children of release</li></ol><h1 id="locks-in-cuda-assignment-3"><a class="markdownIt-Anchor" href="#locks-in-cuda-assignment-3"></a> Locks in CUDA (Assignment 3)</h1><ol><li><p>CUDA has provided <code>atomicCAS</code> and <code>atomicExch</code>. But if we use the following code to implement the mutex, threads will end up in a dead loop.<br />The reason is all warps in a block need to execute the same instructions. But only one thread can have the lock, namely at most one thread in a block can leave the loop, and hence the whole block, including the one with lock, will keep executing the <code>atomicCAS</code>. Obviously the thread with loop cannot execute anything in critical area and the unlock the lock, which causes all threads end up in the dead loop of <code>lock</code>.</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">__share__ <span class="type">int</span> mutex;</span><br><span class="line"></span><br><span class="line"><span class="function">__device__ <span class="type">void</span> <span class="title">lock</span><span class="params">(<span class="type">int</span>* mutex)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">  <span class="keyword">while</span>(<span class="built_in">atomicCAS</span>(mutex, <span class="number">0</span>, <span class="number">1</span>)) ;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function">__device__ <span class="type">void</span> <span class="title">unlock</span><span class="params">(<span class="type">int</span>* mutex)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">  <span class="built_in">atomicExch</span>(mutex, <span class="number">0</span>);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function">__global__ <span class="type">void</span> <span class="title">kernel</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">  <span class="built_in">lock</span>(&amp;mutex);</span><br><span class="line">  <span class="comment">// critical code</span></span><br><span class="line">  <span class="built_in">unlock</span>(&amp;mutex);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>The method to solve the problem also need to consider the special execution mode of condition instruction in CUDA. A loop is necessary, but we want to execute the instruction inside a condition body so that when one thread grabs the lock, it can execute and unlock the lock before the next iteration.<br />So we can have an <code>if</code> condition inside the loop as the following code.</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">__share__ <span class="type">int</span> mutex;</span><br><span class="line"></span><br><span class="line"><span class="function">__kernel__ <span class="type">void</span> <span class="title">kernel</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">  <span class="type">bool</span> leaveLoop = <span class="literal">false</span>;</span><br><span class="line">  <span class="keyword">while</span> (!leaveLoop)</span><br><span class="line">  &#123;</span><br><span class="line">    <span class="keyword">if</span> (<span class="built_in">atomicExch</span>(&amp;mutex, <span class="number">1</span>))</span><br><span class="line">    &#123;</span><br><span class="line">      <span class="comment">// critical cade</span></span><br><span class="line">      leaveLoop = <span class="literal">true</span>;      <span class="comment">// this thread can leave the loop, but it need to </span></span><br><span class="line">                             <span class="comment">// wait for other threads in its block</span></span><br><span class="line">      <span class="built_in">atomicExch</span>(&amp;mutex, <span class="number">0</span>); <span class="comment">// unlock the lock, so that in next iteration, </span></span><br><span class="line">                             <span class="comment">// some other threads can have the lock and finish</span></span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li></ol>]]></content>
      
      
      <categories>
          
          <category> Open Courses </category>
          
          <category> CMU 15-418 / Stanford CS149 Parallel Computing </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Parallelism </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>12. Interconnection Network</title>
      <link href="/2022/07/13/Courses/CS149/12-Interconnection-Network/"/>
      <url>/2022/07/13/Courses/CS149/12-Interconnection-Network/</url>
      
        <content type="html"><![CDATA[<h1 id="interconnection"><a class="markdownIt-Anchor" href="#interconnection"></a> Interconnection</h1><ol><li>All parallel processors are connected and form an interconnection network.</li><li>The interconnection network are used to connect processor cores with other cores, processors and memories, processor cores and caches, caches and caches, I/O devices.</li><li>The design of the interconnection network has an important impact on system scalability (How large of a system can be built? How easy is it to add more nodes?), system performance and energy efficiency (How fast can cores, caches, memory communicate? How long is latency to memory? How much energy is spent on communication?)</li></ol><h2 id="terminology"><a class="markdownIt-Anchor" href="#terminology"></a> Terminology</h2><ol><li><strong>Network node</strong>: a network endpoint connected to a router/switch, like the processor, the cache controller, or the memory controller</li><li><strong>Network interface</strong>: Connects nodes to the network</li><li><strong>Switch/router</strong>: Connects a fixed number of input links to a fixed number of output links</li><li><strong>Link</strong>: A bundle of wires carrying a signal<br /><img src="/imgs/CS149/12/1.png" width="40%"></li></ol><h2 id="design-issues"><a class="markdownIt-Anchor" href="#design-issues"></a> Design issues</h2><ol><li><strong>Topology</strong>: How switches are connected via links. Affects routing, throughput, latency, complexity/cost of implementation.</li><li><strong>Routing</strong>: How a message gets from its source to its destination in the network. Can be static (messages take a predetermined path) or adaptive based on load.</li><li><strong>Buffering and flow control</strong>: What data are stored in the network? packets, partial packets? etc. How does the network manage buffer space?</li></ol><h2 id="properties-of-interconnect-topology"><a class="markdownIt-Anchor" href="#properties-of-interconnect-topology"></a> Properties of interconnect topology</h2><ol><li><strong>Routing distance</strong>: Number of links (“hops”) along a route between two nodes</li><li><strong>Diameter</strong>: the maximum routing distance</li><li><strong>Average distance</strong>: average routing distance over all valid routes</li><li><strong>Direct network</strong>: The switches and nodes are one in the same. The logic of the switch is built into the node itself.</li><li><strong>Indirect network</strong>: The switches are distinct from the nodes that form a chain from one node to the other.</li><li><strong>Blocking or non-blocking</strong>: If connecting any pairing of node simultaneously won’t cause conflict (using the same link or the same switch, assuming that one switch can only handle on message at one time), the network is non-blocking. Otherwise, it is blocking.</li><li><strong>Bisection bandwidth</strong>: A measure of how much connectivity in the network. If we cut the network in half, it is the connection between those two halves, namely the sum bandwidth of all severed links.<br />The low bisection bandwidth will be the choke point of the network.</li><li>Latency increases with load (throughput).<br />The topology, routing algorithm and flow control each has their own min latency. The zero load or idle latency is the sum of the three min latencies.<br />Also, the topology, routing algorithm and flow control each has their own throughput limit. The overall throughput limit is the min of the three limits.</li></ol><h1 id="interconnect-topologies"><a class="markdownIt-Anchor" href="#interconnect-topologies"></a> Interconnect topologies</h1><h2 id="bus"><a class="markdownIt-Anchor" href="#bus"></a> Bus</h2><ol><li><p>Physically, a bus is a wire. But from graph point of view, a bus is a switch.</p></li><li><p>It is simple to design. It costs effective for a small number of nodes. It is easy to implement coherence via snooping</p></li><li><p>Contention: all nodes contend for shared bus</p></li><li><p>Limited bandwidth: all nodes communicate over same wires, and only one communication is allowed at a time.</p></li><li><p>There has a scalibility problem. It is expensive to drive wires across the whole chips. There is quite a lot of power in driving signals on the bus.</p><img src="/imgs/CS149/12/2.png" width="40%"></li></ol><h2 id="crossbar"><a class="markdownIt-Anchor" href="#crossbar"></a> Crossbar</h2><ol><li><p>Every node is connected to every other node by a direct connection. The network is non-blocking and indirect (the network is indirect, but the nodes are connected directly).</p></li><li><p>It has <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>O</mi><mo stretchy="false">(</mo><mn>1</mn><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">O(1)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">O</span><span class="mopen">(</span><span class="mord">1</span><span class="mclose">)</span></span></span></span> latency and high bandwidth.</p></li><li><p>It also has a scalability problem since <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>O</mi><mo stretchy="false">(</mo><msup><mi>N</mi><mn>2</mn></msup><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">O(N^2)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.064108em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">O</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.10903em;">N</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141079999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span> switches are required. Also it has high cost and is difficult to arbitrate at scale.</p></li><li><p>Crossbars were used in recent multi-core processing from Oracle. In a multi-core chip, the crossbar (CCX) occupies about the same chip area as a core.</p><img src="/imgs/CS149/12/3.png" width="40%"></li></ol><h2 id="ring"><a class="markdownIt-Anchor" href="#ring"></a> Ring</h2><ol><li><p>It lets the message to circle around.</p></li><li><p>It is simple enough and quite cheap with only <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>O</mi><mo stretchy="false">(</mo><mi>N</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">O(N)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">O</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.10903em;">N</span><span class="mclose">)</span></span></span></span> cost.</p></li><li><p>But the latency is <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>O</mi><mo stretchy="false">(</mo><mi>N</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">O(N)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">O</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.10903em;">N</span><span class="mclose">)</span></span></span></span>, which is very high. And the bisection bandwidth remains constant as nodes are added, which will cause the scalibility problem.</p></li><li><p>It is used in recent Intel architectures, Core i7, and in IBM CELL Broadband Engine. This is usually used on the scale of 4 or 8 elements on the ring.</p></li><li><p>The Intel’s ring interconnect has four rings (request, snoop, ack, 32 bytes of data) and six interconnect nodes (four “slices” of L3 cache, system agent, graphics). Each bank of L3 connected to ring bus twice.</p><img src="/imgs/CS149/12/4.png" width="40%"></li></ol><h2 id="mesh"><a class="markdownIt-Anchor" href="#mesh"></a> Mesh</h2><ol><li><p>This is a direct network. It echoes locality in grid-based applications.</p></li><li><p>The cost is <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>O</mi><mo stretchy="false">(</mo><mi>N</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">O(N)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">O</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.10903em;">N</span><span class="mclose">)</span></span></span></span>, and the average latency is <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>O</mi><mo stretchy="false">(</mo><msqrt><mi>N</mi></msqrt><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">O(\sqrt{N})</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.176665em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">O</span><span class="mopen">(</span><span class="mord sqrt"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.9266650000000001em;"><span class="svg-align" style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord" style="padding-left:0.833em;"><span class="mord mathnormal" style="margin-right:0.10903em;">N</span></span></span><span style="top:-2.886665em;"><span class="pstrut" style="height:3em;"></span><span class="hide-tail" style="min-width:0.853em;height:1.08em;"><svg width='400em' height='1.08em' viewBox='0 0 400000 1080' preserveAspectRatio='xMinYMin slice'><path d='M95,702c-2.7,0,-7.17,-2.7,-13.5,-8c-5.8,-5.3,-9.5,-10,-9.5,-14c0,-2,0.3,-3.3,1,-4c1.3,-2.7,23.83,-20.7,67.5,-54c44.2,-33.3,65.8,-50.3,66.5,-51c1.3,-1.3,3,-2,5,-2c4.7,0,8.7,3.3,12,10s173,378,173,378c0.7,0,35.3,-71,104,-213c68.7,-142,137.5,-285,206.5,-429c69,-144,104.5,-217.7,106.5,-221l0 -0c5.3,-9.3,12,-14,20,-14H400000v40H845.2724s-225.272,467,-225.272,467s-235,486,-235,486c-2.7,4.7,-9,7,-19,7c-6,0,-10,-1,-12,-3s-194,-422,-194,-422s-65,47,-65,47zM834 80h400000v40h-400000z'/></svg></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.11333499999999996em;"><span></span></span></span></span></span><span class="mclose">)</span></span></span></span>.</p></li><li><p>It is easy to lay out on chip since all links have a fixed-length.</p></li><li><p>Path diversity: many ways for message to travel from one node to another</p><img src="/imgs/CS149/12/5.png" width="40%"></li></ol><h2 id="torus"><a class="markdownIt-Anchor" href="#torus"></a> Torus</h2><ol><li><p>Characteristics of node in mesh topology are different based on whether node is near edge or middle of network. Torus topology introduces new links to avoid this problem.</p></li><li><p>In torus topology, each row or each column forms a ring by adding a new link to connect the two nodes on the edge.</p></li><li><p>Its cost is still <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>O</mi><mo stretchy="false">(</mo><mi>N</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">O(N)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">O</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.10903em;">N</span><span class="mclose">)</span></span></span></span>, but higher than 2D mesh. It also has higher path diversity and bisection bandwidth than mesh.</p></li><li><p>However, it has higher complexity and is difficult to layout on chip since its unequal link lengths.</p></li><li><p>Folded torus interleaving rows and columns to eliminate need for long connections. All connections are doubled in length.</p><img src="/imgs/CS149/12/6.png" width="40%"></li></ol><h2 id="tree"><a class="markdownIt-Anchor" href="#tree"></a> Tree</h2><ol><li><p>This is a planar, hierarchical topology. Like mesh/torus, it performs good when traffic has locality.</p></li><li><p>The latency is <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>O</mi><mo stretchy="false">(</mo><mi>l</mi><mi>o</mi><mi>g</mi><mi>N</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">O(logN)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">O</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.01968em;">l</span><span class="mord mathnormal">o</span><span class="mord mathnormal" style="margin-right:0.03588em;">g</span><span class="mord mathnormal" style="margin-right:0.10903em;">N</span><span class="mclose">)</span></span></span></span></p></li><li><p>In tree routing, if the signal need to go upward, there is only one option. If the signal need to go downward, we can use <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>0</mn></mrow><annotation encoding="application/x-tex">0</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">0</span></span></span></span> to mark go left while <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1</mn></mrow><annotation encoding="application/x-tex">1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">1</span></span></span></span> to mark go right.<br />Everytime, the signal will go upward first until have a common ancestor, then it will go downward.<br />If the tree is a complete tree and we assign numbers to the nodes accroding to their inorder traversal starting from zero, then the way to each node from root node is the binary code of the number.</p></li><li><p>Fat tree increases bandwidth between nodes as move upward. It can alleviate root bandwidth problem with higher bandwidth links near root.</p></li><li><p>The number of wires is the same to the height of the subtree. So the bisection bandwidth of fat tree is <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>O</mi><mo stretchy="false">(</mo><mi>N</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">O(N)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">O</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.10903em;">N</span><span class="mclose">)</span></span></span></span>.</p></li><li><p>The fat tree routing is similar to tree routing, but randomly choose when multiple links possible.</p></li><li><p>Constant-width fat tree (folded clos network): All nodes fixed degree, which makes the hardware design simpler. This is used in Infiniband networks.</p><p><img src="/imgs/CS149/12/7.png" width="30%"><img src="/imgs/CS149/12/8.png" width="30%"><img src="/imgs/CS149/12/9.png" width="30%"></p></li></ol><h2 id="hypercube"><a class="markdownIt-Anchor" href="#hypercube"></a> Hypercube</h2><ol><li><p>It has a low latency of <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>O</mi><mo stretchy="false">(</mo><mi>l</mi><mi>o</mi><mi>g</mi><mi>N</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">O(logN)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">O</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.01968em;">l</span><span class="mord mathnormal">o</span><span class="mord mathnormal" style="margin-right:0.03588em;">g</span><span class="mord mathnormal" style="margin-right:0.10903em;">N</span><span class="mclose">)</span></span></span></span>. Its number of links is <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>O</mi><mo stretchy="false">(</mo><mi>N</mi><mi>l</mi><mi>o</mi><mi>g</mi><mi>N</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">O(NlogN)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">O</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.10903em;">N</span><span class="mord mathnormal" style="margin-right:0.01968em;">l</span><span class="mord mathnormal">o</span><span class="mord mathnormal" style="margin-right:0.03588em;">g</span><span class="mord mathnormal" style="margin-right:0.10903em;">N</span><span class="mclose">)</span></span></span></span>.</p></li><li><p>6D hypercube used in 64-core Cosmic Cube computer developed at Caltech in the 80s.</p></li><li><p>If the address of two nodes only differs by one bit, then there is a link connecting them.<br />So is we want to go from address A to address B, we just do it one bit a time.</p></li><li><p>The problem is that we cannot pack more dimensions to 3D that exists. To implement a higher dimension cube, we need to put enough wires in to make it work. But as we scale up more and more, the wires becomes so much that doesn’t layout well.</p><img src="/imgs/CS149/12/10.png" width="40%"></li></ol><h2 id="multi-stage-logarithmic"><a class="markdownIt-Anchor" href="#multi-stage-logarithmic"></a> Multi-stage logarithmic</h2><ol><li><p>It is an indirect network with multiple switches between terminals.</p></li><li><p>The cost is <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>O</mi><mo stretchy="false">(</mo><mi>N</mi><mi>l</mi><mi>o</mi><mi>g</mi><mi>N</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">O(NlogN)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">O</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.10903em;">N</span><span class="mord mathnormal" style="margin-right:0.01968em;">l</span><span class="mord mathnormal">o</span><span class="mord mathnormal" style="margin-right:0.03588em;">g</span><span class="mord mathnormal" style="margin-right:0.10903em;">N</span><span class="mclose">)</span></span></span></span> while the latency is <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>O</mi><mo stretchy="false">(</mo><mi>l</mi><mi>o</mi><mi>g</mi><mi>N</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">O(logN)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">O</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.01968em;">l</span><span class="mord mathnormal">o</span><span class="mord mathnormal" style="margin-right:0.03588em;">g</span><span class="mord mathnormal" style="margin-right:0.10903em;">N</span><span class="mclose">)</span></span></span></span>.</p></li><li><p>It has many variations: Omega, butterfly, Clos networks, etc.</p></li><li><p>In the topology shown below, each switch has two output wires. In the routing, if 0 stands for up and 1 for down, we can also routing according to the binary code of the number of targeting node.<br />Here up means that we will take the upper wire, and down means that we will take the lower wire. They don’t always means going up or going down.</p><img src="/imgs/CS149/12/11.png" width="40%"></li></ol><h1 id="buffering-and-flow-control"><a class="markdownIt-Anchor" href="#buffering-and-flow-control"></a> Buffering and flow control</h1><ol><li>Circuit switching sets up a full path (acquires all resources) between sender and receiver prior to sending a message. It has higher bandwidth transmission.<br />It has no per-packet link management overhead, but does incur overhead to set up/tear down path. And reserving links can result in low utilization.</li><li>Packet switching makes routing decisions per packet. It has an opportunity to use link for a packet whenever link is idle.<br />It has overhead due to dynamic switching logic during transmission, but no setup/tear down overhead.</li><li>The granularity of communication from larger to miner is message, packet and flit<br />Message is the unit of transfer between network clients, and can be transmitted using many packets.<br />Packet is the unit of transfer for network, and can be transmitted using multiple flits.<br />Flit (flow control digit) is a unit of flow control in the network. Packets broken into flits.</li><li>A packet consists of header, payload/body and tail.<br />Header contains routing and control information, and is at start of packet to router can start forwarding early.<br />Payload/body contains the data to be sent.<br />Tail contains control information, like error code, and is generally located at end of packet so it can be generated “on the way out”.</li><li>When two packets need to be routed onto the same outbound link at the same time, contention is occurred. There are three options buffer one packet and send it over link later, drop one packet, or reroute one packet (deflection).</li></ol><h2 id="circuit-switched-routing"><a class="markdownIt-Anchor" href="#circuit-switched-routing"></a> Circuit-switched routing</h2><ol><li>Main idea: pre-allocate all resources (links across multiple switches) along entire network path for a message (“setup a flow”)</li><li>Costs:<br />Needs setup phase (“probe”) to set up the path (and to tear it down and release<br />the resources when message complete)<br />Lower link utilization. Transmission of two messages cannot share same link (even if some resources on a preallocated path are no longer utilized during a transmission)</li><li>Benefits:<br />No contention during transmission due to preallocation, so no need for buffering<br />Arbitrary message sizes (once path is set up, send data until done)</li></ol><h2 id="packet-based-flow-control"><a class="markdownIt-Anchor" href="#packet-based-flow-control"></a> Packet-based flow control</h2><ol><li>Store-and-forward: Packet copied entirely into network switch before moving to next node, which requires buffering for entire packet in each router</li><li>Flow control unit is an entire packet. Different packets from the same message can take different routes, but all data in a packet is transmitted over the same route</li><li>Store-and-forward has high per-packet latency. Its latency <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>=</mo></mrow><annotation encoding="application/x-tex">=</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.36687em;vertical-align:0em;"></span><span class="mrel">=</span></span></span></span> packet transmission time on link <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>×</mo></mrow><annotation encoding="application/x-tex">\times</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.66666em;vertical-align:-0.08333em;"></span><span class="mord">×</span></span></span></span> network distance)</li><li>Cut-through flow control: Switch starts forwarding data on next link as soon as packet header is received, since header determines how much link bandwidth packet requires and where to route.</li><li>Cut-through flow control reduces transmission latency and reduces to store-and-forward under high contention.</li><li>The latency of cut-through flow control is header transmission time <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>×</mo></mrow><annotation encoding="application/x-tex">\times</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.66666em;vertical-align:-0.08333em;"></span><span class="mord">×</span></span></span></span> network distance <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>+</mo></mrow><annotation encoding="application/x-tex">+</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.66666em;vertical-align:-0.08333em;"></span><span class="mord">+</span></span></span></span> rest packet transmission time on one link <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>≃</mo></mrow><annotation encoding="application/x-tex">\simeq</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.46375em;vertical-align:0em;"></span><span class="mrel">≃</span></span></span></span> network distance <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>+</mo></mrow><annotation encoding="application/x-tex">+</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.66666em;vertical-align:-0.08333em;"></span><span class="mord">+</span></span></span></span> number of packets.</li><li>The difference between store-and-forward and cut-through is whether we parallel the transmission of header and the rest of the packet.</li><li>In cut-through flow control, if output link is blocked (cannot transmit head), transmission of tail can continue. So the switch need to store more data before it can transmit and delete them, which requires switches to have buffering for entire packet, just like store-and-forward.<br />The worst case is that entire message is absorbed into a buffer in a switch, namely cut-through flow control degenerates to store-and-forward in this case.</li></ol><h2 id="wormhole-flow-contorl"><a class="markdownIt-Anchor" href="#wormhole-flow-contorl"></a> Wormhole flow contorl</h2><ol><li>Routing information only in head flit, body flits follows head, and tail flit flows body. It looks like that all flits moves to their next switch simultaneously. If head flit blocks, rest of packet stops.</li><li>Its latency <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>=</mo></mrow><annotation encoding="application/x-tex">=</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.36687em;vertical-align:0em;"></span><span class="mrel">=</span></span></span></span> header transmission time <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>×</mo></mrow><annotation encoding="application/x-tex">\times</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.66666em;vertical-align:-0.08333em;"></span><span class="mord">×</span></span></span></span></li><li>Head-of-line blocking problem: The route of the head flit of one packet is free, but blocked behind flit of another packet in buffer while that packet is blocked waiting for a busy link.</li><li>Virtual channel flow control: Multiplex multiple operations over single physical channel, and divide switch’s input buffer into multiple buffers sharing a single physical channel.</li><li>Virtual channel reduces head-of-line blocking.<br />It can break cyclic dependency of resources by ensuring requests and responses use different virtual channels to avoid deadlock.<br />Also, it provided quality-of-service guarantees. Some virtual channels have higher priority than others</li><li>“Escape” virtual channels: retain at least one virtual channel that uses deadlock-free routing</li></ol>]]></content>
      
      
      <categories>
          
          <category> Open Courses </category>
          
          <category> CMU 15-418 / Stanford CS149 Parallel Computing </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Parallelism </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>11. Memory Consistency</title>
      <link href="/2022/07/10/Courses/CS149/11-Memory-Consistency/"/>
      <url>/2022/07/10/Courses/CS149/11-Memory-Consistency/</url>
      
        <content type="html"><![CDATA[<h1 id="consistency"><a class="markdownIt-Anchor" href="#consistency"></a> Consistency</h1><h2 id="definition"><a class="markdownIt-Anchor" href="#definition"></a> Definition</h2><ol><li>In a correct behaviored parallel memory hierachy, reading a location should return the latest value written by any thread.<br />Side-effects of writes are only observable when reads occur, so we will focus on the values returned by reads.</li><li>Within a thread, “latest” can be defined by program order. But when it comes across threads, we don’t want it be physical time, because there is no way that the hardware can pull that off. If it takes &gt;10 cycles to communicate between processors, there is no way that processor 0 can know what processor 1 did 2 clock ticks ago.</li><li>Writes from any particular thread must be consistent with program order. And writes across threads must be consistent with a valid interleaving of threads.<br />We define the memory model that each thread proceeds in program order, and memory accesses interleaved (one at a time) to a single-ported memory while rate of progress of each thread is unpredictable.<br />“Latest” means consistent with some interleaving that matches this model</li></ol><h2 id="hide-memory-latency"><a class="markdownIt-Anchor" href="#hide-memory-latency"></a> Hide memory latency</h2><ol><li>Idea: overlap memory accesses with other accesses and computation</li><li>“Out of order” pipelining: When an instruction is stuck, perhaps there are subsequent instructions that can be executed.</li><li>We don’t need to wait for a conditional branch to be resolved before proceeding. Just predict the branch outcome and continue executing speculatively. If prediction is wrong, squash any side-effects and restart down correct path.</li><li>Modern processors fetch and graduate instructions in-order, but issue out-of-order. So intra-thread dependences are preserved, but memory accesses get reordered.</li><li>Hiding write latency is simple in uniprocessors, adding a write buffer. But this affects correctness in multiprocessors.<br />In multiprocessor, write buffer or write-back cache might cause that later writes write earlier to memory, namely accesses issued in order may be observed out of order by other processors.</li></ol><h1 id="sequential-consistency-sc-model"><a class="markdownIt-Anchor" href="#sequential-consistency-sc-model"></a> Sequential consistency (SC) model</h1><ol><li>Accesses of each processor in program order, all accesses appear in sequential order. Any order implicitly assumed by programmer is maintained. Any order implicitly assumed by programmer is maintained.</li><li>How to implement sequential consistency:<br />Implement cache coherence: writes to the same location are observed in same order by all processors<br />For each processor, delay start of memory access until previous one completes, namely each processor has only one outstanding memory access at a time</li><li>A read completes when its return value is bound.<br />A write completes when the new value is “visible” to other processors. “Visible” does not mean that other processors have necessarily seen the value yet. It means the new value is committed to the hypothetical serializable order (HSO).</li><li>The strict requirements of SC model severely restrict common hardware and compiler optimizations.<br />Processor issues accesses one-at-a-time and stalls for completion, which results the Low processor utilization even with caching.</li><li>Total store ordering (TSO) model: Comparing to SC model, a read operation doesn’t need to stall for waiting an earlier write operation. This is similar to the architecture with a FIFO write buffer.</li><li>Partial store ordering (PSO) model: Comparing to TSO model, even a write operation doesn’t need to stall for waiting an earlier write operation. This is an architecture with a write buffer that doesn’t have to be FIFO.</li></ol><h1 id="optimization"><a class="markdownIt-Anchor" href="#optimization"></a> Optimization</h1><ol><li>Most programs don’t require strict ordering (all of the time) for correctness. Here correctness means same results as sequential consistency.</li><li>Two accesses conflict if they access same location, and at least one is a write.</li><li>We can order accesses by program order (po) and dependence order (do). Operation2 dependents on operation1 if operation2 reads operation1.</li><li>Data Race is that two conflicting accesses on different processors, not ordered by intervening accesses.</li><li>Properly Synchronized Programs is that all synchronizations are explicitly identified and all data accesses are ordered through synchronization.</li><li>Many parallel programs have mixtures of “private” and “public” parts.  The “private” parts must be protected by synchronization,  like locks and unlocks.<br />Between synchronization operations, we can allow reordering of memory operations as long as intra-thread dependences are preserved.<br />Just before and just after synchronization operations, thread must wait for all prior operations to complete</li><li>MFENCE does not begin until all prior reads &amp; writes from that thread have completed, and no subsequent read or write from that thread can start until after it finishes. Xchg does this implicitly.<br />MFENCE operation does not push values out to other threads. It simply stalls the thread that performs the MFENCE until write buffer empty.<br />MFENCE operations create partial orderings that are observable across threads.</li><li>In weak ordering model, we put MFENCEs before lock operation and after unlock operation.</li><li>Lock operation: only gains (“acquires”) permission to access data. Unlock operation: only gives away (“releases”) permission to access data.<br />Release Consistency (RC) model make sure writes before the lock or in the critical section completed before exit critical section, and make sure reads/writes in the critical section or after exit critical section don’t access shared state until lock acquired.</li><li>LFENCE serializes only with respect to load operations, and SFENCE serializes only with respect to store operations. In practice MFENCE and xchg are the most likely used ones.</li><li>Don’t use only normal memory operations for synchronization, like Peterson’s algorithm. Do use either explicit synchronization operations, like xchg (atomic), or fences.</li></ol>]]></content>
      
      
      <categories>
          
          <category> Open Courses </category>
          
          <category> CMU 15-418 / Stanford CS149 Parallel Computing </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Parallelism </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>10. Snooping Implementation</title>
      <link href="/2022/07/07/Courses/CS149/10-Snooping-Implementation/"/>
      <url>/2022/07/07/Courses/CS149/10-Snooping-Implementation/</url>
      
        <content type="html"><![CDATA[<h1 id="building-with-an-atomic-bus"><a class="markdownIt-Anchor" href="#building-with-an-atomic-bus"></a> Building with an atomic bus</h1><h2 id="transaction"><a class="markdownIt-Anchor" href="#transaction"></a> Transaction</h2><ol><li>There is a bus controller to do arbitration. If a processor wants to communicate on the bus, it has to make a request. If there are simultaneous requests from multiple processors, the arbiter will only grant one of them.</li><li>A transaction on an atomic bus generally need four steps.<br />Client is granted bus access (result of arbitration). The client places command on bus (may also place data on bus).<br />Response to command by another bus client placed on bus. Next client obtains bus access (arbitration)</li><li>In a multi-processor with atomic bus scenario, no other bus transactions is allowed between issuing address and receiving data when one processor want to read. Also, when flush is occurred, address and data are sent simultaneously, received by memory before any other transaction is allowed.</li><li>Both requests from processor and bus require to look the tag on cache.<br />If bus receives priority, during bus transaction, processor is locked out from its own cache.<br />If processor receives priority, during processor cache accesses, cache cannot respond with its snoop result. So it delays other processors even if no sharing of any form is present.</li><li>We can alleviate contention to allow simultaneous access by processor-side and snoop controllers through cache duplicate tags or multi-ported tag memory. In either case cost of the additional performance is additional hardware resources.<br />Tags must stay in sync for correctness, so tag update by one controller will still need to block the other controller, but modifying tags is infrequent compared to checking them.</li></ol><h2 id="read-miss"><a class="markdownIt-Anchor" href="#read-miss"></a> Read miss</h2><ol><li>When a cache read miss occurred, memory needs to know what to do. If the line is dirty, memory should not respond. And the loading cache needs to know what to do. If the line is shared, cache should load into S state, not E.</li><li>If one cache controller find that the line is shared in its cache, the controller will send a message through the “shared” wire on bus. If that line is dirty, the controller will send a message through the “dirty” wire on bus.<br />Everytime a processor has responded a snoop, the value in “snoop-pending” wire will be lower and <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>0</mn></mrow><annotation encoding="application/x-tex">0</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">0</span></span></span></span> value indicates that all processors have responded.</li><li>Memory controller could immediately start accessing DRAM, but not respond (squelch response). If a snoop result from another cache indicates it has copy of most recent data, then cache should provide data, not memory. Memory could assume one of the caches will service request until snoop results are valid. If snoop indicates no cache has data, then memory must respond</li></ol><h2 id="write-back"><a class="markdownIt-Anchor" href="#write-back"></a> Write back</h2><ol><li>Write backs involve two bus transactions, incoming line (line requested by processor) and outgoing line (evicted dirty line in cache that must be flushed).<br />Ideally would like the processor to continue as soon as possible, namely it shouldn’t have to wait for the flush to complete.</li><li>The solution is write-back buffer.<br />Stick line to be flushed in a write-back buffer. Immediately load requested line to allow processor to continue. Flush contents of write-back buffer at a later time.</li><li>If a request of another processor for the address of the data in the write-back buffer appears on the bus, snoop controller must check the write-back buffer addresses in addition to cache tags.<br />If there is a write-back buffer match, the controller will respond with data from write- back buffer rather than cache and cancel outstanding bus access request.</li><li>A write commits when a read-exclusive transaction appears on bus and is acknowledged by all other caches. All future reads will reflect the value of this write, even if data from P has not yet been written to P’s dirty cache line, or to memory.<br />Order of transactions on the bus defines the global order of writes in the parallel program.</li><li>“Commit” is not “complete”. A write completes when the updated value is in the cache line</li></ol><h2 id="race-conditions"><a class="markdownIt-Anchor" href="#race-conditions"></a> Race conditions</h2><ol><li>Coherence protocol state transition diagrams assumed that transitions between states were atomic. However, in practice state transitions are not atomic.</li><li>We’ve assumed the bus transaction itself is atomic, but all the operations the system performs as a result of a memory operation are not.</li><li>Processor, cache, and bus all are resources operating in parallel. They often contend for shared resources: processor and bus contend for cache while caches contend for bus access.</li><li>Cache must be able to handle requests while waiting to acquire bus AND be able to modify its own outstanding requests.</li><li>To avoid deadlock, processor must be able to service incoming transactions while waiting to issue requests.</li><li>To avoid livelock, a write that obtains exclusive ownership must be allowed to complete before exclusive ownership is relinquished.</li><li>Multiple processors competing for bus access must be careful to avoid (or minimize likelihood of) starvation.</li><li>Performance optimization often entails splitting operations into several, smaller transactions. Splitting costs in more hardware needed to exploit additional parallelism, and care needed to ensure abstractions still hold.</li></ol><h1 id="building-with-non-atomic-bus"><a class="markdownIt-Anchor" href="#building-with-non-atomic-bus"></a> Building with non-atomic bus</h1><ol><li>Problem with atomic bus: bus is idle while response is pending, which decreases effective bus bandwidth. The interconnect is a limited, shared resource in a multi-processor system. So it is important to use it as efficiently as possible.</li><li>Bus transactions are split into two transactions, the request and the response. Other transactions can intervene between a transaction’s request and response.</li><li>Basic design:<br />Up to eight outstanding requests at a time (system wide)<br />Responses need not occur in the same order as requests. But request order establishes the total order for the system<br />Flow control via negative acknowledgements (NACKs). When a buffer is full, client can NACK a transaction, causing a retry</li><li>We can think of a split-transaction bus as two separate buses, a request bus and a response bus.<br />The request bus has lines for command and address. The response bus has lines for data and response tag. Response tag has 3 bits to represent 8 requests.</li></ol><h2 id="read-miss-2"><a class="markdownIt-Anchor" href="#read-miss-2"></a> Read miss</h2><h3 id="phase-1"><a class="markdownIt-Anchor" href="#phase-1"></a> Phase 1</h3><ol><li>Request arbitration: cache controllers present request for address to bus (many caches may be doing so in the same cycle)</li><li>Request resolution: address bus arbiter grants access to one of the requestors. Request table entry allocated for request. Special arbitration lines indicate tag assigned to request.</li><li>Bus “winner” places command/address on the bus.</li><li>Caches perform snoop: look up tags, update cache state, etc. Memory operation commits here. (no bus traffic)</li><li>Caches acknowledge this snoop result is ready, or signal they could not complete snoop in time here.</li></ol><h3 id="phase-2"><a class="markdownIt-Anchor" href="#phase-2"></a> Phase 2</h3><ol><li>Data response arbitration: responder presents intent to respond to request with tag T. (many caches or memory may be doing so in the same cycle)</li><li>Data bus arbiter grants one responder bus access.</li><li>Original requestor signals readiness to receive response (or lack thereof: requestor may be busy at this time)</li><li>Then in phase 3, Responder places response data on data bus. Caches present snoop result for request with the data. Request table entry is freed. Those 3 actions can happen parallel.</li></ol><h2 id="pipelined-transactions"><a class="markdownIt-Anchor" href="#pipelined-transactions"></a> Pipelined transactions</h2><ol><li>Request bus and response bus can run parallel. So the response of the last transaction and the request of the next transaction can happen simultaneously. Pipelining may cause out-of-order completion.</li><li>Write backs and BusUpg transactions do not have a response component. Write backs acquire access to both request address bus and data bus as part of “request” phase BusUpg does not need any acknowledgement or data.</li><li>Avoid conflicting requests by disallowing them. Each cache has a copy of the request table. Caches do not make requests that conflict with requests in the request table.</li><li>Caches/memory have buffers for receiving data off the bus. If the buffer fills, client NACKs relevant requests or responses.</li><li>In parallel system, we use queues to accommodate variable (unpredictable) rates of production and consumption. As long as workers, on average, produce and consume at the same rate, all workers can run at full rate. Otherwise, some will stall waiting for others to accept or produce new input.</li><li>We have queues to track requests and responses between L1 and L2 caches and between L2 cache and bus. One queue is for requests and responses from closer (to processor) to farther (L1 to L2 or L2 to bus), and the other is from farther to closer (L2 to L1 or bus to L2).</li><li>This may rise deadlock due to full queue. Outgoing read request (initiated by processor) and incoming read request (due to another cache) both requests generate responses that require space in the other queue (circular dependency)</li><li>Sizing all buffers to accommodate the maximum number of outstanding requests on bus is one solution to avoiding deadlock. But a costly one.</li><li>Avoiding buffer deadlock with separate request/response queues. Namely, we distinguish whether it is a request or a response.<br />Responses can be completed without generating further transactions. Requests increase queue length But responses reduce queue length. While stalled attempting to send a request, cache must be able to service responses. Responses will make progress, eventually freeing up resources for requests.</li></ol>]]></content>
      
      
      <categories>
          
          <category> Open Courses </category>
          
          <category> CMU 15-418 / Stanford CS149 Parallel Computing </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Parallelism </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>09. Directory-Based Cache Cohurence</title>
      <link href="/2022/07/06/Courses/CS149/09-Directory-Based-Cache-Cohurence/"/>
      <url>/2022/07/06/Courses/CS149/09-Directory-Based-Cache-Cohurence/</url>
      
        <content type="html"><![CDATA[<h1 id="problems-to-solve"><a class="markdownIt-Anchor" href="#problems-to-solve"></a> Problems to solve</h1><ol><li>The snooping cache coherence protocols relied on broadcasting coherence information to all processors over the chip interconnect. Every time a cache miss occurred, the triggering cache communicated with all other caches, so the interconnect has a heavy traffic.</li><li>The efficiency of NUMA system does little good if the coherence protocol can’t also be scaled. Processor accesses nearby memory, but to ensure coherence still must broadcast to all other processors.</li><li>One possible solution is hierarchical snooping which arranges nodes in a tree and uses snooping coherence at each level. The interconnects involved in a communication is as low as possible and kept as local as possible.</li><li>The structure of hierarchical snooping is relatively simple to build.<br />It uses a tree to reduce the conjunction at the center part, but if the workload is not nicely partitioned, then the root of the network can become a bottleneck.<br />It also has larger latencies than direct communication and does not apply to more general network topologies (meshes, cubes)</li></ol><h1 id="directory"><a class="markdownIt-Anchor" href="#directory"></a> Directory</h1><ol><li>Snooping schemes broadcast coherence messages to determine the state of a line in the other caches. An alternative idea is to avoid broadcast by storing information about the status of the line in one place, namely a “directory”.</li><li>A line is a region of memory that would be cached as a single block. One directory entry corresponds to one line of memory.<br />In a directory entry, there are a dirty bit that indicates line is dirty in one of the processors’ caches and P presence bits that indicate whether processor P has line in its cache.</li><li>The directory is used in NUMA system, each processor has a “local” memory and a directory.<br />Home node of a line is the node with memory holding the corresponding data for the line.<br />Requesting node is the node containing processor requesting line</li></ol><h2 id="read-and-write"><a class="markdownIt-Anchor" href="#read-and-write"></a> Read and write</h2><ol><li>When a read miss happens:<br />The requesting node will send a read miss message to the home node of the requested line. Then home directory checks entry for line.<br />If dirty bit for cache line is OFF, the home node will respond with contents from memory, set presence bit of the requesting node to true to indicate line is cached by the requesting processor.<br />If dirty bit for cache line is ON, the home node will respond with message providing identity of line owner. Requesting node requests data from owner and owner changes state in cache to SHARED (read only), responds to requesting node. Owner also responds to home node, home clears dirty, updates presence bits (line is cached by both the requesting node and owner), updates memory.</li><li>When a write miss happens:<br />The requesting node will send a write miss message to the home node of the requested line.<br />The home node will response the sharer ids and data to the requesting node.<br />The requesting node will send invalidation signal to all sharers. After receiving invalidation acks from all sharers, the requesting node can perform write.<br />The home node will update presence bits (line is cached by only the requesting node) and dirty bit.</li><li>On reads, directory tells requesting node exactly where to get the line from, either from home node (if the line is clean) or from the owning node (if the line is dirty). Either way, retrieving data involves only point-to-point communication.</li><li>On writes, the advantage of directories depends on the number of sharers. In the limit, if all caches are sharing data, all caches must be communicated with, just like broadcast in a snooping protocol.</li><li>In general only a few processors share the line, namely only a few processors must be told of writes.  And the expected number of sharers typically increases slowly with P.</li></ol><h2 id="reduce-storage-overhead"><a class="markdownIt-Anchor" href="#reduce-storage-overhead"></a> Reduce storage overhead</h2><ol><li>Full bit vector directory storage is proportional to <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>P</mi><mo>×</mo><mi>M</mi></mrow><annotation encoding="application/x-tex">P\times M</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.76666em;vertical-align:-0.08333em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">M</span></span></span></span> where <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>P</mi></mrow><annotation encoding="application/x-tex">P</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span></span></span></span> is the number of nodes and <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>M</mi></mrow><annotation encoding="application/x-tex">M</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">M</span></span></span></span> is the number of lines in memory. The storage overhead of directory is too much, and we do not want it to be DRAM since we need it to run fast.</li><li>One way to reduce storage overhead is to optimize on full-bit vector.<br />Increase cache line size to reduce <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>M</mi></mrow><annotation encoding="application/x-tex">M</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">M</span></span></span></span> term.<br />Group multiple processors into a single directory node to reduce <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>P</mi></mrow><annotation encoding="application/x-tex">P</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span></span></span></span> term. We could use snooping protocol to maintain coherence among processors in a node, directory across nodes.</li><li>Another way is to limit sharer pointer. Since data is expected to only be in a few caches at once, storage for a limited number of pointers per directory entry should be sufficient. Only need a list of the nodes holding a valid copy of the line.</li><li>When an overflow in limited pointer schemes occurs, we can revert to broadcast if broadcast mechanism exists. If no broadcast mechanism present on machine, newest sharer replaces an existing one (must invalidate line in the old sharer’s cache)</li><li>One more way is through sparse directory.<br />The majority of memory is not resident in cache. And to carry out coherence protocol the system only needs sharing information for lines that are currently in some cache. So most directory entries are empty most of the time.<br />We can add a tag for each directory line to indicate the memory held in some cache. The overhead is now <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>P</mi><mo>×</mo><mi>C</mi></mrow><annotation encoding="application/x-tex">P\times C</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.76666em;vertical-align:-0.08333em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.07153em;">C</span></span></span></span> where <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>C</mi></mrow><annotation encoding="application/x-tex">C</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.07153em;">C</span></span></span></span> is the number of lines in each cache.</li></ol><h2 id="reduce-number-of-message-sent"><a class="markdownIt-Anchor" href="#reduce-number-of-message-sent"></a> Reduce number of message sent</h2><ol><li>In a read miss to dirty line, there are five network transactions in total. But only four of the transactions are on the critical path.</li><li>In intervention forward, home node requests data from owner node (intervention read). After the owner has responded, home node updates directory, and responds to requesting node with data.<br />Four network transactions in total (less traffic). But all four of the transactions are on the critical path.</li><li>In request forwarding, home node requests the owner to sent data to the requesting node. Then the owner will send data to requesting node and home node at the same time.<br />Four network transactions in total, with only three of the transactions are on the critical path.</li></ol>]]></content>
      
      
      <categories>
          
          <category> Open Courses </category>
          
          <category> CMU 15-418 / Stanford CS149 Parallel Computing </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Parallelism </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>08. Snooping-based Cache Coherence</title>
      <link href="/2022/06/19/Courses/CS149/08-Snooping-based-Cache-Coherence/"/>
      <url>/2022/06/19/Courses/CS149/08-Snooping-based-Cache-Coherence/</url>
      
        <content type="html"><![CDATA[<h1 id="the-cache-coherence-problem"><a class="markdownIt-Anchor" href="#the-cache-coherence-problem"></a> The cache coherence problem</h1><ol><li>This problem happens in a shared memory multi-processor system. Reading a value at address X should return the last value written to address X by any processor.</li><li>This is a problem created by replicating the data stored at address X in local caches (a hardware implementation detail), and cannot be fixed by adding locks.</li><li>Memory coherence problem exists because there is both global storage (main memory) and per-processor local storage (processor caches) implementing the abstraction of a single shared address space.</li><li>In a cache hierarchy,<br />L1 and L2 caches are private per core while L3 cahce is shared by cores in the same chip.<br />L3 cache is split into sectors or banks. Each bank is physically associated with a core, but managed hardware-wise as a single coherent unit.<br />L2 cache and L3 cache communicate through a ring interconnect where most inter-processor actions happens.</li></ol><h2 id="uniprocessor-case"><a class="markdownIt-Anchor" href="#uniprocessor-case"></a> Uniprocessor case</h2><ol><li>On a uniprocessor, providing coherence is fairly simple, since writes typically come from one client: the processor. Load operation must examine all pending stores in store buffer and select the last sequence.</li><li>There is one exception on a uniprocessor, which is device I/O via direct memory access (DMA).</li><li>One solution to DMA is that CPU writes to shared buffers using uncached stores.<br />Another way is supported by OS which will mark virtual memory pages containing shared buffers as not-cachable, and explicitly flush pages from cache when I/O completes.</li><li>In practice, DMA transfers are infrequent compared to CPU loads and stores (so these heavyweight software solutions are acceptable)</li></ol><h2 id="coherence-definition"><a class="markdownIt-Anchor" href="#coherence-definition"></a> Coherence definition</h2><ol><li>Obeys program order as expected of a uniprocessor system: A read by processor P to address X that follows a write by P to address X, should return the value of the write by P (assuming no other processor wrote to X in between)</li><li>Write propagation: A read by processor P1 to address X that follows a write by processor P2 to X returns the written value, if the read and write are “sufficiently separated” in time (assuming no other write to X occurs in between)</li><li>Write serialization: Writes to the same address are serialized: two writes to address X by any two processors are observed in the same order by all processors.</li><li>Write propagation means that notification of a write must eventually get to the other processors. Note that precisely when information about the write is propagated is not specified in the definition of coherence.</li></ol><h1 id="implementing-choherence"><a class="markdownIt-Anchor" href="#implementing-choherence"></a> Implementing choherence</h1><ol><li>Software-based solution: OS uses page-fault mechanism to propagate writes. It can be used to implement memory coherence over clusters of workstations</li><li>Hardware-based solutions: “snooping”-based coherence implementations and directory-based coherence implementations</li><li>Most modern multi-core CPUs implement cache coherence<br />Discrete GPUs do not implement cache coherence. Overhead of coherence deemed not worth it for graphics and scientific computing applications (NVIDIA GPUs provide single shared L2 + atomic memory operations)<br />But the latest Intel Integrated GPUs do implement cache coherence</li></ol><h2 id="shared-caches"><a class="markdownIt-Anchor" href="#shared-caches"></a> Shared caches</h2><ol><li>One single cache shared by all processors eliminates problem of replicating state in multiple caches and makes coherence easy.</li><li>This has obvious scalability problems since the point of a cache is to be local and fast. It also causes interference and contention due to many clients.</li><li>Facilitates fine-grained sharing (overlapping working sets). Loads/stores by one processor might pre-fetch lines for another processor</li></ol><h2 id="snooping-cache-coherence-schemes"><a class="markdownIt-Anchor" href="#snooping-cache-coherence-schemes"></a> Snooping cache-coherence schemes</h2><ol><li>Main idea: all coherence-related activity is broadcast to all processors</li><li>Cache controllers monitor (“they snoop”) memory operations, and react accordingly to maintain memory coherence</li><li>Cache controller must respond to actions from both ends:<br />It must respond the Load/Store requests from its local processor<br />It also must respond coherence-related activity broadcast over the chip’s interconnect.</li><li>The interconnect is between memory and caches possessed by each processor. There is not only memory-cache information, but also cache-cache information, which will limit the scality of the system.</li></ol><h3 id="write-through-caches"><a class="markdownIt-Anchor" href="#write-through-caches"></a> Write-through caches</h3><ol><li>For the invalidation-based protocol, when one processor write into an address, cache controller broadcasts<br />invalidation message for other caches to mark that line to invalidation.<br />the next read from other processors will trigger cache miss</li><li>For the update-based protocol: other caches will update their local copies as the information is sent.</li><li>States: Valid (V) or Invalid (I)<br />A local processor read (PrRd) always ends at valid. If the operation starts from an invalid state, a message will be sent (BusRd). If it starts from a valid state, no message will be sent.<br />A local processor write (PrWr) always ends at the same state as before the operation (assumes write no-allocate policy), and always sends a message (BusWr).<br />When a write message from other processor is received (BusWr), It always ends at invalid state.<br /><img src="/imgs/CS149/08/1.jpeg" width="20%"></li><li>Requirements of the interconnect:<br />All write transactions visible to all cache controllers.<br />All write transactions visible to all cache controllers in the same order.</li><li>Simplifying assumptions here:<br />Interconnect and memory transactions are atomic<br />Processor waits until previous memory operations is complete before issuing next memory operation<br />Invalidation applied immediately as part of receiving invalidation broadcast</li></ol><h1 id="write-back-caches-invalidation-based"><a class="markdownIt-Anchor" href="#write-back-caches-invalidation-based"></a> Write-back caches (Invalidation-based)</h1><ol><li>Dirty state of cache line now indicates exclusive ownership</li><li>Exclusive: cache is only cache with a valid copy of line (it can safely be written to)<br />Owner: cache is responsible for supplying the line to other processors when they attempt to load it from memory (otherwise a load from another processor will get stale data from memory)</li><li>A line in the “exclusive” state can be modified without notifying<br />the other caches<br />Processor can only write to lines in the exclusive state. So they need a way to tell other caches that they want exclusive access to the line. They will do this by sending all the other caches messages<br />When cache controller snoops a request for exclusive access to line it contains, it must invalidate the line in its own cache</li></ol><h2 id="msi-write-back-invalidation-protocol"><a class="markdownIt-Anchor" href="#msi-write-back-invalidation-protocol"></a> MSI write-back invalidation protocol</h2><ol><li>Three cache line states:<br />Invalid (I): same as meaning of invalid in uniprocessor cache<br />Shared (S): line valid in one or more caches<br />Modified (M): line valid in exactly one cache (a.k.a. “dirty” or “exclusive” state)</li><li>The local processors have the same operations as write-through case.<br />The coherence-related bus transactions from remote caches have three kinds:<br />BusRd: obtain copy of line with no intent to modify<br />BusRdX: obtain copy of line with intent to modify<br />flush: write dirty line out to memory<br /><img src="/imgs/CS149/08/2.png" width="50%"></li><li>When try to write an invalid line without reading it, the content of the current modified state line will be sent to the new writer.</li><li>Write propagation is achieved via combination of invalidation on BusRdX, and flush from M-state on subsequent BusRd/BusRdX from another processors</li><li>Write serialization<br />Writes that appear on interconnect are ordered by the order they appear on interconnect (BusRdX)<br />Reads that appear on interconnect are ordered by order they appear on interconnect (BusRd)<br />Writes that don’t appear on the interconnect (PrWr to line already in M state):<ul><li>Sequence of writes to line comes between two interconnect transactions for the line</li><li>All writes in sequence performed by same processor, P (that processor certainly observes them in correct sequential order)</li><li>All other processors observe notification of these writes only after a interconnect transaction for the line.</li><li>So all processors see writes in the same order.</li></ul></li></ol><h2 id="mesi-invalidation-protocol"><a class="markdownIt-Anchor" href="#mesi-invalidation-protocol"></a> MESI invalidation protocol</h2><ol><li>MSI requires two interconnect transactions for the common case of reading an address, then writing to it<ul><li>Transaction 1: BusRd to move from I to S state</li><li>Transaction 2: BusRdX to move from S to M state</li></ul></li><li>Solution: add additional state E (“exclusive clean”) to mark the line that has not been modified, but only this cache has a copy of the line<br />This state decouples exclusivity from line ownership (line not dirty, so copy in memory is valid copy of data)<br />Upgrade from E to M does not require an interconnect transaction</li><li><img src="/imgs/CS149/08/3.jpeg" width="50%"></li></ol><h2 id="5-stage-invalidation-based-protocol"><a class="markdownIt-Anchor" href="#5-stage-invalidation-based-protocol"></a> 5-stage invalidation-based protocol</h2><ol><li>Who should supply data on a cache miss when line is in the E or S state of another cache? <br />Can get cache line data from memory or can get data from another cache? If source is another cache, which one should provide it?</li><li>Cache-to-cache transfers add complexity, but commonly used to reduce both latency of data access and reduce memory bandwidth required by application</li><li>MESIF: Like MESI, but one cache holds shared line in F state rather than S (F=”forward”). Cache with line in F state services miss<br />Simplifies decision of which cache should service miss (basic MESI: all caches respond)<br />Used by Intel processors</li><li>MOESI: Transition from M to O (O=”owned, but not exclusive”) and do not flush to memory (In MESI protocol, transition from M to S requires flush to memory).<br />Other processors maintain shared line in S state, one processor maintains line in O state. Data in memory is stale, so cache with line in O state must service cache misses.<br />Used in AMD Opteron</li></ol><h1 id="invalidation-based-vs-update-based"><a class="markdownIt-Anchor" href="#invalidation-based-vs-update-based"></a> Invalidation-based vs. Update-based</h1><ol><li>Invalidation-based protocol: To write to a line, cache must obtain exclusive access to it. All other caches must invalidate their copies</li><li>Update-based protocol: Can write to shared copy by broadcasting update to all other copies</li><li>Intuitively, update would seem preferable if other processors<br />sharing data continue to access it after a write occurs<br />But updates are overhead if data just sits in caches (and is never read by another processor again) or application performs many writes before the next read</li><li>Update can reduce cache miss rate since all shared copies remain valid.<br />Update can suffer from high traffic due to multiple writes before the next read by another processor</li></ol><h1 id="snoop-for-a-cache-hierarchy"><a class="markdownIt-Anchor" href="#snoop-for-a-cache-hierarchy"></a> Snoop for a cache hierarchy</h1><ol><li>Challenge: changes made to data at L1 cache may not be visible to L2 cache controller than snoops the interconnect.</li><li>Inclusion property:<br />All lines in closer to processor cache are also in farther from processor cache. Thus, all transactions relevant to L1 are also relevant to L2, so it is sufficient for only the L2 to snoop the interconnect.<br />If line is in owned state (M in MSI/MESI) in L1, it must also be in owned state in L2. Allows L2 to determine if a bus transaction is requesting a modified cache line in L1 without requiring information from L1.</li><li>Even if L2 is larger than L1, the inclusion cannot be maintained automatically. L1 and L2 might choose to evict different lines because the access histories differ.</li><li>When line X is invalidated in L2 cache due to BusRdX from another cache. Must also invalidate line X in L1<br />Solution: Each L2 line contains an additional state bit indicating if line also exists in L1. This bit tells the L2 invalidations of the cache line due to coherence traffic need to be propagated to L1.</li><li>When L1 write is hit, the corresponding line in L2 cache is in modified state in the coherence protocol, but L2 data is stale.<br />When coherence protocol requires X to be flushed from L2, L2 cache must request the data from L1.<br />Add another bit for “modified-but-stale” (flushing a “modified-but-stale” L2 line requires getting the real data from L1 first.)</li></ol><h1 id="false-sharing"><a class="markdownIt-Anchor" href="#false-sharing"></a> False sharing</h1><ol><li>Fasle sharing is that two processors write to different addresses, but those addresses map to the same cache line. The cache line keeps invalidating and request data from another processor, generating significant amounts of communication due to the coherence protocol.</li><li>We can split the line into two parts and each processor only write one part.</li><li>One way is to insert some paddings to make the data written by one processor take up a whole cache line. This can easily implemented in software level. But it causes memory waste.</li><li>Another way is mapping addresses handled by the same processor to the same cache line. This causes no waste, but break the successiveness of memory address within a cache line. Also it needs to know the addresses each processor will write, and is harder to implement.</li></ol>]]></content>
      
      
      <categories>
          
          <category> Open Courses </category>
          
          <category> CMU 15-418 / Stanford CS149 Parallel Computing </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Parallelism </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>07. Workload-driven Perfromance Evaluation</title>
      <link href="/2022/06/11/Courses/CS149/07-Workload-driven-Perfromance-Evaluation/"/>
      <url>/2022/06/11/Courses/CS149/07-Workload-driven-Perfromance-Evaluation/</url>
      
        <content type="html"><![CDATA[<p>We should compare parallel program speedup to the best sequential program, instead of parallel algorithm running on one core.<br />The reason is that to allow for parallelism, we might change the algorithm, and make it slower when executed sequentially.</p><h1 id="scaling"><a class="markdownIt-Anchor" href="#scaling"></a> Scaling</h1><h2 id="why-consider-scaling"><a class="markdownIt-Anchor" href="#why-consider-scaling"></a> Why consider scaling?</h2><ol><li><p>Arithmetic intensity is determined by both problem size and the processors number. Small problem size or large processor number both yields low arithmetic intensity.</p></li><li><p>If the problem size is too small, it might already execute fast enough on a single core. Scaling the performance of small problem may not be all that important.<br />Parallelism overheads dominate parallelism benefits, and may even result in slow downs.</p></li><li><p>If the problem size is too large for a single machine, working set may not fit in memory, and causing thrashing to disk. With enough processors, the key working set fits in per-processor cache.<br />This may get a super-linear speedup and make speedup on a bigger parallel machine with more memory look amazing.</p></li><li><p>Another situation that we might get a super-linear speedup is when we try to search for a solution. With parallelism, we are trying more different variance of search, and more likely to find the solution earlier.</p></li><li><p>So we shouldn’t only consider a fixed problem size. Instead, it is desirable to scale problem size as machine sizes grow.</p></li><li><p>In architecture, scaling up considers how does performance scale with increasing core count, and will design scale to the high end?<br />Scaling down considers how does performance scale with decreasing core count, and will desing scale to the low end?</p></li></ol><h2 id="different-scalings"><a class="markdownIt-Anchor" href="#different-scalings"></a> Different scalings</h2><ol><li><p>Strong scaling: scaling processors with a fixed problem size. Consider the ratio between the runtime of problem <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>X</mi></mrow><annotation encoding="application/x-tex">X</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.07847em;">X</span></span></span></span> on <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>P</mi></mrow><annotation encoding="application/x-tex">P</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span></span></span></span> processors and the runtime <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>X</mi></mrow><annotation encoding="application/x-tex">X</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.07847em;">X</span></span></span></span> on <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1</mn></mrow><annotation encoding="application/x-tex">1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">1</span></span></span></span> processor.</p></li><li><p>The goal ratio is <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>P</mi></mrow><annotation encoding="application/x-tex">P</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span></span></span></span>. This kind of scaling tells us does having more processors get job done faster?</p></li><li><p>Weak scaling: scaling problem size and processors proportionally. Consider the ratio of the runtime of problem <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>P</mi><mo>×</mo><mi>X</mi></mrow><annotation encoding="application/x-tex">P\times X</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.76666em;vertical-align:-0.08333em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.07847em;">X</span></span></span></span> on <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>P</mi></mrow><annotation encoding="application/x-tex">P</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span></span></span></span> processors and the runtime of problem <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>X</mi></mrow><annotation encoding="application/x-tex">X</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.07847em;">X</span></span></span></span> on <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1</mn></mrow><annotation encoding="application/x-tex">1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">1</span></span></span></span> processor.</p></li><li><p>The goal ratio is <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1</mn></mrow><annotation encoding="application/x-tex">1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">1</span></span></span></span>. This kind of scaling tells us does having more procesors let me do bigger jobs?</p></li><li><p>Problem size is often determined by more than one parameter. So in weak scaling, we need to consider how should the parameter be changed.</p></li></ol><h2 id="scaling-constrains"><a class="markdownIt-Anchor" href="#scaling-constrains"></a> Scaling constrains</h2><ol><li><p>When scaling a probelm, we should first ask that in my situation, under what constraints should the problem be scaled?</p></li><li><p>Problem-constrained scaling focuses on using a parallel computer to solve the same problem faster<br />Speedup <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>=</mo><mfrac><mrow><mi>t</mi><mi>i</mi><mi>m</mi><mi>e</mi><mtext> </mtext><mn>1</mn><mtext> </mtext><mi>p</mi><mi>r</mi><mi>o</mi><mi>c</mi><mi>e</mi><mi>s</mi><mi>s</mi><mi>o</mi><mi>r</mi></mrow><mrow><mi>t</mi><mi>i</mi><mi>m</mi><mi>e</mi><mtext> </mtext><mi>P</mi><mtext> </mtext><mi>p</mi><mi>r</mi><mi>o</mi><mi>c</mi><mi>e</mi><mi>s</mi><mi>s</mi><mi>o</mi><mi>r</mi><mi>s</mi></mrow></mfrac></mrow><annotation encoding="application/x-tex">=\frac{time\ 1\ processor}{time\ P\ processors}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.36687em;vertical-align:0em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.38888em;vertical-align:-0.481108em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.907772em;"><span style="top:-2.6550000000000002em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span><span class="mord mathnormal mtight">i</span><span class="mord mathnormal mtight">m</span><span class="mord mathnormal mtight">e</span><span class="mspace mtight"><span class="mtight"> </span></span><span class="mord mathnormal mtight" style="margin-right:0.13889em;">P</span><span class="mspace mtight"><span class="mtight"> </span></span><span class="mord mathnormal mtight">p</span><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span><span class="mord mathnormal mtight">o</span><span class="mord mathnormal mtight">c</span><span class="mord mathnormal mtight">e</span><span class="mord mathnormal mtight">s</span><span class="mord mathnormal mtight">s</span><span class="mord mathnormal mtight">o</span><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span><span class="mord mathnormal mtight">s</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.446108em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span><span class="mord mathnormal mtight">i</span><span class="mord mathnormal mtight">m</span><span class="mord mathnormal mtight">e</span><span class="mspace mtight"><span class="mtight"> </span></span><span class="mord mtight">1</span><span class="mspace mtight"><span class="mtight"> </span></span><span class="mord mathnormal mtight">p</span><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span><span class="mord mathnormal mtight">o</span><span class="mord mathnormal mtight">c</span><span class="mord mathnormal mtight">e</span><span class="mord mathnormal mtight">s</span><span class="mord mathnormal mtight">s</span><span class="mord mathnormal mtight">o</span><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.481108em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></p></li><li><p>Time-constrained scaling focuses on completing more work in a fixed amount of time<br />Speedup $ = \frac{work\ done\ by\ P\ processors}{work\ done\ by\ 1\ processor}$</p></li><li><p>“Work done” may not be linear function of problem inputs. One approach of defining “work done” is by execution time of same computation on a single processor (but consider effects of thrashing if problem too big)</p></li><li><p>Ideally, a measure of work is simple to understand and scales linearly with sequential run time (So ideal speedup remains linear in <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>P</mi></mrow><annotation encoding="application/x-tex">P</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span></span></span></span>)</p></li><li><p>Memory-constrained scaling (weak scaling) focuses on running the largest problem possible without overflowing main memory. Neither work or execution times are held constant.<br />Speedup <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>=</mo><mfrac><mrow><mi>w</mi><mi>o</mi><mi>r</mi><mi>k</mi><mtext> </mtext><mo stretchy="false">(</mo><mi>P</mi><mtext> </mtext><mi>p</mi><mi>r</mi><mi>o</mi><mi>c</mi><mi>e</mi><mi>s</mi><mi>s</mi><mi>o</mi><mi>r</mi><mi>s</mi><mo stretchy="false">)</mo></mrow><mrow><mi>t</mi><mi>i</mi><mi>m</mi><mi>e</mi><mtext> </mtext><mo stretchy="false">(</mo><mi>P</mi><mtext> </mtext><mi>p</mi><mi>r</mi><mi>o</mi><mi>c</mi><mi>e</mi><mi>s</mi><mi>s</mi><mi>o</mi><mi>r</mi><mi>s</mi><mo stretchy="false">)</mo></mrow></mfrac><mi mathvariant="normal">/</mi><mfrac><mrow><mi>w</mi><mi>o</mi><mi>r</mi><mi>k</mi><mtext> </mtext><mo stretchy="false">(</mo><mn>1</mn><mtext> </mtext><mi>p</mi><mi>r</mi><mi>o</mi><mi>c</mi><mi>e</mi><mi>s</mi><mi>s</mi><mi>o</mi><mi>r</mi><mo stretchy="false">)</mo></mrow><mrow><mi>t</mi><mi>i</mi><mi>m</mi><mi>e</mi><mtext> </mtext><mo stretchy="false">(</mo><mn>1</mn><mtext> </mtext><mi>p</mi><mi>r</mi><mi>o</mi><mi>c</mi><mi>e</mi><mi>s</mi><mi>s</mi><mi>o</mi><mi>r</mi><mo stretchy="false">)</mo></mrow></mfrac><mo>=</mo><mfrac><mrow><mi>w</mi><mi>o</mi><mi>r</mi><mi>k</mi><mtext> </mtext><mi>p</mi><mi>e</mi><mi>r</mi><mtext> </mtext><mi>u</mi><mi>n</mi><mi>i</mi><mi>t</mi><mtext> </mtext><mi>t</mi><mi>i</mi><mi>m</mi><mi>e</mi><mtext> </mtext><mi>o</mi><mi>n</mi><mtext> </mtext><mi>P</mi><mtext> </mtext><mi>p</mi><mi>r</mi><mi>o</mi><mi>c</mi><mi>e</mi><mi>s</mi><mi>s</mi><mi>o</mi><mi>r</mi><mi>s</mi></mrow><mrow><mi>w</mi><mi>o</mi><mi>r</mi><mi>k</mi><mtext> </mtext><mi>p</mi><mi>e</mi><mi>r</mi><mtext> </mtext><mi>u</mi><mi>n</mi><mi>i</mi><mi>t</mi><mtext> </mtext><mi>t</mi><mi>i</mi><mi>m</mi><mi>e</mi><mtext> </mtext><mi>o</mi><mi>n</mi><mtext> </mtext><mn>1</mn><mtext> </mtext><mi>p</mi><mi>r</mi><mi>o</mi><mi>c</mi><mi>e</mi><mi>s</mi><mi>s</mi><mi>o</mi><mi>r</mi></mrow></mfrac></mrow><annotation encoding="application/x-tex">= \frac{work\ (P\ processors)}{time\ (P\ processors)}/\frac{work\ (1\ processor)}{time\ (1\ processor)}=\frac{work\ per\ unit\ time\ on\ P\ processors}{work\ per\ unit\ time\ on\ 1\ processor}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.36687em;vertical-align:0em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.53em;vertical-align:-0.52em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.01em;"><span style="top:-2.655em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span><span class="mord mathnormal mtight">i</span><span class="mord mathnormal mtight">m</span><span class="mord mathnormal mtight">e</span><span class="mspace mtight"><span class="mtight"> </span></span><span class="mopen mtight">(</span><span class="mord mathnormal mtight" style="margin-right:0.13889em;">P</span><span class="mspace mtight"><span class="mtight"> </span></span><span class="mord mathnormal mtight">p</span><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span><span class="mord mathnormal mtight">o</span><span class="mord mathnormal mtight">c</span><span class="mord mathnormal mtight">e</span><span class="mord mathnormal mtight">s</span><span class="mord mathnormal mtight">s</span><span class="mord mathnormal mtight">o</span><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span><span class="mord mathnormal mtight">s</span><span class="mclose mtight">)</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.485em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.02691em;">w</span><span class="mord mathnormal mtight">o</span><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span><span class="mspace mtight"><span class="mtight"> </span></span><span class="mopen mtight">(</span><span class="mord mathnormal mtight" style="margin-right:0.13889em;">P</span><span class="mspace mtight"><span class="mtight"> </span></span><span class="mord mathnormal mtight">p</span><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span><span class="mord mathnormal mtight">o</span><span class="mord mathnormal mtight">c</span><span class="mord mathnormal mtight">e</span><span class="mord mathnormal mtight">s</span><span class="mord mathnormal mtight">s</span><span class="mord mathnormal mtight">o</span><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span><span class="mord mathnormal mtight">s</span><span class="mclose mtight">)</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.52em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mord">/</span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.01em;"><span style="top:-2.655em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span><span class="mord mathnormal mtight">i</span><span class="mord mathnormal mtight">m</span><span class="mord mathnormal mtight">e</span><span class="mspace mtight"><span class="mtight"> </span></span><span class="mopen mtight">(</span><span class="mord mtight">1</span><span class="mspace mtight"><span class="mtight"> </span></span><span class="mord mathnormal mtight">p</span><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span><span class="mord mathnormal mtight">o</span><span class="mord mathnormal mtight">c</span><span class="mord mathnormal mtight">e</span><span class="mord mathnormal mtight">s</span><span class="mord mathnormal mtight">s</span><span class="mord mathnormal mtight">o</span><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span><span class="mclose mtight">)</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.485em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.02691em;">w</span><span class="mord mathnormal mtight">o</span><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span><span class="mspace mtight"><span class="mtight"> </span></span><span class="mopen mtight">(</span><span class="mord mtight">1</span><span class="mspace mtight"><span class="mtight"> </span></span><span class="mord mathnormal mtight">p</span><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span><span class="mord mathnormal mtight">o</span><span class="mord mathnormal mtight">c</span><span class="mord mathnormal mtight">e</span><span class="mord mathnormal mtight">s</span><span class="mord mathnormal mtight">s</span><span class="mord mathnormal mtight">o</span><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span><span class="mclose mtight">)</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.52em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.4133239999999998em;vertical-align:-0.481108em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.9322159999999999em;"><span style="top:-2.6550000000000002em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.02691em;">w</span><span class="mord mathnormal mtight">o</span><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span><span class="mspace mtight"><span class="mtight"> </span></span><span class="mord mathnormal mtight">p</span><span class="mord mathnormal mtight">e</span><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span><span class="mspace mtight"><span class="mtight"> </span></span><span class="mord mathnormal mtight">u</span><span class="mord mathnormal mtight">n</span><span class="mord mathnormal mtight">i</span><span class="mord mathnormal mtight">t</span><span class="mspace mtight"><span class="mtight"> </span></span><span class="mord mathnormal mtight">t</span><span class="mord mathnormal mtight">i</span><span class="mord mathnormal mtight">m</span><span class="mord mathnormal mtight">e</span><span class="mspace mtight"><span class="mtight"> </span></span><span class="mord mathnormal mtight">o</span><span class="mord mathnormal mtight">n</span><span class="mspace mtight"><span class="mtight"> </span></span><span class="mord mtight">1</span><span class="mspace mtight"><span class="mtight"> </span></span><span class="mord mathnormal mtight">p</span><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span><span class="mord mathnormal mtight">o</span><span class="mord mathnormal mtight">c</span><span class="mord mathnormal mtight">e</span><span class="mord mathnormal mtight">s</span><span class="mord mathnormal mtight">s</span><span class="mord mathnormal mtight">o</span><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.446108em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.02691em;">w</span><span class="mord mathnormal mtight">o</span><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span><span class="mspace mtight"><span class="mtight"> </span></span><span class="mord mathnormal mtight">p</span><span class="mord mathnormal mtight">e</span><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span><span class="mspace mtight"><span class="mtight"> </span></span><span class="mord mathnormal mtight">u</span><span class="mord mathnormal mtight">n</span><span class="mord mathnormal mtight">i</span><span class="mord mathnormal mtight">t</span><span class="mspace mtight"><span class="mtight"> </span></span><span class="mord mathnormal mtight">t</span><span class="mord mathnormal mtight">i</span><span class="mord mathnormal mtight">m</span><span class="mord mathnormal mtight">e</span><span class="mspace mtight"><span class="mtight"> </span></span><span class="mord mathnormal mtight">o</span><span class="mord mathnormal mtight">n</span><span class="mspace mtight"><span class="mtight"> </span></span><span class="mord mathnormal mtight" style="margin-right:0.13889em;">P</span><span class="mspace mtight"><span class="mtight"> </span></span><span class="mord mathnormal mtight">p</span><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span><span class="mord mathnormal mtight">o</span><span class="mord mathnormal mtight">c</span><span class="mord mathnormal mtight">e</span><span class="mord mathnormal mtight">s</span><span class="mord mathnormal mtight">s</span><span class="mord mathnormal mtight">o</span><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span><span class="mord mathnormal mtight">s</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.481108em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span>There are two assumptions: memory resources scale with processor count, and spilling to disk is infeasible behavior.</p></li></ol><h2 id="challenges-of-scaling-down-or-up"><a class="markdownIt-Anchor" href="#challenges-of-scaling-down-or-up"></a> Challenges of scaling down or up</h2><ol><li><p>Preserve ratio of time spent in different program phases.</p></li><li><p>Preserve important behavioral characteristics.</p></li><li><p>Preserve contention and communication patterns. Tough to preserve contention since contention is a function of timing and ratios.</p></li><li><p>Preserve scaling relationships between problem parameters.</p></li></ol><h1 id="simulation"><a class="markdownIt-Anchor" href="#simulation"></a> Simulation</h1><ol><li><p>Architects evaluate architectural decisions quantitatively using<br />hardware performance simulators.</p></li><li><p>Architect runs simulations with new feature, runs simulations without new feature, compare simulated performance. Or simulate against a wide collection of benchmarks.</p></li><li><p>You can design detailed simulator to test new architectural feature. It would be very expensive to simulate a parallel machine in full detail.<br />Often cannot simulate full machine configurations or realistic problem sizes (must scale down workloads significantly). Architects need to be confident scaled down simulated results predict reality</p></li><li><p>In trace-driven simulator, we instrument real code running on real machine to record a trace of all memory accesses. Then play back trace on simulator.<br />It may lead to overfit the trace you have instead of having a better generalization.</p></li><li><p>In execution-driven simulator, we execute simulated program in software. Simulated processors generate memory references, which are processed by the simulated memory hierarchy.<br />Performance of simulator is typically inversely proportional to level of simulated detail.</p></li><li><p>When dealing with large parameter space of machines (number of processors, cache sizes, cache line sizes, memory bandwidths, etc. ), we can use the architectural simulation state space.</p></li></ol><h1 id="understanding-the-performance"><a class="markdownIt-Anchor" href="#understanding-the-performance"></a> Understanding the performance</h1><ol><li><p>Always, always, always try the simplest parallel solution first, then measure performance to see where you stand.</p></li><li><p>Determine if your performance is limited by computation, memory bandwidth (or memory latency), or synchronization?<br />Try and establish “high watermarks”. What’s the best you can do in practice? How close is your implementation to a best-case scenario?</p></li><li><p>Roofline model: Use microbenchmarks to compute peak performance of a machine as a function of arithmetic intensity of application. Then compare application’s performance to known peak values.</p></li><li><p>The x-axis means operational intensity (like Flops/Byte), and the y-axis means attenable GFlops/s.<br />In the diagonal region, the y grows with x, which means the memory bendwidth is limited. In the horizontal region, the y stays the same as x grows, which means the compute is limited.</p></li><li><p>When compute is limited, we can make use of ILP or SIMD, or balance floating-point.<br />When memory bandwidth is limited, we can limit accesses to unit stride accesses only, develope memory affinity, or use software prefetching.</p></li></ol><h2 id="establish-high-watermarks"><a class="markdownIt-Anchor" href="#establish-high-watermarks"></a> Establish high watermarks</h2><ol><li><p>Add “math” (non-memory instructions).<br />Does execution time increase linearly with operation count as math is added? If so, this is evidence that code is instruction-rate limited</p></li><li><p>Remove almost all math, but load same data.<br />How much does execution-time decrease? If not much, suspect memory bottleneck</p></li><li><p>The first two way need to avoid compiler optimization.</p></li><li><p>Change all array accesses to A[0].<br />How much faster does your code get?<br />This establishes an upper bound on benefit of improving locality of data access</p></li><li><p>Remove all atomic operations or locks.<br />How much faster does your code get? (provided it still does approximately the same amount of work)<br />This establishes an upper bound on benefit of reducing sync overhead.</p></li></ol><h2 id="profilersperformance-monitoring-tools"><a class="markdownIt-Anchor" href="#profilersperformance-monitoring-tools"></a> Profilers/performance monitoring tools</h2><ol><li><p>All modern processors have low-level event “performance counters”, which are registers that count important details such as: instructions completed, clock ticks, L2/L3 cache hits/misses, bytes read from memory controller, etc.</p></li><li><p>Intel’s Performance Counter Monitor Tool provides a C++ API for accessing these registers.</p></li><li><p>It can use <code>getIPC(begin, end)</code>, <code>getL3CacheHitRatio(begin, end)</code>, <code>getBytesReadFromMC(begin, end)</code>, etc. to get values of those information.</p></li><li><p>The <code>begin</code> and <code>end</code> is a <code>SystemCountState</code> instance acquired by <code>getSystemCounterState()</code> at the beginning and end of the code to analyze.</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">PCM *m = PCM::<span class="built_in">getInstance</span>();</span><br><span class="line">SystemCounterState begin = <span class="built_in">getSystemCounterState</span>();</span><br><span class="line"></span><br><span class="line"><span class="comment">// code to analyze goes here</span></span><br><span class="line"></span><br><span class="line">SystemCounterState end = <span class="built_in">getSystemCounterState</span>();</span><br><span class="line"></span><br><span class="line"><span class="built_in">printf</span>(“Instructions per clock: %f\n”, <span class="built_in">getIPC</span>(begin, end));</span><br><span class="line"><span class="built_in">printf</span>(“L3 cache hit ratio: %f\n”, <span class="built_in">getL3CacheHitRatio</span>(begin, end));</span><br><span class="line"><span class="built_in">printf</span>(“Bytes read: %d\n”, <span class="built_in">getBytesReadFromMC</span>(begin, end));</span><br></pre></td></tr></table></figure></li></ol>]]></content>
      
      
      <categories>
          
          <category> Open Courses </category>
          
          <category> CMU 15-418 / Stanford CS149 Parallel Computing </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Parallelism </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>06. Locality, Communication, and Contention</title>
      <link href="/2022/05/21/Courses/CS149/06-Locality-Communication-and-Contention/"/>
      <url>/2022/05/21/Courses/CS149/06-Locality-Communication-and-Contention/</url>
      
        <content type="html"><![CDATA[<h1 id="communication"><a class="markdownIt-Anchor" href="#communication"></a> Communication</h1><h2 id="reduce-communication-time"><a class="markdownIt-Anchor" href="#reduce-communication-time"></a> Reduce communication time</h2><ol><li><p>Total communication time = overhead + occupancy + network delay.</p></li><li><p>Overhead is the time spent on the communication by a processor, occupancy is the time for data to pass through slowest component of system, and network delay is everything else.</p></li><li><p>Reduce overhead of communication to sender/receiver:<br />Reassign tasks in a better way that need to send fewer messages.<br />Make messages larger to amortize overhead.<br />Coalesce many small messages into large ones</p></li><li><p>Reduce delay:<br />Application writer can restructure code to exploit locality.<br />Hardware implementor can improve communication architecture.</p></li></ol><h2 id="reduce-communication-cost"><a class="markdownIt-Anchor" href="#reduce-communication-cost"></a> Reduce communication cost</h2><ol><li><p>Total communication cost = communication time - overlap</p></li><li><p>Overlap: portion of communication performed concurrently with other work (“other work” can be computation or other communication)</p></li><li><p>Cost is the part that your cannot get over with by changing the protocol. The communication time is obviously necessary, and we can hide the overlap part by pipelining.</p></li><li><p>Increase communication/computation overlap:<br />Application writer can use asynchronous communication (e.g., async messages)<br />Hardware implementor can use pipelining, multi-threading, pre-fetching, out-of-order execution<br />Requires additional concurrency in application (more concurrency than number of execution units)</p></li><li><p>Instruction pipeline: Break execution of each instruction down into several smaller steps.<br />Enables higher clock frequency, only a simple, short operation is done by each part of pipeline each clock</p></li><li><p>Non-piplined communication: <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>T</mi><mo stretchy="false">(</mo><mi>n</mi><mo stretchy="false">)</mo><mo>=</mo><msub><mi>T</mi><mn>0</mn></msub><mo>+</mo><mfrac><mi>n</mi><mi>B</mi></mfrac></mrow><annotation encoding="application/x-tex">T(n)=T_0+\frac{n}{B}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="mopen">(</span><span class="mord mathnormal">n</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1.040392em;vertical-align:-0.345em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.695392em;"><span style="top:-2.6550000000000002em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.05017em;">B</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">n</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.345em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span> (<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>T</mi><mn>0</mn></msub></mrow><annotation encoding="application/x-tex">T_0</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> is the start-up latency, n is bytes transferred in operation, B is transfer rate or bandwidth)<br />Efficient bandwidth <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>=</mo><mfrac><mi>n</mi><mrow><mi>T</mi><mo stretchy="false">(</mo><mi>n</mi><mo stretchy="false">)</mo></mrow></mfrac></mrow><annotation encoding="application/x-tex">=\frac{n}{T(n)}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.36687em;vertical-align:0em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.215392em;vertical-align:-0.52em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.695392em;"><span style="top:-2.655em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em;">T</span><span class="mopen mtight">(</span><span class="mord mathnormal mtight">n</span><span class="mclose mtight">)</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">n</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.52em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></p></li></ol><h2 id="improve-arithmetic-intensity"><a class="markdownIt-Anchor" href="#improve-arithmetic-intensity"></a> Improve arithmetic intensity</h2><ol><li><p>Communication-to-computation ratio = amount of communication  / amount of computation<br />The units can be different. If the denominator is the execution time of computation, the ratio gives the average bandwidth requirement</p></li><li><p>Arithmetic intensity = 1 / communication-to-computation ratio</p></li><li><p>Change the traversal order to reduce the time between accesses to same data. We want to do all the calculations related to the accessing data now.<br />This way can improve the utilization of cache by preventing that those data get flushed out when we try to access them again.</p></li><li><p>Fuse loops to reduce the frequency of store operation.</p></li><li><p>Improve arithmetic intensity by sharing data. Co-locate tasks that operate on the same data.  Schedule threads working on the same data structure at the same time on the same processor. Reduces inherent communication</p></li></ol><h2 id="reduce-artifactual-communication"><a class="markdownIt-Anchor" href="#reduce-artifactual-communication"></a> Reduce artifactual communication</h2><ol><li><p>Inherent communication: Communication that must occur in a parallel algorithm. The communication is fundamental to the algorithm.<br />Artifactual communication: all other communication that happens because we want to efficiently use resource.</p></li><li><p>Granularity of communication can be important because it may introduce artifactual communication.<br />Assume that communication granularity is a cache line.</p></li><li><p>If we see data as row-major layout, when the data required is in column, each communication actually only provides one needed data.</p></li><li><p>When Threads access their assigned elements (no inherent communication exists), real machine triggers (artifactual) communication due to the cache line being written to by both processors.</p></li><li><p>Reducing artifactual comm by blocked data layout. Each communication only involves  the data in the same block. If communication granularity is larger than a block row, each communication will transfer multiple rows.</p></li></ol><h1 id="contention"><a class="markdownIt-Anchor" href="#contention"></a> Contention</h1><ol><li><p>Contention occurs when many requests to a resource are made within a small window of time. The resource is a hot spot.<br />Contention for shared resource results in longer overall operation times.</p></li><li><p>Distributed work queues serve to reduce contention (contention in access to single shared work queue)</p></li><li><p>One way to reduce contention is to use finer-granularity locks. Instead of locking the whole data structure, we can only lock a part of that structure.</p></li><li><p>Another way is that each CUDA block computes partial results and merges them afterwards. But this requires extra work for merging, and each CUDA block need to store a partial result instead of all of them using the same result.</p></li><li><p>The best way is to stagger access to contended resources. For example, instead of calculate the final result directly, we can calculate several temporal results which has no contention, and get the final result from them.</p></li></ol><h1 id="understanding-the-performance"><a class="markdownIt-Anchor" href="#understanding-the-performance"></a> Understanding the performance</h1><ol><li><p>Always, always, always try the simplest parallel solution first, then measure performance to see where you stand.</p></li><li><p>We should compare parallel program speedup to the best sequential program, instead of parallel algorithm running on one core.<br />The reason is that to allow for parallelism, we might change the algorithm, and make it slower when executed sequentially.</p></li><li><p>Determine if your performance is limited by computation, memory bandwidth (or memory latency), or synchronization?<br />Try and establish “high watermarks”. What’s the best you can do in practice? How close is your implementation to a best-case scenario?</p></li><li><p>Roofline model: Use microbenchmarks to compute peak performance of a machine as a function of arithmetic intensity of application. Then compare application’s performance to known peak values</p></li></ol><h2 id="establish-high-watermarks"><a class="markdownIt-Anchor" href="#establish-high-watermarks"></a> Establish high watermarks</h2><ol><li><p>Add “math” (non-memory instructions).<br />Does execution time increase linearly with operation count as math is added?<br />If so, this is evidence that code is instruction-rate limited</p></li><li><p>Remove almost all math, but load same data.<br />How much does execution-time decrease?<br />If not much, suspect memory bottleneck</p></li><li><p>Change all array accesses to A[0].<br />How much faster does your code get?<br />This establishes an upper bound on benefit of improving locality of data access</p></li><li><p>Remove all atomic operations or locks.<br />How much faster does your code get? (provided it still does approximately the same amount of work)<br />This establishes an upper bound on benefit of reducing sync overhead.</p></li></ol><h2 id="scaling"><a class="markdownIt-Anchor" href="#scaling"></a> Scaling</h2><ol><li><p>Arithmetic intensity is determined by both problem size and the processors number. Small problem size or large processor number both yields low arithmetic intensity.</p></li><li><p>If the problem size is too small, it might already execute fast enough on a single core. Scaling the performance of small problem ay not be all that important.</p></li><li><p>If the problem size is too large for a single machine, working set may not fit in memory, and causing thrashing to disk. With enough processors, the key working set fits in per-processor cache.<br />This may get a super-linear speedup and make speedup on a bigger parallel machine with more memory look amazing.</p></li><li><p>Desire to scale problem size as machine sizes grow (buy a bigger machine to compute more, rather than just compute the same problem faster)</p></li><li><p>Problem-constrained scaling focuses on using a parallel computer to solve the same problem faster<br /><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>S</mi><mi>p</mi><mi>e</mi><mi>e</mi><mi>d</mi><mi>u</mi><mi>p</mi><mo>=</mo><mfrac><mrow><mi>t</mi><mi>i</mi><mi>m</mi><mi>e</mi><mtext> </mtext><mn>1</mn><mtext> </mtext><mi>p</mi><mi>r</mi><mi>o</mi><mi>c</mi><mi>e</mi><mi>s</mi><mi>s</mi><mi>o</mi><mi>r</mi></mrow><mrow><mi>t</mi><mi>i</mi><mi>m</mi><mi>e</mi><mtext> </mtext><mi>P</mi><mtext> </mtext><mi>p</mi><mi>r</mi><mi>o</mi><mi>c</mi><mi>e</mi><mi>s</mi><mi>s</mi><mi>o</mi><mi>r</mi><mi>s</mi></mrow></mfrac></mrow><annotation encoding="application/x-tex">Speedup=\frac{time\ 1\ processor}{time\ P\ processors}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord mathnormal" style="margin-right:0.05764em;">S</span><span class="mord mathnormal">p</span><span class="mord mathnormal">e</span><span class="mord mathnormal">e</span><span class="mord mathnormal">d</span><span class="mord mathnormal">u</span><span class="mord mathnormal">p</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.38888em;vertical-align:-0.481108em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.907772em;"><span style="top:-2.6550000000000002em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span><span class="mord mathnormal mtight">i</span><span class="mord mathnormal mtight">m</span><span class="mord mathnormal mtight">e</span><span class="mspace mtight"><span class="mtight"> </span></span><span class="mord mathnormal mtight" style="margin-right:0.13889em;">P</span><span class="mspace mtight"><span class="mtight"> </span></span><span class="mord mathnormal mtight">p</span><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span><span class="mord mathnormal mtight">o</span><span class="mord mathnormal mtight">c</span><span class="mord mathnormal mtight">e</span><span class="mord mathnormal mtight">s</span><span class="mord mathnormal mtight">s</span><span class="mord mathnormal mtight">o</span><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span><span class="mord mathnormal mtight">s</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.446108em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span><span class="mord mathnormal mtight">i</span><span class="mord mathnormal mtight">m</span><span class="mord mathnormal mtight">e</span><span class="mspace mtight"><span class="mtight"> </span></span><span class="mord mtight">1</span><span class="mspace mtight"><span class="mtight"> </span></span><span class="mord mathnormal mtight">p</span><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span><span class="mord mathnormal mtight">o</span><span class="mord mathnormal mtight">c</span><span class="mord mathnormal mtight">e</span><span class="mord mathnormal mtight">s</span><span class="mord mathnormal mtight">s</span><span class="mord mathnormal mtight">o</span><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.481108em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></p></li><li><p>Time-constrained scaling focuses on completing more work in a fixed amount of time<br /><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>S</mi><mi>p</mi><mi>e</mi><mi>e</mi><mi>d</mi><mi>u</mi><mi>p</mi><mo>=</mo><mfrac><mrow><mi>w</mi><mi>o</mi><mi>r</mi><mi>k</mi><mtext> </mtext><mi>d</mi><mi>o</mi><mi>n</mi><mi>e</mi><mtext> </mtext><mi>b</mi><mi>y</mi><mtext> </mtext><mi>P</mi><mtext> </mtext><mi>p</mi><mi>r</mi><mi>o</mi><mi>c</mi><mi>e</mi><mi>s</mi><mi>s</mi><mi>o</mi><mi>r</mi><mi>s</mi></mrow><mrow><mi>w</mi><mi>o</mi><mi>r</mi><mi>k</mi><mtext> </mtext><mi>d</mi><mi>o</mi><mi>n</mi><mi>e</mi><mtext> </mtext><mi>b</mi><mi>y</mi><mtext> </mtext><mn>1</mn><mtext> </mtext><mi>p</mi><mi>r</mi><mi>o</mi><mi>c</mi><mi>e</mi><mi>s</mi><mi>s</mi><mi>o</mi><mi>r</mi></mrow></mfrac></mrow><annotation encoding="application/x-tex">Speedup = \frac{work\ done\ by\ P\ processors}{work\ done\ by\ 1\ processor}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord mathnormal" style="margin-right:0.05764em;">S</span><span class="mord mathnormal">p</span><span class="mord mathnormal">e</span><span class="mord mathnormal">e</span><span class="mord mathnormal">d</span><span class="mord mathnormal">u</span><span class="mord mathnormal">p</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.4133239999999998em;vertical-align:-0.481108em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.9322159999999999em;"><span style="top:-2.6550000000000002em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.02691em;">w</span><span class="mord mathnormal mtight">o</span><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span><span class="mspace mtight"><span class="mtight"> </span></span><span class="mord mathnormal mtight">d</span><span class="mord mathnormal mtight">o</span><span class="mord mathnormal mtight">n</span><span class="mord mathnormal mtight">e</span><span class="mspace mtight"><span class="mtight"> </span></span><span class="mord mathnormal mtight">b</span><span class="mord mathnormal mtight" style="margin-right:0.03588em;">y</span><span class="mspace mtight"><span class="mtight"> </span></span><span class="mord mtight">1</span><span class="mspace mtight"><span class="mtight"> </span></span><span class="mord mathnormal mtight">p</span><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span><span class="mord mathnormal mtight">o</span><span class="mord mathnormal mtight">c</span><span class="mord mathnormal mtight">e</span><span class="mord mathnormal mtight">s</span><span class="mord mathnormal mtight">s</span><span class="mord mathnormal mtight">o</span><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.446108em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.02691em;">w</span><span class="mord mathnormal mtight">o</span><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span><span class="mspace mtight"><span class="mtight"> </span></span><span class="mord mathnormal mtight">d</span><span class="mord mathnormal mtight">o</span><span class="mord mathnormal mtight">n</span><span class="mord mathnormal mtight">e</span><span class="mspace mtight"><span class="mtight"> </span></span><span class="mord mathnormal mtight">b</span><span class="mord mathnormal mtight" style="margin-right:0.03588em;">y</span><span class="mspace mtight"><span class="mtight"> </span></span><span class="mord mathnormal mtight" style="margin-right:0.13889em;">P</span><span class="mspace mtight"><span class="mtight"> </span></span><span class="mord mathnormal mtight">p</span><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span><span class="mord mathnormal mtight">o</span><span class="mord mathnormal mtight">c</span><span class="mord mathnormal mtight">e</span><span class="mord mathnormal mtight">s</span><span class="mord mathnormal mtight">s</span><span class="mord mathnormal mtight">o</span><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span><span class="mord mathnormal mtight">s</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.481108em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span><br />“Work done” may not be linear function of problem inputs. One approach of defining “work done” is by execution time of same computation on a single processor (but consider effects of thrashing if problem too big)</p></li><li><p>Memory-constrained scaling (wak scaling) focuses on running the largest problem possible without overflowing main memory. Neither work or execution times are held constant.<br /><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>S</mi><mi>p</mi><mi>e</mi><mi>e</mi><mi>d</mi><mi>u</mi><mi>p</mi><mo>=</mo><mfrac><mrow><mi>w</mi><mi>o</mi><mi>r</mi><mi>k</mi><mtext> </mtext><mo stretchy="false">(</mo><mi>P</mi><mtext> </mtext><mi>p</mi><mi>r</mi><mi>o</mi><mi>c</mi><mi>e</mi><mi>s</mi><mi>s</mi><mi>o</mi><mi>r</mi><mi>s</mi><mo stretchy="false">)</mo></mrow><mrow><mi>t</mi><mi>i</mi><mi>m</mi><mi>e</mi><mtext> </mtext><mo stretchy="false">(</mo><mi>P</mi><mtext> </mtext><mi>p</mi><mi>r</mi><mi>o</mi><mi>c</mi><mi>e</mi><mi>s</mi><mi>s</mi><mi>o</mi><mi>r</mi><mi>s</mi><mo stretchy="false">)</mo></mrow></mfrac><mi mathvariant="normal">/</mi><mfrac><mrow><mi>w</mi><mi>o</mi><mi>r</mi><mi>k</mi><mtext> </mtext><mo stretchy="false">(</mo><mn>1</mn><mtext> </mtext><mi>p</mi><mi>r</mi><mi>o</mi><mi>c</mi><mi>e</mi><mi>s</mi><mi>s</mi><mi>o</mi><mi>r</mi><mo stretchy="false">)</mo></mrow><mrow><mi>t</mi><mi>i</mi><mi>m</mi><mi>e</mi><mtext> </mtext><mo stretchy="false">(</mo><mn>1</mn><mtext> </mtext><mi>p</mi><mi>r</mi><mi>o</mi><mi>c</mi><mi>e</mi><mi>s</mi><mi>s</mi><mi>o</mi><mi>r</mi><mo stretchy="false">)</mo></mrow></mfrac><mo>=</mo><mfrac><mrow><mi>w</mi><mi>o</mi><mi>r</mi><mi>k</mi><mtext> </mtext><mi>p</mi><mi>e</mi><mi>r</mi><mtext> </mtext><mi>u</mi><mi>n</mi><mi>i</mi><mi>t</mi><mtext> </mtext><mi>t</mi><mi>i</mi><mi>m</mi><mi>e</mi><mtext> </mtext><mi>o</mi><mi>n</mi><mtext> </mtext><mi>P</mi><mtext> </mtext><mi>p</mi><mi>r</mi><mi>o</mi><mi>c</mi><mi>e</mi><mi>s</mi><mi>s</mi><mi>o</mi><mi>r</mi><mi>s</mi></mrow><mrow><mi>w</mi><mi>o</mi><mi>r</mi><mi>k</mi><mtext> </mtext><mi>p</mi><mi>e</mi><mi>r</mi><mtext> </mtext><mi>u</mi><mi>n</mi><mi>i</mi><mi>t</mi><mtext> </mtext><mi>t</mi><mi>i</mi><mi>m</mi><mi>e</mi><mtext> </mtext><mi>o</mi><mi>n</mi><mtext> </mtext><mn>1</mn><mtext> </mtext><mi>p</mi><mi>r</mi><mi>o</mi><mi>c</mi><mi>e</mi><mi>s</mi><mi>s</mi><mi>o</mi><mi>r</mi></mrow></mfrac></mrow><annotation encoding="application/x-tex">Speedup = \frac{work\ (P\ processors)}{time\ (P\ processors)}/\frac{work\ (1\ processor)}{time\ (1\ processor)}=\frac{work\ per\ unit\ time\ on\ P\ processors}{work\ per\ unit\ time\ on\ 1\ processor}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord mathnormal" style="margin-right:0.05764em;">S</span><span class="mord mathnormal">p</span><span class="mord mathnormal">e</span><span class="mord mathnormal">e</span><span class="mord mathnormal">d</span><span class="mord mathnormal">u</span><span class="mord mathnormal">p</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.53em;vertical-align:-0.52em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.01em;"><span style="top:-2.655em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span><span class="mord mathnormal mtight">i</span><span class="mord mathnormal mtight">m</span><span class="mord mathnormal mtight">e</span><span class="mspace mtight"><span class="mtight"> </span></span><span class="mopen mtight">(</span><span class="mord mathnormal mtight" style="margin-right:0.13889em;">P</span><span class="mspace mtight"><span class="mtight"> </span></span><span class="mord mathnormal mtight">p</span><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span><span class="mord mathnormal mtight">o</span><span class="mord mathnormal mtight">c</span><span class="mord mathnormal mtight">e</span><span class="mord mathnormal mtight">s</span><span class="mord mathnormal mtight">s</span><span class="mord mathnormal mtight">o</span><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span><span class="mord mathnormal mtight">s</span><span class="mclose mtight">)</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.485em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.02691em;">w</span><span class="mord mathnormal mtight">o</span><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span><span class="mspace mtight"><span class="mtight"> </span></span><span class="mopen mtight">(</span><span class="mord mathnormal mtight" style="margin-right:0.13889em;">P</span><span class="mspace mtight"><span class="mtight"> </span></span><span class="mord mathnormal mtight">p</span><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span><span class="mord mathnormal mtight">o</span><span class="mord mathnormal mtight">c</span><span class="mord mathnormal mtight">e</span><span class="mord mathnormal mtight">s</span><span class="mord mathnormal mtight">s</span><span class="mord mathnormal mtight">o</span><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span><span class="mord mathnormal mtight">s</span><span class="mclose mtight">)</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.52em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mord">/</span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.01em;"><span style="top:-2.655em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span><span class="mord mathnormal mtight">i</span><span class="mord mathnormal mtight">m</span><span class="mord mathnormal mtight">e</span><span class="mspace mtight"><span class="mtight"> </span></span><span class="mopen mtight">(</span><span class="mord mtight">1</span><span class="mspace mtight"><span class="mtight"> </span></span><span class="mord mathnormal mtight">p</span><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span><span class="mord mathnormal mtight">o</span><span class="mord mathnormal mtight">c</span><span class="mord mathnormal mtight">e</span><span class="mord mathnormal mtight">s</span><span class="mord mathnormal mtight">s</span><span class="mord mathnormal mtight">o</span><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span><span class="mclose mtight">)</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.485em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.02691em;">w</span><span class="mord mathnormal mtight">o</span><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span><span class="mspace mtight"><span class="mtight"> </span></span><span class="mopen mtight">(</span><span class="mord mtight">1</span><span class="mspace mtight"><span class="mtight"> </span></span><span class="mord mathnormal mtight">p</span><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span><span class="mord mathnormal mtight">o</span><span class="mord mathnormal mtight">c</span><span class="mord mathnormal mtight">e</span><span class="mord mathnormal mtight">s</span><span class="mord mathnormal mtight">s</span><span class="mord mathnormal mtight">o</span><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span><span class="mclose mtight">)</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.52em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.4133239999999998em;vertical-align:-0.481108em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.9322159999999999em;"><span style="top:-2.6550000000000002em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.02691em;">w</span><span class="mord mathnormal mtight">o</span><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span><span class="mspace mtight"><span class="mtight"> </span></span><span class="mord mathnormal mtight">p</span><span class="mord mathnormal mtight">e</span><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span><span class="mspace mtight"><span class="mtight"> </span></span><span class="mord mathnormal mtight">u</span><span class="mord mathnormal mtight">n</span><span class="mord mathnormal mtight">i</span><span class="mord mathnormal mtight">t</span><span class="mspace mtight"><span class="mtight"> </span></span><span class="mord mathnormal mtight">t</span><span class="mord mathnormal mtight">i</span><span class="mord mathnormal mtight">m</span><span class="mord mathnormal mtight">e</span><span class="mspace mtight"><span class="mtight"> </span></span><span class="mord mathnormal mtight">o</span><span class="mord mathnormal mtight">n</span><span class="mspace mtight"><span class="mtight"> </span></span><span class="mord mtight">1</span><span class="mspace mtight"><span class="mtight"> </span></span><span class="mord mathnormal mtight">p</span><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span><span class="mord mathnormal mtight">o</span><span class="mord mathnormal mtight">c</span><span class="mord mathnormal mtight">e</span><span class="mord mathnormal mtight">s</span><span class="mord mathnormal mtight">s</span><span class="mord mathnormal mtight">o</span><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.446108em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.02691em;">w</span><span class="mord mathnormal mtight">o</span><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span><span class="mspace mtight"><span class="mtight"> </span></span><span class="mord mathnormal mtight">p</span><span class="mord mathnormal mtight">e</span><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span><span class="mspace mtight"><span class="mtight"> </span></span><span class="mord mathnormal mtight">u</span><span class="mord mathnormal mtight">n</span><span class="mord mathnormal mtight">i</span><span class="mord mathnormal mtight">t</span><span class="mspace mtight"><span class="mtight"> </span></span><span class="mord mathnormal mtight">t</span><span class="mord mathnormal mtight">i</span><span class="mord mathnormal mtight">m</span><span class="mord mathnormal mtight">e</span><span class="mspace mtight"><span class="mtight"> </span></span><span class="mord mathnormal mtight">o</span><span class="mord mathnormal mtight">n</span><span class="mspace mtight"><span class="mtight"> </span></span><span class="mord mathnormal mtight" style="margin-right:0.13889em;">P</span><span class="mspace mtight"><span class="mtight"> </span></span><span class="mord mathnormal mtight">p</span><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span><span class="mord mathnormal mtight">o</span><span class="mord mathnormal mtight">c</span><span class="mord mathnormal mtight">e</span><span class="mord mathnormal mtight">s</span><span class="mord mathnormal mtight">s</span><span class="mord mathnormal mtight">o</span><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span><span class="mord mathnormal mtight">s</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.481108em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></p></li></ol>]]></content>
      
      
      <categories>
          
          <category> Open Courses </category>
          
          <category> CMU 15-418 / Stanford CS149 Parallel Computing </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Parallelism </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>05. Graphic processing units and CUDA</title>
      <link href="/2022/05/19/Courses/CS149/05-Graphic-processing-units-and-CUDA/"/>
      <url>/2022/05/19/Courses/CS149/05-Graphic-processing-units-and-CUDA/</url>
      
        <content type="html"><![CDATA[<h1 id="graphics"><a class="markdownIt-Anchor" href="#graphics"></a> Graphics</h1><ol><li>The first step to draw a graphic in screen is to describe the things (key entities) that are manipulated, whose surface is represented as a 3D triangle mesh.<br />So the input of the calculating system is a list of vertices in 3D space and their connectivity into primitives.</li><li>The operations of system is as following:<br />Given a scene camera position, compute where the vertices lie on screen<br />Group vertices into primitives<br />Generate one fragment for each pixel a primitive overlaps<br />Compute color of primitive for each fragment based on scene lighting and primitive material properties<br />Put color of the “closest fragment” to the camera in the output image</li><li>We can Abstract process of rendering a picture as a sequence of operations on vertices, primitives, fragments, and pixels.<br />GPUs are very fast processors for performing the same computation (shader programs) on large collections of data (streams of vertices, fragments, and pixels), which sounds like data-parallelism.</li><li>To do GPU-based scientific computation, we need to set OpenGL output image size to be output array size, and render 2 triangles that exactly cover screen.</li></ol><h1 id="cuda"><a class="markdownIt-Anchor" href="#cuda"></a> CUDA</h1><h2 id="grid-block-and-thread"><a class="markdownIt-Anchor" href="#grid-block-and-thread"></a> Grid, Block and Thread</h2><ol><li>CUDA thread IDs can be up to 3-dimensional. Multiple threads make up a block, and multiple blocks make up a grid.<br />Each kernel has a grid. All the the blocks in a grid form a 3D matrix, and all the threads in a block also form a 3D matrix.<br />We can get information about the shape of threads in a block matrix or block in a grid matrix in a block with <code>block_dim</code> and <code>grid_dim</code></li><li>When launching the CUDA threads, we need to specify the size of blocks and threads with <code>kernel_function&lt;&lt;&lt;block_dim, thread_dim&gt;&gt;&gt;(parameters)</code>.<br />Here <code>block_dim</code> and <code>thread_dim</code> can be either a <code>dim3</code> value or a number of the total number of blocks and threads per-block to make the CUDA compiler figure out how to arrange blocks and threads.</li><li>So the coordinate to declare or locate a block in a grid, or a thread in a block is 3D. In the CUDA code, we can get the information about current block or thread with <code>blockIdx</code>, <code>threadIdx</code>, and their properties <code>x</code>, <code>y</code>, <code>z</code>.</li><li>The calculation object of CUDA is usually matrices. So we would prefer to cut matrices into blocks. Each CUDA block calculate one  block in matrices, and each thread calculate one element in matrices.</li><li>In <code>pthread</code>, there is stack space for thread, and need to allocate control block so OS can schedule thread.<br />Unlike <code>pthread</code>, CUDA control those instances by thread blocks. If control by threads, there will be too many to control.</li><li>Major CUDA assumption: thread block execution can be carried out in any order (no dependencies between blocks)</li></ol><h2 id="kernel-function"><a class="markdownIt-Anchor" href="#kernel-function"></a> Kernel function</h2><ol><li>“Host” code: serial execution runs as part of normal C/C++ application on CPU<br />“CUDA device” code: a kernel function runs on GPU, which is denoted by <code>__global__</code> before the definition of the kernel function.<br />Device function: SPMD execution on GPU, which is denoted by <code>__device__</code>. These functions are called by kernels, and don’t generate new threads.<br />Kernels and device functions only reference device memory. Host code can only reference host memory, but can have pointers to device memory.</li><li>In kernel function, we need to get the indices of the element a thread calculating. For a 2D matrix, we usually take <code>x</code> as column direction, and <code>y</code> as row direction.<br />So to access <code>A[i][j]</code>, <code>i = blockIdx.y * blockDim * y + threadIdx.y</code> and <code>j = blockIdx.x * blockDim.x + threadIdx.x</code>.</li><li>Number of kernel invocations is not determined by size of data collection. So normally we want to do a test before accessing the vector values (array values). The overhead of the test can be ignored, although it does cause some threads are not used.</li><li><code>__syncthreads()</code> is a barrier that wait for all threads in the block to arrive at this point.<br />Atomic operations on both global memory and shared memory variables is also provided, but they are very expensive, should only be used as the last resort.<br />There is an implicit barrier across all threads at return of kernel.</li><li>A compiled CUDA device binary includes program text (instructions) and information about required resources (how many threads per block, how much space per thread, how much shared space per thread block)</li></ol><h2 id="memory-model"><a class="markdownIt-Anchor" href="#memory-model"></a> Memory Model</h2><ol><li>Host and device have distinct address spaces, so before the execution, we need to copy data into CUDA memory.<br /><code>cudaMalloc(ptr, size)</code> can be used to allocate CUDA memory, and <code>cudaFree(ptr)</code> can free CUDA memory. The pointer in <code>cudaMalloc</code> can just be a host variable, but the pointer in <code>cudaFree</code> must be allocated by <code>cudaMalloc</code>.<br /><code>cudaMemcpy(dest, src, size, kind)</code> can copy those data into CUDA memory. <code>kind</code> is the direction of copy, which can be <code>cudaMemcpyHostToDevice</code> or <code>curdaMemcpyDeviceToHost</code>.</li><li>There are three distinct types of memory visible to kernels, per-thread private memory, per-block shared memory, and device global memory.</li><li><code>cudaMalloc</code>, <code>cudaMemcpy</code> and <code>cudaFree</code> all operate on device global memory, and those local variables in kernel function are in perthread private memory.<br />We can declare variables in per-block shared memory with <code>__share__</code>.</li><li>If multiple threads in a block need to access a common memory, they will all read that memory once. And if that memory is in the global memory, it would be really slow.</li><li>To avoid such efficient decrease, we can copy the common memory into the per-block shared memory. So we only need to access global memory once, and later accesses only in per-block shared memory.<br />We just need to declare a <code>__share__</code> array, and assign it with values in global memory.</li><li>All threads copy data from global memory to per-block shared memory asynchronous, so we better ass a <code>_syncthread()</code> to  make sure later operations only start when all data have been copied.</li></ol><h2 id="hardware-implementation"><a class="markdownIt-Anchor" href="#hardware-implementation"></a> Hardware implementation</h2><ol><li>Those synchronization within a warp and scheduling are done by hardware, and programmers don’t need to worry about these things.</li><li>GPU implementation maps thread blocks (“work”) to cores using a dynamic scheduling policy that respects resource requirements.</li><li>In GPU implementation (not a CUDA abstraction), each SM has multiple groups of warps. However, the number of warp execution contexts is far more than the number of warps.<br />And there is a warp selector for each warp to choose the instruction to be executed by that warp. Each warp selector usually has two (or more) Fectch/Decoder unit.</li><li>Shared per-block memory and L1-cache are inside each SM, but L2-cache is shared by all SMs.<br />The devide global memory (GPU memory) only communicates with blocks through L2-cache.</li><li>Each clock, an SM will choose several warp contexts to fill all warps to use thread-level pallelism, and a warp will choose several instructions to fill all Fetch/Decoder units to use instruction-level pallelism.</li><li>When running a CUDA program, GPU work schedulor will map one block to multiple warps in the same SM core. CUDA threads numbered within block in row-major order.<br />Inside a single thread block is SPMD shared address space programming.</li><li>When single warp accesses consecutive memory locations, do block read or write. When single warp accesses separated memory locations, requires gather (read) or scatter(write)</li><li>One SM core may have multiple blocks, so a SMM core is capable of concurrently executing multiple CUDA thread blocks.<br />When all threads in block complete, block resources (shared memory allocations, warp execution contexts) become available for next block.</li><li>The CUDA program is not compiled to SIMD instructions like ISPC gangs. GPU hardware is dynamically checking whether 32 independent CUDA threads share an instruction, and if this is true, it executes all 32 threads in a SIMD manner, or performance can suer due to divergent execution.</li></ol>]]></content>
      
      
      <categories>
          
          <category> Open Courses </category>
          
          <category> CMU 15-418 / Stanford CS149 Parallel Computing </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Parallelism </tag>
            
            <tag> CUDA </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>04. Work Distribution and Scheduling</title>
      <link href="/2022/05/17/Courses/CS149/04-Work-Distribution-and-Scheduling/"/>
      <url>/2022/05/17/Courses/CS149/04-Work-Distribution-and-Scheduling/</url>
      
        <content type="html"><![CDATA[<h1 id="balancing-the-workload"><a class="markdownIt-Anchor" href="#balancing-the-workload"></a> Balancing the workload</h1><p>Always implement the simplest solution first, then measure performance to determine if you need to do better.</p><h2 id="static-assignment"><a class="markdownIt-Anchor" href="#static-assignment"></a> Static assignment</h2><ol><li>The assignment of work to threads is pre-determined. But not necessarily determined at compile-time, may depend on runtime parameters.</li><li>Benefit: simple, essentially zero runtime overhead</li><li>Applicable situation: When the cost (execution time) of work and the amount of work is predictable. The followings are some most common situations:<br />When it is known up front that all work has the same cost<br />When work is predictable, but not all jobs have same cost<br />When statistics about execution time are known</li><li>Semi-static assignment: When the cost of work is predictable for near-term future, we can periodically profile itself and re-adjust assignment.<br />Assignment is “static” for the interval between re-adjustments</li></ol><h2 id="dynamic-assignment"><a class="markdownIt-Anchor" href="#dynamic-assignment"></a> Dynamic assignment</h2><ol><li><p>Program determines assignment dynamically at runtime to ensure a well distributed load. Often used when the execution time of tasks, or the total number of tasks, is unpredictable.</p></li><li><p>The ISPC task is implemented dynamically.</p></li></ol><h3 id="with-one-queue"><a class="markdownIt-Anchor" href="#with-one-queue"></a> With one queue</h3><ol><li><p>The programmers divide the whole problem into sub-problems (or “tasks”, “work”). A queue shared by all threads is a collection of work to do. Whenever a thread finished its task, it will grab another task from the queue.</p></li><li><p>Fine granularity partitioning: each task is small.<br />This is likely to have a good workload balance, but potential for high synchronization cost.</p></li><li><p>Coarse granularity partitioning: each task is larger.<br />This will decrease synchronization cost and the overhead, but may have a worse workload balance.</p></li><li><p>Long tasks should be scheduled first. Thread performing long task performs fewer overall tasks, but approximately the same amount of work as the other threads. This requires some knowledge of workload.</p></li></ol><h3 id="with-a-set-of-queues"><a class="markdownIt-Anchor" href="#with-a-set-of-queues"></a> With a set of queues</h3><ol><li><p>When assign with one queue, all threads have to communicate with each other about the queue.</p></li><li><p>Each thread has their own queue, and they only execute tasks in their queue. So there is no need to communication with other threads.</p></li><li><p>At the beginning, the programmer push tasks into queues arbitarily (a bit like static assignment).<br />The dynamic is that when a queue is empty, that thread can steal from other threads that is  still working.<br />It will steal from a random thread. Every time, it will steal a proportion of the tasks in the target queue, not all of them, and usually more than one task.<br />A thread is terminated when there is no thread for it to steal, namely when a steal is failed, it will try to steal from other threads, util it have tried all of them.</p></li><li><p>Stealing involves communication, but in a lower frequency then one queue method. And in this way, the local queue access is fast.</p></li><li><p>Sometimes it is hard to have fully independent task, but work in task queues need not be independent.<br />A task is not removed from queue and assigned to worker thread until all task dependencies are satisfied. Workers can submit new tasks (with optional explicit dependencies) to task system</p></li></ol><h1 id="scheduling"><a class="markdownIt-Anchor" href="#scheduling"></a> Scheduling</h1><p>In a divide-and-conquer algorithm, there is both dependencies and independencies. Like in quick-sort, both the divide is dependent on the partition, and those two divide is independent.<br />With Cilk Plus, we can express divide-and-conquer easier.</p><h2 id="cilk_spawn"><a class="markdownIt-Anchor" href="#cilk_spawn"></a> cilk_spawn</h2><ol><li><p><code>cilk_spawn</code> is labelled before a function call, so that the called function can run with the code after the call concurrently.<br />The call labelled <code>cilk_spawn</code> is the spawned child, and the rest of the code is the continuation.</p></li><li><p>In divide-and-conquer, there is always a time, when the problem size is small enough that overhead of spawn trumps benefits of<br />potential parallelization. And then we will solve those problems sequentially.</p></li><li><p>The main idea is to expose independent work (potential parallelism) to the system using <code>cilk_spawn</code>.</p></li><li><p><code>cilk_spawn</code> is a bit like <code>pthread_create</code>, and <code>cilk_sync</code> is similar to <code>pthread_join</code>. But <code>pthread</code> has some problems when too many threads are spawned.<br />The first is the heavyweight spawn operation. And many more concurrently running threads than cores, which will cause context switching overhead and larger working set than necessary, less cache locality.</p></li><li><p>The Cilk Plus runtime maintains pool of worker threads. All threads created at application launch.  There are exactly as many worker threads as execution contexts in the machine.<br />If we labelled everything <code>cilk_spawn</code>, the main thread has nothing to do.</p></li><li><p>Each thread in the pool will maintain a work queue to store what word needs to be done.<br />When a thread goes idle, it will look in busy thread’s queue for work, and moves work from busy thread’s queue to its own queue.</p></li><li><p>If caller thread runs the continuation first, the queue should record the child for later execution, and child is made available for stealing by other threads.<br />In this method, caller thread will spawn as many child as it could, like BFS. If no stealing, execution order is very different than<br />that of program withcilk_spawnremoved.</p></li><li><p>If caller thread runs the child first, the queue should record continuation for later execution, and continuation is made available for stealing by other threads.<br />In this method, caller thread will only create one item to steal.<br />If no stealing occurs, thread continually pops continuation from work queue, enqueues new continuation (like DFS). The order of execution is the same as for program with spawn removed.<br />If continuation is stolen, stealing thread spawns next child.</p></li><li><p>If the continuation is run first, there will be more items to steal, and thus makes a better advantage of multi-thread.<br />But if the continuation is run first, the work queue storage for system with T threads is no more than T times that of stack storage for single threaded execution, and thus saves more space.</p></li><li><p>Work queue is implemented as a dequeue (double ended queue).<br />Local thread pushes/pops from the “tail” (bottom), while remote threads steal from “head” (top).<br />Reduces contention with local thread: local thread is not accessing same part of dequeue that stealing threads do.<br />Do larger work first: in divide-and-conquer, the top of the queue is usually at the beginning of call tree, and is a larger piece of work.<br />Maximizes locality: in conjunction with run-child-first policy, local thread works on local part of call tree</p></li></ol><h2 id="cilk_sync"><a class="markdownIt-Anchor" href="#cilk_sync"></a> cilk_sync</h2><ol><li><p><code>cilk_sync</code> is used after those <code>cilk_spawn</code> call code. It will return when all calls spawned by current function have completed.</p></li><li><p>There is an implicitcilk_syncat the end of every function that contains a cilk_spawn, so when a Cilk function returns, all work associated with that function is complete.</p></li><li><p>If no work has been stolen by other threads, then there’s nothing to do at the sync point, <code>cilk_sync</code> is a no-op. But this is not a common situation.</p></li><li><p>One way to implement sync is with stalling joint.<br />Thread that initiates the fork must perform the sync. Therefore it waits for all spawned work to be complete.<br />descriptor for block A created<br />When a stealing from the initial thread happens, a descriptor for that stolen work is created to track the number of outstanding spawns for the block, and the number of those spawns that have completed.<br />When all the child spowned for the block is done, this block is considered done, and the descriptor is free. When all the blocks are done, sync is fullfilled.</p></li><li><p>Another way to implement sync is the greedy policy.<br />When thread that initiates the fork goes idle, it can look to steal new work.  Last thread to reach the join point continues execution after sync. This will also create a decriptor for those stolen work.<br />Worker thread that initiated spawn may not be thread that executes logic after <code>cilk_sync</code>.</p></li><li><p>In greedy policy, All threads always attempt to steal if there is nothing to do, and thread only goes idle if no work to steal is present in system. But in stalling policy, the initial thread doesn’t steal, and only waits when its work is done.</p></li><li><p>Overhead of bookkeeping steals and managing sync points only occurs when steals occur. If large pieces of work are stolen, this should occur infrequently. Most of the time, threads are pushing/popping local work from their local dequeue.</p></li><li><p>Cilk uses greedy join scheduling.</p></li></ol>]]></content>
      
      
      <categories>
          
          <category> Open Courses </category>
          
          <category> CMU 15-418 / Stanford CS149 Parallel Computing </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Parallelism </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>03. Parallel Programming Basics</title>
      <link href="/2022/04/20/Courses/CS149/03-Parallel-Programming-Basics/"/>
      <url>/2022/04/20/Courses/CS149/03-Parallel-Programming-Basics/</url>
      
        <content type="html"><![CDATA[<h1 id="decomposition"><a class="markdownIt-Anchor" href="#decomposition"></a> Decomposition</h1><ol><li><p>Decomposition: The problem to solve is usually a chunk of work. So the first step we need to do is to decomposite them into subproblems (a.k.a tasks, work to do)</p></li><li><p>We usually want the number subproblems to be at least as many as processors.</p></li><li><p>The key aspect of decomposition is to identify dependencies. We want subproblems to be independent, so that they can be paralleled.</p></li><li><p>Amdahl’s Law: dependencies limit maximum speedup due to parallelism<br />Let S = the fraction of sequential execution that is inherently sequential (dependencies prevent parallel execution). Then maximum speedup due to parallel execution ≤ 1/S.</p><p class='katex-block'><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>s</mi><mi>p</mi><mi>e</mi><mi>e</mi><mi>d</mi><mi>u</mi><mi>p</mi><mo>≤</mo><mfrac><mi>t</mi><mrow><mi>s</mi><mi>t</mi><mo>+</mo><mfrac><mrow><mo stretchy="false">(</mo><mn>1</mn><mo>−</mo><mi>s</mi><mo stretchy="false">)</mo><mi>t</mi></mrow><mi>p</mi></mfrac></mrow></mfrac><mo>=</mo><mfrac><mn>1</mn><mrow><mi>s</mi><mo>+</mo><mfrac><mrow><mn>1</mn><mo>−</mo><mi>s</mi></mrow><mi>p</mi></mfrac></mrow></mfrac></mrow><annotation encoding="application/x-tex">speedup \le\frac{t}{st+\frac{(1-s)t}{p}}=\frac1{s+\frac{1-s}{p}} </annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord mathnormal">s</span><span class="mord mathnormal">p</span><span class="mord mathnormal">e</span><span class="mord mathnormal">e</span><span class="mord mathnormal">d</span><span class="mord mathnormal">u</span><span class="mord mathnormal">p</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">≤</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:2.6731879999999997em;vertical-align:-1.381108em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.29208em;"><span style="top:-2.11em;"><span class="pstrut" style="height:3.01em;"></span><span class="mord"><span class="mord mathnormal">s</span><span class="mord mathnormal">t</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.01em;"><span style="top:-2.6550000000000002em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">p</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.485em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mtight">1</span><span class="mbin mtight">−</span><span class="mord mathnormal mtight">s</span><span class="mclose mtight">)</span><span class="mord mathnormal mtight">t</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.481108em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span><span style="top:-3.2399999999999998em;"><span class="pstrut" style="height:3.01em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.687em;"><span class="pstrut" style="height:3.01em;"></span><span class="mord"><span class="mord mathnormal">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.381108em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:2.537656em;vertical-align:-1.216216em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.32144em;"><span style="top:-2.264892em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathnormal">s</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.845108em;"><span style="top:-2.6550000000000002em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">p</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span><span class="mbin mtight">−</span><span class="mord mathnormal mtight">s</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.481108em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord">1</span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.216216em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></span></p></li><li><p>In most cases, the programmer is responsible for performing decomposition.</p></li><li><p>When we are doing the decomposition, it is better to think of partitioning computation instead of data.</p></li></ol><h1 id="assignment"><a class="markdownIt-Anchor" href="#assignment"></a> Assignment</h1><ol><li><p>Assignment: When the subproblems is more than processors, we then will group them together to form a larger chunk of work, and assign the grouped tasks to parallel threads.</p></li><li><p>One goal is to balance workload, so that each processor finish their work almost at the same time.<br />Another goal is to reduce communication costs. Getting data from another processor is nontrivial expensive, either cache miss or waiting for a message.<br />These two goals are at odds with each other.</p></li><li><p>This step can be performed statically, or dynamically during execution<br />Static way: Before the processors begin to do the work, we have already decide how to divide things up.<br />Dynamic way: We work out the way to divide on the way as processing.</p></li><li><p>We can choose the static way with the programCount and programIndex assignment or pthread</p></li><li><p>We can choose the dynamic way with foreach if the system choose the dynamic way, or the queue<br />In the queue way, we arrange all tasks in a queue, and when a processor has done its job, it will grab another task from the queue. This is a good way for balancing workload, but maintain the queue and acquire task from it might cost some performance.</p></li></ol><h1 id="orchestration"><a class="markdownIt-Anchor" href="#orchestration"></a> Orchestration</h1><ol><li><p>Orchestration: When parallel threads are running, they may need to coorperate with each other. So we need to let them communicate correctly.</p></li><li><p>There are things that we will worry about, like structure communication, synchronization, orgnizing data structure in memory, and scheduling tasks</p></li><li><p>The goal is to reduce costs of communication/sync, preserve locality of data reference, reduce overhead of synchronization or communication, etc.</p></li><li><p>In shared address space model, lock/unlock is common used for preserving atomicity, and barriers can divide computation into phases. When threads execute to barriers, they will stop and wait. Until enough number of threads hit the barrier, those stalled threads are allowed to execute rest codes.</p></li><li><p>A common used optimization strategy is that try to use less lock/unlock and barriers.<br />Everytime when we operate a shared variable, we need to use the lock/unlock to keep atomicity. But maybe we can operate on partial variable locally and then merge the partial results together.<br />When we use barrier to keep a shared variable valid when it might be changed at the next phase, we can use different shared variable in successive phases. This is to trade off footprint for removing dependencies.</p></li></ol><h1 id="mapping"><a class="markdownIt-Anchor" href="#mapping"></a> Mapping</h1><ol><li><p>Mapping: Finally, we need to map each thread to physical hardware.</p></li><li><p>When we map pthreads to hardware execution context on a CPU core, this is done by the operating system<br />When we map ISPC program instances to vector instruction lanes, this is done by the compiler<br />When we map CUDA thread blocks to GPU cores, this is done by the hardware</p></li><li><p>Place related threads (cooperating threads) on the same processor to maximize locality, data sharing, minimize costs of comm/sync<br />Place unrelated threads on the same processor (one might be bandwidth limited and another might be compute limited) to use machine more efficiently</p></li><li><p>Normally, we just let the OS do the mapping as it want. But sometimes we still want to control the way of mapping.</p></li></ol>]]></content>
      
      
      <categories>
          
          <category> Open Courses </category>
          
          <category> CMU 15-418 / Stanford CS149 Parallel Computing </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Parallelism </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>02. Parallel programming models</title>
      <link href="/2022/04/18/Courses/CS149/02-Parallel-programming-models/"/>
      <url>/2022/04/18/Courses/CS149/02-Parallel-programming-models/</url>
      
        <content type="html"><![CDATA[<h1 id="ispc-intel-spmd-program-compiler"><a class="markdownIt-Anchor" href="#ispc-intel-spmd-program-compiler"></a> ISPC (Intel SPMD Program Compiler)</h1><h2 id="format-of-ispc"><a class="markdownIt-Anchor" href="#format-of-ispc"></a> Format of ISPC</h2><ol><li><p>ISPC is an SPMD compiler, not an SIMD.</p></li><li><p>The code that need to be paralleled will be written in a file with surfix of “.ispc” as a function. And we will call that function in the main.cpp.<br />Call to ISPC function spawns gang of ISPC program instances. All instances run ISPC code concurrently. The ISPC function will return when all instances have completed.<br />All code in main.cpp will be executed sequentially.</p></li><li><p><code>programCount</code>: the number of simultaneously executing instances in the gang. It is the same for all instances, thus called “uniform value”. This is not set by programmer, but by the run-time system. programmer can only read it but don’t set that.</p></li><li><p><code>programIndex</code>: the ID of the current instance in the gang. It is a non-uniform value, namely varying.<br />This is used to assign work to each instance. If we don’t use the programIndex to control the work to be done by each instance, they will all do all the work. Thus there will be redundant and have no performance improve.</p></li><li><p><code>uniform</code>: a type modifier. All instances have a copy of the same value for this variable. Its use is purely an optimization. Not needed for correctness.<br />We cannot add a non-uniform value to a uniform value directly, which will cause a compile-time type error. In order to do so, we need a reduce_add function from ISPC library.</p></li><li><p>Those ISPC program instances is not separate threads. The ISPC complier actually generates an SIMD thread. So the programCount is the vector width of the machine.<br />So it can only run on one core. And “task” is used to achieve multi-core execution.</p></li></ol><h2 id="ways-of-assignment"><a class="markdownIt-Anchor" href="#ways-of-assignment"></a> Ways of assignment</h2><ol><li><p>Interleaved assignment: the data processed by each instance is discontinuous, namely the subsctipt is:</p><p class='katex-block'><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>p</mi><mi>r</mi><mi>o</mi><mi>g</mi><mi>r</mi><mi>a</mi><mi>m</mi><mi>I</mi><mi>n</mi><mi>d</mi><mi>e</mi><mi>x</mi><mo>+</mo><mi>i</mi><mo>×</mo><mi>p</mi><mi>r</mi><mi>o</mi><mi>g</mi><mi>r</mi><mi>a</mi><mi>m</mi><mi>C</mi><mi>o</mi><mi>u</mi><mi>n</mi><mi>t</mi><mo separator="true">,</mo><mi>i</mi><mo>∈</mo><mo stretchy="false">[</mo><mn>0</mn><mo separator="true">,</mo><mfrac><mrow><mi>N</mi><mo>−</mo><mi>p</mi><mi>r</mi><mi>o</mi><mi>g</mi><mi>r</mi><mi>a</mi><mi>m</mi><mi>I</mi><mi>n</mi><mi>d</mi><mi>e</mi><mi>x</mi></mrow><mrow><mi>p</mi><mi>r</mi><mi>o</mi><mi>g</mi><mi>r</mi><mi>a</mi><mi>m</mi><mi>C</mi><mi>o</mi><mi>u</mi><mi>n</mi><mi>t</mi></mrow></mfrac><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">programIndex+i\times programCount,i\in[0,\frac{N-programIndex}{programCount}) </annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord mathnormal">p</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mord mathnormal">o</span><span class="mord mathnormal" style="margin-right:0.03588em;">g</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mord mathnormal">a</span><span class="mord mathnormal">m</span><span class="mord mathnormal" style="margin-right:0.07847em;">I</span><span class="mord mathnormal">n</span><span class="mord mathnormal">d</span><span class="mord mathnormal">e</span><span class="mord mathnormal">x</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.74285em;vertical-align:-0.08333em;"></span><span class="mord mathnormal">i</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.8777699999999999em;vertical-align:-0.19444em;"></span><span class="mord mathnormal">p</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mord mathnormal">o</span><span class="mord mathnormal" style="margin-right:0.03588em;">g</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mord mathnormal">a</span><span class="mord mathnormal">m</span><span class="mord mathnormal" style="margin-right:0.07153em;">C</span><span class="mord mathnormal">o</span><span class="mord mathnormal">u</span><span class="mord mathnormal">n</span><span class="mord mathnormal">t</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal">i</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:2.25188em;vertical-align:-0.8804400000000001em;"></span><span class="mopen">[</span><span class="mord">0</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.3714399999999998em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathnormal">p</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mord mathnormal">o</span><span class="mord mathnormal" style="margin-right:0.03588em;">g</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mord mathnormal">a</span><span class="mord mathnormal">m</span><span class="mord mathnormal" style="margin-right:0.07153em;">C</span><span class="mord mathnormal">o</span><span class="mord mathnormal">u</span><span class="mord mathnormal">n</span><span class="mord mathnormal">t</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.10903em;">N</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mord mathnormal">p</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mord mathnormal">o</span><span class="mord mathnormal" style="margin-right:0.03588em;">g</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mord mathnormal">a</span><span class="mord mathnormal">m</span><span class="mord mathnormal" style="margin-right:0.07847em;">I</span><span class="mord mathnormal">n</span><span class="mord mathnormal">d</span><span class="mord mathnormal">e</span><span class="mord mathnormal">x</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.8804400000000001em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mclose">)</span></span></span></span></span></p></li><li><p>Block assignment: the data is split into several chunks, and each instance process one chunk. So the data is continuous, namely the subscript is:</p><p class='katex-block'><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>p</mi><mi>r</mi><mi>o</mi><mi>g</mi><mi>r</mi><mi>a</mi><mi>m</mi><mi>I</mi><mi>n</mi><mi>d</mi><mi>e</mi><mi>x</mi><mo>×</mo><mi>c</mi><mi>o</mi><mi>u</mi><mi>n</mi><mi>t</mi><mo>+</mo><mi>i</mi><mo separator="true">,</mo><mi>i</mi><mo>∈</mo><mo stretchy="false">[</mo><mn>0</mn><mo separator="true">,</mo><mi>c</mi><mi>o</mi><mi>u</mi><mi>n</mi><mi>t</mi><mo stretchy="false">)</mo><mo separator="true">,</mo><mi>c</mi><mi>o</mi><mi>u</mi><mi>n</mi><mi>t</mi><mo>=</mo><mfrac><mi>N</mi><mrow><mi>p</mi><mi>r</mi><mi>o</mi><mi>g</mi><mi>r</mi><mi>a</mi><mi>m</mi><mi>C</mi><mi>o</mi><mi>u</mi><mi>n</mi><mi>t</mi></mrow></mfrac></mrow><annotation encoding="application/x-tex">programIndex\times count+i, i\in[0,count),count=\frac{N}{programCount}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord mathnormal">p</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mord mathnormal">o</span><span class="mord mathnormal" style="margin-right:0.03588em;">g</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mord mathnormal">a</span><span class="mord mathnormal">m</span><span class="mord mathnormal" style="margin-right:0.07847em;">I</span><span class="mord mathnormal">n</span><span class="mord mathnormal">d</span><span class="mord mathnormal">e</span><span class="mord mathnormal">x</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.69841em;vertical-align:-0.08333em;"></span><span class="mord mathnormal">c</span><span class="mord mathnormal">o</span><span class="mord mathnormal">u</span><span class="mord mathnormal">n</span><span class="mord mathnormal">t</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.85396em;vertical-align:-0.19444em;"></span><span class="mord mathnormal">i</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal">i</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">[</span><span class="mord">0</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal">c</span><span class="mord mathnormal">o</span><span class="mord mathnormal">u</span><span class="mord mathnormal">n</span><span class="mord mathnormal">t</span><span class="mclose">)</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal">c</span><span class="mord mathnormal">o</span><span class="mord mathnormal">u</span><span class="mord mathnormal">n</span><span class="mord mathnormal">t</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:2.2407700000000004em;vertical-align:-0.8804400000000001em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.36033em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathnormal">p</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mord mathnormal">o</span><span class="mord mathnormal" style="margin-right:0.03588em;">g</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mord mathnormal">a</span><span class="mord mathnormal">m</span><span class="mord mathnormal" style="margin-right:0.07153em;">C</span><span class="mord mathnormal">o</span><span class="mord mathnormal">u</span><span class="mord mathnormal">n</span><span class="mord mathnormal">t</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.10903em;">N</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.8804400000000001em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></span></p></li><li><p>When using the block assignment, there might exist some situation when the cost of processing later data is more expensive than processing former data, which will make the assignment uneven. So the interleaved assignment is less risky.</p></li><li><p>Since ISPC only generate one thread, the continuous access of data in block assignment is not more cache-friend then the discontinuous access in interleaved assignment.<br />If there are several threads, than block assignment might be more cache-friend.</p></li><li><p>The data requested by all instances at the same time is a vector. In interleaved assignment, the data in a vector is memory continuous, while it is not in block assignment. So in memory access, interleaved assignment is faster.</p></li><li><p><code>foreach (i = 0 ... N)</code> says that these loop iterations can be paralleled, and ISPC implementation assigns iterations to program instances in gang. Current ISPC implementation will perform a static interleaved assignment</p></li></ol><h2 id="system-layers"><a class="markdownIt-Anchor" href="#system-layers"></a> System layers</h2><ol><li><p>The layers from up to down is that parallel applications, compilers and/or parallel runtime, operating system, Micro-architecture (hardware implementation)</p></li><li><p>Different parallel models can have different combinations of concerned layers.</p></li><li><p>If we express parallelism with pthread, it goes through all layers. First the parallel application calls <code>pthread_create()</code> to access pthread library implementation. Then the pthread library uses <code>System call API</code> to ask OS support: kernel thread management. Finally, the OS uses <code>x86-64</code> to control modern multi-core CPU.</p></li><li><p>If we express parallelism with ISPC without “task”, it doesn’t need the support of OS. The parallel application uses ISPC language to ask for service of ISPC compiler. And the complier will produce machine language of x86-64 including <code>AVX vector instruction</code> to control a single-core of CPU.</p></li></ol><h1 id="communication"><a class="markdownIt-Anchor" href="#communication"></a> Communication</h1><h2 id="shared-address-space"><a class="markdownIt-Anchor" href="#shared-address-space"></a> Shared Address Space</h2><ol><li><p>The whole machine has a common space address. When threads aren’t working together, they just access their memory space. They can communicate with each by reading or writing the same data and manipulating synchronization primitives (like locks)</p></li><li><p>This model requires hardware support to implement efficiently. In hardware implementation, any processor can directly reference any memory location</p></li><li><p>Symmetric (shared-memory) multi-processor (SMP): all processors have uniform memory access time, namely the cost of accessing an uncached memory address is the same for all processors<br />This is unscalarable since the access latency will increase fast with more and more processors and memory chips.<br />The cores can share memory through a shared L3 cahce or a crossbar switch with die area of one core</p></li><li><p>Non-uniform memory access (NUMA): All processors can access any memory location, but the cost of memory access (latency and/or bandwidth) is different for different processors. Each processor has a memory chip that is close to it.<br />This is more scalarable since the low latency and high bandwidth to local memory.<br />Cost is the increased programmer effort for performance tuning. Finding, exploiting locality is important to performance (want most memory accesses to be to local memories)</p></li></ol><h2 id="message-passing"><a class="markdownIt-Anchor" href="#message-passing"></a> Message Passing</h2><ol><li><p>Threads operate within their own private address spaces, and they communicate by sending/receiving messages</p></li><li><p>send: specifies recipient, buffer to be transmitted, and optional message identifier (“tag”)<br />receive: sender, specifies buffer to store data, and optional message identifier</p></li><li><p>With this model, we can easily build large scale of parallel machine by just interconnect them together. Hardware need not implement system-wide loads and stores to execute message passing programs, need only be able to communicate messages<br />But the interconnect speed can be the bottleneck of the system.</p></li><li><p>We can implement the message passing model with shared memory space.<br />Sending message is copying memory from message library buffers, while receiving message is copying data from message library buffers</p></li><li><p>We can also implement shared address space abstraction on machines that do not support it in hardware via less efficient software solution.<br />Mark all pages with shared variables as invalid at first, and page-fault handler issues appropriate network requests</p></li><li><p>Synchronous (blocking) send and receive<br />Send(): call returns when sender receives acknowledgement that message data resides in address space of receiver<br />Recv(): call returns when data from received message is copied into address space of receiver and acknowledgement sent back to sender<br />So when using message passing model, we need to be careful for the order of send() and recv() in each threads because it may easily raise a deadlock.<br />If the first call of all threads is send(), then no one is receiving and all is waiting someone to receive what they have sent.<br />One common way to program is to arrage one thread to send first and the receiver of that send to receive first.</p></li><li><p>Non-blocking asynchronous send/recv<br />Send() call returns immediately, while recv() posts intent to receive in the future and returns immediately.<br />We can use checksend(), checkrecv() to determine actual status of send/receipt.<br />Buffer provided to send() cannot be modified by calling thread since message processing occurs concurrently with thread execution</p></li></ol><h2 id="data-parallel"><a class="markdownIt-Anchor" href="#data-parallel"></a> Data Parallel</h2><ol><li><p>Data parallel has a very rigid computation struture. If it works well, it will work very well. But sometimes it just won’t work.</p></li><li><p>Nowadays, data parallel usually takes the form of SPMD instead of SIMD. Programs perform same function on different data elements in a collection<br /><code>map(function, collection)</code>: Synchronization is implicit at the end of the map. Map returns when function has been applied to all elements ofcollection</p></li><li><p>When the function is too complicated, the result might be non-deterministic.<br />Data-parallel model (foreach) provides no specification of order in which iterations occur and no primitives for fine-grained mutual exclusion/synchronization.</p></li><li><p>Streams: collections of elements. Elements can be processed independently.<br />Kernels: side-effect-free functions. Operate element-wise on collections.</p></li><li><p>A stream can be claimed by <code>stream&lt;ElemType&gt; name(N)</code><br />When define the kernel function, its parameters are single elements instead of a whole collection. But when call the kernel function, we pass the streams into the function directly.</p></li><li><p>Benefits of stream programming:<br />Functions really are side-effect free (cannot write a non-deterministic program)<br />Program data flow is known by compiler: Inputs and outputs of each invocation are known in advance and thus prefetching can be employed to hide latency.<br />When there are multiple kernels, and the output of the last kernel is the input of the next kernel, producer-consumer locality is known in advance.<br />Implementation can be structured so outputs of first kernel are immediately processed by second kernel. The values are stored in on-chip buffers/caches and never written to memory, which saves bandwidth.<br />These optimizations are responsibility of stream program compiler. Requires global program analysis.</p></li><li><p>Drawback of stream programming: Need library of operators to describe complex data flows, so it might go wrong.</p></li><li><p><code>stream_gather(input, indices, tmp_input)</code>: Put elements in input to tmp_input according to indices. This is called before the kernel function, and the kernel function will deal with gathered stream.<br /><code>stream_scatter(tmp_output, indices, output)</code>: Similar to stream_gather, but it is called after the kernel function, and kernel function will deal with original stream.<br />The parameters of both function are all stream.</p></li></ol><h2 id="synchronization-and-communication"><a class="markdownIt-Anchor" href="#synchronization-and-communication"></a> Synchronization and Communication</h2><ol><li><p>In shared address space, mutual exclusion is required for shared variables, and barriers are used to express dependencies between phases of computation.<br />They can communicate through implicit loads/stores to shared variables.</p></li><li><p>In message passing model, the synchronizations and communications are both performed by sending and receiving messages.</p></li><li><p>In data parallel model, a single logical thread is in control, but iterations of forall loop may be parallelized by the system. There is an implicit barrier at end offorallloop body.<br />They can also communicate throught implicit loads and stores, like shared address space. There is also some special built-in primitives for more complex communication patterns, e.g., reduce</p></li></ol><h2 id="modern-practice"><a class="markdownIt-Anchor" href="#modern-practice"></a> Modern practice</h2><ol><li><p>Use shared address space programming within a multi-core chip of a cluster, use message passing between chips<br />Use convenience of shared address space where it can be implemented efficiently (within a chip), require explicit communication elsewhere.</p></li><li><p>Data-parallel-ish programming models support shared-memory style synchronization primitives in kernels. This could permit limited forms of inter-iteration communication.</p></li></ol>]]></content>
      
      
      <categories>
          
          <category> Open Courses </category>
          
          <category> CMU 15-418 / Stanford CS149 Parallel Computing </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Parallelism </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>01. Modern Multicore Processors</title>
      <link href="/2022/04/13/Courses/CS149/01-Modern-Multicore-Processors/"/>
      <url>/2022/04/13/Courses/CS149/01-Modern-Multicore-Processors/</url>
      
        <content type="html"><![CDATA[<h1 id="speedup"><a class="markdownIt-Anchor" href="#speedup"></a> Speedup</h1><ol><li>Speedup (using P processors) = execution time (using 1 processor) / execution time (using P processors)</li><li>When using P processors, we can only get a speedup less than P times.<br />One reason is that although cores are in the same chip, when they want to communicate with each other, they have to transmit information through wires, which takes some time.<br />Another reason is that the imbalance in work assignment, which caused that one core has too heavy assignment while other cores has nothing to do but wait.<br />Communication costs can dominate a parallel computation, severely limiting speedup. Especially when you assign tasks to too many cores, each core gets little computation.</li></ol><h1 id="parallelism"><a class="markdownIt-Anchor" href="#parallelism"></a> Parallelism</h1><p>Why parallelism?<br />Before 2004, the performance of single-processor grew exponentially. However, in 2004, Intel hit the Power Density Wall. If you get more than 100 watts in a chip, it goes to hot and will melt. And the battery won’t hold long.</p><h2 id="ilp"><a class="markdownIt-Anchor" href="#ilp"></a> ILP</h2><ol><li>Instruction-Level Parallelism. Extract several instructions from the same instruction stream, and multiple ALU performs multiple operations parallel (within a core). This has to be done in a semantics of program.</li><li>Superscalar processor: exploit ILP within an instruction stream. Parallelism automatically and dynamically discovered by the hardware during execution (not programmer visible)</li><li>Example: Pentium 4<br />Its inctruction decoder will yank a whole bunch of instructions out of instruction stream, and map them to a new kind of computation called data flow computation that will track which value is generated and feed which instruction there<br />Decoders map them to independent processing units that can each performs a subset of the whole operations.<br />Control logics try to predict what’s going on and deal with it when it predicts incorrectly. The Branch Target Buffer keeps a record of all the control flow instructions to predict where they will go again. If it predicts wrong, it will back out and doesn’t commit to those results generated, flushes them away<br />Meltdown inspector: This logic leaks informations about what other processors are doing.</li><li>Most available ILP is exploited by a processor capable of issuing four instructions per clock, and only little performance benefit from building a processor that can issue more.</li></ol><h2 id="multi-core"><a class="markdownIt-Anchor" href="#multi-core"></a> Multi-Core</h2><p>Before multi-core era, Majority of chip transistors used to perform operations that help a single instruction stream run fast.<br />More transistors mean larger cache, smarter out-of-order logic, smarter branch predictor, etc. Also, more transistors get smaller transistors, and thus higher clock frequencies</p><h3 id="simpler-cores"><a class="markdownIt-Anchor" href="#simpler-cores"></a> Simpler cores</h3><ol><li>It uses increasing transistor count to add more cores to the processor, rather than use transistors to increase sophistication of processor logic that accelerates a single instruction stream (e.g., out-of-order and speculative operations)</li><li>Each core is slower at running a single instruction stream than our original large core, but the sum performance is faster. With a smaller core, the communication cost inside of a chip will be cheaper.</li><li>However, the original programs express no parallelism and run as one thread on one of the processor cores.</li><li>One way to express paralllelism is by using pthreads. It will create threads to deal with tasks we assigned.</li><li>Another way is called data-parallele expression. The programmer declare loop iterations to be independent, and a compiler might automatically generate parallel threaded code</li></ol><h3 id="simd-processing"><a class="markdownIt-Anchor" href="#simd-processing"></a> SIMD processing</h3><ol><li>Amortize cost/complexity of managing an instruction stream across many ALUs. Same instruction broadcast to all ALUs, executed in parallel on all ALUs</li><li>Each core has  an independent vector register set different from the regular register set. And Each core has multiple ALUs to execute the same instruction to different data.</li><li>Only a very structual, carefully written code can do an automatical vectorization by compliers.</li><li>When conditional executions are occurred, it will run the condition first, and create a mask according to the result, which is used to disable the ALUs that should not execute current instructions. Those active ALUs will execute the instructions, and a new mask is created. This procession will continue until all ALUs have execute all conditional instructions they should execute, and then they can execute remaining unconditional codes together again.<br />When a core can handle n elements at the same time, the performance in the worst case is 1 / n of the peak performance.</li><li>Instruction stream coherence (“coherent execution”): Same instruction sequence applies to all elements operated upon simultaneously.<br />“Divergent” execution: A lack of instruction stream coherence</li><li>Coherent execution is necessary for efficient use of SIMD processing resources. However, coherent execution is not necessary for efficient parallelization across cores, since each core has the capability to fetch/decode a different instruction stream</li></ol><h4 id="simd-on-modern-cpus"><a class="markdownIt-Anchor" href="#simd-on-modern-cpus"></a> SIMD on modern CPUs</h4><ol><li>SSE instructions: 128-bit operations: 4x32 bits or 2x64 bits (4-wide float vectors)<br />AVX instructions: 256 bit operations: 8x32 bits or 4x64 bits (8-wide float vectors)<br />AVX512 instructions: 512 bit operations: 16x32 bits or 8x64 bits (8-wide float vectors)</li><li>Instructions are generated by the complier. Parallelism is explicitly requested by programmer using intrinsics, and conveyed using parallel language semantics. Finally, it is inferred by dependency analysis of loops by “auto-vectorizing” compiler.</li><li>Explicit SIMD: SIMD parallelization is performed at compile time. We can inspect program binary and see SIMD instructions.</li></ol><h4 id="simd-on-modern-gpus"><a class="markdownIt-Anchor" href="#simd-on-modern-gpus"></a> SIMD on modern GPUs</h4><ol><li>In GPUs, it usually is SPMD (Single Program Multiple Data), and uses SIMD to implement much of the logic.</li><li>Implicit SIMD: Compiler generates a scalar binary (scalar instructions). But N instances of the program are <em>always run</em> together on the processor. In other words, the interface to the hardware itself is data-parallel.</li><li>Hardware (not compiler) is responsible for simultaneously executing the same instruction from multiple instances on different data on SIMD ALUs</li><li>SIMD width of most modern GPUs ranges from 8 to 32</li></ol><h1 id="access-memory"><a class="markdownIt-Anchor" href="#access-memory"></a> Access Memory</h1><ol><li>Memory latency: The amount of time for a memory request (e.g., load, store) from a processor to be serviced by the memory system. Memory “access time” is a measure of latency.</li><li>Memory bandwidth: The rate at which the memory system can provide data to a processor</li><li>Stall: A processor “stalls” when it cannot run the next instruction in an instruction stream because of a dependency on a previous instruction. Accessing memory is a major source of stalls</li><li>One way to reduce stall is reducing latency.<br />One stratege is cache, which also provides high bandwidth data transfer to CPU.</li><li>Another way is hiding latency, namely the latency of the memory operation is not changed, it just no longer causes reduced processor utilization.<br />One common strategy is the prefetch. All modern CPUs have logic for prefetching data into caches. Prefetching can also reduce performance if the guess is wrong (hogs bandwidth, pollutes caches)<br />The other is using multi-threading. The idea is to interleave processing of multiple threads on the same core to hide stalls.</li></ol><h2 id="multi-threading"><a class="markdownIt-Anchor" href="#multi-threading"></a> Multi-threading</h2><ol><li>Key idea of throughput-oriented systems is that potentially increase time to complete work by any one thread, in order to increase overall system throughput when running multiple threads.<br />There exists some time when one thread is runnable, but it is not being executed by the processor, since the core is running some other thread.</li><li>With more storing executiong contexts in the cache, the working set per thread is smaller, and the latency hiding ability is higher.<br />And since the cache space per thread is less, may go to memory more often. Thus relies heavily on memory bandwidth.<br />When the thread is much enough to achieve 100% utilization of the core, additional threads yield no benefit.</li><li>The instruction decoder will choose instructions from multiple threads, and fire them to the execution units the threads shared. And the memory interface unit will detect dependencies automatically.</li><li>Interleaved multi-threading (a.k.a. temporal multi-threading): Each clock, the core chooses a thread, and runs an instruction from the thread on the ALUs</li><li>Simultaneous multi-threading (SMT): Each clock, core chooses instructions from multiple threads to run on ALUs. It is an extension of superscalar CPU design</li><li>The operating system is responsible for mapping your pthreads to the processor’s thread execution contexts</li></ol><h2 id="cpus-and-gpus"><a class="markdownIt-Anchor" href="#cpus-and-gpus"></a> CPUs and GPUs</h2><ol><li>CPU has big caches, few threads, modest memory BW, and rely mainly on caches and prefetching.<br />GPU has small caches, many threads, huge memory BW, and rely mainly on multi-threading.</li><li>The bandwidth of GPUs is a lot faster than CPUs.</li><li>In GPUs, ALUs run at twice the clock rate of rest of chip. So each decoded instruction runs on 32 pieces of data on the 16 ALUs over two ALU clocks. (but to the programmer, it behaves like a 32-wide SIMD operation)<br />Warp: An instruction operating on a whole vector of data at a time.<br />SM: Streaming Multi-processor. Each SM has multiple warp selector. Each selector has multiple ALUs with different functions. The selectors in the same SM have shared momery and L1 cache. And all selectors can run parallel.</li><li>A core can have multiple scalar ALUs and multiple vector ALUs. Each vector ALU can perform either both MUL and ADD or ADD only.<br />And the maximum number of threads activated in a core is determined by the number of the execution contexts.</li></ol><h2 id="bandwidth"><a class="markdownIt-Anchor" href="#bandwidth"></a> Bandwidth</h2><ol><li>If processors request data at too high a rate, the memory system cannot keep up. No amount of latency hiding helps this.</li><li>Organize computation to fetch data from memory less often.<br />Reuse data previously loaded by the same thread (traditional intra-thread temporal locality optimizations). <br />Share data across threads (inter-thread cooperation)</li><li>Request data less often (instead, do more arithmetic: it’s “free”).<br />Arithmetic intensity: Ratio of math operations to data access operations in an instruction stream.<br />The main point is that programs must have high arithmetic intensity to utilize modern processors efficiently.<br />If a data needed can be recalculated in ALUs, than don’t access memory, do the calculation.</li></ol>]]></content>
      
      
      <categories>
          
          <category> Open Courses </category>
          
          <category> CMU 15-418 / Stanford CS149 Parallel Computing </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Parallelism </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>

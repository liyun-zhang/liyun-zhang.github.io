<!DOCTYPE html>
<html lang="zh-Hans">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222" media="(prefers-color-scheme: light)">
<meta name="theme-color" content="#222" media="(prefers-color-scheme: dark)"><meta name="generator" content="Hexo 6.3.0">

  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">



<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css" integrity="sha256-HtsXJanqjKTc8vVQjO4YMhiqFoXkfBsjBWcX91T1jr8=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/animate.css/3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">

<script class="next-config" data-name="main" type="application/json">{"hostname":"liyun-zhang.github.io","root":"/","images":"/images","scheme":"Mist","darkmode":true,"version":"8.17.0","exturl":false,"sidebar":{"position":"right","display":"post","padding":18,"offset":12},"copycode":{"enable":false,"style":null},"bookmark":{"enable":false,"color":"#222","save":"auto"},"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"stickytabs":false,"motion":{"enable":true,"async":false,"transition":{"menu_item":"fadeInDown","post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"prism":false,"i18n":{"placeholder":"Searching...","empty":"We didn't find any results for the search: ${query}","hits_time":"${hits} results found in ${time} ms","hits":"${hits} results found"},"path":"/search.xml","localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false}}</script><script src="/js/config.js"></script>

    <meta property="og:type" content="website">
<meta property="og:title" content="LiyunZhang">
<meta property="og:url" content="http://liyun-zhang.github.io/index.html">
<meta property="og:site_name" content="LiyunZhang">
<meta property="og:locale">
<meta property="article:author" content="LiyunZhang">
<meta name="twitter:card" content="summary">


<link rel="canonical" href="http://liyun-zhang.github.io/">



<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":true,"isPost":false,"lang":"zh-Hans","comments":"","permalink":"","path":"index.html","title":""}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>LiyunZhang</title>
  








  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
</head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <div class="column">
      <header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar" role="button">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <h1 class="site-title">LiyunZhang</h1>
      <i class="logo-line"></i>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger" aria-label="Search" role="button">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i>Home</a></li><li class="menu-item menu-item-about"><a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>About</a></li><li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>Tags</a></li><li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>Categories</a></li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>Search
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup"><div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off" maxlength="80"
           placeholder="Searching..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close" role="button">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div class="search-result-container no-result">
  <div class="search-result-icon">
    <i class="fa fa-spinner fa-pulse fa-5x"></i>
  </div>
</div>
    </div>
  </div>

</header>
        
  
  <aside class="sidebar">

    <div class="sidebar-inner sidebar-overview-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">LiyunZhang</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/archives/">
          <span class="site-state-item-count">17</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
          <a href="/categories/">
        <span class="site-state-item-count">4</span>
        <span class="site-state-item-name">categories</span></a>
      </div>
      <div class="site-state-item site-state-tags">
          <a href="/tags/">
        <span class="site-state-item-count">9</span>
        <span class="site-state-item-name">tags</span></a>
      </div>
  </nav>
</div>

        </div>
      </div>
    </div>

    
  </aside>


    </div>

    <div class="main-inner index posts-expand">

    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://liyun-zhang.github.io/2023/08/30/Courses/15445/14-Database-Recovery/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="LiyunZhang">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="LiyunZhang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | LiyunZhang">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2023/08/30/Courses/15445/14-Database-Recovery/" class="post-title-link" itemprop="url">14 Database Recovery</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2023-08-30 19:12:36" itemprop="dateCreated datePublished" datetime="2023-08-30T19:12:36+08:00">2023-08-30</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">Edited on</span>
      <time title="Modified: 2023-08-31 02:19:14" itemprop="dateModified" datetime="2023-08-31T02:19:14+08:00">2023-08-31</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">In</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Open-Courses/" itemprop="url" rel="index"><span itemprop="name">Open Courses</span></a>
        </span>
          , 
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Open-Courses/CMU-15-445-645-Database-System/" itemprop="url" rel="index"><span itemprop="name">CMU 15-445/645 Database System</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p>@[toc]</p>
<h1 id="What-are-the-main-ideas-of-ARIES"><a href="#What-are-the-main-ideas-of-ARIES" class="headerlink" title="What are the main ideas of ARIES?"></a>What are the main ideas of ARIES?</h1><ol>
<li>ARIES: Algorithms for Recovery and Isolation Exploiting Semantics</li>
<li>Write-Ahead Logging:<ul>
<li>Any change is recorded in log on stable storage before the database change is written to disk. </li>
<li>Must use steal and no-force buffer pool policies. <ul>
<li>Logs are forced to be flushed into disk while modified pages are not. </li>
<li>Force is also correct, but it damages runtime performance, which makes no one uses it. </li>
</ul>
</li>
</ul>
</li>
<li>Repeating History During Redo: On DBMS restart, retrace actions and restore database to exact state before crash. </li>
<li>Logging Changes During Undo: Record undo actions to log to ensure action is not repeated in the event of repeated failures. </li>
</ol>
<h1 id="Record-logs"><a href="#Record-logs" class="headerlink" title="Record logs"></a>Record logs</h1><h2 id="What-are-the-LSNs"><a href="#What-are-the-LSNs" class="headerlink" title="What are the LSNs?"></a>What are the LSNs?</h2><ol>
<li>Every log record now includes a globally unique, monotonically increasing log sequence number (LSN).<ul>
<li>LSNs represent the physical order that transactions make changes to the database. </li>
</ul>
</li>
<li>Various components in the system keep track of LSNs that pertain to them<ul>
<li>In memory, the system uses <code>flushedLSN</code> to track the last LSN in log on disk. </li>
<li>In each page in disk, <code>pageLSN</code> is used to track the newest update to that page while <code>recLSN</code> is tracking the oldest update to that page since it was last flushed. </li>
<li>Each transaction maintains <code>lastLSN</code> representing the latest record of that transaction. </li>
<li>In disk, there is also a <code>MasterRecord</code> meaning the LSN of latest checkpoint. </li>
</ul>
</li>
<li>Before the DBMS can write page x to disk, it must flush the log at least to the point where $pageLSN_x ≤ flushedLSN$. </li>
<li>Update the <code>pageLSN</code> every time a transaction modifies a record in the page. </li>
<li>Update the <code>flushedLSN</code> in memory every time the DBMS writes out the WAL buffer to disk. </li>
</ol>
<h2 id="How-to-handle-transaction-commit"><a href="#How-to-handle-transaction-commit" class="headerlink" title="How to handle transaction commit?"></a>How to handle transaction commit?</h2><ol>
<li>When a transaction commits, the DBMS writes a <code>COMMIT</code> record to log and guarantees that all log records up to transaction’s <code>COMMIT</code> record are flushed to disk. <ul>
<li>Log flushes are sequential, synchronous writes to disk. </li>
</ul>
</li>
<li>When the commit succeeds, write a special <code>TXN-END</code> record to log. <ul>
<li>Indicates that no new log record for a transaction will appear in the log ever again. </li>
<li>This does not need to be flushed immediately. </li>
</ul>
</li>
</ol>
<h2 id="How-to-handle-transaction-abort"><a href="#How-to-handle-transaction-abort" class="headerlink" title="How to handle transaction abort?"></a>How to handle transaction abort?</h2><ol>
<li>Another <code>prevLSN</code> is added to log records pointing to the previous LSN for that transaction to make it easy to walk through its records. </li>
<li>First write an <code>ABORT</code> record to log for the transaction. <ul>
<li>Following that, we need to records steps taken to undo the transaction. <ul>
<li>A <code>CLR</code> describes the actions taken to undo the actions of a previous update record. </li>
<li>It has all the fields of an update log record plus the <code>undoNext</code> pointer pointing to the next-to-be-undone LSN. </li>
<li><code>CLR</code>s are added to log records but the DBMS does not wait for them to be flushed before notifying the application that the transaction aborted. </li>
</ul>
</li>
<li>Lastly, write a <code>TXN-END</code> record. </li>
</ul>
</li>
<li>To add <code>CLR</code> records, we need to analyze the transaction’s updates in reverse order. <ul>
<li>For each update record, write a <code>CLR</code> entry to the log, and restore old value. </li>
<li><code>CLR</code>s never need to be undone. </li>
</ul>
</li>
</ol>
<h1 id="Fuzzy-checkpoints"><a href="#Fuzzy-checkpoints" class="headerlink" title="Fuzzy checkpoints"></a>Fuzzy checkpoints</h1><h2 id="How-can-we-improve-the-naive-checkpoints"><a href="#How-can-we-improve-the-naive-checkpoints" class="headerlink" title="How can we improve the naive checkpoints?"></a>How can we improve the naive checkpoints?</h2><ol>
<li>The naive checkpoint needs to halt the start of any new transactions and wait until all active transactions finish executing. </li>
<li>We can only pause modifying transactions while the DBMS takes the checkpoint. <ul>
<li>It can be done through preventing queries from acquiring write latch on table/index pages. </li>
<li>Don’t have to wait until all transactions finish before taking the checkpoint. </li>
</ul>
</li>
<li>We must record internal state as of the beginning of the checkpoint. <ul>
<li>Active Transaction Table (ATT): What transactions are running at the time we took checkpoint. </li>
<li>Dirty Page Table (DPT): What pages are dirty. </li>
</ul>
</li>
<li>ATT is maintained at runtime and recovery. There is a entry per currently active transaction<ul>
<li>Each entry contains<ul>
<li><code>transactionId</code>: Unique transaction identifier</li>
<li><code>status</code>: The current “mode” of the transaction</li>
<li><code>lastLSN</code>: Most recent LSN created by transaction. </li>
</ul>
</li>
<li>Remove entry after the <code>TXN-END</code> record. </li>
<li>Txn Status Codes<ul>
<li><code>R</code>: Running</li>
<li><code>C</code>: Committing</li>
<li><code>U</code>: Candidate for undo</li>
</ul>
</li>
<li><code>U</code> is the default mode in recovery. <ul>
<li>When replaying the log, we cannot see what’s come up ahead, assuming not gonna see a transaction commit record. </li>
<li>Flip to commit when see a transaction commit record</li>
</ul>
</li>
</ul>
</li>
<li>DPT contains one entry per dirty page in the buffer pool including <code>recLSN</code>. <ul>
<li><code>recLSN</code> is the LSN of the log record that first caused the page to be dirty. </li>
</ul>
</li>
<li>Each checkpoint record includes ATT and DPT in it. </li>
</ol>
<h2 id="How-can-we-checkpoint-without-stalling-transactions"><a href="#How-can-we-checkpoint-without-stalling-transactions" class="headerlink" title="How can we checkpoint without stalling transactions?"></a>How can we checkpoint without stalling transactions?</h2><ol>
<li>In fuzzy checkpoint, there are two kind of records to track checkpoint boundaries. <ul>
<li><code>CHECKPOINT-BEGIN</code> indicates start of checkpoint. Recovery begins from here. </li>
<li><code>CHECKPOINT-END</code> contains ATT and DPT at the moment of <code>CHECKPOINT-BEGIN</code>. </li>
</ul>
</li>
<li>The <code>LSN</code> of the <code>CHECKPOINT-BEGIN</code> record is written to the <code>MasterRecord</code> when it completes. </li>
<li>Any transaction that begins after the checkpoint starts is excluded from the ATT in the <code>CHECKPOINT-END</code> record. </li>
</ol>
<h1 id="Recovery"><a href="#Recovery" class="headerlink" title="Recovery"></a>Recovery</h1><h2 id="How-does-ARIES-recover-from-crash"><a href="#How-does-ARIES-recover-from-crash" class="headerlink" title="How does ARIES recover from crash?"></a>How does ARIES recover from crash?</h2><ol>
<li>The first phase is analysis. <ul>
<li>Examine the WAL in forward direction starting at MasterRecord to identify dirty pages in the buffer pool and active transactions at the time of the crash. </li>
<li>This is to figure out which transactions committed or failed since checkpoint.</li>
</ul>
</li>
<li>The second phase is redo phase. <ul>
<li>Repeat all actions starting from an appropriate point in the log in forward direction. </li>
<li>This phase is to repeat all actions, even transactions that will abort. </li>
</ul>
</li>
<li>The last phase is undo. <ul>
<li>Reverse the actions of transactions that did not commit before the crash in reverse order. </li>
<li>This phase is to reverse effects of failed transactions. </li>
</ul>
</li>
<li>If crashes happen during recovery, just run recovery again. </li>
</ol>
<p><img src="/imgs/15445/Recovery/aries.png" width="20%"></p>
<h2 id="What-does-analysis-phase-do"><a href="#What-does-analysis-phase-do" class="headerlink" title="What does analysis phase do?"></a>What does analysis phase do?</h2><ol>
<li>Scan log forward from the <code>CHECKPOINT-END</code> of the last successful checkpoint. </li>
<li>If the DBMS finds a <code>TXN-END</code> record, remove its corresponding transaction from ATT. </li>
<li>For all other records,<ul>
<li>If transaction not in ATT, add it with status <code>UNDO</code>. On commit, change transaction status to <code>COMMIT</code>.</li>
<li>For update log records, if page $P$ not in DPT, add $P$ to DPT, set its <code>recLSN=LSN</code>.</li>
</ul>
</li>
<li>At end of the Analysis Phase,<ul>
<li>ATT identifies which transactions were active at time of crash. </li>
<li>DPT identifies which dirty pages might not have made it to disk. </li>
</ul>
</li>
</ol>
<h2 id="What-does-redo-phase-do"><a href="#What-does-redo-phase-do" class="headerlink" title="What does redo phase do?"></a>What does redo phase do?</h2><ol>
<li>The goal is to repeat history to reconstruct the database state at the moment of the crash. </li>
<li>Scan forward from the log record containing smallest <code>recLSN</code> in DPT.</li>
<li>For each update log record or <code>CLR</code> with a given LSN, redo the action unless affected page is not in DPT, or affected page is in DPT but that record’s LSN is less than the page’s <code>recLSN</code>. <ul>
<li>If the affected page is not in DPT, that means that that modification is already flushed in disk. </li>
<li>If that record’s LSN is less than the page’s <code>recLSN</code>, that means that that page is dirty but due to some updates after the record. The modification of that record is also flushed into the disk. </li>
</ul>
</li>
<li>To redo an action, <ul>
<li>Reapply logged update.</li>
<li>Set <code>pageLSN</code> to log record’s LSN.</li>
<li>No additional logging, no forced flushes. </li>
<li>To improve performance, we can assume that it is not going to crash again and flush all changes to disk asynchronously in the background.</li>
</ul>
</li>
<li>At the end of Redo Phase, write <code>TXN-END</code> log records for all transactions with status <code>C</code> and remove them from the ATT. </li>
</ol>
<h2 id="What-does-undo-phase-do"><a href="#What-does-undo-phase-do" class="headerlink" title="What does undo phase do?"></a>What does undo phase do?</h2><ol>
<li>Undo all transactions that were active at the time of crash and therefore will never commit. </li>
<li>These are all the transactions with <code>U</code> status in the ATT after the Analysis Phase. </li>
<li>Process them in reverse LSN order using the <code>lastLSN</code> to speed up traversal. </li>
<li>Write a <code>CLR</code> for every modification. </li>
<li>To improve performance, <ul>
<li>Lazily rollback changes before new transactions access pages. </li>
<li>Rewrite the application to avoid long-running transactions, which will never be used. </li>
</ul>
</li>
</ol>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://liyun-zhang.github.io/2023/08/29/Courses/15445/13-Database-Logging/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="LiyunZhang">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="LiyunZhang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | LiyunZhang">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2023/08/29/Courses/15445/13-Database-Logging/" class="post-title-link" itemprop="url">13 Database Logging</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2023-08-29 11:42:20" itemprop="dateCreated datePublished" datetime="2023-08-29T11:42:20+08:00">2023-08-29</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">Edited on</span>
      <time title="Modified: 2023-08-30 00:20:49" itemprop="dateModified" datetime="2023-08-30T00:20:49+08:00">2023-08-30</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">In</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Open-Courses/" itemprop="url" rel="index"><span itemprop="name">Open Courses</span></a>
        </span>
          , 
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Open-Courses/CMU-15-445-645-Database-System/" itemprop="url" rel="index"><span itemprop="name">CMU 15-445/645 Database System</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p>@[toc]</p>
<h1 id="Crash"><a href="#Crash" class="headerlink" title="Crash"></a>Crash</h1><h2 id="How-to-recover-from-crash"><a href="#How-to-recover-from-crash" class="headerlink" title="How to recover from crash?"></a>How to recover from crash?</h2><ol>
<li>Recovery algorithms are techniques to ensure database consistency, transaction atomicity, and durability despite failures. </li>
<li>The DBMS needs to ensure the following:<ul>
<li>The changes for any transaction are durable once the DBMS has told somebody that it committed.</li>
<li>No partial changes are durable if the transaction aborted.</li>
</ul>
</li>
<li>Recovery algorithms have two parts:<ul>
<li>The first is runtime part: Actions during normal transaction processing to ensure that the DBMS can recover from a failure. </li>
<li>The second is startup part: Actions after a failure to recover the database to a state that ensures atomicity, consistency, and durability. </li>
</ul>
</li>
</ol>
<h2 id="What-are-the-possible-classification-of-failures"><a href="#What-are-the-possible-classification-of-failures" class="headerlink" title="What are the possible classification of failures?"></a>What are the possible classification of failures?</h2><ol>
<li>Transaction failures:<ul>
<li>Logical errors: Transaction cannot complete due to some internal error condition (e.g., integrity constraint violation).</li>
<li>Internal state errors: DBMS must terminate an active transaction due to an error condition (e.g., deadlock). </li>
</ul>
</li>
<li>System failures: <ul>
<li>Software failure: Problem with the OS or DBMS implementation (e.g., uncaught divide-by-zero exception). </li>
<li>Hardware failure: The computer hosting the DBMS crashes (e.g., power plug gets pulled). </li>
<li>Fail-stop assumption: Non-volatile storage contents are assumed to not be corrupted by system crash. </li>
</ul>
</li>
<li>Storage media failure: <ul>
<li>Non-repairable hardware failure: A head crash or similar disk failure destroys all or part of non-volatile storage. </li>
<li>Destruction is assumed to be detectable (e.g., disk controller use checksums to detect failures).</li>
<li>No DBMS can recover from this! Database must be restored from archived version. </li>
<li>Stable storage is a non-existent form of non-volatile storage that survives all possible failures scenarios. </li>
</ul>
</li>
</ol>
<h1 id="Naive-solution"><a href="#Naive-solution" class="headerlink" title="Naive solution"></a>Naive solution</h1><h2 id="What-buffer-pool-policies-can-we-choose"><a href="#What-buffer-pool-policies-can-we-choose" class="headerlink" title="What buffer pool policies can we choose?"></a>What buffer pool policies can we choose?</h2><ol>
<li>Steal policy: <ul>
<li>Whether the DBMS allows an uncommitted transaction to overwrite the most recent committed value of an object in non-volatile storage. </li>
<li>Steal: Is allowed</li>
<li>No-steal: Is not allowed</li>
</ul>
</li>
<li>Force policy:<ul>
<li>Whether the DBMS requires that all updates made by a transaction are reflected on non-volatile storage before the transaction can commit. </li>
<li>Force: Is required</li>
<li>No-force: Is not required</li>
</ul>
</li>
<li>Undo: The process of removing the effects of an incomplete or aborted transaction. </li>
<li>Redo: The process of re-applying the effects of a committed transaction for durability. </li>
<li>Stead and no-force policy has the best runtime performance since it does not need to wait for conflicted uncommitted transactions and not necessarily to flush when commit. </li>
<li>No-steal and force policy has the best recovery performance since it does not need undo and redo anything. </li>
</ol>
<h2 id="What-are-the-pros-and-cons-of-no-steal-and-force-policy"><a href="#What-are-the-pros-and-cons-of-no-steal-and-force-policy" class="headerlink" title="What are the pros and cons of no-steal and force policy?"></a>What are the pros and cons of no-steal and force policy?</h2><ol>
<li>This approach is the easiest to implement:<ul>
<li>Never have to undo changes of an aborted transaction because the changes were not written to disk. </li>
<li>Never have to redo changes of a committed transaction because all the changes are guaranteed to be written to disk at commit time (assuming atomic hardware writes).</li>
</ul>
</li>
<li>An uncommitted transaction and another committing transaction may have written the same page. Then the buffer pool manager needs to copy that page with only modifications from the committing transaction and writes that copied page to non-volatile storage. </li>
<li>The disadvantages are as following:<ul>
<li>Copying data is expensive. </li>
<li>The buffer pool manager needs to be aware of the context. </li>
<li>Cannot support write sets that exceed the amount of physical memory available. </li>
</ul>
</li>
</ol>
<h2 id="How-does-shadow-paging-work"><a href="#How-does-shadow-paging-work" class="headerlink" title="How does shadow paging work?"></a>How does shadow paging work?</h2><ol>
<li>Instead of copying the entire database, the DBMS copies pages on write to create two versions<ul>
<li>Master: Contains only changes from committed transactions. Read-only transactions access the current master. </li>
<li>Shadow: Temporary database with changes made from uncommitted transactions. </li>
</ul>
</li>
<li>Active modifying transaction copies the page table as the shadow page table. <ul>
<li>When it tries to modify a page, it will copy that page, and modify the shadow page table to point to the new copied page. </li>
<li>To install updates when a transaction commits, overwrite the root so it points to the shadow, thereby swapping the master and shadow. Then DMBS needs to do some garbage collection. </li>
</ul>
</li>
<li>The buffer pool policy is no-steal and force. </li>
<li>To support rollbacks and recovery, the DBMS needs to Remove the shadow pages. Leave the master and the DB root pointer alone on undo phase, and no need to redo at all. </li>
</ol>
<h2 id="What-are-the-disadvantages-of-shadow-paging"><a href="#What-are-the-disadvantages-of-shadow-paging" class="headerlink" title="What are the disadvantages of shadow paging?"></a>What are the disadvantages of shadow paging?</h2><ol>
<li>Copying the entire page table is expensive: <ul>
<li>We can use a page table structured like a B+tree (LMDB). There is no need to copy entire tree, only need to copy paths in the tree that lead to updated leaf nodes. </li>
</ul>
</li>
<li>Commit overhead is high:<ul>
<li>Need to flush every updated page, page table, and root. </li>
<li>Data gets fragmented, which is bad for sequential scans. </li>
<li>Require the DBMS to perform writes to random non-contiguous pages on disk.</li>
<li>Need garbage collection. </li>
</ul>
</li>
<li>Only supports one writer transaction at a time or transactions in a batch. If two concurrent writer write on the same page, they all copies from master version causing only one write is reflected on the committed database. </li>
</ol>
<h2 id="How-does-journal-file-work"><a href="#How-does-journal-file-work" class="headerlink" title="How does journal file work?"></a>How does journal file work?</h2><ol>
<li>When a transaction modifies a page, the DBMS copies the original page to a separate journal file before overwriting master version. </li>
<li>After restarting, if a journal file exists, then the DBMS restores it to undo changes from uncommitted transactions. </li>
</ol>
<h1 id="Write-ahead-log"><a href="#Write-ahead-log" class="headerlink" title="Write-ahead log"></a>Write-ahead log</h1><h2 id="What-is-the-main-idea-of-WAL"><a href="#What-is-the-main-idea-of-WAL" class="headerlink" title="What is the main idea of WAL?"></a>What is the main idea of WAL?</h2><ol>
<li>Maintain a log file separate from data files that contains the changes that transactions make to database. <ul>
<li>Assume that the log is on stable storage. </li>
<li>Log contains enough information to perform the necessary undo and redo actions to restore the database. </li>
</ul>
</li>
<li>DBMS must write to disk the log file records that correspond to changes made to a database object before it can flush that object to disk. <ul>
<li>The buffer pool policy is steal and no-force. </li>
</ul>
</li>
</ol>
<h2 id="How-to-write-under-WAL-protocol"><a href="#How-to-write-under-WAL-protocol" class="headerlink" title="How to write under WAL protocol?"></a>How to write under WAL protocol?</h2><ol>
<li>The DBMS stages all a transaction’s log records in volatile storage backed by buffer pool. <ul>
<li>All log records pertaining to an updated page are written to non-volatile storage before the page itself is over-written in non-volatile storage.</li>
<li>A transaction is not considered committed until all its log records have been written to stable storage. </li>
</ul>
</li>
<li>A <code>&lt;BEGIN&gt;</code> record is written to the log for each transaction to mark its starting point. <ul>
<li>Most DBMS only writes <code>&lt;BEGIN&gt;</code> on first write command of a transaction instead of on the beginning. </li>
</ul>
</li>
<li>When a transaction finishes, the DBMS will write a <code>&lt;COMMIT&gt;</code> record on the log, and make sure that all log records are flushed before it returns an acknowledgement to application. </li>
<li>Each log entry contains information about the change to a single object <ul>
<li>Transaction ID, object ID, before value (for undo) and after value (for redo). </li>
</ul>
</li>
</ol>
<h2 id="How-to-reduce-flushing-the-log-buffer"><a href="#How-to-reduce-flushing-the-log-buffer" class="headerlink" title="How to reduce flushing the log buffer?"></a>How to reduce flushing the log buffer?</h2><ol>
<li>Flushing the log buffer to disk every time a transaction commits will become a bottleneck. </li>
<li>The DBMS can use the group commit optimization to batch multiple log flushes together to amortize overhead.<ul>
<li>When the buffer is full, flush it to disk. Or if there is a timeout. </li>
<li>Log records from different transaction are mixed. This is fine since we can sort them out by recorded transaction ID. </li>
</ul>
</li>
</ol>
<h2 id="How-to-store-changes"><a href="#How-to-store-changes" class="headerlink" title="How to store changes?"></a>How to store changes?</h2><ol>
<li>The first logging scheme is physical logging. <ul>
<li>Record the byte-level changes made to a specific page. </li>
</ul>
</li>
<li>The second is logical logging. <ul>
<li>Record the high-level operations executed by transactions, e.g. queries. </li>
<li>Logical logging requires less data written in each log record than physical logging. </li>
<li>Difficult to implement recovery with logical logging if you have concurrent transactions running at lower isolation levels. <ul>
<li>The crash may happen in the middle of a query. </li>
<li>It is hard to determine which parts of the database may have been modified by a query before crash. </li>
</ul>
</li>
<li>Also takes longer to recover because you must re-execute every transaction all over again. </li>
</ul>
</li>
<li>The last is physiological logging. <ul>
<li>Hybrid approach with byte-level changes for a single tuple identified by page ID and slot number. </li>
</ul>
</li>
</ol>
<h2 id="What-is-log-structured-system"><a href="#What-is-log-structured-system" class="headerlink" title="What is log-structured system?"></a>What is log-structured system?</h2><ol>
<li>Log-structured DBMSs do not have dirty pages. <ul>
<li>Any page retrieved from disk is immutable. </li>
<li>All modifications are reflected through logs. </li>
</ul>
</li>
<li>The DBMS buffers log records in in-memory pages (MemTable). <ul>
<li>If this buffer is full, it must be flushed to disk. But it may contain changes from uncommitted transactions. </li>
</ul>
</li>
<li>These DBMSs still maintain a separate WAL to recreate the MemTable on crash. </li>
</ol>
<h2 id="How-to-prevent-WAL-from-growing-forever"><a href="#How-to-prevent-WAL-from-growing-forever" class="headerlink" title="How to prevent WAL from growing forever?"></a>How to prevent WAL from growing forever?</h2><ol>
<li>If the WAL will grow forever, after a crash, the DBMS must replay the entire log, which will take a long time. </li>
<li>The DBMS periodically takes a checkpoint where it flushes all buffers out to disk. </li>
<li>In blocking / consistent checkpoint protocol, <ul>
<li>Procedure<ul>
<li>Pause all queries</li>
<li>Flush all WAL records in memory to disk</li>
<li>Flush all modified pages in the buffer pool to disk</li>
<li>Write a <code>&lt;CHECKPOINT&gt;</code> entry to WAL and flush to disk</li>
<li>Resume queries</li>
</ul>
</li>
<li>On recovery, we can use the <code>&lt;CHECKPOINT&gt;</code> record as the starting point for analyzing the WAL. <ul>
<li>Any transaction that committed before the checkpoint is ignored. </li>
<li>Redo transactions that is committed after checkpoint and undo transactions that is not committed before the crash. </li>
</ul>
</li>
</ul>
</li>
</ol>
<h2 id="What-is-the-problem-of-this-naive-checkpoint-protocol"><a href="#What-is-the-problem-of-this-naive-checkpoint-protocol" class="headerlink" title="What is the problem of this naive checkpoint protocol?"></a>What is the problem of this naive checkpoint protocol?</h2><ol>
<li>The DBMS must stall transactions when it takes a checkpoint to ensure a consistent snapshot. <ul>
<li>Checkpointing too often causes the runtime performance to degrade due to system spends too much time flushing buffers. </li>
<li>But waiting a long time is just as bad since the checkpoint will be large and slow, which makes recovery time much longer. </li>
</ul>
</li>
<li>Scanning the log to find uncommitted transactions can take a long time. </li>
</ol>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://liyun-zhang.github.io/2023/08/22/Courses/15445/12-Multi-Version-Concurrency-Control/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="LiyunZhang">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="LiyunZhang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | LiyunZhang">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2023/08/22/Courses/15445/12-Multi-Version-Concurrency-Control/" class="post-title-link" itemprop="url">12 Multi-Version Concurrency Control</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>
      

      <time title="Created: 2023-08-22 15:34:19 / Modified: 18:18:42" itemprop="dateCreated datePublished" datetime="2023-08-22T15:34:19+08:00">2023-08-22</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">In</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Open-Courses/" itemprop="url" rel="index"><span itemprop="name">Open Courses</span></a>
        </span>
          , 
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Open-Courses/CMU-15-445-645-Database-System/" itemprop="url" rel="index"><span itemprop="name">CMU 15-445/645 Database System</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p>@[toc]</p>
<h1 id="Multi-version-logic"><a href="#Multi-version-logic" class="headerlink" title="Multi-version logic"></a>Multi-version logic</h1><h2 id="What-does-multi-version-mean"><a href="#What-does-multi-version-mean" class="headerlink" title="What does multi-version mean?"></a>What does multi-version mean?</h2><ol>
<li><p>The DBMS maintains multiple physical versions of a single logical object in the database. </p>
<ul>
<li><p>When a txn writes to an object, the DBMS creates a new version of that object. </p>
</li>
<li><p>When a txn reads an object, it reads the newest version that existed when the txn started. </p>
</li>
</ul>
</li>
<li><p>Writers do not block readers and readers do not block writers. </p>
</li>
<li><p>Read-only txns can read a consistent snapshot without acquiring locks using timestamps to determine visibility. </p>
</li>
<li><p>Multi-version can easily support time-travel queries on a snapshot version on database. </p>
</li>
</ol>
<h2 id="How-to-maintain-multi-version-logically"><a href="#How-to-maintain-multi-version-logically" class="headerlink" title="How to maintain multi-version logically?"></a>How to maintain multi-version logically?</h2><ol>
<li>Each version describes the current version number, the value for this version and the range of lifetime, i.e. the begin and end timestamps. </li>
<li>End timestamp is marked infinity for the newest version. </li>
<li>When a transaction writes an object: <ul>
<li>First it creates a new entry with a new version number and setting its begin timestamp as its timestamp and end timestamp being infinity. </li>
<li>Then it marks the end timestamp of last version as its timestamp. </li>
<li>Physically this transaction should modifiy the last version to point to this new version. Hence it need to wait for the transaction creating last version to commit to begin its own commit phase. </li>
</ul>
</li>
</ol>
<h2 id="What-isolation-can-MVCC-support"><a href="#What-isolation-can-MVCC-support" class="headerlink" title="What isolation can MVCC support?"></a>What isolation can MVCC support?</h2><ol>
<li><code>SNAPSHOT ISOLATION</code> is another isolation supported by Oracle. <ul>
<li>It guarantees that all reads made in a transaction see a consistent snapshot of the database that existed at the time the transaction started.</li>
<li>A transaction will commit only if its writes do not conflict with any concurrent updates made since that snapshot.</li>
</ul>
</li>
<li>It is susceptible to write skew anomaly. <ul>
<li>Two concurrent transactions modify different objects resulting in race conditions. </li>
<li>If a transaction wants to modify all values to $1$ while another transaction wants to modifiy all values to $0$. The first transaction changes all $0$s and the second transaction changes all $1$s. When their result merges to the database, it would be the $1$s and $0$s are flipped instead of all being $1$s or $0$s. </li>
</ul>
</li>
</ol>
<h1 id="Design-decisions"><a href="#Design-decisions" class="headerlink" title="Design decisions"></a>Design decisions</h1><h2 id="What-concurrency-control-protocol-can-be-used"><a href="#What-concurrency-control-protocol-can-be-used" class="headerlink" title="What concurrency control protocol can be used?"></a>What concurrency control protocol can be used?</h2><ol>
<li>All aforementioned protocols can be used in MVCC. </li>
<li>Timestamp ordering assigns transactions timestamps to determine what they can see. </li>
<li>Optimistic concurrency control uses private workspace for new versions. </li>
<li>Two-phase locking requires transactions to acquire appropriate lock on physical version before they can read/write a logical tuple. </li>
</ol>
<h2 id="How-are-versions-stored"><a href="#How-are-versions-stored" class="headerlink" title="How are versions stored?"></a>How are versions stored?</h2><ol>
<li>The DBMS uses the tuples’ pointer field to create a version chain per logical tuple. <ul>
<li>This allows the DBMS to find the version that is visible to a particular txn at runtime. </li>
<li>Indexes always point to the “head” of the chain. </li>
</ul>
</li>
<li>The first approach is append-only storage: New versions are appended to the same table space. <ul>
<li>The versions of different logical tuples are inter-mixed. </li>
<li>On every update, append a new version of the tuple into an empty space in the table. </li>
<li>If the chain is from oldest-to-newest, the DBMS must traverse chain on look-ups. However, the update do not need to update index. </li>
<li>Or, the chain can be from oldest-to-newest. The pros and cons are contrary with last scenario. </li>
</ul>
</li>
<li>The second approach is time-travel storage: Old versions are copied to separate table space.<ul>
<li>On every update, copy the current version to the time- travel table. Update pointers. Then Overwrite master version in the main table and update pointers. </li>
</ul>
</li>
<li>The third approach is delta storage: The original values of the modified attributes are copied into a separate delta record space. <ul>
<li>On every update, copy only the values that were modified to the delta storage and overwrite the master version. </li>
<li>Txns can recreate old versions by applying the delta in reverse order. </li>
</ul>
</li>
</ol>
<h2 id="How-to-perform-garbage-collection"><a href="#How-to-perform-garbage-collection" class="headerlink" title="How to perform garbage collection?"></a>How to perform garbage collection?</h2><ol>
<li>The DBMS needs to remove reclaimable physical versions from the database over time. <ul>
<li>Reclaimable means that no active txn in the DBMS can see that version (SI), or the version was created by an aborted txn. </li>
<li>To support time-travel queries, the DBMS can only reclaim versions created by an aborted txn. </li>
</ul>
</li>
<li>To look for expired versions, the implementation has two choices. </li>
<li>The first approach is tuple-level: Find old versions by examining tuples directly.<ul>
<li>In background vacuuming manner, separate thread(s) periodically scan the table and look for reclaimable versions. This design works with any storage. </li>
<li>In cooperative cleaning manner, worker threads identify reclaimable versions as they traverse version chain. It only works with oldest-to-newest. </li>
</ul>
</li>
<li>The second approach is transaction-level: Txns keep track of their old versions on updates so the DBMS does not have to scan tuples to determine visibility. <ul>
<li>Each txn keeps track of its read/write set. On commit/abort, the txn provides this information to a centralized vacuum worker. </li>
<li>The DBMS periodically determines when all versions created by a finished txn are no longer visible. </li>
</ul>
</li>
</ol>
<h2 id="How-to-manage-indexes"><a href="#How-to-manage-indexes" class="headerlink" title="How to manage indexes?"></a>How to manage indexes?</h2><ol>
<li>Primary key indexes point to version chain head. <ul>
<li>How often the DBMS must update the primary key index depends on whether the system creates new versions when a tuple is updated.</li>
<li>If a txn updates a tuple’s primary key attribute(s), then this is treated as a <code>DELETE</code> followed by an <code>INSERT</code>. </li>
</ul>
</li>
<li>Secondary indexes may use the physical address to the version chain head the same way as primary key index. </li>
<li>The secondary indexes may also use logical pointers. <ul>
<li>It uses a fixed identifier per tuple that does not change, e.g. primary key or tuple ID. </li>
<li>This would require an extra indirection layer. </li>
</ul>
</li>
</ol>
<h2 id="How-to-delete-a-tuple"><a href="#How-to-delete-a-tuple" class="headerlink" title="How to delete a tuple?"></a>How to delete a tuple?</h2><ol>
<li>The DBMS physically deletes a tuple from the database only when all versions of a logically deleted tuple are not visible. </li>
<li>If a tuple is deleted, then there cannot be a new version of that tuple after the newest version. </li>
<li>There are two ways to denote that tuple has been logically delete at some point in time. <ul>
<li>The first deleted flag way is to maintain a flag to indicate that the logical tuple has been deleted after the newest physical version. The flag can either be in tuple header or a separate column. </li>
<li>The second tombstone tuple way is to create an empty physical version to indicate that a logical tuple is deleted. <ul>
<li>It uses a separate pool for tombstone tuples with only a special bit pattern in version chain pointer to reduce the storage overhead.</li>
</ul>
</li>
</ul>
</li>
</ol>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://liyun-zhang.github.io/2023/08/20/Courses/15445/11-Timestamp-Ordering-Concurrency-Control/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="LiyunZhang">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="LiyunZhang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | LiyunZhang">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2023/08/20/Courses/15445/11-Timestamp-Ordering-Concurrency-Control/" class="post-title-link" itemprop="url">11 Timestamp Ordering Concurrency Control</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2023-08-20 23:59:40" itemprop="dateCreated datePublished" datetime="2023-08-20T23:59:40+08:00">2023-08-20</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">Edited on</span>
      <time title="Modified: 2023-08-22 16:04:33" itemprop="dateModified" datetime="2023-08-22T16:04:33+08:00">2023-08-22</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">In</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Open-Courses/" itemprop="url" rel="index"><span itemprop="name">Open Courses</span></a>
        </span>
          , 
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Open-Courses/CMU-15-445-645-Database-System/" itemprop="url" rel="index"><span itemprop="name">CMU 15-445/645 Database System</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p>@[toc]</p>
<h1 id="T-O-Protocols"><a href="#T-O-Protocols" class="headerlink" title="T/O Protocols"></a>T/O Protocols</h1><h2 id="What-is-the-difference-between-2PL-and-T-O"><a href="#What-is-the-difference-between-2PL-and-T-O" class="headerlink" title="What is the difference between 2PL and T/O?"></a>What is the difference between 2PL and T/O?</h2><ol>
<li>2PL determine serializability order of conflicting operations at runtime while transactions execute while T/O determine serializability order of transactions before they execute. <ul>
<li>If $TS(T_i) &lt; TS(T_j)$, then the DBMS must ensure that the execution schedule is equivalent to a serial schedule where $T_i$ appears before $T_j$. </li>
<li>Different schemes assign timestamps at different times during the transaction. </li>
<li>Timestamps can be implemented by different strategies: system/wall clock, logical counter, or hybrid. </li>
</ul>
</li>
<li>2PL is in a manner of pessimistic way. It assumes that conflicts between transactions are very common. <ul>
<li>Hence it uses locks to prevent conflicts. </li>
</ul>
</li>
<li>Timestamp  ordering (T/O) is a more optimistic way. It assumes that conflicts between transactions are rare. <ul>
<li>Hence it allows each transaction to execute all operations they want and validates their legitimate after each transaction committing and before applying anything to main database. </li>
</ul>
</li>
</ol>
<h2 id="Basic-T-O-protocol"><a href="#Basic-T-O-protocol" class="headerlink" title="Basic T/O protocol"></a>Basic T/O protocol</h2><h3 id="What-is-the-main-idea-of-basic-T-O-protocol"><a href="#What-is-the-main-idea-of-basic-T-O-protocol" class="headerlink" title="What is the main idea of basic T/O protocol?"></a>What is the main idea of basic T/O protocol?</h3><ol>
<li>Txns read and write objects without locks.</li>
<li>The timestamp of each transaction is assigned at the <code>BEGIN</code> command. </li>
<li>Every object $X$ is tagged with timestamp of the last transaction that successfully did read/write<ul>
<li>$W-TS(X)$: Write timestamp on $X$</li>
<li>$R-TS(X)$: Read timestamp on $X$</li>
</ul>
</li>
<li>Check timestamps for every operation. If transaction tries to access an object “from the future”, it aborts and restarts. </li>
</ol>
<h3 id="How-does-basic-T-O-check-each-operation"><a href="#How-does-basic-T-O-check-each-operation" class="headerlink" title="How does basic T/O check each operation?"></a>How does basic T/O check each operation?</h3><ol>
<li>When $T_i$ wants to read $X$:<ul>
<li>If $TS(T_i)&lt;W-TS(X)$, abort $T_i$ and restart it with a new TS to prevent it from starvation. <ul>
<li>This condition means that this $T_i$ is trying to read something from the future. </li>
</ul>
</li>
<li>Else, allow $T_i$ to read $X$, and update $R-TS(X)$ to $max(R-TS(X), TS(T_i))$. </li>
<li>A local copy of $X$ is made to ensure repeatable reads for $T_i$. </li>
</ul>
</li>
<li>When $T_i$ wants to write $X$:<ul>
<li>If $TS(T_i)&lt;R-TS(X)$ or $TS(T_i)&lt;W-TS(X)$, abort and restart $T_i$. <ul>
<li>The first condition means that another transaction from the future cannot see the write from $T_i$ in the past. </li>
<li>The second condition means that another transaction from the future already wrote this object and $T_i$ cannot overwrite it in the past. </li>
</ul>
</li>
<li>Else, allow $T_i$ to write $X$ and update $W-TS(X)$. </li>
<li>Also, a local copy is made. </li>
</ul>
</li>
</ol>
<h3 id="Can-we-optimize-the-write-rule-to-decrease-possibility-of-abort"><a href="#Can-we-optimize-the-write-rule-to-decrease-possibility-of-abort" class="headerlink" title="Can we optimize the write rule to decrease possibility of abort?"></a>Can we optimize the write rule to decrease possibility of abort?</h3><ol>
<li>Thomas write rule: If $TS(T_i) &lt; W-TS(X)$, ignore the write to allow the transaction to continue executing without aborting. <ul>
<li>The thought is that we can see this violation as an immediate write from a future transaction right after the successful write from $T_i$. </li>
<li>The effects are similar, i.e. no one sees what does $T_i$ write. </li>
</ul>
</li>
<li>If $TS(T_i)&lt;R-TS(X)$, we still need to abort $T_i$. </li>
</ol>
<h3 id="What-is-the-issues-of-basic-T-O"><a href="#What-is-the-issues-of-basic-T-O" class="headerlink" title="What is the issues of basic T/O?"></a>What is the issues of basic T/O?</h3><ol>
<li>High overhead from copying data to transaction’s workspace and from updating timestamps. Every read requires the transaction to write to the database. </li>
<li>Long running transactions can get starved. The likelihood that a transaction will read something from a newer transaction increases. </li>
<li>If you assume that conflicts between transactions are rare and that most transactions are short-lived, then forcing transactions to acquire locks or update timestamps adds unnecessary overhead. </li>
</ol>
<h2 id="Optimistic-concurrency-control"><a href="#Optimistic-concurrency-control" class="headerlink" title="Optimistic concurrency control"></a>Optimistic concurrency control</h2><h3 id="What-is-the-main-idea-of-OCC"><a href="#What-is-the-main-idea-of-OCC" class="headerlink" title="What is the main idea of OCC?"></a>What is the main idea of OCC?</h3><ol>
<li>OCC assumes that the number of conflicts is low. Especially when: <ul>
<li>All transactions are read-only (ideal).</li>
<li>Txns access disjoint subsets of data.</li>
<li>The database is large and the workload is not skewed. </li>
</ul>
</li>
<li>The DBMS creates a private workspace for each transaction. <ul>
<li>Any object read is copied into workspace. Modifications are applied to workspace. </li>
<li>When a transaction commits, the DBMS compares workspace write set to see whether it conflicts with other transactions. </li>
<li>If there are no conflicts, the write set is installed into the “global” database. </li>
</ul>
</li>
<li>OCC has three phases:<ul>
<li>Read Phase: Track the read/write sets of transactions and store their writes in a private workspace, i.e. execution of transaction content. </li>
<li>Validation Phase: When a transaction commits, check whether it conflicts with other transactions. </li>
<li>Write Phase: If validation succeeds, apply private changes to database. Otherwise abort and restart the transaction. <ul>
<li>Serial Commits: Use a global latch to limit a single transaction to be in the Validation/Write phases at a time. </li>
<li>Parallel Commits: Use fine-grained write latches to support parallel Validation/Write phases. Txns acquire latches in primary key order to avoid deadlocks.</li>
</ul>
</li>
</ul>
</li>
</ol>
<h3 id="What-will-happen-in-validation-phase"><a href="#What-will-happen-in-validation-phase" class="headerlink" title="What will happen in validation phase?"></a>What will happen in validation phase?</h3><ol>
<li>When transaction $T_i$ invokes <code>COMMIT</code>, the DBMS checks if it conflicts with other transactions. <ul>
<li>The DBMS needs to guarantee only serializable schedules are permitted.</li>
<li>Checks other transactions for RW and WW conflicts and ensure that conflicts are in one direction (e.g., older→younger). </li>
</ul>
</li>
<li>There are two approaches to valid: <ul>
<li>In backward validation, check whether the committing transaction intersects its read/write sets with those of any transactions that have already committed.<br><img src="/imgs/15445/TO/backward.png" width="50%"></li>
<li>In forward validation, check whether the committing transaction intersects its read/write sets with any active transactions that have not yet committed.<br><img src="/imgs/15445/TO/forward.png" width="50%"></li>
</ul>
</li>
<li>Each transaction’s timestamp is assigned at the beginning of the validation phase. Check the timestamp ordering of the committing transaction with all other concerned transactions. When $TS(T_i)&lt;TS(T_j)$, there are only three cases: <ul>
<li>If $T_i$ completes all three phases before $T_j$ begins its execution. This just means that there is serial ordering. </li>
<li>If $T_i$ completes before $T_j$ starts its Write phase, then we require that $T_i$ does not write to any object read by $T_j$, i.e. $WriteSet(T_i)\cap ReadSet(T_j)=\empty$. <ul>
<li>At this condition, we can conclude that $T_j$ cannot see anythin written by $T_i$. Therefore, if $T_j$ read anything written by $T_i$, it is a violation. </li>
</ul>
</li>
<li>If $T_i$ completes its Read phase before $T_j$​ completes its Read phase, then we require that $T_i$ does not write to any object that is either read or written by $T_j$. <ul>
<li>$WriteSet(T_i) \cap ReadSet(T_j) = \empty$ and $WriteSet(T_i) \cap WriteSet(T_j) = \empty$. </li>
<li>Anything wrote by $T_i$ should be seen by $T_j$ and should not conflict with what $T_j$ intends to write. </li>
<li>OCC wants more than just serializable order. Similar with Thomas write rule, if we allow the write sets have something in common it still would be serializable, yet in conflict. </li>
</ul>
</li>
</ul>
</li>
</ol>
<h3 id="What-are-the-issues-of-OCC"><a href="#What-are-the-issues-of-OCC" class="headerlink" title="What are the issues of OCC?"></a>What are the issues of OCC?</h3><ol>
<li>High overhead for copying data locally. </li>
<li>Validation/Write phase bottlenecks.</li>
<li>Aborts are more wasteful than in 2PL because they only occur after a transaction has already executed.</li>
</ol>
<h1 id="The-phantom-problem"><a href="#The-phantom-problem" class="headerlink" title="The phantom problem"></a>The phantom problem</h1><h2 id="What-is-the-phantom-problem"><a href="#What-is-the-phantom-problem" class="headerlink" title="What is the phantom problem?"></a>What is the phantom problem?</h2><ol>
<li>In the above transaction management protocols, we assume that the total number  of tuples in a table is fixed, i.e. transactions will not execute insertion or deletion. </li>
<li>Insertion or deletions result in different results for the same range scan queries, e.g. count, maximum. <ul>
<li>The reason is that transactions can only lock on existing records and not one under way. </li>
</ul>
</li>
</ol>
<h2 id="How-can-we-solve-the-phantom-problem"><a href="#How-can-we-solve-the-phantom-problem" class="headerlink" title="How can we solve the phantom problem?"></a>How can we solve the phantom problem?</h2><ol>
<li>The first approach is to re-execute scans. <ul>
<li>The DBMS tracks the <code>WHERE</code> clause for all queries that the transaction executes. Retain the scan set for every range query in a transaction. </li>
<li>Upon commit, re-execute just the scan portion of each query and check whether it generates the same result. </li>
<li>This could double the execute time for all queries, which may be unacceptable. </li>
</ul>
</li>
<li>The second approach is by predicate locking. <ul>
<li>Shared lock on the predicate in a <code>WHERE</code> clause of a <code>SELECT</code> query. </li>
<li>Exclusive lock on the predicate in a <code>WHERE</code> clause of any <code>UPDATE</code>, <code>INSERT</code>, or <code>DELETE</code> query. </li>
<li>Prevent any query changing the result of locked predicate from executing. </li>
</ul>
</li>
<li>The third approach is by index locking. <ul>
<li>Key-value locks only cover a single existing key-value in an index, while gap locks cover those virtual keys for non-existent values. </li>
<li>Key-range locks takes multiple key-value locks and gap locks to lock on a range. </li>
<li>Hierarchical locking allows for a transaction to hold wider key-range locks with different locking modes to reduce the number of visits to lock manager. </li>
</ul>
</li>
<li>If there is no suitable index, then the transaction must obtain: <ul>
<li>A lock on every page in the table to prevent a record’s attributes from being changed to fit the predicates. </li>
<li>The lock for the table itself to prevent records fit the predicates from being added or deleted. </li>
</ul>
</li>
</ol>
<h2 id="What-are-isolation-levels"><a href="#What-are-isolation-levels" class="headerlink" title="What are isolation levels?"></a>What are isolation levels?</h2><ol>
<li>We may want to use a weaker level of consistency to improve scalability. </li>
<li>Provides for greater concurrency at the cost of exposing transactions to uncommitted changes: dirty reads, unrepeatable reads and phantom reads. </li>
<li>The four isolation levels are as shown below:<br><img src="/imgs/15445/TO/isolation.png" width="50%"></li>
<li>Each isolation level requires different locks to implement:<ul>
<li><code>SERIALIZABLE</code>: Obtain all locks first; plus index locks, plus strict 2PL.</li>
<li><code>REPEATABLE READS</code>: Same as above, but no index locks.</li>
<li><code>READ COMMITTED</code>: Same as above, but S locks are released immediately.</li>
<li><code>READ UNCOMMITTED</code>: Same as above but allows dirty reads (no S locks). </li>
</ul>
</li>
</ol>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://liyun-zhang.github.io/2023/08/04/Courses/15445/10-Two-Phase-Locking/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="LiyunZhang">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="LiyunZhang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | LiyunZhang">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2023/08/04/Courses/15445/10-Two-Phase-Locking/" class="post-title-link" itemprop="url">10 Two-Phase Locking</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2023-08-04 16:47:09" itemprop="dateCreated datePublished" datetime="2023-08-04T16:47:09+08:00">2023-08-04</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">Edited on</span>
      <time title="Modified: 2023-08-05 17:36:14" itemprop="dateModified" datetime="2023-08-05T17:36:14+08:00">2023-08-05</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">In</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Open-Courses/" itemprop="url" rel="index"><span itemprop="name">Open Courses</span></a>
        </span>
          , 
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Open-Courses/CMU-15-445-645-Database-System/" itemprop="url" rel="index"><span itemprop="name">CMU 15-445/645 Database System</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p>@[toc]</p>
<h1 id="Two-phase-Locking"><a href="#Two-phase-Locking" class="headerlink" title="Two-phase Locking"></a>Two-phase Locking</h1><h2 id="How-can-we-guarantee-serializable-without-knowing-the-entire-schedule-ahead-of-time"><a href="#How-can-we-guarantee-serializable-without-knowing-the-entire-schedule-ahead-of-time" class="headerlink" title="How can we guarantee serializable without knowing the entire schedule ahead of time?"></a>How can we guarantee serializable without knowing the entire schedule ahead of time?</h2><ol>
<li><p>We can use locks to protect database objects. </p>
<ul>
<li><p>When a transaction wants to access some objects, it needs to acquire locks of that objects from a centralized lock manager. </p>
</li>
<li><p>Locks are issued by applications and handled in lock manager while latches are issued and acquired locally. Hence acquiring locks are more expensive than acquiring latches even if locks are free. </p>
</li>
</ul>
</li>
<li><p>There are <code>S-LOCK</code> and <code>X-LOCK</code>. </p>
<ul>
<li><p><code>S-LOCKs</code> are shared locks for reads while <code>X-LOCKs</code> are exclusive locks for writes. </p>
</li>
<li><p>Their compatibility matrix is as followed: </p>
<p><img src="/imgs/15445/2pl/sx_comp_matrix.png" width="50%"></p>
</li>
</ul>
</li>
<li><p>Lock manager keeps track of what transaction hold what locks and what transactions are waiting to acquire any locks. </p>
<ul>
<li>When transactions request or upgrade locks, lock manager grants or blocks requests. When transactions release or downgrade locks, lock manager updates its internal lock-table. </li>
<li>Lock manager is responsible for detecting deadlock and choosing some transactions to kill. </li>
</ul>
</li>
</ol>
<h2 id="What-is-the-problem-of-releasing-locks-and-acquiring-it-later-again"><a href="#What-is-the-problem-of-releasing-locks-and-acquiring-it-later-again" class="headerlink" title="What is the problem of releasing locks and acquiring it later again?"></a>What is the problem of releasing locks and acquiring it later again?</h2><ol>
<li>This may cause in-consistent reads for a transaction when another transaction modified the object during lock is available. </li>
<li>This problem can be solved by two-phase locking. <ul>
<li>The first phase is growing: <ul>
<li>Each transaction requests or upgrades the locks that it needs from the DBMS’s lock manager. The lock manager grants/denies lock requests.</li>
</ul>
</li>
<li>The second phase is shrinking: <ul>
<li>The transaction is allowed to only release or downgrade locks that it previously acquired. It cannot acquire new locks. </li>
</ul>
</li>
</ul>
</li>
<li>Two-phase locking on its own is sufficient to guarantee conflict serializability because it generates schedules whose precedence graph is acyclic.</li>
</ol>
<h2 id="What-is-the-problem-of-two-phase-locking"><a href="#What-is-the-problem-of-two-phase-locking" class="headerlink" title="What is the problem of two-phase locking?"></a>What is the problem of two-phase locking?</h2><ol>
<li>It is subject to cascading aborts caused by dirty reads. <ul>
<li>When a transaction modified an object, and released the lock before it is aborted, the modified object is exposed to other transactions. </li>
<li>When the modifier is aborted, all other transactions that have used the modified object needs to abort. </li>
</ul>
</li>
<li>This can be solved by strong strict two-phase locking (rigorous two-phase locking). <ul>
<li>The transaction is only allowed to release locks after it has ended, i.e., committed or aborted. </li>
</ul>
</li>
<li>A schedule is strict if a value written by a transaction is not read or overwritten by other transactions until that transaction finishes. <ul>
<li>Its advantages are that it does not incurcascading aborts, and aborted transactions can be undone by just restoring original values of modified tuples. </li>
<li>However, it allows only conflict serializable schedules, but it is often stronger than needed for some apps. Most DBMSs prefer correctness before performance. </li>
</ul>
</li>
</ol>
<h1 id="Deadlock"><a href="#Deadlock" class="headerlink" title="Deadlock"></a>Deadlock</h1><h2 id="How-to-detect-and-resolve-deadlocks"><a href="#How-to-detect-and-resolve-deadlocks" class="headerlink" title="How to detect and resolve deadlocks?"></a>How to detect and resolve deadlocks?</h2><ol>
<li>The two-phase locking may lead to deadlocks. </li>
<li>The DBMS creates a waits-for graph to keep track of what locks each transaction is waiting to acquire<ul>
<li>Nodes are transactions. Edge from $T_i$ to $T_j$ if $T_i$ is waiting for $T_j$ to release a lock. </li>
<li>The system periodically checks for cycles in waits- for graph and then decides how to break it. </li>
</ul>
</li>
<li>When the DBMS detects a deadlock, it will select a “victim” transaction to rollback to break the cycle. <ul>
<li>The victim transaction will either restart or abort (more common) depending on how it was invoked. </li>
<li>There is a trade-off between the frequency of checking for deadlocks and how long transactions wait before deadlocks are broken. </li>
</ul>
</li>
<li>Selecting the proper victim depends on a lot of different variables<ul>
<li>By age (lowest timestamp)</li>
<li>By progress (least/most queries executed)</li>
<li>By the number of items already locked</li>
<li>By the number of transactions that we have to rollback with it</li>
<li>We also should consider the # of times a transaction has been restarted in the past to prevent starvation. </li>
</ul>
</li>
<li>After selecting a victim transaction to abort, the DBMS can also decide on how far to rollback the transaction’s changes. <ul>
<li>The first approach is to rollback entire transaction and tell the application it was aborted. </li>
<li>The second approach is rolling back a portion of a transaction to break deadlock and then attempts to re-execute the undone queries. </li>
</ul>
</li>
</ol>
<h2 id="How-to-prevent-deadlocks"><a href="#How-to-prevent-deadlocks" class="headerlink" title="How to prevent deadlocks?"></a>How to prevent deadlocks?</h2><ol>
<li>When a transaction tries to acquire a lock that is held by another transaction, the DBMS kills one of them to prevent a deadlock. </li>
<li>Assign priorities based on timestamps, e.g older timestamp means higher priority. </li>
<li>The first kind of rule is Wait-Die (“Old Waits for Young”)<ul>
<li>If requesting transaction has higher priority than holding transaction, then requesting transaction waits for holding transaction. Otherwise requesting transaction aborts. </li>
</ul>
</li>
<li>The second kind of rule is Wound-Wait (“Young Waits for Old”)<ul>
<li>If requesting transaction has higher priority than holding transaction, then holding transaction aborts and releases lock. Otherwise requesting transaction waits. </li>
</ul>
</li>
<li>In this case, only one “type” of direction allowed when waiting for a lock. </li>
<li>When a transaction restarts, its new priority is still its original timestamp to prevent it from getting starved for resources like an old man at a corrupt senior center. </li>
</ol>
<h1 id="Lock-granularity"><a href="#Lock-granularity" class="headerlink" title="Lock granularity"></a>Lock granularity</h1><h2 id="What-are-the-database-objects"><a href="#What-are-the-database-objects" class="headerlink" title="What are the database objects?"></a>What are the database objects?</h2><ol>
<li>It can be attributes, tuples, pages, tables depending on the lock granularity. </li>
<li>The trade-off is between parallelism versus overhead of requesting and lock manager processing. </li>
<li>In a hierachical lock scheme, the objects from top-layer to lower-layer are database, table, page, tuple, attribute. </li>
</ol>
<h2 id="How-to-support-multiple-granularities"><a href="#How-to-support-multiple-granularities" class="headerlink" title="How to support multiple granularities?"></a>How to support multiple granularities?</h2><ol>
<li><p>With only <code>S-LOCK</code> and <code>X-LOCK</code>, we have to check the locks of all children when we try to lock a higher-level node. </p>
</li>
<li><p>An intention lock allows a higher-level node to be locked in shared or exclusive mode without having to check all descendent nodes. </p>
</li>
<li><p>If a node is locked in an intention mode, then some transaction is doing explicit locking at a lower level in the tree. </p>
<ul>
<li><p>Intention-Shared (<code>IS</code>) indicates explicit locking at lower level with shared locks. </p>
</li>
<li><p>Intention-Exclusive (<code>IX</code>) indicates explicit locking at lower level with exclusive locks. </p>
</li>
<li><p>Shared+Intention-Exclusive (<code>SIX</code>) indicates that the subtree rooted by that node is locked explicitly in shared mode and explicit locking is being done at a lower level with exclusive-mode locks. </p>
</li>
<li><p>Their compatibility matrix is as followed: </p>
<p><img src="/imgs/15445/2pl/intention.png" width="50%"></p>
</li>
</ul>
</li>
<li><p>Each transaction obtains appropriate lock at highest level of the database hierarchy. </p>
<ul>
<li>To get <code>S</code> or <code>IS</code> lock on a node, the transaction must hold at least <code>IS</code> on parent node. </li>
<li>To get <code>X</code>, <code>IX</code>, or <code>SIX</code> on a node, must hold at least <code>IX</code> on parent node. </li>
</ul>
</li>
<li><p>Multiple lock granularities is shown in the <code>S</code>, <code>X</code>, <code>SIX</code> locks on higher-level objects. </p>
<ul>
<li>Intention-Shared (<code>IS</code>): Intent to get <code>S</code> lock(s) at finer granularity. </li>
<li>Intention-Exclusive (<code>IX</code>): Intent to get <code>X</code> lock(s) at finer granularity. </li>
<li>Shared+Intention-Exclusive (<code>SIX</code>): Like <code>S</code> and <code>IX</code> at the same time. </li>
</ul>
</li>
</ol>
<h2 id="How-to-use-locks"><a href="#How-to-use-locks" class="headerlink" title="How to use locks?"></a>How to use locks?</h2><ol>
<li>Applications typically don’t acquire a transaction’s locks manually (i.e., explicit SQL commands). <ul>
<li>Sometimes you need to provide the DBMS with hints to help it to improve concurrency. </li>
<li>Explicit locks are also useful when doing major changes to the database. </li>
</ul>
</li>
<li>Lock escalation: The DBMS can automatically switch to coarser- grained locks when a transaction acquires too many low-level locks. This reduces the number of requests that the lock manager must process. </li>
</ol>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://liyun-zhang.github.io/2023/08/02/OpenSource/BusTub/Project-3-Query-Execution/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="LiyunZhang">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="LiyunZhang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | LiyunZhang">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2023/08/02/OpenSource/BusTub/Project-3-Query-Execution/" class="post-title-link" itemprop="url">Project #3: Query Execution</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2023-08-02 00:52:07" itemprop="dateCreated datePublished" datetime="2023-08-02T00:52:07+08:00">2023-08-02</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">Edited on</span>
      <time title="Modified: 2023-08-17 12:47:30" itemprop="dateModified" datetime="2023-08-17T12:47:30+08:00">2023-08-17</time>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p>@[toc]</p>
<h1 id="Executors"><a href="#Executors" class="headerlink" title="Executors"></a>Executors</h1><h2 id="Overall"><a href="#Overall" class="headerlink" title="Overall"></a>Overall</h2><ol>
<li>The planner for each operation stores the necessary information to calculate the correct output. </li>
<li>The executor class for each operation stores the corresponding plan and other information for it to determine what tuple will be returned. <ul>
<li>All executors need to override the <code>Init()</code> and <code>Next(Tuple *tuple, RID *rid)</code>. </li>
<li><code>Init()</code> is used to initialize the information to determine what tuple will be returned. It is separated from the constructor because its parent executor may need to fetch the tuples of the current executor several times. </li>
</ul>
</li>
<li>The <code>ExecutorContext</code> in each executor stores the metadata of the database system, including catalog, buffer pool manager. <ul>
<li>Catalog maintains the tables and indexes in the current database. </li>
<li>We can register a new table or index through catalog or acquire metadata of a table (<code>TableInfo</code>) or index (<code>IndexInfo</code>) from catalog. </li>
</ul>
</li>
<li>The <code>TableInfo</code> stores the name, OID, schema of the table, and a pointer of <code>TableHeap</code>. <ul>
<li>We can manipulate a table through its <code>TableHeap</code>. </li>
<li>The <code>TableHeap</code> provides methods to insert or get tuples and update or get tuple metadata. <ul>
<li>To delete a tuple, we just need to mark the <code>is_deleted_</code> flag in its metadata as <code>true</code>. </li>
<li>To update a tuple, we need to delete it first and insert the new updated tuple into the table again. </li>
<li>To iterate through the table, <code>TableHeap</code> also provided <code>MakeIterator()</code>. </li>
</ul>
</li>
</ul>
</li>
<li>The <code>IndexInfo</code> stores the name and OID of the index, the schema for the index key, the name of the table and a pointer of <code>Index</code>. <ul>
<li>We can manipulate an index through its <code>Index</code>. </li>
<li>The <code>Index</code> provides methods to insert or delete an entry from the index, and get metadata of the index. <ul>
<li>The metadata includes the names of the index and table, mapping relation between key schema and tuple schema, and the schema of the indexed key. </li>
<li>The <code>Index</code> is the abstract class of all kinds of index implementations. To use a specific known index implementation, we can <code>dynamic_cast</code> it. </li>
</ul>
</li>
</ul>
</li>
<li>This system support <code>ArithmeticExpression</code>, <code>ColumnValueExpression</code>, <code>ComparisonExpression</code>, <code>ConstantValueExpression</code>, <code>LogicExpression</code>, <code>StringExpression</code>. <ul>
<li>The <code>AbstractExpression</code> provides an <code>Evaluate</code> method to calculate desired <code>Value</code> according to provided one <code>Tuple</code> and <code>Schema</code>. <ul>
<li>The <code>ArithmeticExpression</code> only supports <code>PLUS</code> and <code>MINUS</code> operation of two <code>Value</code>s. </li>
<li>The <code>ColumnValueExpression</code> returns the <code>Value</code> of the designated column. </li>
<li>The <code>ComparisonExpression</code> supports the comparison result of two <code>Values</code>s of <code>equal, not equal, less, less or equal, greater, greater or equal</code>. </li>
<li>The <code>ConstantValueExpression</code> returns a single constant <code>Value</code>. </li>
<li>The <code>LogicExpression</code> supports the <code>AND/OR</code> of two <code>Value</code>s. </li>
<li>The <code>StringExpression</code> converts a string  to lower-case or upper-case. </li>
</ul>
</li>
<li>The <code>AbstractExpression</code> also provides an <code>EvaluateJoin</code> method to calculate the join condition of two <code>Tuple</code>s. They support the same functions as <code>Evaluation</code> except that they consider two tuples. </li>
<li><code>ArithmeticExpression</code>, <code>ComparisonExpression</code>, <code>LogicExpression</code> and <code>LogicExpression</code> may have child-expressions. During evaluation, they will perform child expressions first recursively. </li>
</ul>
</li>
</ol>
<h2 id="Scan"><a href="#Scan" class="headerlink" title="Scan"></a>Scan</h2><ol>
<li>In sequential scan, we only need to know which table to scan. <ul>
<li>The object ID and name of the table is stored in the planner. </li>
<li>In the <code>Init()</code>, the metadata of the table (<code>TableInfo</code>) is fetched from catalog and the corresponding iterator of the table is created. </li>
<li>In the <code>Next(Tuple *tuple, RID *rid)</code>, as long as the iterator is not at the end, we need to find the first tuple with <code>is_deleted_</code> being <code>false</code> and matching with <code>filter_predicate_</code>. </li>
</ul>
</li>
<li>In the index scan, we need to know which index to scan and which table to fetch the tuple. <ul>
<li>The OID of the index is stored in the planner while the name of the table is stored in the <code>IndexInfo</code>. </li>
<li>To fetch the iterator of the index, we need to cast the <code>Index</code> into the specific implementation. </li>
<li>Each iterator points to a paire of the key and the RecordID. We can fetch the tuple with the <code>GetTuple</code> of the <code>TableHeap</code>. </li>
<li>As long as the iterator is not at the end, we need to find the first tuple with <code>is_deleted_</code> being <code>false</code>. </li>
</ul>
</li>
</ol>
<h2 id="Modification"><a href="#Modification" class="headerlink" title="Modification"></a>Modification</h2><ol>
<li>In the modification executors, we will modify the table and all the associated indexes. <ul>
<li>The table OIDs are stored in corresponding planner, while we can fetch all indexes of that table with the name of the table in <code>TableInfo</code>. </li>
<li>The indexed keys can be acquired with the <code>KeyFromTuple</code> method of the <code>Tuple</code>. The stored values are RecordIDs. </li>
</ul>
</li>
<li>All the modification executors only return one row representing the number of modified tuples. Hence in one <code>Next</code> call, the executor should handle all the modification. <ul>
<li>When no modification is performed, we should also return one row of $0$. </li>
<li>To distinguish between no modification and modification already finished in last call, we should have a flag representing whether or not we have already modified the table. </li>
</ul>
</li>
<li>In the insert executor and delete executor, the tuples to insert or delete are acquired from child executor. </li>
<li>In the update planner, there is a target expression for each output column. <ul>
<li>After acquired the original tuple from the child executor, we can evaluate each output column with target expressions. </li>
<li>The expressions can be any kind of expressions here. </li>
<li>When updating indexes, it needs to first delete the old indexes first before insert updated indexes. </li>
</ul>
</li>
</ol>
<h2 id="Aggregation"><a href="#Aggregation" class="headerlink" title="Aggregation"></a>Aggregation</h2><ol>
<li>The aggregations are implemented with a hash table. <ul>
<li>The hash table hashes the aggregate keys to the aggregate result. </li>
<li>When insert a tuple into the hash table, it updates the aggregate result in it according to the aggregate function and the aggregate values from the tuple. </li>
<li>To use <code>std::hash</code>, the key is <code>AggregateKey</code> containing a vector of <code>Value</code> describing the group-by keys while the value is <code>AggregateValue</code> containing another vector of <code>Value</code> describing aggregate values. <ul>
<li>The <code>AggregateKey</code> needs to override <code>==</code> operator and provide <code>()</code> operator in <code>struct std::hash&lt;bustub::AggregateKey&gt;</code> to calculate the hash value of <code>AggregateKey</code>. </li>
</ul>
</li>
</ul>
</li>
<li>Aggregations are pipeline breakers. Hence the build phase could be performed in the <code>Init()</code> where all tuples from child executor are read and inserted into the hash table to calculate the outputs. <ul>
<li>If no tuple is inserted, the aggregation executor still need to return the default values for each aggregate function. </li>
<li>The aggregation planner has two vectors of <code>AbstractExpressionRef</code> to fetch the aggregate keys and aggregate values from tuples received from child executor for aggregate computation. They are all <code>ColumnExpression</code>. </li>
</ul>
</li>
<li>In the <code>Next(Tuple *tuple, RID *rid)</code>, we just need to iterate over the hash table and output a tuple combining the aggregate keys and aggregate results. </li>
</ol>
<h2 id="NestedLoopJoin"><a href="#NestedLoopJoin" class="headerlink" title="NestedLoopJoin"></a>NestedLoopJoin</h2><ol>
<li><p>The executor needs to iterate over left child executor and right child executor. </p>
<ul>
<li>When the right child executor has emitted all tuples, the join executor will try to fetch a new tuple from the left child executor and re-initialize the right child executor for the following comparison. </li>
<li>Since we do not always fetch from left child executor when the <code>Next</code> is called, we need to record the current left tuple when it is fetched. </li>
<li>To distinguish between the status of no more left tuples and have not fetched any left tuples yet, we can fetch the first left tuple in <code>Init()</code>. </li>
<li>To mark the status of no more left tuples, i.e. no more tuples to emit, we need a flag to record the status of left tuples, which is the returned value of the <code>Next</code> of left child executor. </li>
</ul>
</li>
<li><p>For left join, if an outer tuple does not match with any inner tuple, we still need to emit the concatenation of that outer tuple with all-null inner tuple. </p>
</li>
<li><p>The predicate expression of the executor can be either a <code>LogicExpression</code> or <code>ComparisonExpression</code>. </p>
</li>
</ol>
<h2 id="HashJoin"><a href="#HashJoin" class="headerlink" title="HashJoin"></a>HashJoin</h2><ol>
<li>Similar with aggregations, we need a hash table for the outer table. We define <code>JoinKey</code> and <code>JoinBucket</code> to hash. <ul>
<li>We store all tuples with the same values in the attributes of join condition. </li>
<li>To support left join, we also need to record whether one tuple is used. <ul>
<li>When a tuple is matched with some inner tuple, all tuples in the same bucket must also matched. Hence we only need to record the usage of each <code>JoinBucket</code>. </li>
<li>For left join, when there is no more right tuples, the executor still need to iterate through the hash table to see if any bucket is unused. </li>
</ul>
</li>
<li>Similar with aggregation, <code>HashJoin</code> need to build the hash table based on the outer table in <code>Init()</code>. </li>
</ul>
</li>
<li>Different with <code>NestedLoopJoin</code>, the plan of <code>HashJoin</code> only need to know how to fetch columns from each tuples to determine whether those tuples are matched. <ul>
<li>The expressions of the <code>HashJoin</code> planner are only <code>ColumnValueExpression</code>. </li>
</ul>
</li>
</ol>
<h2 id="Sort-amp-Top-N"><a href="#Sort-amp-Top-N" class="headerlink" title="Sort &amp; Top-N"></a>Sort &amp; Top-N</h2><ol>
<li>The compare function needs specific expressions to fetch designated columns from each tuple. <ul>
<li>Hence we cannot only implement a non-static member function or a function with expressions being one of the parameters. </li>
<li>We need to implement a structure with override <code>()</code> operator. The expressions are passed to the object in initialization. </li>
<li>For <code>priority_queue</code>, two nodes will be swapped when the comparison function returns true. </li>
</ul>
</li>
<li>In the <code>Init()</code>, we need to fetch all tuples from child executor and sort them. <ul>
<li>For Top-N executor, the heap size should not be larger than $N$. The heap after the <code>Init()</code> is the counter-order of the output order, hence we still need a stack to support output in <code>Next</code>. </li>
</ul>
</li>
</ol>
<h1 id="Optimizer"><a href="#Optimizer" class="headerlink" title="Optimizer"></a>Optimizer</h1><ol>
<li>When trying to optimize a plan, the root plan is passed to the optimizer and the optimizer will perform a post-root-order DFS of the plan tree. </li>
<li>Each optimizer tries to recognize the pattern they need to handle and produce a new plan when it is matched. </li>
<li>To optimize limit followed by sort into top-N, we just need to check whether the child of a limit plan is a sort. </li>
</ol>
<h2 id="Optimize-nested-loop-join"><a href="#Optimize-nested-loop-join" class="headerlink" title="Optimize nested loop join"></a>Optimize nested loop join</h2><ol>
<li>To optimize nested loop join with hash join, the optimizer need to find a nested loop join and separate all the conditions from <code>LogicExpression</code> into <code>ComparisonExpression</code>. <ul>
<li>If all the <code>ComparisonExpression</code> are <code>ComparisonType::Equal</code>, we can create a new plan of <code>HashJoin</code> with <code>left_key_expressions</code> and <code>right_key_expressions</code> extracted from those <code>ComparisonExpression</code>. </li>
</ul>
</li>
<li>We can push down predicates of nested loop join to reduce the complexity of join. <ul>
<li>If a predicate is the conjunctions of <code>ComparisonExpression</code>s, we can decompose it into basic <code>ComparisonExpression</code> to examine them one by one to determine whether they can be pushed down. </li>
<li>If the two sides of a <code>ComparisonExpression</code> are from two different tables, it cannot be pushed down. </li>
<li>To push down a <code>ComparisonExpression</code>, we need to ajust the expressions of the two sides. <ul>
<li></li>
</ul>
</li>
</ul>
</li>
</ol>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://liyun-zhang.github.io/2023/07/16/Courses/15445/09-Concurrency-Control/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="LiyunZhang">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="LiyunZhang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | LiyunZhang">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2023/07/16/Courses/15445/09-Concurrency-Control/" class="post-title-link" itemprop="url">09 Concurrency Control</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>
      

      <time title="Created: 2023-07-16 16:35:24 / Modified: 18:14:52" itemprop="dateCreated datePublished" datetime="2023-07-16T16:35:24+08:00">2023-07-16</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">In</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Open-Courses/" itemprop="url" rel="index"><span itemprop="name">Open Courses</span></a>
        </span>
          , 
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Open-Courses/CMU-15-445-645-Database-System/" itemprop="url" rel="index"><span itemprop="name">CMU 15-445/645 Database System</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p>@[toc]</p>
<h1 id="Concurency-control-amp-recovery"><a href="#Concurency-control-amp-recovery" class="headerlink" title="Concurency control &amp; recovery"></a>Concurency control &amp; recovery</h1><h2 id="What-do-we-want-from-concurrency-control-amp-recovery"><a href="#What-do-we-want-from-concurrency-control-amp-recovery" class="headerlink" title="What do we want from concurrency control &amp; recovery?"></a>What do we want from concurrency control &amp; recovery?</h2><ol>
<li>The concurrency control is responsible for lost update problem. <ul>
<li>How can we avoid race conditions when updating records at the same time? </li>
<li>This involves the buffer pool manager layer, access methods layer and operator execution layer. </li>
</ul>
</li>
<li>Recovery is responsible for durability problems. <ul>
<li>How can we ensure the correct state in case of a power failure? </li>
<li>This involves the disk manager layer and buffer pool manager layer. </li>
</ul>
</li>
</ol>
<h2 id="How-does-applications-issue-changes-to-a-DBMS"><a href="#How-does-applications-issue-changes-to-a-DBMS" class="headerlink" title="How does applications issue changes to a DBMS?"></a>How does applications issue changes to a DBMS?</h2><ol>
<li>A transaction is the execution of a sequence of one or more operations (e.g., SQL queries) on a database to perform some higher-level function. <ul>
<li>Transaction is the basic unit of change in a DBMS. Partial transactions are not allowed. </li>
<li>A new transaction starts with the <code>BEGIN</code> command. </li>
<li>The transaction stops with either <code>COMMIT</code> or <code>ABORT</code>:<ul>
<li>If commit, the DBMS either saves all the transaction’s changes <strong>or aborts</strong> it.</li>
<li>If abort, all changes are undone so that it’s like as if the transaction never executed at all. </li>
<li>Abort can be either self-inflicted or caused by the DBMS.</li>
</ul>
</li>
</ul>
</li>
<li>In a strawman system, each transaction is executed one-by-one as  they arrive at the DBMS. <ul>
<li>Before a transaction starts, copy the entire database to a new file and make all changes to that file.  <ul>
<li>If the txn completes successfully, overwrite the original file with the new one. </li>
<li>If the txn fails, just remove the dirty copy. </li>
</ul>
</li>
<li>The problem of this system is that there is no concurrency and copying the entire database can be expensive if the it is large. </li>
</ul>
</li>
<li>Besides correctness and fairness, we also want the DBMS to allow concurrent execution of independent transactions to provide better utilization / throughput and increase response times to users. </li>
</ol>
<h2 id="What-does-the-DBMS-want-to-prevent-when-supporting-concurrency"><a href="#What-does-the-DBMS-want-to-prevent-when-supporting-concurrency" class="headerlink" title="What does the DBMS want to prevent when supporting concurrency?"></a>What does the DBMS want to prevent when supporting concurrency?</h2><ol>
<li>Arbitrary interleaving of operations can lead to temporary inconsistency and permanent inconsistency. <ul>
<li>Temporary inconsistency is unavoidable and it is fine as long as no other transactions can see it. </li>
<li>Permanent inconsistency is unacceptable. </li>
</ul>
</li>
<li>The DBMS is only concerned about what data is read/written from/to the database. Changes to the “outside world”, e.g. sending an email, are beyond the scope of the DBMS. </li>
</ol>
<h1 id="Correctness"><a href="#Correctness" class="headerlink" title="Correctness"></a>Correctness</h1><h2 id="What-is-the-correctness-criteria"><a href="#What-is-the-correctness-criteria" class="headerlink" title="What is the correctness criteria?"></a>What is the correctness criteria?</h2><ol>
<li><strong>Atomicity</strong>: All actions in transaction happen, or none happen, i.e. “all or nothing”. </li>
<li><strong>Consistency</strong>: If each transaction is consistent and the DB starts consistent, then it ends up consistent. </li>
<li><strong>Isolation</strong>: Execution of one transaction is isolated from that of other transactions. </li>
<li><strong>Durability</strong>: If a txn commits, its effects persist. </li>
</ol>
<h2 id="How-to-ensure-atomicity"><a href="#How-to-ensure-atomicity" class="headerlink" title="How to ensure atomicity?"></a>How to ensure atomicity?</h2><ol>
<li>The first approach is logging (Write Ahead Log / WAL). <ul>
<li>DBMS logs all actions so that it can undo the actions of aborted transactions. </li>
<li>Maintain undo records both in memory and on disk. </li>
<li>When the DBMS come back from a crash, it need to undo partial transactions according to the undo records. </li>
</ul>
</li>
<li>Another approach is shadow paging. <ul>
<li>DBMS makes copies of pages and txns make changes to those copies. </li>
<li>Only when the txn commits is the page made visible to others by modifying the pointer at directory. </li>
<li>It does not need extra operations when come back from crash. </li>
</ul>
</li>
</ol>
<h2 id="What-is-consistency"><a href="#What-is-consistency" class="headerlink" title="What is consistency?"></a>What is consistency?</h2><ol>
<li>At a high level, consisitency means the “world” represented by the database is logically correct. All questions (i.e., queries) that the application asks about the data will return logically correct results. </li>
<li>There are two notions of consistency<ul>
<li>Database consistency means that the database accurately models the real world and follows integrity constraints. <ul>
<li>Transactions in the future see the effects of transactions committed in the past inside of the database. </li>
<li>The designer of DBMS should maintain this consistency. </li>
</ul>
</li>
<li>Transaction consistency means that if the database is consistent before the transaction starts, it will also be consistent after. <ul>
<li>The application programmer is responsible for this consistency. The DBMS does not know the semantics of correctness. </li>
</ul>
</li>
</ul>
</li>
</ol>
<h2 id="Isolation"><a href="#Isolation" class="headerlink" title="Isolation"></a>Isolation</h2><h3 id="What-do-we-want-from-isolation"><a href="#What-do-we-want-from-isolation" class="headerlink" title="What do we want from isolation?"></a>What do we want from isolation?</h3><ol>
<li>Users submit txns, and each txn executes as if it was running by itself, i.e. it is executed in a strawman system where no other transaction is executing at the same time. </li>
<li>Isolation provides an easier programming model to reason about. </li>
<li>But the DBMS achieves concurrency by interleaving the actions (reads/writes of DB objects) of txns. Hence we need to schedule to interleave txns but still make it appear as if they ran one-at-a-time. </li>
<li>There is no guarantee that $T_1$ will execute before $T_2$ or vice-versa, if both are submitted together. The net effect must be equivalent to these two transactions running serially in some order.</li>
</ol>
<h3 id="How-to-decide-whether-a-schedule-matches-isolation"><a href="#How-to-decide-whether-a-schedule-matches-isolation" class="headerlink" title="How to decide whether a schedule matches isolation?"></a>How to decide whether a schedule matches isolation?</h3><ol>
<li>If the schedule is equivalent to some serial execution, we can consider it correct. </li>
<li>For any database state, if the effect of executing the first schedule is identical to the effect of executing the second schedule, we say these two schedules are equivalent. </li>
<li>A schedule is serializable schedule if it is equivalent to some serial execution of the transactions. <ul>
<li>If each transaction preserves consistency, every serializable schedule preserves consistency. </li>
</ul>
</li>
<li>There are two different levels of serializability: conflict serializability (most commonly used) and view serializability. </li>
</ol>
<h3 id="What-conflicts-do-we-want-to-prevent"><a href="#What-conflicts-do-we-want-to-prevent" class="headerlink" title="What conflicts do we want to prevent?"></a>What conflicts do we want to prevent?</h3><ol>
<li>Two operations conflict if: They are by different transactions, and they are on the same object while one of them is a write. </li>
<li>A read-write conflict will cause unrepeatable read. <ul>
<li>Transaction gets different values when reading the same object multiple times. </li>
<li>The conflict is between the write from one transaction and a repeated following read from another transaction, i.e. this is actually $read_1-write-read_2$ conflict where the conflict is between $write-read_2$. </li>
<li>If there is only one read, it is not a read-write conflict. The first read will never be a read-write conflict. </li>
</ul>
</li>
</ol>
<ul>
<li>A write-read conflict will cause dirty read. <ul>
<li>One transaction reads data written by another transaction that has not committed yet. </li>
<li>The problem will happen when the read transaction is commited before the write transaction aborts. </li>
<li>If the write transaction successfully commits, there is no problem. But we cannot know that when we commit the read transaction first. </li>
</ul>
</li>
<li>A write-write conflict will cause lost update. <ul>
<li>One transaction overwrites uncommitted data from another uncommitted transaction. </li>
<li>This may cause the result becoming combination of two partial transactions. </li>
<li>There is no problem when every data written by $T_2$ is the last write to that data, i.e. every data written by $T_2$ is not overwritten by $T_1$. The problem happens when $T_1$ overwrites some data of $T_2$ while $T_2$ overwrites some data of $T_1$. </li>
</ul>
</li>
</ul>
<h3 id="How-do-we-determine-whether-a-schedule-is-conflict-serializable"><a href="#How-do-we-determine-whether-a-schedule-is-conflict-serializable" class="headerlink" title="How do we determine whether a schedule is conflict serializable?"></a>How do we determine whether a schedule is conflict serializable?</h3><ol>
<li>When there are only two schedules: <ul>
<li>Two schedules are conflict equivalent if and only if they involve the same actions of the same transactions and every pair of conflicting actions is ordered the same way. </li>
<li>Schedule S is conflict serializable if S is conflict equivalent to some serial schedule. </li>
<li>We can transform S into a serial schedule by swapping consecutive non-conflicting operations of different transactions. </li>
</ul>
</li>
<li>For more schedules, we can use the dependency graphs. <ul>
<li>Create one node per txn in the graph. </li>
<li>Create an edge from $T_i$ to $T_j$ if an operation $O_i$ of $T_i$ conflicts with an<br>operation $O_j$ of $T_j$ and $O_i$ appears earlier in the schedule than $O_j$. </li>
<li>A schedule is conflict serializable if and only if its dependency graph is acyclic. </li>
</ul>
</li>
</ol>
<h3 id="How-do-we-determine-whether-a-schedule-is-view-serializable"><a href="#How-do-we-determine-whether-a-schedule-is-view-serializable" class="headerlink" title="How do we determine whether a schedule is view serializable?"></a>How do we determine whether a schedule is view serializable?</h3><ol>
<li>Schedules $S_1$ and $S_2$ are view equivalent if:<ul>
<li>If $T_1$ reads initial value of A in $S_1$, then $T_1$ also reads initial value of A in $S_2$. </li>
<li>If $T_1$ reads value of A written by $T_2$ in $S_1$, then $T_1$ also reads value of A written by $T_2$ in $S_2$. </li>
<li>If $T_1$ writes final value of A in $S_1$, then $T_1$ also writes final value of A in $S_2$. </li>
</ul>
</li>
<li>In a word, each transaction is different schedules read the same values written by the same transaction and at the final end of all transactions, all data are written by the same transaction in the same value. </li>
<li>View Serializability allows for (slightly) more schedules than Conflict Serializability does. Neither definition allows all serializable schedules. </li>
</ol>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://liyun-zhang.github.io/2023/07/15/Courses/15445/08-Query-Planning-Optimization/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="LiyunZhang">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="LiyunZhang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | LiyunZhang">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2023/07/15/Courses/15445/08-Query-Planning-Optimization/" class="post-title-link" itemprop="url">08 Query Planning & Optimization</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2023-07-15 19:52:41" itemprop="dateCreated datePublished" datetime="2023-07-15T19:52:41+08:00">2023-07-15</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">Edited on</span>
      <time title="Modified: 2023-07-16 02:02:27" itemprop="dateModified" datetime="2023-07-16T02:02:27+08:00">2023-07-16</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">In</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Open-Courses/" itemprop="url" rel="index"><span itemprop="name">Open Courses</span></a>
        </span>
          , 
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Open-Courses/CMU-15-445-645-Database-System/" itemprop="url" rel="index"><span itemprop="name">CMU 15-445/645 Database System</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p>@[toc]</p>
<h1 id="Query-planning"><a href="#Query-planning" class="headerlink" title="Query planning"></a>Query planning</h1><h2 id="What-are-the-logical-plans-and-physical-plans"><a href="#What-are-the-logical-plans-and-physical-plans" class="headerlink" title="What are the logical plans and physical plans?"></a>What are the logical plans and physical plans?</h2><ol>
<li>The optimizer generates a mapping of a logical algebra expression to the optimal equivalent physical algebra expression. </li>
<li>Physical operators define a specific execution strategy using an access path, i.e. a specific algorithm. <ul>
<li>They depend on the physical format of the data that they process, i.e., sorting, compression. </li>
</ul>
</li>
</ol>
<h2 id="What-is-the-process-flow-of-query-execution"><a href="#What-is-the-process-flow-of-query-execution" class="headerlink" title="What is the process flow of query execution?"></a>What is the process flow of query execution?</h2><ol>
<li>The application connected to the database system and sends a SQL query, which may be rewritten to a different format in SQL rewriter. </li>
<li>The SQL string is parsed into tokens that make up the syntax tree. </li>
<li>The binder converts named objects in the syntax tree to internal identifiers by consulting the system catalog. </li>
<li>The binder emits a logical plan which may be fed to a tree rewriter for additional schema info. </li>
<li>The logical plan is given to the optimizer which selects the most efficient procedure to execute the plan. </li>
</ol>
<p><img src="/imgs/15445/Optimizer/architecture.png" width="50%"></p>
<h2 id="How-does-optimizer-work"><a href="#How-does-optimizer-work" class="headerlink" title="How does optimizer work?"></a>How does optimizer work?</h2><ol>
<li>One way is heuristics / rules. <ul>
<li>Rewrite the query to remove stupid / inefficient things. </li>
<li>These techniques may need to examine catalog, but they do not need to examine data. </li>
</ul>
</li>
<li>Another way is the cost-based search. <ul>
<li>We need to use a model to estimate the cost of executing a plan. </li>
<li>Enumerate multiple equivalent plans for a query and pick the one with the lowest cost. </li>
</ul>
</li>
</ol>
<h1 id="Heuristics-optimization"><a href="#Heuristics-optimization" class="headerlink" title="Heuristics optimization"></a>Heuristics optimization</h1><h2 id="How-should-we-optimize-logical-plans"><a href="#How-should-we-optimize-logical-plans" class="headerlink" title="How should we optimize logical plans?"></a>How should we optimize logical plans?</h2><ol>
<li>Split conjunctive predicates. <ul>
<li>Decompose predicates into their simplest forms to make it easier for the optimizer to move them around. </li>
</ul>
</li>
<li>Predicate pushdown<ul>
<li>Move the predicate to the lowest applicable point in the plan. </li>
</ul>
</li>
<li>Replace cartesian products with joins<ul>
<li>Replace all Cartesian Products with inner joins using the join predicates. </li>
</ul>
</li>
<li>Projection pushdown<ul>
<li>This is to eliminate redundant attributes before pipeline breakers to reduce materialization cost and the data passed aroung. </li>
</ul>
</li>
</ol>
<h2 id="How-should-we-optimize-for-nested-sub-queries"><a href="#How-should-we-optimize-for-nested-sub-queries" class="headerlink" title="How should we optimize for nested sub-queries?"></a>How should we optimize for nested sub-queries?</h2><ol>
<li>Rewrite to de-correlate and/or flatten them<ul>
<li>E.g. an <code>EXISTS</code> sub-query in <code>WHERE</code> clause may be rewrited as an inner-join. </li>
</ul>
</li>
<li>Decompose nested query and store result to temporary table. <ul>
<li>For those sub-queries uncorrelated with outer query, the optimizer breaks up queries into blocks and then concentrates on one block at a time. </li>
<li>Sub-queries are written to a temporary table that are discarded after the query finishes. </li>
</ul>
</li>
</ol>
<h2 id="How-can-we-rewrite-expression"><a href="#How-can-we-rewrite-expression" class="headerlink" title="How can we rewrite expression?"></a>How can we rewrite expression?</h2><ol>
<li>This is implemented using if/then/else clauses or a pattern-matching rule engine. <ul>
<li>Search for expressions that match a pattern. When a match is found, rewrite the expression. Halt if there are no more rules that match. </li>
</ul>
</li>
<li>One approach is replacing impossible or unnecessary predicates by false. </li>
<li>Another approach is merging predicates, e.g. numeric ranging predicates. </li>
</ol>
<h1 id="Cost-based-search"><a href="#Cost-based-search" class="headerlink" title="Cost-based search"></a>Cost-based search</h1><h2 id="Cost-estimation"><a href="#Cost-estimation" class="headerlink" title="Cost estimation"></a>Cost estimation</h2><h3 id="What-cost-do-we-care"><a href="#What-cost-do-we-care" class="headerlink" title="What cost do we care?"></a>What cost do we care?</h3><ol>
<li>Physical Costs<ul>
<li>Predict CPU cycles, I/O, cache misses, RAM consumption, network messages. </li>
<li>This cost depends heavily on hardware. </li>
</ul>
</li>
<li>Logical Costs<ul>
<li>Estimate output size per operator. </li>
<li>This cost is independent of the operator algorithm since algorithms are physical. </li>
<li>It need estimations for operator result sizes. </li>
</ul>
</li>
<li>Algorithmic Costs<ul>
<li>Mainly the complexity of the operator algorithm implementation. </li>
</ul>
</li>
<li>We may use a combination of multiple costs that are weighted by magic constant factors. <ul>
<li>Some assumptions is that processing a tuple in memory is $400\times$ faster than reading a tuple from disk, and sequential I/O is $4\times$ faster than random I/O. </li>
<li>Most commonly used cost is the combination of the physical costs and logical costs. </li>
</ul>
</li>
</ol>
<h3 id="How-do-DBMS-estimate-the-costs"><a href="#How-do-DBMS-estimate-the-costs" class="headerlink" title="How do DBMS estimate the costs?"></a>How do DBMS estimate the costs?</h3><ol>
<li>The DBMS stores internal statistics about tables, attributes, and indexes in its internal catalog. <ul>
<li>Different systems update them at different times. </li>
</ul>
</li>
<li>Then DBMS derives the <strong>selection cardinality</strong> (<strong>selectivity</strong>) of a predicate which is the fraction of tuples that qualify. </li>
<li>We can make some assumptions to estimate selectivity<ul>
<li>Uniform data: The distribution of values (except for the heavy hitters) is the same. May maintain a heavy hitter list that stores most common values and assume that the occurrence of the rest data is the same. </li>
<li>Independent predicates: The predicates on attributes are independent, i.e. the conjuction of predicates can result in multiplication or addition of probabilities. </li>
<li>Inclusion principle: The domain of join keys overlap such that each key in the inner relation will also exist in the outer table.</li>
<li>These assumptions may not be true. </li>
</ul>
</li>
</ol>
<h3 id="What-statistics-does-the-DBMS-maintain"><a href="#What-statistics-does-the-DBMS-maintain" class="headerlink" title="What statistics does the DBMS maintain?"></a>What statistics does the DBMS maintain?</h3><ol>
<li>Histograms: <ul>
<li>The naive and most accurate way is to maintain an occurrence count per value in a column. </li>
<li>Equi-width histograms maintain counts for a group of values. All buckets have the same width, i.e. the same number of values. </li>
<li>Equi-depth histograms vary the width of buckets so that the total number of occurrences for each bucket is roughly the same. </li>
<li>Equi-width or equi-depth histograms use the total count of a bucket dividing by the number of values in that bucket as the count of each values. </li>
</ul>
</li>
<li>Sketches: <ul>
<li>Probabilistic data structure that gives an approximate count for a given value. </li>
<li>Cost-model can replace histograms with sketches to improve its selectivity estimate accuracy. </li>
</ul>
</li>
<li>Sampling: <ul>
<li>DBMS maintains a small subset of each table that it then uses to evaluate expressions to compute selectivity. </li>
<li>The selectivity is estimated by running the same query on the sample table. </li>
<li>Sample table is updated when the underlying tables changes significantly. </li>
</ul>
</li>
</ol>
<h2 id="Query-optimization"><a href="#Query-optimization" class="headerlink" title="Query optimization"></a>Query optimization</h2><h3 id="How-do-we-perform-cost-based-optimization"><a href="#How-do-we-perform-cost-based-optimization" class="headerlink" title="How do we perform cost-based optimization?"></a>How do we perform cost-based optimization?</h3><ol>
<li>After performing rule-based rewriting, the DBMS will enumerate different plans for the query and estimate their costs. <ul>
<li>It chooses the best plan it has seen for the query after exhausting all plans or some timeout. </li>
<li>The time spent on search should be significantly smaller than the time of executing query. DBMS can set a time threshold to end search. </li>
</ul>
</li>
<li>DBMS mainly enumerates the access methods (sequential scan, binary search / clustered indexes, index scan) and evaluation ordering. </li>
<li>Query planning for OLTP queries is easy because they are <strong>sargable</strong> (Search Argument Able). <ul>
<li>It is usually just picking the best index. </li>
<li>Joins are almost always on foreign key relationships with a small cardinality. </li>
</ul>
</li>
<li>For multi-relation query planning, there are two choices. <ul>
<li>Bottom-up optimization: Start with nothing and then build up the plan to get to the outcome that you want. </li>
<li>Top-down optimization: Start with the outcome that you want, and then work down the tree to find the optimal plan that gets you to that goal. </li>
</ul>
</li>
</ol>
<h3 id="How-does-bottom-up-optimization-work"><a href="#How-does-bottom-up-optimization-work" class="headerlink" title="How does bottom-up optimization work?"></a>How does bottom-up optimization work?</h3><ol>
<li>Break query up into blocks and generate the logical operators for each block. For each logical operator, generate a set of physical operators that implement it. </li>
<li>The whole diagram can be layered by relations or temporary relations, i.e. results of logical operators. </li>
<li>We can visualize the whole optimization diagram as a tree with different layers. <ul>
<li>The top layer is the output of the query and the bottom layer is all the relations. </li>
<li>The middle layers are the enumerations of different ordering. Each layer only performs one more operator than its last layer. </li>
<li>Hence each pair of layers is connected with an undetermined physical operator. </li>
</ul>
</li>
<li>From bottom layer up, we enumarate the possible physical algorithm of each logical operator. <ul>
<li>Then estimate the cost of all possible physical algorithms. </li>
<li>Leave only the more efficient physical algorithm for each logical operator after comare with only the possible physical algorithms of the same logical operator. </li>
</ul>
</li>
<li>When reaches the top layer, we can determine the most efficient path of all possible paths. </li>
<li>Then iteratively construct a “left-deep” join tree that minimizes the estimated amount of work to execute the plan. <ul>
<li>Generate a left-deep tree is to take advantages of pipeline. </li>
</ul>
</li>
</ol>
<h3 id="How-does-top-down-optimization-work"><a href="#How-does-top-down-optimization-work" class="headerlink" title="How does top-down optimization work?"></a>How does top-down optimization work?</h3><ol>
<li>Start with a logical plan of what we want the query to be. </li>
<li>Perform a branch-and-bound search to traverse the plan tree by converting logical operators into physical operators. <ul>
<li>When traversing from logical operator to logical operators, it is enumarating different ordering. </li>
<li>When traversing from logical operator to physical operators, it is enumarating different physical algorithm. </li>
<li>The layers are similar with bottom-up optimization. </li>
<li>When we meet a logical operator, we need to estimate the cost of its all possible physical algorithms. <ul>
<li>So for each physical algorithm, we need to go deeper until the bottom to calculate the estimation. </li>
<li>For the sub-logical-operators in the physical algorithm, we will enumarate its optimal execution in the lower levels. </li>
</ul>
</li>
<li>During the search, we can cut-off a branch if its cost is already more expensive then another branch we have already seen. </li>
</ul>
</li>
</ol>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://liyun-zhang.github.io/2023/07/12/Courses/15445/07-Query-Execution/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="LiyunZhang">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="LiyunZhang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | LiyunZhang">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2023/07/12/Courses/15445/07-Query-Execution/" class="post-title-link" itemprop="url">07 Query Execution</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2023-07-12 16:51:12" itemprop="dateCreated datePublished" datetime="2023-07-12T16:51:12+08:00">2023-07-12</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">Edited on</span>
      <time title="Modified: 2023-07-15 16:52:19" itemprop="dateModified" datetime="2023-07-15T16:52:19+08:00">2023-07-15</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">In</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Open-Courses/" itemprop="url" rel="index"><span itemprop="name">Open Courses</span></a>
        </span>
          , 
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Open-Courses/CMU-15-445-645-Database-System/" itemprop="url" rel="index"><span itemprop="name">CMU 15-445/645 Database System</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p>@[toc]</p>
<h1 id="Sequential-Execution"><a href="#Sequential-Execution" class="headerlink" title="Sequential Execution"></a>Sequential Execution</h1><h2 id="Processing-model"><a href="#Processing-model" class="headerlink" title="Processing model"></a>Processing model</h2><h3 id="What-does-processing-model-do"><a href="#What-does-processing-model-do" class="headerlink" title="What does processing model do?"></a>What does processing model do?</h3><ol>
<li>Processing model defines how the system executes a query plan, i.e. how to traverse the query plan tree. </li>
<li>There are two processing directions: <ul>
<li>Top-to-Bottom: Start with the root and “pull” data up from its children. Tuples are always passed with function calls. </li>
<li>Bottom-to-Top: Start with leaf nodes and push data to their parents. Allows for tighter control of caches/registers in pipelines. </li>
</ul>
</li>
<li>There are three commonly used model: iterator model (volcano/pipeline model), materialization model and vectorized/batch model. </li>
</ol>
<h3 id="How-does-iterator-model-execute"><a href="#How-does-iterator-model-execute" class="headerlink" title="How does iterator model execute?"></a>How does iterator model execute?</h3><ol>
<li><p>In iterator model, operators are executed top-to-down. </p>
</li>
<li><p>Each query plan operator implements a <code>Next()</code> function. On each invocation, the operator returns either a single tuple or a <code>null</code> marker if there are no more tuples. </p>
<ul>
<li><p>The operator implements a loop that calls <code>Next()</code> on its children to retrieve their tuples and then process them. </p>
</li>
<li><p><code>Next()</code> is first called on the root operator and the nodes on the tree will call the <code>Next()</code> on their children recursively. </p>
</li>
</ul>
</li>
<li><p>This model allows for uple pipelining. Although some operators must block until their children emit all their tuples. </p>
<ul>
<li>Joins must wait until all tuples in the leaf child are processed and built the hash table to further process tuples from right child. Hence, the tuples from leaft child need to block the pipeline while the tuples from right child can enable pipeline. </li>
<li>Subqueries and ordering (<code>Order By</code>) clauses also need to block pipeline. These are called pipeline breaker. </li>
</ul>
</li>
<li><p>Output control works easily with this approach. We only need to add constraints on the root operator. </p>
</li>
</ol>
<h3 id="How-does-materialization-model-execute"><a href="#How-does-materialization-model-execute" class="headerlink" title="How does materialization model execute?"></a>How does materialization model execute?</h3><ol>
<li><p>In materialization model, operators are called bottom-to-up. </p>
</li>
<li><p>Each query plan operator implements a <code>Output()</code> function. </p>
<ul>
<li><p>On each invocation, the operator processes its input all at once and then emits its output all at once. </p>
</li>
<li><p>The operator materializes its output as a single result. </p>
</li>
<li>The operators can send either a materialized row or a single column. </li>
</ul>
</li>
<li><p>The DBMS can push down hints (e.g., <code>LIMIT</code>) to avoid scanning too many tuples. </p>
</li>
<li><p>The output can be either whole tuples (NSM) or subsets of columns (DSM). </p>
</li>
<li><p>This model is better for OLTP workloads because queries only access a small number of tuples at a time which means lower execution and coordination overhead and fewer function calls. </p>
<ul>
<li>It is not good for OLAP queries with large intermediate results. </li>
</ul>
</li>
</ol>
<h3 id="How-does-vectorization-model-execute"><a href="#How-does-vectorization-model-execute" class="headerlink" title="How does vectorization model execute?"></a>How does vectorization model execute?</h3><ol>
<li>The problem of iterator model is that it can only process one tuple at a time when we can take multiple tuples and vectorize them to process in parallel (SIMD). </li>
<li>Vectorization model is similar with iterator model except that each operator emits a batch of tuples instead of a single tuple. </li>
<li>This is ideal for OLAP queries because it greatly reduces the number of invocations per operator. <ul>
<li>It allows for operators to more easily use vectorized (SIMD) instructions to process batches of tuples. </li>
</ul>
</li>
</ol>
<h2 id="Access-methods"><a href="#Access-methods" class="headerlink" title="Access methods"></a>Access methods</h2><h3 id="How-can-we-optimize-sequential-scan-with-data-skipping"><a href="#How-can-we-optimize-sequential-scan-with-data-skipping" class="headerlink" title="How can we optimize sequential scan with data skipping?"></a>How can we optimize sequential scan with data skipping?</h3><ol>
<li><p>The first approach is approximate queries. </p>
<ul>
<li><p>This method is lossy, which means that it may return incorrect results, but it is OK. </p>
</li>
<li><p>Execute queries on a sampled subset of the entire table to produce approximate results. </p>
</li>
</ul>
</li>
<li><p>The second approach is zone maps. </p>
<ul>
<li>This method is lossless. </li>
<li>Pre-computed aggregates for the attribute values in a page. DBMS checks the zone map first to decide whether it wants to access the page. </li>
<li>The trade-off is between page size and filter efficacy. </li>
</ul>
</li>
</ol>
<h3 id="What-is-multi-index-scan"><a href="#What-is-multi-index-scan" class="headerlink" title="What is multi-index scan?"></a>What is multi-index scan?</h3><ol>
<li>If there are multiple indexes that the DBMS can use for a query, one method for DBMS to execute is try to filter tuples with index that has least number of tuples matches and filter other indexes based on the filtered tuples of previous indexes. <ul>
<li>This is ideal in the case that some indexes has little tuples that matches. Filtering those indexes first can significantly reduce the number of tuples to process in following indexes. </li>
</ul>
</li>
<li>If all indexes has a lot of matching tuples, we can use another method:<ul>
<li>Compute sets of Record IDs using each matching index. Combine these sets based on the query’s predicates (union or intersect). Retrieve the records and apply any remaining predicates. </li>
<li>In this way, we can reduce a log of I/O and memory space by only fetching Record IDs in the first phase instead of fetching entire tuple. </li>
</ul>
</li>
</ol>
<h2 id="Modification-queries"><a href="#Modification-queries" class="headerlink" title="Modification queries"></a>Modification queries</h2><h3 id="How-should-we-execute-update-and-delete-queries"><a href="#How-should-we-execute-update-and-delete-queries" class="headerlink" title="How should we execute update and delete queries?"></a>How should we execute update and delete queries?</h3><ol>
<li>Operators that modify the database (<code>INSERT</code>, <code>UPDATE</code>, <code>DELETE</code>) are responsible for modifying the target table and its indexes. <ul>
<li>The output of these operators can either be Record Ids or tuple data (i.e., <code>RETURNING</code>). </li>
</ul>
</li>
<li>For update or delete, child operators pass Record IDs for target tuples. <ul>
<li>The operator should remove the corresponding item from index. </li>
<li>Then the operator can modify tuple or remove tuple. </li>
<li>Update should re-insert modified tuple into index again. </li>
</ul>
</li>
<li>Updates have a possible Halloween problem: <ul>
<li>When we re-inserted the modified tuple, its new place may be ahead of cursor, i.e. we will pass the new tuple again in the future. <ul>
<li>E.g. when the index is sorted according to an attribute, and the modification increases that attribute. </li>
</ul>
</li>
<li>An update operation changes the physical location of a tuple, which causes a scan operator to visit the tuple multiple times. It can occur on clustered tables or index scans. </li>
<li>The solution is to keep track of previously seen tuples (e.g. through Record IDs). </li>
</ul>
</li>
</ol>
<h3 id="How-should-we-execute-insert-queries"><a href="#How-should-we-execute-insert-queries" class="headerlink" title="How should we execute insert queries?"></a>How should we execute insert queries?</h3><ol>
<li>The first choice is to materialize tuples inside of the operator. <ul>
<li>The insert operator needs to implement its own method of how to materialize tuples. </li>
</ul>
</li>
<li>The second choice is that operator inserts any tuple passed in from child operators. <ul>
<li>The insert operator only need to accept tuples from its children instead of implementing itself. </li>
</ul>
</li>
</ol>
<h2 id="How-to-evaluate-expressions"><a href="#How-to-evaluate-expressions" class="headerlink" title="How to evaluate expressions?"></a>How to evaluate expressions?</h2><ol>
<li>The DBMS represents a <code>WHERE</code> clause as an expression tree. </li>
<li>The nodes in the tree represent different expression types: Comparisons (<code>=, &lt;, &gt;, !=</code>), conjunction (<code>AND</code>), disjunction (<code>OR</code>), arithmetic operators (<code>+, -, *, /, %</code>), constant values, tuple attribute references. </li>
<li>When evaluate the expression, DFS through the expression tree from the root. <ul>
<li>The performance is poor due to that the DBMS traverses the tree and for each node that it visits it must figure out what the operator needs to do. </li>
</ul>
</li>
<li>A better approach is to just evaluate the expression directly. <ul>
<li>Compile a function of the express (e.g. JIT compilation). In evaluation, DBMS just execute the compiled function instead of traversing through the tree. </li>
</ul>
</li>
</ol>
<h1 id="Parallel-execution"><a href="#Parallel-execution" class="headerlink" title="Parallel execution"></a>Parallel execution</h1><h2 id="Parallel-and-distributed"><a href="#Parallel-and-distributed" class="headerlink" title="Parallel and distributed"></a>Parallel and distributed</h2><h3 id="Why-care-about-parallel-execution"><a href="#Why-care-about-parallel-execution" class="headerlink" title="Why care about parallel execution?"></a>Why care about parallel execution?</h3><ol>
<li>It increased performance for potentially the same hardware resources, i.e. to gain higher throughput and lower latency. </li>
<li>It increased the responsiveness of the system. </li>
<li>It potentially lower total cost of ownership (TCO). <ul>
<li>Fewer machines means less parts / physical footprint / energy consumption. </li>
</ul>
</li>
</ol>
<h3 id="What-are-the-similarities-and-differences-between-parallel-and-distributed-DBMS"><a href="#What-are-the-similarities-and-differences-between-parallel-and-distributed-DBMS" class="headerlink" title="What are the similarities and differences between parallel and distributed DBMS?"></a>What are the similarities and differences between parallel and distributed DBMS?</h3><ol>
<li>Similarities:<ul>
<li>Database is spread out across multiple resources to improve different aspects of the DBMS. </li>
<li>They both need to make database  to appear as a single logical database instance to the application, regardless of physical organization. </li>
<li>SQL query for a single-resource DBMS should generate same result on a parallel or distributed DBMS. </li>
</ul>
</li>
<li>Differences:<ul>
<li>For parallel DBMSs, resources are physically close to each other. Hence resources communicate over high-speed interconnect. And communication is assumed to be cheap and reliable. </li>
<li>For distributed DBMSs, resources can be far from each other. Resources communicate using slow(er) interconnect. Therefore, communication cost and problems cannot be ignored. And communication is considered unreliable. </li>
</ul>
</li>
</ol>
<h2 id="Process-model"><a href="#Process-model" class="headerlink" title="Process model"></a>Process model</h2><h3 id="What-does-process-model-of-parallel-DBMSs-need-to-do"><a href="#What-does-process-model-of-parallel-DBMSs-need-to-do" class="headerlink" title="What does process model of parallel DBMSs need to do?"></a>What does process model of parallel DBMSs need to do?</h3><ol>
<li>It defines how the system is architected to support concurrent requests from a multi-user application. </li>
<li>A worker is the DBMS component that is responsible for executing tasks on behalf of the client and returning the results. </li>
<li>There are three approaches: process per DBMS worker, thread per DBMS worker and embedded DBMS</li>
</ol>
<h3 id="What-is-process-per-worker-model"><a href="#What-is-process-per-worker-model" class="headerlink" title="What is process per worker model?"></a>What is process per worker model?</h3><ol>
<li>Each worker is a separate OS process. Hence, this model relies on OS scheduler entirely. </li>
<li>When an application connect with DBMS, it connect with a dispatcher process. The dispatcher picks on the processes for the application. Then the application communicate with the process directly. </li>
<li>The processes can use shared-memory for global data structures. </li>
<li>The advantage of this model is that a process crash does not take down entire system. </li>
</ol>
<h3 id="What-is-thread-per-worker-model"><a href="#What-is-thread-per-worker-model" class="headerlink" title="What is thread per worker model?"></a>What is thread per worker model?</h3><ol>
<li>In this model, the whole DBMS is a single process with multiple worker threads. </li>
<li>DBMS (mostly) manages its own scheduling by controlling what each threads is doing. <ul>
<li>This also means less overhead per context switch and that DBMS does not have to manage shared memory. </li>
</ul>
</li>
<li>There may or may not have a dispatcher thread in the front. <ul>
<li>Applications may connect to dispatcher, and dispatcher immediately forward request to another thread while application does not know about it. </li>
<li>Or applications can use the same scheme as process per worker model. </li>
</ul>
</li>
<li>In this model, thread crash may kill the entire system. </li>
</ol>
<h3 id="What-is-considered-when-DBMS-scheduling-threads"><a href="#What-is-considered-when-DBMS-scheduling-threads" class="headerlink" title="What is considered when DBMS scheduling threads?"></a>What is considered when DBMS scheduling threads?</h3><p>For each query plan, the DBMS decides where, when, and how to execute it. </p>
<ol>
<li>How many tasks should it use?</li>
<li>How many CPU cores should it use?</li>
<li>What CPU core should the tasks execute on? </li>
<li>Where should a task store its output?</li>
</ol>
<h3 id="What-is-embedded-DBMS-model"><a href="#What-is-embedded-DBMS-model" class="headerlink" title="What is embedded DBMS model?"></a>What is embedded DBMS model?</h3><ol>
<li>In aforementioned systems and most common systems, applications are in separate machines. They are connected through TCP or socket. Even if the applications crashed, DBMS still remains running. </li>
<li>In embedded DBMS, DBMS runs inside of the same address space as the application. Application is (mostly) responsible for threads and scheduling. </li>
<li>The application may support outside connections. </li>
</ol>
<h2 id="Query-level-parallelism"><a href="#Query-level-parallelism" class="headerlink" title="Query-level parallelism"></a>Query-level parallelism</h2><h3 id="What-are-the-query-level-parallelisms"><a href="#What-are-the-query-level-parallelisms" class="headerlink" title="What are the query-level parallelisms?"></a>What are the query-level parallelisms?</h3><ol>
<li>Inter-Query: Execute multiple disparate queries simultaneously. <ul>
<li>This parallelism increases throughput and reduces latency. It improves overall performance by allowing multiple queries to execute simultaneously. </li>
<li>If queries are read-only, then this requires almost no explicit coordination between queries. Buffer pool can handle most of the sharing if necessary. </li>
<li>If multiple queries are updating the database at the same time, then this is hard to do correctly. </li>
</ul>
</li>
<li>Intra-Query: Execute the operations of a single query in parallel. <ul>
<li>This parallelism decreases latency for long-running queries, especially for OLAP queries. It improves the performance of a single query by executing its operators in parallel. </li>
<li>Organize operators in terms of a producer/consumer paradigm. </li>
</ul>
</li>
</ol>
<h3 id="How-can-we-achieve-intra-query-parallelism"><a href="#How-can-we-achieve-intra-query-parallelism" class="headerlink" title="How can we achieve intra-query parallelism?"></a>How can we achieve intra-query parallelism?</h3><ol>
<li>The first approach is using intra-operator (horizontal) parallelism. <ul>
<li>Decompose operators into independent fragments that perform the same function on different subsets of data. </li>
<li>In the generated query plan, those decomposed operators are copied for each thread. </li>
<li>The DBMS inserts an exchange operator into the query plan to coalesce/split results from multiple children/parent operators. The exchange operators are similar with barriers stating that data cannot be sent up to parent until received all results. </li>
<li>There are three kinds of exchange operators:<ul>
<li>Gather: Combine the results from multiple workers into a single output stream. </li>
<li>Distribute: Split a single input stream into multiple output streams. </li>
<li>Repartition: Shuffle multiple input streams across multiple output streams. </li>
</ul>
</li>
</ul>
</li>
<li>The second approach is using inter-operator (vertical / pipeline) parallelism. <ul>
<li>Operations are overlapped in order to pipeline data from one stage to the next without materialization. </li>
<li>Each operator is a worker. Workers execute operators from different segments of a query plan at the same time. </li>
</ul>
</li>
<li>We can also combine these two approaches, which is call bushy parallelism. </li>
</ol>
<h2 id="I-O-paralleism"><a href="#I-O-paralleism" class="headerlink" title="I/O paralleism"></a>I/O paralleism</h2><h3 id="What-is-the-problem-of-query-level-parallelism"><a href="#What-is-the-problem-of-query-level-parallelism" class="headerlink" title="What is the problem of query-level parallelism?"></a>What is the problem of query-level parallelism?</h3><ol>
<li>Using additional processes/threads to execute queries in parallel won’t help if the disk is always the main bottleneck. </li>
<li>It can sometimes make the DBMS’s performance worse if worker is accessing different segments of the disk at the same time. </li>
</ol>
<h3 id="How-can-we-parallel-I-Os-with-multi-disk"><a href="#How-can-we-parallel-I-Os-with-multi-disk" class="headerlink" title="How can we parallel I/Os with multi-disk?"></a>How can we parallel I/Os with multi-disk?</h3><ol>
<li><p>Split the DBMS across multiple storage devices to improve disk bandwidth latency. </p>
<ul>
<li>There are many options<ul>
<li>Multiple disks per database, one database per disk, one relation per disk, split relation across multiple disks. </li>
<li>The main trade-off is the number of disks and I/O parallelism. </li>
</ul>
</li>
</ul>
</li>
<li><p>Configure OS/hardware to store the DBMS’s files across multiple storage<br>devices, e.g. storage appliances, RAID configuration. </p>
<ul>
<li><p>This is transparent to the DBMS. </p>
</li>
<li><p>RAID 0 strips data into different disks. Each disk stores different data. </p>
</li>
<li>RAID 1 mirrors data in different disks. Each disk stores the same data. </li>
</ul>
</li>
</ol>
<h3 id="How-can-we-partition-database"><a href="#How-can-we-partition-database" class="headerlink" title="How can we partition database?"></a>How can we partition database?</h3><ol>
<li>Some DBMSs allow you to specify the disk location of each individual database. <ul>
<li>The buffer pool manager maps a page to a disk location. </li>
<li>This is also easy to do at the filesystem level if the DBMS stores each database in a separate directory. </li>
<li>The DBMS recovery log file might still be shared if transactions can update multiple databases. </li>
</ul>
</li>
<li>Logical splitting is to split single logical table into disjoint physical segments that are stored/managed separately. <ul>
<li>Partitioning should (ideally) be transparent to the application. </li>
<li>The application should only access logical tables and not have to worry about how things are physically stored. </li>
</ul>
</li>
</ol>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://liyun-zhang.github.io/2023/07/07/OpenSource/BusTub/Project-2-B-Tree/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="LiyunZhang">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="LiyunZhang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | LiyunZhang">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2023/07/07/OpenSource/BusTub/Project-2-B-Tree/" class="post-title-link" itemprop="url">Project #2: B+Tree</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2023-07-07 13:28:28" itemprop="dateCreated datePublished" datetime="2023-07-07T13:28:28+08:00">2023-07-07</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">Edited on</span>
      <time title="Modified: 2023-07-09 22:07:54" itemprop="dateModified" datetime="2023-07-09T22:07:54+08:00">2023-07-09</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">In</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Open-Source-Code/" itemprop="url" rel="index"><span itemprop="name">Open Source Code</span></a>
        </span>
          , 
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Open-Source-Code/BusTub/" itemprop="url" rel="index"><span itemprop="name">BusTub</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p>@<a href="c">toc</a></p>
<h1 id="B-Tree-Page"><a href="#B-Tree-Page" class="headerlink" title="B+Tree Page"></a>B+Tree Page</h1><ol>
<li><p>The <code>size_</code> in each page means the number of stored values not keys, i.e. in internal nodes, <code>size_</code> is $1$ larger than the number of keys. </p>
</li>
<li><p><code>KeyComparator</code> accept two keys to compare, which will return $0$ when they are equal, $-1$ for the first key “smaller” than the second key, $1$ for the second key being larger. </p>
</li>
<li><p>We need to design the sematic of the binary search that will be used in search, insert and delete a key inside a node. </p>
<ul>
<li>In the leaf node: <ul>
<li>For search and delete, we want this function to tell us the index of the key is it exists. </li>
<li>For insert, we want this function to indicate the index we need to place the key. </li>
</ul>
</li>
<li>In the internal node:<ul>
<li>For search, we only want it to inform us the child that might have the given key. </li>
<li>For insert, we want it to return the page ID to find a proper leaf page to store the key in forward search and give the index we need to place the split key when backward split is required. </li>
<li>For delete, we want it the same as for insert in the forward search and to provide the index to help merge two children when the backward merge is required. </li>
</ul>
</li>
<li>In the following implemetation of binary search, it will return the index of the key if it exists, or it will return the largest index with smaller key. <ul>
<li>Notably that if the given key is smaller than all keys in the node, it will return $-1$. </li>
<li>In internal node, we would expect the smallest possible result is $0$ since the first key is <code>NULL</code> which should be smaller than any other keys. </li>
</ul>
</li>
</ul>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">auto</span> <span class="title">BinarySearch</span><span class="params">(KeyType key, KeyComparator comparator)</span> <span class="type">const</span> -&gt; <span class="type">int</span> </span>&#123;</span><br><span class="line">  <span class="type">int</span> lo = <span class="number">0</span>;</span><br><span class="line">  <span class="type">int</span> hi = <span class="built_in">GetSize</span>();</span><br><span class="line">  <span class="keyword">while</span> (lo &lt; hi) &#123;</span><br><span class="line">    <span class="type">int</span> mid = (lo + hi) / <span class="number">2</span>;</span><br><span class="line">    <span class="keyword">if</span> (<span class="number">0</span> &lt; mid &amp;&amp; <span class="built_in">comparator</span>(key, array_[mid].first) &lt; <span class="number">0</span>) &#123;</span><br><span class="line">      hi = mid;</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">      lo = mid + <span class="number">1</span>;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">return</span> lo - <span class="number">1</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
<li><p><code>FindNextPageID</code> will provide the proper child for the caller to access to find a certain key. </p>
<ul>
<li>For leaf node, this will only be used in B+Tree search. If the binary search result is $-1$, we can conclude that that key does not exist and should tell caller that. </li>
<li>For internal node, this will be used in B+Tree search or the forward search in insert and delete. If the binary search result is $-1$, then we should return the first value to indicate the key is smaller than all keys. </li>
</ul>
</li>
<li><p><code>InsertKey</code> should </p>
</li>
</ol>
<h1 id="B-Tree-search"><a href="#B-Tree-search" class="headerlink" title="B+Tree search"></a>B+Tree search</h1><ol>
<li>The thought is simple: we just go down from the root until hit a leaf node. If the key is in the leaf node, return the value. Otherwise, the key does not exists. </li>
<li>For concurrency control, we can only release the latch of a page after acquired the latch of its child. <ul>
<li>This can be implemented with the move assignment operation of <code>PageGuard</code>. In the execution, the right expression will first acquire the latch of next page, then destroy the original page guard of the left variable. </li>
</ul>
</li>
</ol>
<h1 id="B-Tree-insert"><a href="#B-Tree-insert" class="headerlink" title="B+Tree insert"></a>B+Tree insert</h1><ol>
<li><p>For concurrency control, I implemented both the optimistic scheme and the pessimistic scheme. </p>
<ul>
<li><p>The program will first try with optimistic search with only write latch on leaf node. </p>
</li>
<li><p>If the leaf node may overflow, release all latches and start again trying to acquire write latch for all nodes. </p>
</li>
</ul>
</li>
<li><p>In the optimistic search, we can use the queue in <code>Context</code>. </p>
<ul>
<li>When we fetched a new page guard, we push it to the back of <code>ctx.read_set_</code> and pop the front element out of the queue. Every time we just need to access the last element of the queue to find the next page to read. </li>
<li>When we realised that we have reached the leaf node, we are holding a read latch for that page. Hence, we still need to release the read latch and re-acquire the write latch, i.e. we cannot release the latch of last internal page when we first acquire the leaf page. </li>
<li>The solution is to release the latch before read the “grand-child” of it. </li>
</ul>
</li>
<li><p>In the pessimistic search, we need to acquire write latch for all pages we want to access. </p>
<ul>
<li>We can check whether a node is safe after its write latch is acquired. If the node is safe, we can release all latches acquired before it, including the header page. </li>
</ul>
</li>
<li><p>In the insert function, there are three cases to handle: </p>
<ul>
<li>The first case is that this is an empty tree, i.e. the <code>root_page_id_</code> in header page is invalid. We just need to create a new page for the node and update header page. </li>
<li>The second case is that the leaf node won’t overflow where a simple insertion is enough. </li>
<li>The last case is that the leaf node might overflow. </li>
</ul>
</li>
<li><p>When the leaf node might overflow: </p>
<ul>
<li>After acquired the write latches, we need to check whether there is an overflow again in case that other thread already handled overflow causing unexpected split. </li>
<li><code>SolveLeafOverflow</code><ul>
<li>When a leaf reaches max size after insertion, it will immediately split. So this is used after the insertion. </li>
<li>It will create a new page to store the larger half the nodes and return the first key in the new page to insert to its parent node to indicate to this page. </li>
<li>Also, it need to take care of the sibling pointers between leaf nodes. The new page will point to what the original page points to. And the original page will point to the new page. </li>
</ul>
</li>
<li><code>SolveInternalOverflow</code><ul>
<li>Internal nodes won’t split immediately when it reaches max size. This means that internal nodes must split first before insertion, otherwise the address will overflow. </li>
<li>The process is similar with the leaf case, except that it will choose a proper page to insert the key after split. (Or it just does not need to split if it is a safe node). </li>
</ul>
</li>
</ul>
</li>
</ol>
<h1 id="B-Tree-delete"><a href="#B-Tree-delete" class="headerlink" title="B+Tree delete"></a>B+Tree delete</h1><ol>
<li>The concurrency control is similar with the insert operation, except that the condition of whether a node is safe is different. </li>
<li>Compare with insertion, <ul>
<li>if the tree is empty, there is nothing else to do; </li>
<li>if the leaf node won’t underflow, a simple deletion is enough; </li>
<li>if the leaf node might underflow, we need to handle it and possible following cascade underflow. </li>
</ul>
</li>
<li>When the leaf node might overflow:<ul>
<li>Similar with the insertion situation, we need to re-acquire write latches, and check whether the underflow is handled by another thread. </li>
<li>If the underflowed leaf is the root, i.e. the tree has only one node, we do not need to do anything further. </li>
<li><code>SolveLeafUnderflow</code><ul>
<li>There are three situations: left sibling can borrow a key, right sibling can borrow a key or neither siblings can borrow a key. </li>
<li>When we can borrow a key, the underflow is solved easily, no more cascading. We need to modify the key in parent node that separates the two involving node to the new first key of the right node. </li>
<li>When we need to merge with one of the siblings, we also need to handle the pointers between leaf nodes. If we move the data of the left node to the right node and delete the left node, it is hard for us to modify the pointer of the left of the left node. Instead, if we move delete the right node, we only need to modify the pointer of the left node to the original pointer of the right node. </li>
<li>If a leaf only has left sibling or right sibling to merge with, then we do not have a choice. </li>
</ul>
</li>
<li><code>SolveInternalUnderflow</code><ul>
<li>The process is similar with <code>SolveLeafUnderflow</code>, except how to borrow a key. </li>
<li>When a node is borrowing a key to its left sibling, it will borrow the first valid key and the fire value, i.e. <code>array_[1].first</code> and <code>array_[0].second</code>. </li>
<li>When a node is borrowing a key to its right sibling, it will borrow the last key-value pair. And the node accpeting those keys will use the key as its first valid key and the value as its first valid value. </li>
<li>We need to set the corresponding key in parent node to the borrowed key. </li>
</ul>
</li>
</ul>
</li>
</ol>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




  <nav class="pagination">
    <span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><a class="extend next" rel="next" title="Next page" aria-label="Next page" href="/page/2/"><i class="fa fa-angle-right"></i></a>
  </nav>

</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">


<div class="copyright">
  &copy; 
  <span itemprop="copyrightYear">2023</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">LiyunZhang</span>
</div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.js.org/mist/" rel="noopener" target="_blank">NexT.Mist</a>
  </div>

    </div>
  </footer>

  
  <div class="toggle sidebar-toggle" role="button">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>
  <div class="sidebar-dimmer"></div>
  <div class="back-to-top" role="button" aria-label="Back to top">
    <i class="fa fa-arrow-up fa-lg"></i>
    <span>0%</span>
  </div>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


  
  <script src="https://cdnjs.cloudflare.com/ajax/libs/animejs/3.2.1/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script>
<script src="/js/comments.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/schemes/muse.js"></script><script src="/js/next-boot.js"></script>

  <script src="https://cdnjs.cloudflare.com/ajax/libs/hexo-generator-searchdb/1.4.1/search.js" integrity="sha256-1kfA5uHPf65M5cphT2dvymhkuyHPQp5A53EGZOnOLmc=" crossorigin="anonymous"></script>
<script src="/js/third-party/search/local-search.js"></script>







  




  

  <script class="next-config" data-name="enableMath" type="application/json">true</script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.7/katex.min.css" integrity="sha256-hLTCMFlKxdNgPXyWlSSxYN0ykJmxxq9Yt3MNfdRGWeA=" crossorigin="anonymous">



</body>
</html>
